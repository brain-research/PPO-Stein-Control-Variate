Logging to halfcheetah_unbiased_169
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
----------------------------
| Steps         | 10000    |
| _MeanReward   | -376     |
| _max_act      | 2.93244  |
| _max_adv      | 3.77     |
| _max_discrew  | 0.0439   |
| _max_obs      | 1.24     |
| _mean_act     | 0.182146 |
| _mean_adv     | 3.69e-17 |
| _mean_discrew | -0.29    |
| _mean_obs     | 0.0293   |
| _min_adv      | -3.61    |
| _min_discrew  | -0.58    |
| _min_obs      | -1.63    |
| _std_act      | 0.448778 |
| _std_adv      | 1        |
| _std_discrew  | 0.0195   |
----------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.524       |
| ExplainedVarOld | -1.76       |
| KL              | 0.000222627 |
| Phi_loss        | 1.93859     |
| PolicyEntropy   | 5.5135      |
| PolicyLoss      | 0.000409143 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00929     |
| _MeanReward     | -326        |
| _lr_multiplier  | 1           |
| _max_act        | 3.17147     |
| _max_adv        | 4.19        |
| _max_discrew    | 0.00225     |
| _max_obs        | 1.31        |
| _mean_act       | 0.0382642   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | -0.257      |
| _mean_obs       | 0.0113      |
| _min_adv        | -4.3        |
| _min_discrew    | -0.583      |
| _min_obs        | -1.26       |
| _std_act        | 0.447246    |
| _std_adv        | 1           |
| _std_discrew    | 0.00851     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.341      |
| ExplainedVarOld | -0.0708    |
| KL              | 0.00130385 |
| Phi_loss        | 14.9874    |
| PolicyEntropy   | 5.5116     |
| PolicyLoss      | 0.00541241 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00561    |
| _MeanReward     | -319       |
| _lr_multiplier  | 1          |
| _max_act        | 2.79017    |
| _max_adv        | 4.85       |
| _max_discrew    | 0.00901    |
| _max_obs        | 1.4        |
| _mean_act       | 0.0571164  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | -0.247     |
| _mean_obs       | 0.0212     |
| _min_adv        | -4.39      |
| _min_discrew    | -0.574     |
| _min_obs        | -1.55      |
| _std_act        | 0.44706    |
| _std_adv        | 1          |
| _std_discrew    | 0.0107     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.532       |
| ExplainedVarOld | 0.505       |
| KL              | 0.00121985  |
| Phi_loss        | 21.8507     |
| PolicyEntropy   | 5.5085      |
| PolicyLoss      | -0.00127507 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00504     |
| _MeanReward     | -312        |
| _lr_multiplier  | 1           |
| _max_act        | 3.24349     |
| _max_adv        | 4.57        |
| _max_discrew    | 0.00214     |
| _max_obs        | 1.4         |
| _mean_act       | 0.0463105   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | -0.256      |
| _mean_obs       | 0.0242      |
| _min_adv        | -5.25       |
| _min_discrew    | -0.703      |
| _min_obs        | -1.56       |
| _std_act        | 0.43514     |
| _std_adv        | 1           |
| _std_discrew    | 0.0111      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.553      |
| ExplainedVarOld | 0.486      |
| KL              | 0.00278706 |
| Phi_loss        | 13.8905    |
| PolicyEntropy   | 5.46717    |
| PolicyLoss      | 0.011211   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00496    |
| _MeanReward     | -296       |
| _lr_multiplier  | 1          |
| _max_act        | 2.91266    |
| _max_adv        | 4.86       |
| _max_discrew    | 0.00245    |
| _max_obs        | 1.47       |
| _mean_act       | 0.0505253  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | -0.234     |
| _mean_obs       | 0.0256     |
| _min_adv        | -5.5       |
| _min_discrew    | -0.577     |
| _min_obs        | -1.52      |
| _std_act        | 0.431685   |
| _std_adv        | 1          |
| _std_discrew    | 0.00709    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.538        |
| ExplainedVarOld | 0.482        |
| KL              | 0.00245941   |
| Phi_loss        | 15.3946      |
| PolicyEntropy   | 5.46528      |
| PolicyLoss      | -0.000872593 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0034       |
| _MeanReward     | -304         |
| _lr_multiplier  | 1            |
| _max_act        | 2.84273      |
| _max_adv        | 5.62         |
| _max_discrew    | 0.00333      |
| _max_obs        | 1.44         |
| _mean_act       | 0.064894     |
| _mean_adv       | 8.53e-18     |
| _mean_discrew   | -0.251       |
| _mean_obs       | 0.0212       |
| _min_adv        | -5.72        |
| _min_discrew    | -0.582       |
| _min_obs        | -1.63        |
| _std_act        | 0.445724     |
| _std_adv        | 1            |
| _std_discrew    | 0.0101       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.56       |
| ExplainedVarOld | 0.528      |
| KL              | 0.00786861 |
| Phi_loss        | 20.271     |
| PolicyEntropy   | 5.47569    |
| PolicyLoss      | 0.00261893 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00448    |
| _MeanReward     | -290       |
| _lr_multiplier  | 1          |
| _max_act        | 2.94527    |
| _max_adv        | 6.04       |
| _max_discrew    | 0.00457    |
| _max_obs        | 1.47       |
| _mean_act       | 0.0602907  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.225     |
| _mean_obs       | 0.0273     |
| _min_adv        | -5.02      |
| _min_discrew    | -0.621     |
| _min_obs        | -1.6       |
| _std_act        | 0.438409   |
| _std_adv        | 1          |
| _std_discrew    | 0.00818    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.518      |
| ExplainedVarOld | 0.487      |
| KL              | 0.00114115 |
| Phi_loss        | 17.3756    |
| PolicyEntropy   | 5.46461    |
| PolicyLoss      | 0.00182296 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00401    |
| _MeanReward     | -267       |
| _lr_multiplier  | 1          |
| _max_act        | 2.71297    |
| _max_adv        | 5.65       |
| _max_discrew    | 0.0168     |
| _max_obs        | 1.39       |
| _mean_act       | 0.0487789  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.22      |
| _mean_obs       | 0.0274     |
| _min_adv        | -4.24      |
| _min_discrew    | -0.496     |
| _min_obs        | -1.44      |
| _std_act        | 0.43279    |
| _std_adv        | 1          |
| _std_discrew    | 0.00693    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.569      |
| ExplainedVarOld | 0.544      |
| KL              | 0.00245821 |
| Phi_loss        | 17.3476    |
| PolicyEntropy   | 5.44281    |
| PolicyLoss      | 0.00309293 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00299    |
| _MeanReward     | -284       |
| _lr_multiplier  | 1          |
| _max_act        | 3.10445    |
| _max_adv        | 5.98       |
| _max_discrew    | 0.039      |
| _max_obs        | 1.42       |
| _mean_act       | 0.0572496  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | -0.223     |
| _mean_obs       | 0.0286     |
| _min_adv        | -5.89      |
| _min_discrew    | -0.528     |
| _min_obs        | -1.55      |
| _std_act        | 0.436344   |
| _std_adv        | 1          |
| _std_discrew    | 0.00723    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.588      |
| ExplainedVarOld | 0.538      |
| KL              | 0.00250455 |
| Phi_loss        | 15.4314    |
| PolicyEntropy   | 5.4073     |
| PolicyLoss      | 0.00901568 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00298    |
| _MeanReward     | -270       |
| _lr_multiplier  | 1          |
| _max_act        | 3.08166    |
| _max_adv        | 5.64       |
| _max_discrew    | 0.011      |
| _max_obs        | 1.47       |
| _mean_act       | 0.0605531  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | -0.217     |
| _mean_obs       | 0.0287     |
| _min_adv        | -5.5       |
| _min_discrew    | -0.543     |
| _min_obs        | -1.41      |
| _std_act        | 0.426628   |
| _std_adv        | 1          |
| _std_discrew    | 0.00867    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.555      |
| ExplainedVarOld | 0.533      |
| KL              | 0.0039329  |
| Phi_loss        | 14.904     |
| PolicyEntropy   | 5.38766    |
| PolicyLoss      | 0.00656849 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00387    |
| _MeanReward     | -265       |
| _lr_multiplier  | 1          |
| _max_act        | 2.96123    |
| _max_adv        | 4.84       |
| _max_discrew    | 0.0105     |
| _max_obs        | 1.48       |
| _mean_act       | 0.0568818  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | -0.214     |
| _mean_obs       | 0.0286     |
| _min_adv        | -5.36      |
| _min_discrew    | -0.446     |
| _min_obs        | -1.72      |
| _std_act        | 0.425873   |
| _std_adv        | 1          |
| _std_discrew    | 0.0059     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.564      |
| ExplainedVarOld | 0.521      |
| KL              | 0.00383885 |
| Phi_loss        | 14.6415    |
| PolicyEntropy   | 5.3556     |
| PolicyLoss      | 0.00440135 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00258    |
| _MeanReward     | -259       |
| _lr_multiplier  | 1          |
| _max_act        | 2.71137    |
| _max_adv        | 4.66       |
| _max_discrew    | 0.00728    |
| _max_obs        | 1.63       |
| _mean_act       | 0.0494185  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | -0.203     |
| _mean_obs       | 0.0277     |
| _min_adv        | -5.45      |
| _min_discrew    | -0.492     |
| _min_obs        | -1.49      |
| _std_act        | 0.417904   |
| _std_adv        | 1          |
| _std_discrew    | 0.0057     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.641      |
| ExplainedVarOld | 0.598      |
| KL              | 0.00385465 |
| Phi_loss        | 14.7083    |
| PolicyEntropy   | 5.32811    |
| PolicyLoss      | 0.00441766 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00206    |
| _MeanReward     | -228       |
| _lr_multiplier  | 1          |
| _max_act        | 2.76181    |
| _max_adv        | 5.3        |
| _max_discrew    | 0.00773    |
| _max_obs        | 1.58       |
| _mean_act       | 0.0463488  |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | -0.189     |
| _mean_obs       | 0.0281     |
| _min_adv        | -4.54      |
| _min_discrew    | -0.334     |
| _min_obs        | -1.81      |
| _std_act        | 0.414752   |
| _std_adv        | 1          |
| _std_discrew    | 0.00375    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.615      |
| ExplainedVarOld | 0.582      |
| KL              | 0.00389521 |
| Phi_loss        | 14.2463    |
| PolicyEntropy   | 5.3087     |
| PolicyLoss      | 0.00861909 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00147    |
| _MeanReward     | -221       |
| _lr_multiplier  | 1          |
| _max_act        | 3.03627    |
| _max_adv        | 5.64       |
| _max_discrew    | 0.00738    |
| _max_obs        | 1.37       |
| _mean_act       | 0.0540693  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | -0.182     |
| _mean_obs       | 0.0301     |
| _min_adv        | -5.4       |
| _min_discrew    | -0.326     |
| _min_obs        | -1.63      |
| _std_act        | 0.416204   |
| _std_adv        | 1          |
| _std_discrew    | 0.00403    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.639      |
| ExplainedVarOld | 0.582      |
| KL              | 0.00324281 |
| Phi_loss        | 15.3004    |
| PolicyEntropy   | 5.28615    |
| PolicyLoss      | 0.00654709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00146    |
| _MeanReward     | -233       |
| _lr_multiplier  | 1          |
| _max_act        | 2.96845    |
| _max_adv        | 4.21       |
| _max_discrew    | 0.0189     |
| _max_obs        | 1.55       |
| _mean_act       | 0.0526098  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.186     |
| _mean_obs       | 0.0295     |
| _min_adv        | -5.93      |
| _min_discrew    | -0.419     |
| _min_obs        | -1.97      |
| _std_act        | 0.411684   |
| _std_adv        | 1          |
| _std_discrew    | 0.00496    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.638      |
| ExplainedVarOld | 0.56       |
| KL              | 0.00439143 |
| Phi_loss        | 14.147     |
| PolicyEntropy   | 5.23882    |
| PolicyLoss      | 0.0113385  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0018     |
| _MeanReward     | -209       |
| _lr_multiplier  | 1          |
| _max_act        | 2.79904    |
| _max_adv        | 5.32       |
| _max_discrew    | 0.011      |
| _max_obs        | 1.62       |
| _mean_act       | 0.0511708  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | -0.172     |
| _mean_obs       | 0.0291     |
| _min_adv        | -6.11      |
| _min_discrew    | -0.432     |
| _min_obs        | -1.51      |
| _std_act        | 0.407428   |
| _std_adv        | 1          |
| _std_discrew    | 0.00459    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.588      |
| ExplainedVarOld | 0.582      |
| KL              | 0.00473623 |
| Phi_loss        | 16.1849    |
| PolicyEntropy   | 5.19889    |
| PolicyLoss      | 0.00823357 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00193    |
| _MeanReward     | -187       |
| _lr_multiplier  | 1          |
| _max_act        | 2.69188    |
| _max_adv        | 5.32       |
| _max_discrew    | 0.034      |
| _max_obs        | 1.51       |
| _mean_act       | 0.0436089  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.162     |
| _mean_obs       | 0.0285     |
| _min_adv        | -5.01      |
| _min_discrew    | -0.336     |
| _min_obs        | -1.38      |
| _std_act        | 0.401289   |
| _std_adv        | 1          |
| _std_discrew    | 0.00381    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.621      |
| ExplainedVarOld | 0.442      |
| KL              | 0.00227092 |
| Phi_loss        | 13.2519    |
| PolicyEntropy   | 5.16488    |
| PolicyLoss      | 0.0103098  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00146    |
| _MeanReward     | -207       |
| _lr_multiplier  | 1          |
| _max_act        | 2.62376    |
| _max_adv        | 3.99       |
| _max_discrew    | 0.00776    |
| _max_obs        | 1.86       |
| _mean_act       | 0.0402207  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | -0.162     |
| _mean_obs       | 0.0276     |
| _min_adv        | -5.87      |
| _min_discrew    | -0.382     |
| _min_obs        | -1.69      |
| _std_act        | 0.401475   |
| _std_adv        | 1          |
| _std_discrew    | 0.00328    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.585      |
| ExplainedVarOld | 0.372      |
| KL              | 0.00593241 |
| Phi_loss        | 12.7216    |
| PolicyEntropy   | 5.14937    |
| PolicyLoss      | 0.00282599 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00136    |
| _MeanReward     | -192       |
| _lr_multiplier  | 1          |
| _max_act        | 3.06035    |
| _max_adv        | 4.66       |
| _max_discrew    | 0.00929    |
| _max_obs        | 1.45       |
| _mean_act       | 0.0473089  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | -0.151     |
| _mean_obs       | 0.029      |
| _min_adv        | -5.56      |
| _min_discrew    | -0.353     |
| _min_obs        | -1.6       |
| _std_act        | 0.39676    |
| _std_adv        | 1          |
| _std_discrew    | 0.00375    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.504      |
| ExplainedVarOld | 0.498      |
| KL              | 0.00408316 |
| Phi_loss        | 18.763     |
| PolicyEntropy   | 5.10587    |
| PolicyLoss      | 0.00892709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0019     |
| _MeanReward     | -182       |
| _lr_multiplier  | 1          |
| _max_act        | 2.87065    |
| _max_adv        | 5.23       |
| _max_discrew    | 0.0153     |
| _max_obs        | 1.46       |
| _mean_act       | 0.0365997  |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | -0.15      |
| _mean_obs       | 0.0274     |
| _min_adv        | -4.55      |
| _min_discrew    | -0.454     |
| _min_obs        | -1.65      |
| _std_act        | 0.388521   |
| _std_adv        | 1          |
| _std_discrew    | 0.00368    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.428      |
| ExplainedVarOld | 0.38       |
| KL              | 0.00409191 |
| Phi_loss        | 16.7017    |
| PolicyEntropy   | 5.07242    |
| PolicyLoss      | 0.00929197 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00213    |
| _MeanReward     | -162       |
| _lr_multiplier  | 1          |
| _max_act        | 2.52731    |
| _max_adv        | 6.13       |
| _max_discrew    | 0.0151     |
| _max_obs        | 1.55       |
| _mean_act       | 0.0281565  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | -0.141     |
| _mean_obs       | 0.0267     |
| _min_adv        | -3.45      |
| _min_discrew    | -0.256     |
| _min_obs        | -1.72      |
| _std_act        | 0.389411   |
| _std_adv        | 1          |
| _std_discrew    | 0.00277    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.563      |
| ExplainedVarOld | 0.524      |
| KL              | 0.00374023 |
| Phi_loss        | 19.1449    |
| PolicyEntropy   | 5.03082    |
| PolicyLoss      | 0.0103823  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00128    |
| _MeanReward     | -159       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75513    |
| _max_adv        | 3.56       |
| _max_discrew    | 0.0161     |
| _max_obs        | 1.39       |
| _mean_act       | 0.0345708  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.126     |
| _mean_obs       | 0.0277     |
| _min_adv        | -6.98      |
| _min_discrew    | -0.432     |
| _min_obs        | -1.61      |
| _std_act        | 0.383225   |
| _std_adv        | 1          |
| _std_discrew    | 0.00278    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.539      |
| ExplainedVarOld | 0.48       |
| KL              | 0.00602573 |
| Phi_loss        | 14.6117    |
| PolicyEntropy   | 4.99329    |
| PolicyLoss      | 0.0088465  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00133    |
| _MeanReward     | -162       |
| _lr_multiplier  | 1          |
| _max_act        | 2.5976     |
| _max_adv        | 5.79       |
| _max_discrew    | 0.019      |
| _max_obs        | 1.41       |
| _mean_act       | 0.0388073  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.134     |
| _mean_obs       | 0.0282     |
| _min_adv        | -6.51      |
| _min_discrew    | -0.294     |
| _min_obs        | -1.63      |
| _std_act        | 0.382072   |
| _std_adv        | 1          |
| _std_discrew    | 0.00219    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.605      |
| ExplainedVarOld | 0.591      |
| KL              | 0.00264736 |
| Phi_loss        | 18.3763    |
| PolicyEntropy   | 4.97098    |
| PolicyLoss      | 0.00645998 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000898   |
| _MeanReward     | -140       |
| _lr_multiplier  | 1          |
| _max_act        | 2.34424    |
| _max_adv        | 7.24       |
| _max_discrew    | 0.0273     |
| _max_obs        | 1.86       |
| _mean_act       | 0.0303568  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.122     |
| _mean_obs       | 0.0274     |
| _min_adv        | -5.18      |
| _min_discrew    | -0.24      |
| _min_obs        | -1.67      |
| _std_act        | 0.376697   |
| _std_adv        | 1          |
| _std_discrew    | 0.00193    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.493      |
| ExplainedVarOld | 0.369      |
| KL              | 0.00150246 |
| Phi_loss        | 18.582     |
| PolicyEntropy   | 4.95208    |
| PolicyLoss      | 0.00911992 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000991   |
| _MeanReward     | -130       |
| _lr_multiplier  | 1          |
| _max_act        | 2.59325    |
| _max_adv        | 6.42       |
| _max_discrew    | 0.0268     |
| _max_obs        | 1.49       |
| _mean_act       | 0.027994   |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.112     |
| _mean_obs       | 0.0275     |
| _min_adv        | -8.38      |
| _min_discrew    | -0.374     |
| _min_obs        | -1.97      |
| _std_act        | 0.376869   |
| _std_adv        | 1          |
| _std_discrew    | 0.00242    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.371      |
| ExplainedVarOld | 0.312      |
| KL              | 0.00308043 |
| Phi_loss        | 18.3631    |
| PolicyEntropy   | 4.92228    |
| PolicyLoss      | 0.0117348  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00156    |
| _MeanReward     | -131       |
| _lr_multiplier  | 1          |
| _max_act        | 2.70536    |
| _max_adv        | 6.3        |
| _max_discrew    | 0.00865    |
| _max_obs        | 1.74       |
| _mean_act       | 0.028132   |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.113     |
| _mean_obs       | 0.0275     |
| _min_adv        | -5.85      |
| _min_discrew    | -0.281     |
| _min_obs        | -1.6       |
| _std_act        | 0.377995   |
| _std_adv        | 1          |
| _std_discrew    | 0.00204    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.537      |
| ExplainedVarOld | 0.522      |
| KL              | 0.00229918 |
| Phi_loss        | 20.1497    |
| PolicyEntropy   | 4.8843     |
| PolicyLoss      | 0.00857109 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000948   |
| _MeanReward     | -129       |
| _lr_multiplier  | 1          |
| _max_act        | 2.48655    |
| _max_adv        | 10         |
| _max_discrew    | 0.0419     |
| _max_obs        | 1.62       |
| _mean_act       | 0.0303251  |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | -0.114     |
| _mean_obs       | 0.0278     |
| _min_adv        | -5.41      |
| _min_discrew    | -0.215     |
| _min_obs        | -1.72      |
| _std_act        | 0.373287   |
| _std_adv        | 1          |
| _std_discrew    | 0.00165    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.448      |
| ExplainedVarOld | 0.406      |
| KL              | 0.00260094 |
| Phi_loss        | 18.4978    |
| PolicyEntropy   | 4.86147    |
| PolicyLoss      | 0.00595235 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000917   |
| _MeanReward     | -157       |
| _lr_multiplier  | 1          |
| _max_act        | 2.81182    |
| _max_adv        | 4.41       |
| _max_discrew    | 0.0834     |
| _max_obs        | 1.8        |
| _mean_act       | 0.0402881  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.138     |
| _mean_obs       | 0.0189     |
| _min_adv        | -4.07      |
| _min_discrew    | -0.485     |
| _min_obs        | -1.91      |
| _std_act        | 0.39666    |
| _std_adv        | 1          |
| _std_discrew    | 0.00775    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.809      |
| ExplainedVarOld | -0.818     |
| KL              | 0.00282445 |
| Phi_loss        | 8.58075    |
| PolicyEntropy   | 4.83606    |
| PolicyLoss      | 0.0121631  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00151    |
| _MeanReward     | -131       |
| _lr_multiplier  | 1          |
| _max_act        | 2.50734    |
| _max_adv        | 9.18       |
| _max_discrew    | 0.0174     |
| _max_obs        | 1.74       |
| _mean_act       | 0.0217578  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | -0.113     |
| _mean_obs       | 0.0265     |
| _min_adv        | -6.66      |
| _min_discrew    | -0.211     |
| _min_obs        | -1.81      |
| _std_act        | 0.363896   |
| _std_adv        | 1          |
| _std_discrew    | 0.00145    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.594     |
| ExplainedVarOld | 0.543     |
| KL              | 0.002906  |
| Phi_loss        | 20.77     |
| PolicyEntropy   | 4.8182    |
| PolicyLoss      | 0.0042643 |
| Steps           | 10000     |
| VarFuncLoss     | 0.000591  |
| _MeanReward     | -118      |
| _lr_multiplier  | 1         |
| _max_act        | 2.6145    |
| _max_adv        | 7.37      |
| _max_discrew    | 0.012     |
| _max_obs        | 1.52      |
| _mean_act       | 0.0309541 |
| _mean_adv       | 5.97e-17  |
| _mean_discrew   | -0.101    |
| _mean_obs       | 0.0281    |
| _min_adv        | -7.05     |
| _min_discrew    | -0.207    |
| _min_obs        | -1.5      |
| _std_act        | 0.360876  |
| _std_adv        | 1         |
| _std_discrew    | 0.00138   |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.397      |
| ExplainedVarOld | 0.299      |
| KL              | 0.00181214 |
| Phi_loss        | 21.0109    |
| PolicyEntropy   | 4.78604    |
| PolicyLoss      | 0.0105051  |
| Steps           | 10000      |
| VarFuncLoss     | 0.000879   |
| _MeanReward     | -120       |
| _lr_multiplier  | 1          |
| _max_act        | 2.4433     |
| _max_adv        | 6.25       |
| _max_discrew    | 0.0159     |
| _max_obs        | 1.63       |
| _mean_act       | 0.0288688  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | -0.103     |
| _mean_obs       | 0.0277     |
| _min_adv        | -8.57      |
| _min_discrew    | -0.349     |
| _min_obs        | -1.68      |
| _std_act        | 0.361712   |
| _std_adv        | 1          |
| _std_discrew    | 0.00199    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.466      |
| ExplainedVarOld | 0.446      |
| KL              | 0.00227283 |
| Phi_loss        | 20.1778    |
| PolicyEntropy   | 4.78229    |
| PolicyLoss      | 0.00383748 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00107    |
| _MeanReward     | -105       |
| _lr_multiplier  | 1          |
| _max_act        | 2.73068    |
| _max_adv        | 3.91       |
| _max_discrew    | 0.00579    |
| _max_obs        | 1.53       |
| _mean_act       | 0.0278544  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | -0.0911    |
| _mean_obs       | 0.0283     |
| _min_adv        | -4.95      |
| _min_discrew    | -0.202     |
| _min_obs        | -1.59      |
| _std_act        | 0.360412   |
| _std_adv        | 1          |
| _std_discrew    | 0.00138    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.479      |
| ExplainedVarOld | 0.454      |
| KL              | 0.00183862 |
| Phi_loss        | 29.0445    |
| PolicyEntropy   | 4.75901    |
| PolicyLoss      | 0.00808953 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000766   |
| _MeanReward     | -101       |
| _lr_multiplier  | 1          |
| _max_act        | 2.65262    |
| _max_adv        | 6.07       |
| _max_discrew    | 0.053      |
| _max_obs        | 1.55       |
| _mean_act       | 0.02597    |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | -0.0874    |
| _mean_obs       | 0.0281     |
| _min_adv        | -6.06      |
| _min_discrew    | -0.329     |
| _min_obs        | -1.6       |
| _std_act        | 0.363265   |
| _std_adv        | 1          |
| _std_discrew    | 0.00225    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.298      |
| ExplainedVarOld | 0.269      |
| KL              | 0.0020115  |
| Phi_loss        | 20.6884    |
| PolicyEntropy   | 4.73035    |
| PolicyLoss      | 0.00525531 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00159    |
| _MeanReward     | -91.9      |
| _lr_multiplier  | 1          |
| _max_act        | 2.57753    |
| _max_adv        | 6.64       |
| _max_discrew    | 0.037      |
| _max_obs        | 1.63       |
| _mean_act       | 0.0237006  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | -0.0885    |
| _mean_obs       | 0.0276     |
| _min_adv        | -3.37      |
| _min_discrew    | -0.19      |
| _min_obs        | -1.57      |
| _std_act        | 0.356549   |
| _std_adv        | 1          |
| _std_discrew    | 0.00143    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.414      |
| ExplainedVarOld | 0.206      |
| KL              | 0.00258615 |
| Phi_loss        | 24.956     |
| PolicyEntropy   | 4.69231    |
| PolicyLoss      | 0.00635605 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000843   |
| _MeanReward     | -102       |
| _lr_multiplier  | 1          |
| _max_act        | 2.89981    |
| _max_adv        | 5.35       |
| _max_discrew    | 0.0257     |
| _max_obs        | 1.51       |
| _mean_act       | 0.023736   |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.0831    |
| _mean_obs       | 0.0275     |
| _min_adv        | -7.55      |
| _min_discrew    | -0.308     |
| _min_obs        | -1.67      |
| _std_act        | 0.356124   |
| _std_adv        | 1          |
| _std_discrew    | 0.00183    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.321      |
| ExplainedVarOld | 0.35       |
| KL              | 0.00324409 |
| Phi_loss        | 26.1297    |
| PolicyEntropy   | 4.66344    |
| PolicyLoss      | 0.00764634 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00125    |
| _MeanReward     | -71.7      |
| _lr_multiplier  | 1          |
| _max_act        | 2.62384    |
| _max_adv        | 7.66       |
| _max_discrew    | 0.0614     |
| _max_obs        | 1.64       |
| _mean_act       | 0.0230979  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | -0.0705    |
| _mean_obs       | 0.0281     |
| _min_adv        | -5.89      |
| _min_discrew    | -0.163     |
| _min_obs        | -1.73      |
| _std_act        | 0.354053   |
| _std_adv        | 1          |
| _std_discrew    | 0.00121    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.242       |
| ExplainedVarOld | 0.212       |
| KL              | 0.00197182  |
| Phi_loss        | 27.8183     |
| PolicyEntropy   | 4.64249     |
| PolicyLoss      | -0.00452991 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000993    |
| _MeanReward     | -70.4       |
| _lr_multiplier  | 1           |
| _max_act        | 2.59128     |
| _max_adv        | 5.56        |
| _max_discrew    | 0.0727      |
| _max_obs        | 1.33        |
| _mean_act       | 0.0210738   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.064      |
| _mean_obs       | 0.0279      |
| _min_adv        | -7          |
| _min_discrew    | -0.191      |
| _min_obs        | -1.51       |
| _std_act        | 0.353834    |
| _std_adv        | 1           |
| _std_discrew    | 0.00152     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.243        |
| ExplainedVarOld | 0.23         |
| KL              | 0.00241334   |
| Phi_loss        | 32.2823      |
| PolicyEntropy   | 4.61598      |
| PolicyLoss      | -0.000110299 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00115      |
| _MeanReward     | -70.8        |
| _lr_multiplier  | 1            |
| _max_act        | 2.83051      |
| _max_adv        | 4.7          |
| _max_discrew    | 0.0424       |
| _max_obs        | 1.43         |
| _mean_act       | 0.0214914    |
| _mean_adv       | 3.41e-17     |
| _mean_discrew   | -0.0662      |
| _mean_obs       | 0.0279       |
| _min_adv        | -5.55        |
| _min_discrew    | -0.156       |
| _min_obs        | -1.79        |
| _std_act        | 0.354216     |
| _std_adv        | 1            |
| _std_discrew    | 0.0011       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.35       |
| ExplainedVarOld | 0.334      |
| KL              | 0.00189909 |
| Phi_loss        | 33.1639    |
| PolicyEntropy   | 4.58772    |
| PolicyLoss      | 0.00736867 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00072    |
| _MeanReward     | -75        |
| _lr_multiplier  | 1          |
| _max_act        | 2.6122     |
| _max_adv        | 4.09       |
| _max_discrew    | 0.0382     |
| _max_obs        | 1.53       |
| _mean_act       | 0.0173057  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.0605    |
| _mean_obs       | 0.0274     |
| _min_adv        | -7         |
| _min_discrew    | -0.248     |
| _min_obs        | -1.68      |
| _std_act        | 0.353939   |
| _std_adv        | 1          |
| _std_discrew    | 0.00134    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.165      |
| ExplainedVarOld | 0.0404     |
| KL              | 0.00243195 |
| Phi_loss        | 28.6808    |
| PolicyEntropy   | 4.54679    |
| PolicyLoss      | 0.00804799 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00113    |
| _MeanReward     | -41.6      |
| _lr_multiplier  | 1          |
| _max_act        | 2.59051    |
| _max_adv        | 6.63       |
| _max_discrew    | 0.076      |
| _max_obs        | 1.41       |
| _mean_act       | 0.0180306  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.041     |
| _mean_obs       | 0.0282     |
| _min_adv        | -5.57      |
| _min_discrew    | -0.179     |
| _min_obs        | -1.54      |
| _std_act        | 0.350613   |
| _std_adv        | 1          |
| _std_discrew    | 0.000922   |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.106       |
| ExplainedVarOld | 0.0444      |
| KL              | 0.00210194  |
| Phi_loss        | 30.2752     |
| PolicyEntropy   | 4.52203     |
| PolicyLoss      | -0.00207307 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000921    |
| _MeanReward     | -45.5       |
| _lr_multiplier  | 1           |
| _max_act        | 2.8391      |
| _max_adv        | 5.52        |
| _max_discrew    | 0.0684      |
| _max_obs        | 1.44        |
| _mean_act       | 0.0138341   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.0424     |
| _mean_obs       | 0.0273      |
| _min_adv        | -4.75       |
| _min_discrew    | -0.142      |
| _min_obs        | -1.8        |
| _std_act        | 0.345831    |
| _std_adv        | 1           |
| _std_discrew    | 0.001       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.156      |
| ExplainedVarOld | 0.0915     |
| KL              | 0.00204346 |
| Phi_loss        | 33.0225    |
| PolicyEntropy   | 4.49396    |
| PolicyLoss      | 0.00219091 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000849   |
| _MeanReward     | -31        |
| _lr_multiplier  | 1          |
| _max_act        | 2.59613    |
| _max_adv        | 6.28       |
| _max_discrew    | 0.106      |
| _max_obs        | 1.63       |
| _mean_act       | 0.0107509  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.0343    |
| _mean_obs       | 0.0273     |
| _min_adv        | -4.43      |
| _min_discrew    | -0.151     |
| _min_obs        | -1.49      |
| _std_act        | 0.351736   |
| _std_adv        | 1          |
| _std_discrew    | 0.00131    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.133      |
| ExplainedVarOld | 0.124      |
| KL              | 0.00239972 |
| Phi_loss        | 39.3032    |
| PolicyEntropy   | 4.46354    |
| PolicyLoss      | 0.00592846 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00115    |
| _MeanReward     | -29.6      |
| _lr_multiplier  | 1          |
| _max_act        | 2.84696    |
| _max_adv        | 4.44       |
| _max_discrew    | 0.0931     |
| _max_obs        | 1.36       |
| _mean_act       | 0.00795672 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.0291    |
| _mean_obs       | 0.0275     |
| _min_adv        | -6.73      |
| _min_discrew    | -0.13      |
| _min_obs        | -1.75      |
| _std_act        | 0.353597   |
| _std_adv        | 1          |
| _std_discrew    | 0.00102    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.156       |
| ExplainedVarOld | 0.00345     |
| KL              | 0.00172906  |
| Phi_loss        | 29.6106     |
| PolicyEntropy   | 4.44092     |
| PolicyLoss      | -0.00110526 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000878    |
| _MeanReward     | -11         |
| _lr_multiplier  | 1           |
| _max_act        | 2.49505     |
| _max_adv        | 5.73        |
| _max_discrew    | 0.138       |
| _max_obs        | 1.53        |
| _mean_act       | 0.00290492  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | -0.0138     |
| _mean_obs       | 0.0267      |
| _min_adv        | -5.66       |
| _min_discrew    | -0.0964     |
| _min_obs        | -1.63       |
| _std_act        | 0.345282    |
| _std_adv        | 1           |
| _std_discrew    | 0.000777    |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | -0.000844  |
| ExplainedVarOld | -0.0339    |
| KL              | 0.00233212 |
| Phi_loss        | 40.7976    |
| PolicyEntropy   | 4.4073     |
| PolicyLoss      | 0.00112466 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000815   |
| _MeanReward     | 2.78       |
| _lr_multiplier  | 1          |
| _max_act        | 2.5548     |
| _max_adv        | 4.57       |
| _max_discrew    | 0.102      |
| _max_obs        | 1.99       |
| _mean_act       | 0.00469689 |
| _mean_adv       | 2.7e-17    |
| _mean_discrew   | -0.00303   |
| _mean_obs       | 0.0276     |
| _min_adv        | -4.47      |
| _min_discrew    | -0.117     |
| _min_obs        | -2.02      |
| _std_act        | 0.350467   |
| _std_adv        | 1          |
| _std_discrew    | 0.00103    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.0481      |
| ExplainedVarOld | -0.0298     |
| KL              | 0.00192209  |
| Phi_loss        | 41.3283     |
| PolicyEntropy   | 4.37752     |
| PolicyLoss      | 0.00340915  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000997    |
| _MeanReward     | -9.52       |
| _lr_multiplier  | 1           |
| _max_act        | 2.65863     |
| _max_adv        | 4.76        |
| _max_discrew    | 0.134       |
| _max_obs        | 1.53        |
| _mean_act       | -0.00122057 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | -0.011      |
| _mean_obs       | 0.0265      |
| _min_adv        | -4.16       |
| _min_discrew    | -0.0969     |
| _min_obs        | -1.92       |
| _std_act        | 0.353983    |
| _std_adv        | 1           |
| _std_discrew    | 0.00114     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.0389     |
| ExplainedVarOld | 0.0307     |
| KL              | 0.0017029  |
| Phi_loss        | 45.07      |
| PolicyEntropy   | 4.35509    |
| PolicyLoss      | 0.0024735  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00111    |
| _MeanReward     | 1.01       |
| _lr_multiplier  | 1          |
| _max_act        | 2.88005    |
| _max_adv        | 4.53       |
| _max_discrew    | 0.116      |
| _max_obs        | 1.43       |
| _mean_act       | 0.00258579 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.00754   |
| _mean_obs       | 0.0271     |
| _min_adv        | -4.63      |
| _min_discrew    | -0.0944    |
| _min_obs        | -1.91      |
| _std_act        | 0.343852   |
| _std_adv        | 1          |
| _std_discrew    | 0.00134    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.306        |
| ExplainedVarOld | 0.19         |
| KL              | 0.00229503   |
| Phi_loss        | 38.972       |
| PolicyEntropy   | 4.32647      |
| PolicyLoss      | -0.000420104 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00093      |
| _MeanReward     | 12.4         |
| _lr_multiplier  | 1            |
| _max_act        | 2.70252      |
| _max_adv        | 3.41         |
| _max_discrew    | 0.143        |
| _max_obs        | 1.49         |
| _mean_act       | -0.00101471  |
| _mean_adv       | -1.28e-17    |
| _mean_discrew   | 0.00424      |
| _mean_obs       | 0.027        |
| _min_adv        | -8.25        |
| _min_discrew    | -0.322       |
| _min_obs        | -1.9         |
| _std_act        | 0.34901      |
| _std_adv        | 1            |
| _std_discrew    | 0.00235      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.178       |
| ExplainedVarOld | 0.0632      |
| KL              | 0.00220317  |
| Phi_loss        | 30.143      |
| PolicyEntropy   | 4.3119      |
| PolicyLoss      | -0.0027216  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00196     |
| _MeanReward     | 6.74        |
| _lr_multiplier  | 1           |
| _max_act        | 2.79253     |
| _max_adv        | 9.39        |
| _max_discrew    | 0.12        |
| _max_obs        | 1.61        |
| _mean_act       | -0.00382576 |
| _mean_adv       | -2.42e-17   |
| _mean_discrew   | 0.00494     |
| _mean_obs       | 0.0267      |
| _min_adv        | -7.73       |
| _min_discrew    | -0.196      |
| _min_obs        | -1.47       |
| _std_act        | 0.351195    |
| _std_adv        | 1           |
| _std_discrew    | 0.00102     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.132       |
| ExplainedVarOld | 0.0343      |
| KL              | 0.00360083  |
| Phi_loss        | 25.3008     |
| PolicyEntropy   | 4.28409     |
| PolicyLoss      | 0.00790923  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000891    |
| _MeanReward     | 39.7        |
| _lr_multiplier  | 1           |
| _max_act        | 3.05796     |
| _max_adv        | 6.66        |
| _max_discrew    | 0.197       |
| _max_obs        | 1.43        |
| _mean_act       | -0.00565658 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 0.0288      |
| _mean_obs       | 0.0272      |
| _min_adv        | -7.09       |
| _min_discrew    | -0.103      |
| _min_obs        | -1.6        |
| _std_act        | 0.344216    |
| _std_adv        | 1           |
| _std_discrew    | 0.0013      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.251       |
| ExplainedVarOld | 0.202       |
| KL              | 0.00408107  |
| Phi_loss        | 42.9609     |
| PolicyEntropy   | 4.26805     |
| PolicyLoss      | -0.00936035 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00107     |
| _MeanReward     | 37          |
| _lr_multiplier  | 1           |
| _max_act        | 2.898       |
| _max_adv        | 11.8        |
| _max_discrew    | 0.117       |
| _max_obs        | 1.73        |
| _mean_act       | -0.00630324 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.0279      |
| _mean_obs       | 0.0271      |
| _min_adv        | -7.73       |
| _min_discrew    | -0.0782     |
| _min_obs        | -1.76       |
| _std_act        | 0.349488    |
| _std_adv        | 1           |
| _std_discrew    | 0.00109     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.182       |
| ExplainedVarOld | 0.0883      |
| KL              | 0.00178521  |
| Phi_loss        | 40.6126     |
| PolicyEntropy   | 4.25351     |
| PolicyLoss      | 0.000481352 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000892    |
| _MeanReward     | 44.5        |
| _lr_multiplier  | 1           |
| _max_act        | 2.50507     |
| _max_adv        | 6.35        |
| _max_discrew    | 0.186       |
| _max_obs        | 1.58        |
| _mean_act       | -0.0116964  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.0301      |
| _mean_obs       | 0.0266      |
| _min_adv        | -5.78       |
| _min_discrew    | -0.0725     |
| _min_obs        | -1.46       |
| _std_act        | 0.349652    |
| _std_adv        | 1           |
| _std_discrew    | 0.00126     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.246      |
| ExplainedVarOld | 0.236      |
| KL              | 0.0025155  |
| Phi_loss        | 47.6579    |
| PolicyEntropy   | 4.25359    |
| PolicyLoss      | -0.0128455 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000948   |
| _MeanReward     | 48.4       |
| _lr_multiplier  | 1          |
| _max_act        | 2.95297    |
| _max_adv        | 3.63       |
| _max_discrew    | 0.137      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0138227 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.0366     |
| _mean_obs       | 0.027      |
| _min_adv        | -7.74      |
| _min_discrew    | -0.134     |
| _min_obs        | -1.76      |
| _std_act        | 0.356717   |
| _std_adv        | 1          |
| _std_discrew    | 0.00191    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.109      |
| ExplainedVarOld | 0.0993     |
| KL              | 0.00231941 |
| Phi_loss        | 46.4876    |
| PolicyEntropy   | 4.21966    |
| PolicyLoss      | 0.00776212 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00175    |
| _MeanReward     | 59.6       |
| _lr_multiplier  | 1          |
| _max_act        | 2.4878     |
| _max_adv        | 5.67       |
| _max_discrew    | 0.2        |
| _max_obs        | 1.41       |
| _mean_act       | -0.0136949 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.0388     |
| _mean_obs       | 0.0269     |
| _min_adv        | -3.68      |
| _min_discrew    | -0.0457    |
| _min_obs        | -1.51      |
| _std_act        | 0.353747   |
| _std_adv        | 1          |
| _std_discrew    | 0.00151    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.35       |
| ExplainedVarOld | 0.311      |
| KL              | 0.0028135  |
| Phi_loss        | 49.9335    |
| PolicyEntropy   | 4.18828    |
| PolicyLoss      | 0.00599588 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000985   |
| _MeanReward     | 72.8       |
| _lr_multiplier  | 1          |
| _max_act        | 2.59782    |
| _max_adv        | 5.2        |
| _max_discrew    | 0.159      |
| _max_obs        | 1.65       |
| _mean_act       | -0.019279  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.0567     |
| _mean_obs       | 0.0267     |
| _min_adv        | -6.48      |
| _min_discrew    | -0.0464    |
| _min_obs        | -1.54      |
| _std_act        | 0.353117   |
| _std_adv        | 1          |
| _std_discrew    | 0.00182    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.329      |
| ExplainedVarOld | 0.309      |
| KL              | 0.00205942 |
| Phi_loss        | 51.6112    |
| PolicyEntropy   | 4.15305    |
| PolicyLoss      | 0.00176294 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00131    |
| _MeanReward     | 81.8       |
| _lr_multiplier  | 1          |
| _max_act        | 2.59684    |
| _max_adv        | 3.37       |
| _max_discrew    | 0.177      |
| _max_obs        | 1.49       |
| _mean_act       | -0.0211225 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 0.0683     |
| _mean_obs       | 0.0264     |
| _min_adv        | -6.51      |
| _min_discrew    | -0.052     |
| _min_obs        | -1.56      |
| _std_act        | 0.352345   |
| _std_adv        | 1          |
| _std_discrew    | 0.00164    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.291       |
| ExplainedVarOld | 0.152       |
| KL              | 0.00191064  |
| Phi_loss        | 37.8274     |
| PolicyEntropy   | 4.12765     |
| PolicyLoss      | -0.00499336 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00125     |
| _MeanReward     | 82.5        |
| _lr_multiplier  | 1           |
| _max_act        | 2.66783     |
| _max_adv        | 5.49        |
| _max_discrew    | 0.198       |
| _max_obs        | 1.59        |
| _mean_act       | -0.0221054  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 0.0645      |
| _mean_obs       | 0.0263      |
| _min_adv        | -5.89       |
| _min_discrew    | -0.0657     |
| _min_obs        | -1.64       |
| _std_act        | 0.346372    |
| _std_adv        | 1           |
| _std_discrew    | 0.00139     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.414      |
| ExplainedVarOld | 0.403      |
| KL              | 0.00307577 |
| Phi_loss        | 46.2031    |
| PolicyEntropy   | 4.10353    |
| PolicyLoss      | 0.00411852 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00082    |
| _MeanReward     | 101        |
| _lr_multiplier  | 1          |
| _max_act        | 2.61501    |
| _max_adv        | 3.89       |
| _max_discrew    | 0.228      |
| _max_obs        | 1.67       |
| _mean_act       | -0.02342   |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.0806     |
| _mean_obs       | 0.0268     |
| _min_adv        | -6.69      |
| _min_discrew    | -0.039     |
| _min_obs        | -1.67      |
| _std_act        | 0.350456   |
| _std_adv        | 1          |
| _std_discrew    | 0.00242    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.384       |
| ExplainedVarOld | 0.357       |
| KL              | 0.00296145  |
| Phi_loss        | 50.4841     |
| PolicyEntropy   | 4.09674     |
| PolicyLoss      | -0.00423662 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00157     |
| _MeanReward     | 118         |
| _lr_multiplier  | 1           |
| _max_act        | 2.70166     |
| _max_adv        | 4.26        |
| _max_discrew    | 0.263       |
| _max_obs        | 1.66        |
| _mean_act       | -0.0293364  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.0923      |
| _mean_obs       | 0.0263      |
| _min_adv        | -4.73       |
| _min_discrew    | -0.0376     |
| _min_obs        | -1.63       |
| _std_act        | 0.354176    |
| _std_adv        | 1           |
| _std_discrew    | 0.00197     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.386       |
| ExplainedVarOld | 0.347       |
| KL              | 0.00209411  |
| Phi_loss        | 51.1501     |
| PolicyEntropy   | 4.06777     |
| PolicyLoss      | -0.00140647 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00123     |
| _MeanReward     | 107         |
| _lr_multiplier  | 1           |
| _max_act        | 2.66295     |
| _max_adv        | 4.56        |
| _max_discrew    | 0.211       |
| _max_obs        | 1.45        |
| _mean_act       | -0.0316697  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.0839      |
| _mean_obs       | 0.0257      |
| _min_adv        | -6.47       |
| _min_discrew    | -0.0467     |
| _min_obs        | -1.56       |
| _std_act        | 0.354774    |
| _std_adv        | 1           |
| _std_discrew    | 0.00238     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.473       |
| ExplainedVarOld | 0.451       |
| KL              | 0.00256671  |
| Phi_loss        | 48.6551     |
| PolicyEntropy   | 4.04601     |
| PolicyLoss      | -0.00582533 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00128     |
| _MeanReward     | 91.6        |
| _lr_multiplier  | 1           |
| _max_act        | 2.58769     |
| _max_adv        | 3.39        |
| _max_discrew    | 0.214       |
| _max_obs        | 1.58        |
| _mean_act       | -0.0225825  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.08        |
| _mean_obs       | 0.027       |
| _min_adv        | -8.31       |
| _min_discrew    | -0.173      |
| _min_obs        | -1.75       |
| _std_act        | 0.356067    |
| _std_adv        | 1           |
| _std_discrew    | 0.00258     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.424      |
| ExplainedVarOld | 0.37       |
| KL              | 0.00251807 |
| Phi_loss        | 37.0127    |
| PolicyEntropy   | 4.01627    |
| PolicyLoss      | 0.00729586 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00149    |
| _MeanReward     | 126        |
| _lr_multiplier  | 1          |
| _max_act        | 2.66728    |
| _max_adv        | 8.6        |
| _max_discrew    | 0.247      |
| _max_obs        | 1.58       |
| _mean_act       | -0.0251164 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 0.0941     |
| _mean_obs       | 0.0275     |
| _min_adv        | -3.26      |
| _min_discrew    | -0.0149    |
| _min_obs        | -1.74      |
| _std_act        | 0.357003   |
| _std_adv        | 1          |
| _std_discrew    | 0.00204    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.474      |
| ExplainedVarOld | 0.448      |
| KL              | 0.00923056 |
| Phi_loss        | 53.2455    |
| PolicyEntropy   | 3.9944     |
| PolicyLoss      | -0.0113008 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0011     |
| _MeanReward     | 140        |
| _lr_multiplier  | 1          |
| _max_act        | 2.65905    |
| _max_adv        | 7.6        |
| _max_discrew    | 0.278      |
| _max_obs        | 1.39       |
| _mean_act       | -0.0259164 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.109      |
| _mean_obs       | 0.0278     |
| _min_adv        | -4.17      |
| _min_discrew    | -0.0258    |
| _min_obs        | -1.53      |
| _std_act        | 0.358425   |
| _std_adv        | 1          |
| _std_discrew    | 0.00302    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.536       |
| ExplainedVarOld | 0.489       |
| KL              | 0.00128844  |
| Phi_loss        | 59.9526     |
| PolicyEntropy   | 3.97368     |
| PolicyLoss      | -0.00588201 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00144     |
| _MeanReward     | 151         |
| _lr_multiplier  | 1           |
| _max_act        | 2.79799     |
| _max_adv        | 4.16        |
| _max_discrew    | 0.245       |
| _max_obs        | 1.7         |
| _mean_act       | -0.0323556  |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 0.121       |
| _mean_obs       | 0.027       |
| _min_adv        | -6          |
| _min_discrew    | -0.025      |
| _min_obs        | -1.54       |
| _std_act        | 0.355155    |
| _std_adv        | 1           |
| _std_discrew    | 0.00252     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.697       |
| ExplainedVarOld | 0.668       |
| KL              | 0.00215081  |
| Phi_loss        | 63.4258     |
| PolicyEntropy   | 3.95308     |
| PolicyLoss      | -0.00934351 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000795    |
| _MeanReward     | 164         |
| _lr_multiplier  | 1           |
| _max_act        | 2.67127     |
| _max_adv        | 4.47        |
| _max_discrew    | 0.275       |
| _max_obs        | 1.59        |
| _mean_act       | -0.0306346  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.129       |
| _mean_obs       | 0.0274      |
| _min_adv        | -3.66       |
| _min_discrew    | -0.0222     |
| _min_obs        | -1.53       |
| _std_act        | 0.353174    |
| _std_adv        | 1           |
| _std_discrew    | 0.00289     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.722      |
| ExplainedVarOld | 0.707      |
| KL              | 0.00219178 |
| Phi_loss        | 65.3092    |
| PolicyEntropy   | 3.93451    |
| PolicyLoss      | -0.0055757 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000821   |
| _MeanReward     | 163        |
| _lr_multiplier  | 1          |
| _max_act        | 2.63371    |
| _max_adv        | 3.26       |
| _max_discrew    | 0.279      |
| _max_obs        | 1.76       |
| _mean_act       | -0.0261775 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.134      |
| _mean_obs       | 0.0287     |
| _min_adv        | -6.74      |
| _min_discrew    | -0.0155    |
| _min_obs        | -1.97      |
| _std_act        | 0.363509   |
| _std_adv        | 1          |
| _std_discrew    | 0.00369    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.628      |
| ExplainedVarOld | 0.601      |
| KL              | 0.00198086 |
| Phi_loss        | 54.1734    |
| PolicyEntropy   | 3.90056    |
| PolicyLoss      | 0.0017942  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00142    |
| _MeanReward     | 177        |
| _lr_multiplier  | 1          |
| _max_act        | 2.81895    |
| _max_adv        | 4.29       |
| _max_discrew    | 0.317      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0269995 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.139      |
| _mean_obs       | 0.0288     |
| _min_adv        | -4.31      |
| _min_discrew    | -0.00937   |
| _min_obs        | -1.51      |
| _std_act        | 0.363374   |
| _std_adv        | 1          |
| _std_discrew    | 0.00366    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.631      |
| ExplainedVarOld | 0.626      |
| KL              | 0.00186625 |
| Phi_loss        | 63.247     |
| PolicyEntropy   | 3.8857     |
| PolicyLoss      | -0.0096164 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00135    |
| _MeanReward     | 190        |
| _lr_multiplier  | 1          |
| _max_act        | 2.52745    |
| _max_adv        | 4.33       |
| _max_discrew    | 0.3        |
| _max_obs        | 1.39       |
| _mean_act       | -0.0320083 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.156      |
| _mean_obs       | 0.0286     |
| _min_adv        | -7.29      |
| _min_discrew    | -0.0625    |
| _min_obs        | -1.7       |
| _std_act        | 0.370968   |
| _std_adv        | 1          |
| _std_discrew    | 0.00368    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.628      |
| ExplainedVarOld | 0.614      |
| KL              | 0.00189305 |
| Phi_loss        | 52.9489    |
| PolicyEntropy   | 3.86645    |
| PolicyLoss      | -0.0105923 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00146    |
| _MeanReward     | 200        |
| _lr_multiplier  | 1          |
| _max_act        | 2.82694    |
| _max_adv        | 4.56       |
| _max_discrew    | 0.308      |
| _max_obs        | 1.44       |
| _mean_act       | -0.0276413 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 0.166      |
| _mean_obs       | 0.029      |
| _min_adv        | -7.12      |
| _min_discrew    | -0.0118    |
| _min_obs        | -1.65      |
| _std_act        | 0.366481   |
| _std_adv        | 1          |
| _std_discrew    | 0.00419    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.626      |
| ExplainedVarOld | 0.619      |
| KL              | 0.00270287 |
| Phi_loss        | 62.7982    |
| PolicyEntropy   | 3.84348    |
| PolicyLoss      | -0.0171545 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00161    |
| _MeanReward     | 197        |
| _lr_multiplier  | 1          |
| _max_act        | 2.9685     |
| _max_adv        | 4.96       |
| _max_discrew    | 0.336      |
| _max_obs        | 1.5        |
| _mean_act       | -0.0310649 |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 0.17       |
| _mean_obs       | 0.0291     |
| _min_adv        | -6.39      |
| _min_discrew    | -0.128     |
| _min_obs        | -1.61      |
| _std_act        | 0.374205   |
| _std_adv        | 1          |
| _std_discrew    | 0.00565    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.595       |
| ExplainedVarOld | 0.567       |
| KL              | 0.00183966  |
| Phi_loss        | 42.8904     |
| PolicyEntropy   | 3.81358     |
| PolicyLoss      | -0.00177147 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0023      |
| _MeanReward     | 217         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60638     |
| _max_adv        | 5.49        |
| _max_discrew    | 0.339       |
| _max_obs        | 1.54        |
| _mean_act       | -0.0362798  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.184       |
| _mean_obs       | 0.0288      |
| _min_adv        | -5.8        |
| _min_discrew    | -0.0125     |
| _min_obs        | -1.77       |
| _std_act        | 0.380112    |
| _std_adv        | 1           |
| _std_discrew    | 0.00564     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.747       |
| ExplainedVarOld | 0.732       |
| KL              | 0.00246401  |
| Phi_loss        | 56.2082     |
| PolicyEntropy   | 3.7718      |
| PolicyLoss      | -0.00380574 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00144     |
| _MeanReward     | 243         |
| _lr_multiplier  | 1           |
| _max_act        | 2.61203     |
| _max_adv        | 8.44        |
| _max_discrew    | 0.336       |
| _max_obs        | 1.55        |
| _mean_act       | -0.0353091  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 0.2         |
| _mean_obs       | 0.0297      |
| _min_adv        | -5.9        |
| _min_discrew    | -0.00652    |
| _min_obs        | -1.9        |
| _std_act        | 0.38321     |
| _std_adv        | 1           |
| _std_discrew    | 0.0055      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.751       |
| ExplainedVarOld | 0.727       |
| KL              | 0.00210176  |
| Phi_loss        | 54.3188     |
| PolicyEntropy   | 3.75056     |
| PolicyLoss      | -0.00938814 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00142     |
| _MeanReward     | 249         |
| _lr_multiplier  | 1           |
| _max_act        | 3.11748     |
| _max_adv        | 4.91        |
| _max_discrew    | 0.382       |
| _max_obs        | 1.58        |
| _mean_act       | -0.0365416  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.21        |
| _mean_obs       | 0.0296      |
| _min_adv        | -5.63       |
| _min_discrew    | -0.00809    |
| _min_obs        | -1.9        |
| _std_act        | 0.390265    |
| _std_adv        | 1           |
| _std_discrew    | 0.00659     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.753      |
| ExplainedVarOld | 0.742      |
| KL              | 0.00174382 |
| Phi_loss        | 60.925     |
| PolicyEntropy   | 3.71564    |
| PolicyLoss      | 0.00481149 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00166    |
| _MeanReward     | 271        |
| _lr_multiplier  | 1          |
| _max_act        | 2.98832    |
| _max_adv        | 9.27       |
| _max_discrew    | 0.396      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0357995 |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 0.22       |
| _mean_obs       | 0.0303     |
| _min_adv        | -3.06      |
| _min_discrew    | -0.0113    |
| _min_obs        | -1.59      |
| _std_act        | 0.391197   |
| _std_adv        | 1          |
| _std_discrew    | 0.00597    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.78        |
| ExplainedVarOld | 0.765       |
| KL              | 0.00203198  |
| Phi_loss        | 60.5415     |
| PolicyEntropy   | 3.68952     |
| PolicyLoss      | -0.00286933 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00132     |
| _MeanReward     | 260         |
| _lr_multiplier  | 1           |
| _max_act        | 2.72643     |
| _max_adv        | 4.77        |
| _max_discrew    | 0.366       |
| _max_obs        | 1.43        |
| _mean_act       | -0.0316063  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.212       |
| _mean_obs       | 0.0305      |
| _min_adv        | -5.46       |
| _min_discrew    | -0.0091     |
| _min_obs        | -1.95       |
| _std_act        | 0.391369    |
| _std_adv        | 1           |
| _std_discrew    | 0.00639     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.758        |
| ExplainedVarOld | 0.751        |
| KL              | 0.00231206   |
| Phi_loss        | 62.3772      |
| PolicyEntropy   | 3.66022      |
| PolicyLoss      | -0.000510169 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00157      |
| _MeanReward     | 300          |
| _lr_multiplier  | 1            |
| _max_act        | 2.88026      |
| _max_adv        | 4.99         |
| _max_discrew    | 0.439        |
| _max_obs        | 1.92         |
| _mean_act       | -0.0292031   |
| _mean_adv       | 3.98e-17     |
| _mean_discrew   | 0.244        |
| _mean_obs       | 0.032        |
| _min_adv        | -5.06        |
| _min_discrew    | -0.0114      |
| _min_obs        | -1.65        |
| _std_act        | 0.396361     |
| _std_adv        | 1            |
| _std_discrew    | 0.00839      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.856      |
| ExplainedVarOld | 0.83       |
| KL              | 0.00289598 |
| Phi_loss        | 67.6333    |
| PolicyEntropy   | 3.61248    |
| PolicyLoss      | 0.00579943 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00136    |
| _MeanReward     | 302        |
| _lr_multiplier  | 1          |
| _max_act        | 2.58149    |
| _max_adv        | 4.94       |
| _max_discrew    | 0.414      |
| _max_obs        | 1.46       |
| _mean_act       | -0.0343658 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.252      |
| _mean_obs       | 0.0313     |
| _min_adv        | -5.19      |
| _min_discrew    | -0.00875   |
| _min_obs        | -1.58      |
| _std_act        | 0.396101   |
| _std_adv        | 1          |
| _std_discrew    | 0.0073     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.865       |
| ExplainedVarOld | 0.858       |
| KL              | 0.00241465  |
| Phi_loss        | 68.4657     |
| PolicyEntropy   | 3.57255     |
| PolicyLoss      | 0.000120752 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00102     |
| _MeanReward     | 307         |
| _lr_multiplier  | 1           |
| _max_act        | 2.46595     |
| _max_adv        | 5.72        |
| _max_discrew    | 0.408       |
| _max_obs        | 1.43        |
| _mean_act       | -0.0347535  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.254       |
| _mean_obs       | 0.0313      |
| _min_adv        | -6.14       |
| _min_discrew    | -0.00655    |
| _min_obs        | -1.61       |
| _std_act        | 0.395877    |
| _std_adv        | 1           |
| _std_discrew    | 0.00835     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.87        |
| ExplainedVarOld | 0.867       |
| KL              | 0.00238922  |
| Phi_loss        | 65.3208     |
| PolicyEntropy   | 3.53291     |
| PolicyLoss      | -0.00287616 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00108     |
| _MeanReward     | 325         |
| _lr_multiplier  | 1           |
| _max_act        | 2.69572     |
| _max_adv        | 4.28        |
| _max_discrew    | 0.479       |
| _max_obs        | 1.36        |
| _mean_act       | -0.0401147  |
| _mean_adv       | -4.05e-17   |
| _mean_discrew   | 0.273       |
| _mean_obs       | 0.0308      |
| _min_adv        | -5.93       |
| _min_discrew    | -0.00673    |
| _min_obs        | -1.71       |
| _std_act        | 0.397104    |
| _std_adv        | 1           |
| _std_discrew    | 0.00828     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.826       |
| ExplainedVarOld | 0.82        |
| KL              | 0.00224304  |
| Phi_loss        | 66.6838     |
| PolicyEntropy   | 3.49593     |
| PolicyLoss      | 0.000555049 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00152     |
| _MeanReward     | 364         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83565     |
| _max_adv        | 6.09        |
| _max_discrew    | 0.46        |
| _max_obs        | 1.51        |
| _mean_act       | -0.0417718  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.298       |
| _mean_obs       | 0.0318      |
| _min_adv        | -4.75       |
| _min_discrew    | -0.00563    |
| _min_obs        | -1.77       |
| _std_act        | 0.402418    |
| _std_adv        | 1           |
| _std_discrew    | 0.0107      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.829      |
| ExplainedVarOld | 0.825      |
| KL              | 0.00184425 |
| Phi_loss        | 74.3921    |
| PolicyEntropy   | 3.47031    |
| PolicyLoss      | -0.0111319 |
| Steps           | 10000      |
| VarFuncLoss     | 0.002      |
| _MeanReward     | 358        |
| _lr_multiplier  | 1          |
| _max_act        | 2.97658    |
| _max_adv        | 4.3        |
| _max_discrew    | 0.449      |
| _max_obs        | 1.49       |
| _mean_act       | -0.0411357 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.292      |
| _mean_obs       | 0.0315     |
| _min_adv        | -4.18      |
| _min_discrew    | -0.00831   |
| _min_obs        | -1.65      |
| _std_act        | 0.408825   |
| _std_adv        | 1          |
| _std_discrew    | 0.0105     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.9         |
| ExplainedVarOld | 0.882       |
| KL              | 0.00203937  |
| Phi_loss        | 74.0341     |
| PolicyEntropy   | 3.43345     |
| PolicyLoss      | -0.00210215 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00106     |
| _MeanReward     | 378         |
| _lr_multiplier  | 1           |
| _max_act        | 2.80727     |
| _max_adv        | 4.65        |
| _max_discrew    | 0.498       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0402366  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.314       |
| _mean_obs       | 0.0323      |
| _min_adv        | -5.64       |
| _min_discrew    | -0.00222    |
| _min_obs        | -1.58       |
| _std_act        | 0.410098    |
| _std_adv        | 1           |
| _std_discrew    | 0.0103      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.85        |
| ExplainedVarOld | 0.846       |
| KL              | 0.00180292  |
| Phi_loss        | 83.2284     |
| PolicyEntropy   | 3.40129     |
| PolicyLoss      | -0.00703646 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00163     |
| _MeanReward     | 377         |
| _lr_multiplier  | 1           |
| _max_act        | 2.63969     |
| _max_adv        | 3.21        |
| _max_discrew    | 0.504       |
| _max_obs        | 1.62        |
| _mean_act       | -0.0319577  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.316       |
| _mean_obs       | 0.0332      |
| _min_adv        | -6.77       |
| _min_discrew    | -0.0053     |
| _min_obs        | -1.58       |
| _std_act        | 0.415173    |
| _std_adv        | 1           |
| _std_discrew    | 0.0114      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.871      |
| ExplainedVarOld | 0.85       |
| KL              | 0.00208114 |
| Phi_loss        | 70.0878    |
| PolicyEntropy   | 3.37762    |
| PolicyLoss      | -0.0144214 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00148    |
| _MeanReward     | 385        |
| _lr_multiplier  | 1          |
| _max_act        | 2.57013    |
| _max_adv        | 6.49       |
| _max_discrew    | 0.504      |
| _max_obs        | 1.62       |
| _mean_act       | -0.0367574 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.318      |
| _mean_obs       | 0.0324     |
| _min_adv        | -5.91      |
| _min_discrew    | -0.00279   |
| _min_obs        | -1.48      |
| _std_act        | 0.410872   |
| _std_adv        | 1          |
| _std_discrew    | 0.0119     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.857      |
| ExplainedVarOld | 0.854      |
| KL              | 0.00491704 |
| Phi_loss        | 87.2858    |
| PolicyEntropy   | 3.34244    |
| PolicyLoss      | -0.0164414 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00171    |
| _MeanReward     | 415        |
| _lr_multiplier  | 1          |
| _max_act        | 2.90631    |
| _max_adv        | 6.91       |
| _max_discrew    | 0.524      |
| _max_obs        | 1.43       |
| _mean_act       | -0.0394777 |
| _mean_adv       | 3.55e-17   |
| _mean_discrew   | 0.345      |
| _mean_obs       | 0.0333     |
| _min_adv        | -7.45      |
| _min_discrew    | -0.0126    |
| _min_obs        | -1.52      |
| _std_act        | 0.425122   |
| _std_adv        | 1          |
| _std_discrew    | 0.0137     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.871      |
| ExplainedVarOld | 0.862      |
| KL              | 0.0022033  |
| Phi_loss        | 75.4592    |
| PolicyEntropy   | 3.3169     |
| PolicyLoss      | -0.0123679 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00193    |
| _MeanReward     | 408        |
| _lr_multiplier  | 1          |
| _max_act        | 3.13789    |
| _max_adv        | 6.15       |
| _max_discrew    | 0.495      |
| _max_obs        | 1.54       |
| _mean_act       | -0.0424092 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.34       |
| _mean_obs       | 0.0329     |
| _min_adv        | -6.09      |
| _min_discrew    | -0.00377   |
| _min_obs        | -1.47      |
| _std_act        | 0.431277   |
| _std_adv        | 1          |
| _std_discrew    | 0.0109     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.87       |
| ExplainedVarOld | 0.852      |
| KL              | 0.00178341 |
| Phi_loss        | 74.0463    |
| PolicyEntropy   | 3.276      |
| PolicyLoss      | 0.00872367 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00143    |
| _MeanReward     | 422        |
| _lr_multiplier  | 1          |
| _max_act        | 3.11119    |
| _max_adv        | 7.92       |
| _max_discrew    | 0.535      |
| _max_obs        | 1.44       |
| _mean_act       | -0.0409961 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 0.354      |
| _mean_obs       | 0.0329     |
| _min_adv        | -7.44      |
| _min_discrew    | -0.00308   |
| _min_obs        | -1.61      |
| _std_act        | 0.420307   |
| _std_adv        | 1          |
| _std_discrew    | 0.013      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.889      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00306367 |
| Phi_loss        | 83.863     |
| PolicyEntropy   | 3.2525     |
| PolicyLoss      | -0.0111615 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00149    |
| _MeanReward     | 447        |
| _lr_multiplier  | 1          |
| _max_act        | 2.70211    |
| _max_adv        | 7.13       |
| _max_discrew    | 0.544      |
| _max_obs        | 1.48       |
| _mean_act       | -0.038443  |
| _mean_adv       | -6.82e-17  |
| _mean_discrew   | 0.371      |
| _mean_obs       | 0.0339     |
| _min_adv        | -7.44      |
| _min_discrew    | -0.00907   |
| _min_obs        | -1.82      |
| _std_act        | 0.432124   |
| _std_adv        | 1          |
| _std_discrew    | 0.0145     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00176846 |
| Phi_loss        | 83.0446    |
| PolicyEntropy   | 3.21612    |
| PolicyLoss      | -0.0082107 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00151    |
| _MeanReward     | 424        |
| _lr_multiplier  | 1          |
| _max_act        | 2.92926    |
| _max_adv        | 3.84       |
| _max_discrew    | 0.541      |
| _max_obs        | 1.56       |
| _mean_act       | -0.0414932 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.364      |
| _mean_obs       | 0.0331     |
| _min_adv        | -7.63      |
| _min_discrew    | -0.0017    |
| _min_obs        | -1.7       |
| _std_act        | 0.430252   |
| _std_adv        | 1          |
| _std_discrew    | 0.0156     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.898       |
| ExplainedVarOld | 0.877       |
| KL              | 0.00304039  |
| Phi_loss        | 65.6445     |
| PolicyEntropy   | 3.185       |
| PolicyLoss      | -0.00458983 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00159     |
| _MeanReward     | 450         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83363     |
| _max_adv        | 6.97        |
| _max_discrew    | 0.536       |
| _max_obs        | 1.36        |
| _mean_act       | -0.0429302  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.37        |
| _mean_obs       | 0.0332      |
| _min_adv        | -3.3        |
| _min_discrew    | -0.00432    |
| _min_obs        | -1.65       |
| _std_act        | 0.437177    |
| _std_adv        | 1           |
| _std_discrew    | 0.013       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.897       |
| KL              | 0.00270826  |
| Phi_loss        | 82.6477     |
| PolicyEntropy   | 3.14336     |
| PolicyLoss      | -0.00281615 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00125     |
| _MeanReward     | 487         |
| _lr_multiplier  | 1           |
| _max_act        | 2.62769     |
| _max_adv        | 6.2         |
| _max_discrew    | 0.595       |
| _max_obs        | 1.49        |
| _mean_act       | -0.0422975  |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 0.404       |
| _mean_obs       | 0.0339      |
| _min_adv        | -7.18       |
| _min_discrew    | -0.00195    |
| _min_obs        | -1.9        |
| _std_act        | 0.433308    |
| _std_adv        | 1           |
| _std_discrew    | 0.0156      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.908       |
| ExplainedVarOld | 0.901       |
| KL              | 0.00210903  |
| Phi_loss        | 94.0689     |
| PolicyEntropy   | 3.1117      |
| PolicyLoss      | -0.00921117 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00176     |
| _MeanReward     | 481         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93475     |
| _max_adv        | 5.13        |
| _max_discrew    | 0.628       |
| _max_obs        | 1.43        |
| _mean_act       | -0.0469436  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.4         |
| _mean_obs       | 0.0335      |
| _min_adv        | -7.28       |
| _min_discrew    | -0.00631    |
| _min_obs        | -1.76       |
| _std_act        | 0.439446    |
| _std_adv        | 1           |
| _std_discrew    | 0.0172      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.902       |
| KL              | 0.00248576  |
| Phi_loss        | 100.552     |
| PolicyEntropy   | 3.07307     |
| PolicyLoss      | -0.00402617 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00155     |
| _MeanReward     | 500         |
| _lr_multiplier  | 1           |
| _max_act        | 2.5718      |
| _max_adv        | 4.37        |
| _max_discrew    | 0.591       |
| _max_obs        | 1.41        |
| _mean_act       | -0.0415293  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.421       |
| _mean_obs       | 0.0345      |
| _min_adv        | -10.1       |
| _min_discrew    | -0.00281    |
| _min_obs        | -1.72       |
| _std_act        | 0.440515    |
| _std_adv        | 1           |
| _std_discrew    | 0.0165      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.917       |
| KL              | 0.00207793  |
| Phi_loss        | 86.3518     |
| PolicyEntropy   | 3.04482     |
| PolicyLoss      | -0.00950274 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00143     |
| _MeanReward     | 494         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86592     |
| _max_adv        | 4.69        |
| _max_discrew    | 0.595       |
| _max_obs        | 1.52        |
| _mean_act       | -0.0370796  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 0.419       |
| _mean_obs       | 0.0352      |
| _min_adv        | -7.51       |
| _min_discrew    | -0.00322    |
| _min_obs        | -1.73       |
| _std_act        | 0.451293    |
| _std_adv        | 1           |
| _std_discrew    | 0.0184      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.922       |
| KL              | 0.0021213   |
| Phi_loss        | 97.159      |
| PolicyEntropy   | 3.01117     |
| PolicyLoss      | -0.00902139 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00135     |
| _MeanReward     | 516         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1123      |
| _max_adv        | 5.64        |
| _max_discrew    | 0.654       |
| _max_obs        | 1.38        |
| _mean_act       | -0.0384402  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.425       |
| _mean_obs       | 0.0355      |
| _min_adv        | -4.3        |
| _min_discrew    | -0.00397    |
| _min_obs        | -1.39       |
| _std_act        | 0.453536    |
| _std_adv        | 1           |
| _std_discrew    | 0.0194      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.9        |
| KL              | 0.0031068  |
| Phi_loss        | 105.102    |
| PolicyEntropy   | 2.97703    |
| PolicyLoss      | -0.0189221 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00164    |
| _MeanReward     | 534        |
| _lr_multiplier  | 1          |
| _max_act        | 2.95549    |
| _max_adv        | 5.79       |
| _max_discrew    | 0.642      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0390458 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.447      |
| _mean_obs       | 0.0356     |
| _min_adv        | -6.9       |
| _min_discrew    | -0.00548   |
| _min_obs        | -1.65      |
| _std_act        | 0.453176   |
| _std_adv        | 1          |
| _std_discrew    | 0.0198     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.925      |
| KL              | 0.00213541 |
| Phi_loss        | 106.626    |
| PolicyEntropy   | 2.93351    |
| PolicyLoss      | 0.00110224 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00156    |
| _MeanReward     | 521        |
| _lr_multiplier  | 1          |
| _max_act        | 2.68084    |
| _max_adv        | 3.7        |
| _max_discrew    | 0.655      |
| _max_obs        | 1.34       |
| _mean_act       | -0.0396995 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.447      |
| _mean_obs       | 0.035      |
| _min_adv        | -8.9       |
| _min_discrew    | -0.000923  |
| _min_obs        | -1.49      |
| _std_act        | 0.451715   |
| _std_adv        | 1          |
| _std_discrew    | 0.0198     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.865      |
| KL              | 0.00257295 |
| Phi_loss        | 85.4774    |
| PolicyEntropy   | 2.91315    |
| PolicyLoss      | 0.00996407 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00193    |
| _MeanReward     | 547        |
| _lr_multiplier  | 1          |
| _max_act        | 2.65959    |
| _max_adv        | 7.7        |
| _max_discrew    | 0.65       |
| _max_obs        | 1.45       |
| _mean_act       | -0.041808  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.455      |
| _mean_obs       | 0.0353     |
| _min_adv        | -7.41      |
| _min_discrew    | -0.00298   |
| _min_obs        | -1.52      |
| _std_act        | 0.451731   |
| _std_adv        | 1          |
| _std_discrew    | 0.0207     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.931       |
| ExplainedVarOld | 0.929       |
| KL              | 0.00602976  |
| Phi_loss        | 118.6       |
| PolicyEntropy   | 2.88104     |
| PolicyLoss      | -0.00743261 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00142     |
| _MeanReward     | 553         |
| _lr_multiplier  | 1           |
| _max_act        | 2.62966     |
| _max_adv        | 6.6         |
| _max_discrew    | 0.642       |
| _max_obs        | 1.6         |
| _mean_act       | -0.0413427  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.452       |
| _mean_obs       | 0.0352      |
| _min_adv        | -7.19       |
| _min_discrew    | -0.00427    |
| _min_obs        | -1.67       |
| _std_act        | 0.443465    |
| _std_adv        | 1           |
| _std_discrew    | 0.0193      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.892       |
| KL              | 0.00103871  |
| Phi_loss        | 105.402     |
| PolicyEntropy   | 2.8514      |
| PolicyLoss      | -0.00892172 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00161     |
| _MeanReward     | 555         |
| _lr_multiplier  | 1           |
| _max_act        | 2.77203     |
| _max_adv        | 7.43        |
| _max_discrew    | 0.677       |
| _max_obs        | 1.48        |
| _mean_act       | -0.0401583  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.462       |
| _mean_obs       | 0.0357      |
| _min_adv        | -8.14       |
| _min_discrew    | -0.00381    |
| _min_obs        | -1.52       |
| _std_act        | 0.460952    |
| _std_adv        | 1           |
| _std_discrew    | 0.0238      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.919      |
| KL              | 0.00274646 |
| Phi_loss        | 117.849    |
| PolicyEntropy   | 2.80732    |
| PolicyLoss      | 0.00134481 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00166    |
| _MeanReward     | 588        |
| _lr_multiplier  | 1          |
| _max_act        | 2.56446    |
| _max_adv        | 5.23       |
| _max_discrew    | 0.662      |
| _max_obs        | 1.42       |
| _mean_act       | -0.0431098 |
| _mean_adv       | 5.68e-17   |
| _mean_discrew   | 0.485      |
| _mean_obs       | 0.0357     |
| _min_adv        | -7.76      |
| _min_discrew    | -0.0048    |
| _min_obs        | -1.69      |
| _std_act        | 0.456605   |
| _std_adv        | 1          |
| _std_discrew    | 0.0215     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.922      |
| KL              | 0.00299306 |
| Phi_loss        | 132.208    |
| PolicyEntropy   | 2.76084    |
| PolicyLoss      | 0.00332857 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00156    |
| _MeanReward     | 580        |
| _lr_multiplier  | 1          |
| _max_act        | 2.86823    |
| _max_adv        | 5.59       |
| _max_discrew    | 0.684      |
| _max_obs        | 1.44       |
| _mean_act       | -0.0396846 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.482      |
| _mean_obs       | 0.0359     |
| _min_adv        | -7.28      |
| _min_discrew    | -0.000238  |
| _min_obs        | -1.57      |
| _std_act        | 0.455853   |
| _std_adv        | 1          |
| _std_discrew    | 0.0221     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00307413 |
| Phi_loss        | 142.252    |
| PolicyEntropy   | 2.71108    |
| PolicyLoss      | 0.00375191 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000928   |
| _MeanReward     | 598        |
| _lr_multiplier  | 1          |
| _max_act        | 2.74822    |
| _max_adv        | 4.68       |
| _max_discrew    | 0.719      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0344934 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.499      |
| _mean_obs       | 0.0364     |
| _min_adv        | -7.52      |
| _min_discrew    | -0.00359   |
| _min_obs        | -1.46      |
| _std_act        | 0.455131   |
| _std_adv        | 1          |
| _std_discrew    | 0.0262     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00237491 |
| Phi_loss        | 129.279    |
| PolicyEntropy   | 2.67082    |
| PolicyLoss      | 0.00439885 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00166    |
| _MeanReward     | 610        |
| _lr_multiplier  | 1          |
| _max_act        | 2.59626    |
| _max_adv        | 4.44       |
| _max_discrew    | 0.689      |
| _max_obs        | 1.35       |
| _mean_act       | -0.0411855 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.51       |
| _mean_obs       | 0.0362     |
| _min_adv        | -9.11      |
| _min_discrew    | -0.000629  |
| _min_obs        | -1.65      |
| _std_act        | 0.455854   |
| _std_adv        | 1          |
| _std_discrew    | 0.0238     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.944       |
| ExplainedVarOld | 0.941       |
| KL              | 0.00208188  |
| Phi_loss        | 120.308     |
| PolicyEntropy   | 2.65604     |
| PolicyLoss      | -0.00536396 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00134     |
| _MeanReward     | 617         |
| _lr_multiplier  | 1           |
| _max_act        | 2.7778      |
| _max_adv        | 5.97        |
| _max_discrew    | 0.719       |
| _max_obs        | 1.45        |
| _mean_act       | -0.0349425  |
| _mean_adv       | -1.56e-17   |
| _mean_discrew   | 0.513       |
| _mean_obs       | 0.037       |
| _min_adv        | -6.95       |
| _min_discrew    | -0.00434    |
| _min_obs        | -1.47       |
| _std_act        | 0.458346    |
| _std_adv        | 1           |
| _std_discrew    | 0.0243      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.95       |
| KL              | 0.0033866  |
| Phi_loss        | 155.246    |
| PolicyEntropy   | 2.62597    |
| PolicyLoss      | 0.00878124 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00119    |
| _MeanReward     | 635        |
| _lr_multiplier  | 1          |
| _max_act        | 2.58206    |
| _max_adv        | 5.13       |
| _max_discrew    | 0.742      |
| _max_obs        | 1.31       |
| _mean_act       | -0.0375146 |
| _mean_adv       | 5.4e-17    |
| _mean_discrew   | 0.531      |
| _mean_obs       | 0.0366     |
| _min_adv        | -10.1      |
| _min_discrew    | -0.00586   |
| _min_obs        | -1.66      |
| _std_act        | 0.455209   |
| _std_adv        | 1          |
| _std_discrew    | 0.0277     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.944      |
| KL              | 0.00268271 |
| Phi_loss        | 138.237    |
| PolicyEntropy   | 2.58826    |
| PolicyLoss      | -0.0151534 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00149    |
| _MeanReward     | 632        |
| _lr_multiplier  | 1          |
| _max_act        | 2.73951    |
| _max_adv        | 6.26       |
| _max_discrew    | 0.733      |
| _max_obs        | 1.65       |
| _mean_act       | -0.0303629 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 0.527      |
| _mean_obs       | 0.0375     |
| _min_adv        | -9.51      |
| _min_discrew    | -0.00353   |
| _min_obs        | -1.6       |
| _std_act        | 0.457386   |
| _std_adv        | 1          |
| _std_discrew    | 0.0273     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.963       |
| KL              | 0.00272955  |
| Phi_loss        | 131.52      |
| PolicyEntropy   | 2.55574     |
| PolicyLoss      | -0.00596489 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000953    |
| _MeanReward     | 646         |
| _lr_multiplier  | 1           |
| _max_act        | 2.64934     |
| _max_adv        | 5.92        |
| _max_discrew    | 0.73        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0345853  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.537       |
| _mean_obs       | 0.0372      |
| _min_adv        | -9.3        |
| _min_discrew    | -0.00526    |
| _min_obs        | -1.62       |
| _std_act        | 0.45488     |
| _std_adv        | 1           |
| _std_discrew    | 0.028       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00275457  |
| Phi_loss        | 149.549     |
| PolicyEntropy   | 2.5297      |
| PolicyLoss      | -0.00595425 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000999    |
| _MeanReward     | 651         |
| _lr_multiplier  | 1           |
| _max_act        | 2.47385     |
| _max_adv        | 5.8         |
| _max_discrew    | 0.752       |
| _max_obs        | 1.46        |
| _mean_act       | -0.0331772  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.537       |
| _mean_obs       | 0.0373      |
| _min_adv        | -3.43       |
| _min_discrew    | -0.00562    |
| _min_obs        | -1.54       |
| _std_act        | 0.459596    |
| _std_adv        | 1           |
| _std_discrew    | 0.0276      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.954       |
| ExplainedVarOld | 0.953       |
| KL              | 0.00224182  |
| Phi_loss        | 180.176     |
| PolicyEntropy   | 2.48684     |
| PolicyLoss      | 0.000284214 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00128     |
| _MeanReward     | 665         |
| _lr_multiplier  | 1           |
| _max_act        | 2.78012     |
| _max_adv        | 4.81        |
| _max_discrew    | 0.755       |
| _max_obs        | 1.56        |
| _mean_act       | -0.0333856  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.553       |
| _mean_obs       | 0.0374      |
| _min_adv        | -6.18       |
| _min_discrew    | -0.00432    |
| _min_obs        | -1.57       |
| _std_act        | 0.45423     |
| _std_adv        | 1           |
| _std_discrew    | 0.0278      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.959       |
| KL              | 0.00221106  |
| Phi_loss        | 164.797     |
| PolicyEntropy   | 2.45888     |
| PolicyLoss      | 0.000333898 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00116     |
| _MeanReward     | 682         |
| _lr_multiplier  | 1           |
| _max_act        | 2.73365     |
| _max_adv        | 5.77        |
| _max_discrew    | 0.773       |
| _max_obs        | 1.48        |
| _mean_act       | -0.0321625  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 0.566       |
| _mean_obs       | 0.0378      |
| _min_adv        | -7.32       |
| _min_discrew    | -0.00506    |
| _min_obs        | -1.51       |
| _std_act        | 0.453816    |
| _std_adv        | 1           |
| _std_discrew    | 0.0284      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.958      |
| KL              | 0.0027118  |
| Phi_loss        | 185.469    |
| PolicyEntropy   | 2.4203     |
| PolicyLoss      | 0.00443819 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00114    |
| _MeanReward     | 685        |
| _lr_multiplier  | 1          |
| _max_act        | 2.7053     |
| _max_adv        | 5.27       |
| _max_discrew    | 0.788      |
| _max_obs        | 1.6        |
| _mean_act       | -0.0345427 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.565      |
| _mean_obs       | 0.0377     |
| _min_adv        | -6.83      |
| _min_discrew    | -0.00455   |
| _min_obs        | -1.56      |
| _std_act        | 0.458117   |
| _std_adv        | 1          |
| _std_discrew    | 0.0322     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.945      |
| KL              | 0.00234743 |
| Phi_loss        | 168.75     |
| PolicyEntropy   | 2.38227    |
| PolicyLoss      | -0.0133885 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0016     |
| _MeanReward     | 672        |
| _lr_multiplier  | 1          |
| _max_act        | 2.46471    |
| _max_adv        | 2.38       |
| _max_discrew    | 0.774      |
| _max_obs        | 1.64       |
| _mean_act       | -0.0287202 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 0.565      |
| _mean_obs       | 0.0382     |
| _min_adv        | -8.83      |
| _min_discrew    | -0.000648  |
| _min_obs        | -1.53      |
| _std_act        | 0.460985   |
| _std_adv        | 1          |
| _std_discrew    | 0.0312     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.944      |
| KL              | 0.00213908 |
| Phi_loss        | 137.687    |
| PolicyEntropy   | 2.36178    |
| PolicyLoss      | -0.0175203 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00158    |
| _MeanReward     | 711        |
| _lr_multiplier  | 1          |
| _max_act        | 2.72518    |
| _max_adv        | 4.87       |
| _max_discrew    | 0.784      |
| _max_obs        | 1.52       |
| _mean_act       | -0.0317084 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.586      |
| _mean_obs       | 0.0381     |
| _min_adv        | -5.37      |
| _min_discrew    | -0.00283   |
| _min_obs        | -1.58      |
| _std_act        | 0.462144   |
| _std_adv        | 1          |
| _std_discrew    | 0.0317     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00247432 |
| Phi_loss        | 199.007    |
| PolicyEntropy   | 2.31298    |
| PolicyLoss      | 0.00901928 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00144    |
| _MeanReward     | 725        |
| _lr_multiplier  | 1          |
| _max_act        | 2.84631    |
| _max_adv        | 6.12       |
| _max_discrew    | 0.795      |
| _max_obs        | 1.59       |
| _mean_act       | -0.0303907 |
| _mean_adv       | -6.82e-17  |
| _mean_discrew   | 0.598      |
| _mean_obs       | 0.0382     |
| _min_adv        | -7.43      |
| _min_discrew    | -0.00642   |
| _min_obs        | -1.49      |
| _std_act        | 0.45675    |
| _std_adv        | 1          |
| _std_discrew    | 0.0324     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.966      |
| KL              | 0.00213995 |
| Phi_loss        | 178.87     |
| PolicyEntropy   | 2.27444    |
| PolicyLoss      | 0.00301047 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00101    |
| _MeanReward     | 722        |
| _lr_multiplier  | 1          |
| _max_act        | 2.77952    |
| _max_adv        | 7.38       |
| _max_discrew    | 0.79       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0272611 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 0.597      |
| _mean_obs       | 0.0388     |
| _min_adv        | -7.41      |
| _min_discrew    | -0.0038    |
| _min_obs        | -1.6       |
| _std_act        | 0.464465   |
| _std_adv        | 1          |
| _std_discrew    | 0.0317     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00289731  |
| Phi_loss        | 199.959     |
| PolicyEntropy   | 2.2332      |
| PolicyLoss      | -0.00457107 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000615    |
| _MeanReward     | 730         |
| _lr_multiplier  | 1           |
| _max_act        | 2.54323     |
| _max_adv        | 4.89        |
| _max_discrew    | 0.844       |
| _max_obs        | 1.58        |
| _mean_act       | -0.0312376  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.605       |
| _mean_obs       | 0.0381      |
| _min_adv        | -7.49       |
| _min_discrew    | -0.000779   |
| _min_obs        | -1.55       |
| _std_act        | 0.456569    |
| _std_adv        | 1           |
| _std_discrew    | 0.0355      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.959       |
| KL              | 0.00264573  |
| Phi_loss        | 199.378     |
| PolicyEntropy   | 2.18379     |
| PolicyLoss      | 0.000640644 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00139     |
| _MeanReward     | 734         |
| _lr_multiplier  | 1           |
| _max_act        | 2.43445     |
| _max_adv        | 3.01        |
| _max_discrew    | 0.851       |
| _max_obs        | 1.71        |
| _mean_act       | -0.0284359  |
| _mean_adv       | -1.85e-17   |
| _mean_discrew   | 0.615       |
| _mean_obs       | 0.0388      |
| _min_adv        | -10.5       |
| _min_discrew    | -0.00185    |
| _min_obs        | -1.51       |
| _std_act        | 0.466958    |
| _std_adv        | 1           |
| _std_discrew    | 0.0366      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.936       |
| ExplainedVarOld | 0.922       |
| KL              | 0.00273661  |
| Phi_loss        | 122.414     |
| PolicyEntropy   | 2.16171     |
| PolicyLoss      | -0.00651022 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00241     |
| _MeanReward     | 731         |
| _lr_multiplier  | 1           |
| _max_act        | 2.49128     |
| _max_adv        | 7.53        |
| _max_discrew    | 0.83        |
| _max_obs        | 1.61        |
| _mean_act       | -0.027803   |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 0.606       |
| _mean_obs       | 0.0384      |
| _min_adv        | -6.4        |
| _min_discrew    | -0.00346    |
| _min_obs        | -1.62       |
| _std_act        | 0.458666    |
| _std_adv        | 1           |
| _std_discrew    | 0.0346      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00256322 |
| Phi_loss        | 196.464    |
| PolicyEntropy   | 2.13512    |
| PolicyLoss      | 0.00685366 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00132    |
| _MeanReward     | 765        |
| _lr_multiplier  | 1          |
| _max_act        | 2.64118    |
| _max_adv        | 7.7        |
| _max_discrew    | 0.874      |
| _max_obs        | 1.5        |
| _mean_act       | -0.0240931 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.63       |
| _mean_obs       | 0.0397     |
| _min_adv        | -4.41      |
| _min_discrew    | -0.00494   |
| _min_obs        | -1.66      |
| _std_act        | 0.458034   |
| _std_adv        | 1          |
| _std_discrew    | 0.0366     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.961       |
| KL              | 0.00177703  |
| Phi_loss        | 196.594     |
| PolicyEntropy   | 2.09736     |
| PolicyLoss      | -0.00727988 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00139     |
| _MeanReward     | 762         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04097     |
| _max_adv        | 4.99        |
| _max_discrew    | 0.894       |
| _max_obs        | 1.45        |
| _mean_act       | -0.025209   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.631       |
| _mean_obs       | 0.0392      |
| _min_adv        | -10.2       |
| _min_discrew    | -0.0065     |
| _min_obs        | -1.74       |
| _std_act        | 0.462274    |
| _std_adv        | 1           |
| _std_discrew    | 0.0372      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.00344799 |
| Phi_loss        | 207.063    |
| PolicyEntropy   | 2.07455    |
| PolicyLoss      | -0.0114534 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0011     |
| _MeanReward     | 772        |
| _lr_multiplier  | 1          |
| _max_act        | 2.55131    |
| _max_adv        | 6.46       |
| _max_discrew    | 0.858      |
| _max_obs        | 1.47       |
| _mean_act       | -0.0238625 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.635      |
| _mean_obs       | 0.0395     |
| _min_adv        | -4.76      |
| _min_discrew    | -0.0029    |
| _min_obs        | -1.49      |
| _std_act        | 0.462628   |
| _std_adv        | 1          |
| _std_discrew    | 0.037      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00224375  |
| Phi_loss        | 222.736     |
| PolicyEntropy   | 2.03811     |
| PolicyLoss      | -0.00215319 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00128     |
| _MeanReward     | 765         |
| _lr_multiplier  | 1           |
| _max_act        | 2.61625     |
| _max_adv        | 4.08        |
| _max_discrew    | 0.864       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0271243  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.636       |
| _mean_obs       | 0.0386      |
| _min_adv        | -10.5       |
| _min_discrew    | -0.00353    |
| _min_obs        | -1.55       |
| _std_act        | 0.462394    |
| _std_adv        | 1           |
| _std_discrew    | 0.0373      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00304137 |
| Phi_loss        | 213.262    |
| PolicyEntropy   | 2.01466    |
| PolicyLoss      | 0.00708437 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00137    |
| _MeanReward     | 780        |
| _lr_multiplier  | 1          |
| _max_act        | 2.5171     |
| _max_adv        | 5.3        |
| _max_discrew    | 0.885      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0218647 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.647      |
| _mean_obs       | 0.0396     |
| _min_adv        | -9.65      |
| _min_discrew    | -0.00284   |
| _min_obs        | -1.34      |
| _std_act        | 0.461451   |
| _std_adv        | 1          |
| _std_discrew    | 0.0369     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.965       |
| KL              | 0.00401639  |
| Phi_loss        | 196.406     |
| PolicyEntropy   | 1.98324     |
| PolicyLoss      | -0.00473219 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00123     |
| _MeanReward     | 776         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60437     |
| _max_adv        | 9.03        |
| _max_discrew    | 0.866       |
| _max_obs        | 1.38        |
| _mean_act       | -0.0232554  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.647       |
| _mean_obs       | 0.0394      |
| _min_adv        | -7.24       |
| _min_discrew    | -0.00304    |
| _min_obs        | -1.63       |
| _std_act        | 0.469428    |
| _std_adv        | 1           |
| _std_discrew    | 0.0367      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00251287 |
| Phi_loss        | 214.669    |
| PolicyEntropy   | 1.96188    |
| PolicyLoss      | 0.006538   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00118    |
| _MeanReward     | 791        |
| _lr_multiplier  | 1          |
| _max_act        | 2.44821    |
| _max_adv        | 5.81       |
| _max_discrew    | 0.904      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0272125 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.662      |
| _mean_obs       | 0.0388     |
| _min_adv        | -10.7      |
| _min_discrew    | -0.00794   |
| _min_obs        | -1.61      |
| _std_act        | 0.462394   |
| _std_adv        | 1          |
| _std_discrew    | 0.0395     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.962       |
| ExplainedVarOld | 0.961       |
| KL              | 0.00257518  |
| Phi_loss        | 213.305     |
| PolicyEntropy   | 1.92605     |
| PolicyLoss      | -0.00607846 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00156     |
| _MeanReward     | 810         |
| _lr_multiplier  | 1           |
| _max_act        | 2.55515     |
| _max_adv        | 4.45        |
| _max_discrew    | 0.923       |
| _max_obs        | 1.28        |
| _mean_act       | -0.0263258  |
| _mean_adv       | -6.82e-17   |
| _mean_discrew   | 0.675       |
| _mean_obs       | 0.0395      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.00292    |
| _min_obs        | -1.6        |
| _std_act        | 0.4635      |
| _std_adv        | 1           |
| _std_discrew    | 0.0437      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00212572 |
| Phi_loss        | 211.577    |
| PolicyEntropy   | 1.9069     |
| PolicyLoss      | -0.0170637 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00126    |
| _MeanReward     | 819        |
| _lr_multiplier  | 1          |
| _max_act        | 2.45522    |
| _max_adv        | 7.18       |
| _max_discrew    | 0.938      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0209476 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.673      |
| _mean_obs       | 0.0401     |
| _min_adv        | -5.6       |
| _min_discrew    | -0.00175   |
| _min_obs        | -1.51      |
| _std_act        | 0.463065   |
| _std_adv        | 1          |
| _std_discrew    | 0.0427     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.965      |
| KL              | 0.0122961  |
| Phi_loss        | 288.718    |
| PolicyEntropy   | 1.88104    |
| PolicyLoss      | 0.00982398 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00146    |
| _MeanReward     | 817        |
| _lr_multiplier  | 1          |
| _max_act        | 2.44134    |
| _max_adv        | 4.51       |
| _max_discrew    | 0.903      |
| _max_obs        | 1.36       |
| _mean_act       | -0.0194072 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.68       |
| _mean_obs       | 0.0402     |
| _min_adv        | -8.76      |
| _min_discrew    | -0.00403   |
| _min_obs        | -1.47      |
| _std_act        | 0.464772   |
| _std_adv        | 1          |
| _std_discrew    | 0.0415     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.967       |
| KL              | 0.00157595  |
| Phi_loss        | 249.628     |
| PolicyEntropy   | 1.8554      |
| PolicyLoss      | -0.00512971 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00127     |
| _MeanReward     | 814         |
| _lr_multiplier  | 1           |
| _max_act        | 2.59456     |
| _max_adv        | 6.17        |
| _max_discrew    | 0.888       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0204049  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.676       |
| _mean_obs       | 0.0398      |
| _min_adv        | -11.4       |
| _min_discrew    | -0.00549    |
| _min_obs        | -1.5        |
| _std_act        | 0.465751    |
| _std_adv        | 1           |
| _std_discrew    | 0.0419      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00118426  |
| Phi_loss        | 288.735     |
| PolicyEntropy   | 1.82985     |
| PolicyLoss      | 0.000254185 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00116     |
| _MeanReward     | 822         |
| _lr_multiplier  | 1           |
| _max_act        | 2.33736     |
| _max_adv        | 7.78        |
| _max_discrew    | 0.893       |
| _max_obs        | 1.28        |
| _mean_act       | -0.0183504  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.682       |
| _mean_obs       | 0.04        |
| _min_adv        | -7.12       |
| _min_discrew    | -0.00365    |
| _min_obs        | -1.57       |
| _std_act        | 0.459851    |
| _std_adv        | 1           |
| _std_discrew    | 0.0408      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00299948 |
| Phi_loss        | 269.995    |
| PolicyEntropy   | 1.80592    |
| PolicyLoss      | -0.0162077 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00139    |
| _MeanReward     | 841        |
| _lr_multiplier  | 1          |
| _max_act        | 2.5128     |
| _max_adv        | 5.79       |
| _max_discrew    | 0.916      |
| _max_obs        | 1.28       |
| _mean_act       | -0.020798  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.698      |
| _mean_obs       | 0.04       |
| _min_adv        | -5.47      |
| _min_discrew    | -0.00542   |
| _min_obs        | -1.4       |
| _std_act        | 0.462939   |
| _std_adv        | 1          |
| _std_discrew    | 0.0416     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00176139 |
| Phi_loss        | 287.674    |
| PolicyEntropy   | 1.77994    |
| PolicyLoss      | -0.0013948 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00123    |
| _MeanReward     | 843        |
| _lr_multiplier  | 1          |
| _max_act        | 2.40114    |
| _max_adv        | 5.8        |
| _max_discrew    | 0.912      |
| _max_obs        | 1.45       |
| _mean_act       | -0.0174758 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 0.69       |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.39      |
| _min_discrew    | -0.00228   |
| _min_obs        | -1.45      |
| _std_act        | 0.463929   |
| _std_adv        | 1          |
| _std_discrew    | 0.044      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00253102 |
| Phi_loss        | 307.301    |
| PolicyEntropy   | 1.73757    |
| PolicyLoss      | 0.00600548 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00116    |
| _MeanReward     | 851        |
| _lr_multiplier  | 1          |
| _max_act        | 2.37304    |
| _max_adv        | 3.75       |
| _max_discrew    | 0.939      |
| _max_obs        | 1.61       |
| _mean_act       | -0.0178746 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.702      |
| _mean_obs       | 0.0402     |
| _min_adv        | -7.99      |
| _min_discrew    | -0.00411   |
| _min_obs        | -1.49      |
| _std_act        | 0.463191   |
| _std_adv        | 1          |
| _std_discrew    | 0.0455     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.969       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00241692  |
| Phi_loss        | 289.055     |
| PolicyEntropy   | 1.7029      |
| PolicyLoss      | 0.000759157 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00143     |
| _MeanReward     | 852         |
| _lr_multiplier  | 1           |
| _max_act        | 2.50115     |
| _max_adv        | 4.08        |
| _max_discrew    | 0.917       |
| _max_obs        | 1.28        |
| _mean_act       | -0.0143212  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 0.703       |
| _mean_obs       | 0.0408      |
| _min_adv        | -6.66       |
| _min_discrew    | -0.00247    |
| _min_obs        | -1.57       |
| _std_act        | 0.463473    |
| _std_adv        | 1           |
| _std_discrew    | 0.0457      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00208212 |
| Phi_loss        | 317.081    |
| PolicyEntropy   | 1.67799    |
| PolicyLoss      | -0.0242199 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00101    |
| _MeanReward     | 838        |
| _lr_multiplier  | 1          |
| _max_act        | 2.64513    |
| _max_adv        | 5.17       |
| _max_discrew    | 0.949      |
| _max_obs        | 1.37       |
| _mean_act       | -0.0162759 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.696      |
| _mean_obs       | 0.0402     |
| _min_adv        | -8.49      |
| _min_discrew    | -0.00412   |
| _min_obs        | -1.64      |
| _std_act        | 0.465812   |
| _std_adv        | 1          |
| _std_discrew    | 0.0465     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00201623  |
| Phi_loss        | 313.758     |
| PolicyEntropy   | 1.6454      |
| PolicyLoss      | -0.00150972 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00124     |
| _MeanReward     | 877         |
| _lr_multiplier  | 1           |
| _max_act        | 2.5579      |
| _max_adv        | 5.76        |
| _max_discrew    | 0.968       |
| _max_obs        | 1.52        |
| _mean_act       | -0.0157615  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.723       |
| _mean_obs       | 0.041       |
| _min_adv        | -7.56       |
| _min_discrew    | -0.00236    |
| _min_obs        | -1.56       |
| _std_act        | 0.465175    |
| _std_adv        | 1           |
| _std_discrew    | 0.0478      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.975       |
| KL              | 0.00232617  |
| Phi_loss        | 303.81      |
| PolicyEntropy   | 1.60607     |
| PolicyLoss      | -0.00446245 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00125     |
| _MeanReward     | 868         |
| _lr_multiplier  | 1           |
| _max_act        | 2.48711     |
| _max_adv        | 3.56        |
| _max_discrew    | 0.975       |
| _max_obs        | 1.4         |
| _mean_act       | -0.0174303  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.725       |
| _mean_obs       | 0.0405      |
| _min_adv        | -11.8       |
| _min_discrew    | -0.00263    |
| _min_obs        | -1.59       |
| _std_act        | 0.467198    |
| _std_adv        | 1           |
| _std_discrew    | 0.0465      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00222083 |
| Phi_loss        | 234.643    |
| PolicyEntropy   | 1.57042    |
| PolicyLoss      | 0.00261641 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00115    |
| _MeanReward     | 872        |
| _lr_multiplier  | 1          |
| _max_act        | 2.49805    |
| _max_adv        | 4.45       |
| _max_discrew    | 0.965      |
| _max_obs        | 1.66       |
| _mean_act       | -0.0160919 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 0.731      |
| _mean_obs       | 0.0407     |
| _min_adv        | -8.66      |
| _min_discrew    | -0.00221   |
| _min_obs        | -1.66      |
| _std_act        | 0.466632   |
| _std_adv        | 1          |
| _std_discrew    | 0.0486     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00413161  |
| Phi_loss        | 288.617     |
| PolicyEntropy   | 1.55172     |
| PolicyLoss      | -0.00629814 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00127     |
| _MeanReward     | 876         |
| _lr_multiplier  | 1           |
| _max_act        | 2.34766     |
| _max_adv        | 5.29        |
| _max_discrew    | 0.982       |
| _max_obs        | 1.29        |
| _mean_act       | -0.0128451  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.732       |
| _mean_obs       | 0.0408      |
| _min_adv        | -9.5        |
| _min_discrew    | -0.000503   |
| _min_obs        | -1.43       |
| _std_act        | 0.466479    |
| _std_adv        | 1           |
| _std_discrew    | 0.0502      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00220565 |
| Phi_loss        | 274.159    |
| PolicyEntropy   | 1.52461    |
| PolicyLoss      | -0.0115194 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00113    |
| _MeanReward     | 918        |
| _lr_multiplier  | 1          |
| _max_act        | 2.33419    |
| _max_adv        | 5.78       |
| _max_discrew    | 0.989      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0143078 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 0.759      |
| _mean_obs       | 0.0415     |
| _min_adv        | -3.28      |
| _min_discrew    | -0.00459   |
| _min_obs        | -1.55      |
| _std_act        | 0.468198   |
| _std_adv        | 1          |
| _std_discrew    | 0.0498     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00340215  |
| Phi_loss        | 296.867     |
| PolicyEntropy   | 1.51029     |
| PolicyLoss      | -0.00585788 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00147     |
| _MeanReward     | 902         |
| _lr_multiplier  | 1           |
| _max_act        | 2.45611     |
| _max_adv        | 3.57        |
| _max_discrew    | 0.99        |
| _max_obs        | 1.31        |
| _mean_act       | -0.00990852 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.749       |
| _mean_obs       | 0.0414      |
| _min_adv        | -7.68       |
| _min_discrew    | -0.00443    |
| _min_obs        | -1.44       |
| _std_act        | 0.470966    |
| _std_adv        | 1           |
| _std_discrew    | 0.0524      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00320865 |
| Phi_loss        | 330.715    |
| PolicyEntropy   | 1.49182    |
| PolicyLoss      | -0.0219036 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00126    |
| _MeanReward     | 904        |
| _lr_multiplier  | 1          |
| _max_act        | 2.40227    |
| _max_adv        | 4.65       |
| _max_discrew    | 0.976      |
| _max_obs        | 1.28       |
| _mean_act       | -0.0185314 |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 0.745      |
| _mean_obs       | 0.0404     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.0038    |
| _min_obs        | -1.39      |
| _std_act        | 0.465575   |
| _std_adv        | 1          |
| _std_discrew    | 0.0492     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.978       |
| ExplainedVarOld | 0.978       |
| KL              | 0.00217981  |
| Phi_loss        | 366.348     |
| PolicyEntropy   | 1.45755     |
| PolicyLoss      | 0.000334773 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00107     |
| _MeanReward     | 901         |
| _lr_multiplier  | 1           |
| _max_act        | 2.26377     |
| _max_adv        | 3.1         |
| _max_discrew    | 0.986       |
| _max_obs        | 1.47        |
| _mean_act       | -0.0119971  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.756       |
| _mean_obs       | 0.041       |
| _min_adv        | -9.04       |
| _min_discrew    | -0.00194    |
| _min_obs        | -1.65       |
| _std_act        | 0.471045    |
| _std_adv        | 1           |
| _std_discrew    | 0.0517      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00255605 |
| Phi_loss        | 295.505    |
| PolicyEntropy   | 1.44193    |
| PolicyLoss      | -0.0175101 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00137    |
| _MeanReward     | 917        |
| _lr_multiplier  | 1          |
| _max_act        | 2.50874    |
| _max_adv        | 6.05       |
| _max_discrew    | 1.03       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0190109 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 0.758      |
| _mean_obs       | 0.0407     |
| _min_adv        | -8.56      |
| _min_discrew    | -0.00308   |
| _min_obs        | -1.53      |
| _std_act        | 0.469528   |
| _std_adv        | 1          |
| _std_discrew    | 0.0529     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.975      |
| KL              | 0.0135237  |
| Phi_loss        | 365.979    |
| PolicyEntropy   | 1.41972    |
| PolicyLoss      | 0.0602626  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00122    |
| _MeanReward     | 907        |
| _lr_multiplier  | 1          |
| _max_act        | 2.52366    |
| _max_adv        | 6.05       |
| _max_discrew    | 1.02       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0173535 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.751      |
| _mean_obs       | 0.0404     |
| _min_adv        | -7.83      |
| _min_discrew    | -0.0011    |
| _min_obs        | -1.54      |
| _std_act        | 0.470012   |
| _std_adv        | 1          |
| _std_discrew    | 0.0536     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00147888 |
| Phi_loss        | 377.129    |
| PolicyEntropy   | 1.40557    |
| PolicyLoss      | 0.00215571 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00114    |
| _MeanReward     | 929        |
| _lr_multiplier  | 1          |
| _max_act        | 2.31054    |
| _max_adv        | 7.26       |
| _max_discrew    | 1.02       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0175395 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.767      |
| _mean_obs       | 0.0405     |
| _min_adv        | -11        |
| _min_discrew    | -0.00421   |
| _min_obs        | -1.54      |
| _std_act        | 0.467254   |
| _std_adv        | 1          |
| _std_discrew    | 0.0547     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.977        |
| ExplainedVarOld | 0.975        |
| KL              | 0.00214687   |
| Phi_loss        | 401.061      |
| PolicyEntropy   | 1.37763      |
| PolicyLoss      | -0.000230383 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00131      |
| _MeanReward     | 917          |
| _lr_multiplier  | 1            |
| _max_act        | 2.4463       |
| _max_adv        | 5.44         |
| _max_discrew    | 1            |
| _max_obs        | 1.29         |
| _mean_act       | -0.0165008   |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 0.758        |
| _mean_obs       | 0.0404       |
| _min_adv        | -8.95        |
| _min_discrew    | -0.00108     |
| _min_obs        | -1.36        |
| _std_act        | 0.466509     |
| _std_adv        | 1            |
| _std_discrew    | 0.0531       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0021954  |
| Phi_loss        | 371.511    |
| PolicyEntropy   | 1.35708    |
| PolicyLoss      | -0.0200381 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00101    |
| _MeanReward     | 935        |
| _lr_multiplier  | 1          |
| _max_act        | 2.44121    |
| _max_adv        | 6.13       |
| _max_discrew    | 1.04       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0145343 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.775      |
| _mean_obs       | 0.0409     |
| _min_adv        | -10.2      |
| _min_discrew    | -0.00183   |
| _min_obs        | -1.63      |
| _std_act        | 0.467874   |
| _std_adv        | 1          |
| _std_discrew    | 0.0549     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00300024 |
| Phi_loss        | 413.578    |
| PolicyEntropy   | 1.3185     |
| PolicyLoss      | -0.0094813 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00137    |
| _MeanReward     | 932        |
| _lr_multiplier  | 1          |
| _max_act        | 2.42849    |
| _max_adv        | 3.62       |
| _max_discrew    | 1.04       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0124808 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.78       |
| _mean_obs       | 0.0412     |
| _min_adv        | -12        |
| _min_discrew    | -0.00575   |
| _min_obs        | -1.63      |
| _std_act        | 0.469967   |
| _std_adv        | 1          |
| _std_discrew    | 0.0581     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.974       |
| KL              | 0.0022633   |
| Phi_loss        | 315.969     |
| PolicyEntropy   | 1.29843     |
| PolicyLoss      | -0.00219588 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0014      |
| _MeanReward     | 935         |
| _lr_multiplier  | 1           |
| _max_act        | 2.71697     |
| _max_adv        | 6.69        |
| _max_discrew    | 1.01        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0133656  |
| _mean_adv       | 5.12e-17    |
| _mean_discrew   | 0.771       |
| _mean_obs       | 0.0408      |
| _min_adv        | -9.69       |
| _min_discrew    | -0.00501    |
| _min_obs        | -1.42       |
| _std_act        | 0.474626    |
| _std_adv        | 1           |
| _std_discrew    | 0.0547      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0129024  |
| Phi_loss        | 429.885    |
| PolicyEntropy   | 1.26869    |
| PolicyLoss      | 0.0599561  |
| Steps           | 10000      |
| VarFuncLoss     | 0.000988   |
| _MeanReward     | 930        |
| _lr_multiplier  | 1          |
| _max_act        | 2.2588     |
| _max_adv        | 5.57       |
| _max_discrew    | 1.02       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0124227 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.78       |
| _mean_obs       | 0.0405     |
| _min_adv        | -10.5      |
| _min_discrew    | -0.00193   |
| _min_obs        | -1.6       |
| _std_act        | 0.469178   |
| _std_adv        | 1          |
| _std_discrew    | 0.0562     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00273556  |
| Phi_loss        | 386.478     |
| PolicyEntropy   | 1.26032     |
| PolicyLoss      | 0.00785704  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00133     |
| _MeanReward     | 925         |
| _lr_multiplier  | 1           |
| _max_act        | 2.48814     |
| _max_adv        | 3.83        |
| _max_discrew    | 1.05        |
| _max_obs        | 1.45        |
| _mean_act       | -0.00983308 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.782       |
| _mean_obs       | 0.0407      |
| _min_adv        | -9.86       |
| _min_discrew    | -0.00244    |
| _min_obs        | -1.4        |
| _std_act        | 0.472952    |
| _std_adv        | 1           |
| _std_discrew    | 0.0551      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.966       |
| KL              | 0.00185832  |
| Phi_loss        | 376.967     |
| PolicyEntropy   | 1.24084     |
| PolicyLoss      | -0.0187179  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00162     |
| _MeanReward     | 938         |
| _lr_multiplier  | 1           |
| _max_act        | 2.23109     |
| _max_adv        | 6.84        |
| _max_discrew    | 1.03        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00993414 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.778       |
| _mean_obs       | 0.041       |
| _min_adv        | -9.49       |
| _min_discrew    | -0.00344    |
| _min_obs        | -1.58       |
| _std_act        | 0.470251    |
| _std_adv        | 1           |
| _std_discrew    | 0.0564      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00167103 |
| Phi_loss        | 420.244    |
| PolicyEntropy   | 1.22929    |
| PolicyLoss      | -0.0363495 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00169    |
| _MeanReward     | 942        |
| _lr_multiplier  | 1          |
| _max_act        | 2.35509    |
| _max_adv        | 7.07       |
| _max_discrew    | 1.02       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0111956 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.78       |
| _mean_obs       | 0.0408     |
| _min_adv        | -7.61      |
| _min_discrew    | -0.00446   |
| _min_obs        | -1.38      |
| _std_act        | 0.470808   |
| _std_adv        | 1          |
| _std_discrew    | 0.0549     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00119707 |
| Phi_loss        | 377.617    |
| PolicyEntropy   | 1.22013    |
| PolicyLoss      | 0.00720322 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00131    |
| _MeanReward     | 973        |
| _lr_multiplier  | 1          |
| _max_act        | 2.23638    |
| _max_adv        | 8.71       |
| _max_discrew    | 1.05       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0111814 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.798      |
| _mean_obs       | 0.0412     |
| _min_adv        | -5.73      |
| _min_discrew    | -0.00111   |
| _min_obs        | -1.43      |
| _std_act        | 0.470406   |
| _std_adv        | 1          |
| _std_discrew    | 0.0587     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00195224  |
| Phi_loss        | 451.385     |
| PolicyEntropy   | 1.18047     |
| PolicyLoss      | -0.00610748 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00099     |
| _MeanReward     | 978         |
| _lr_multiplier  | 1           |
| _max_act        | 2.413       |
| _max_adv        | 5.34        |
| _max_discrew    | 1.07        |
| _max_obs        | 1.39        |
| _mean_act       | -0.010677   |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 0.803       |
| _mean_obs       | 0.0412      |
| _min_adv        | -5.09       |
| _min_discrew    | -0.00457    |
| _min_obs        | -1.46       |
| _std_act        | 0.465273    |
| _std_adv        | 1           |
| _std_discrew    | 0.0614      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00211411  |
| Phi_loss        | 451.593     |
| PolicyEntropy   | 1.14906     |
| PolicyLoss      | -0.00783788 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000942    |
| _MeanReward     | 978         |
| _lr_multiplier  | 1           |
| _max_act        | 2.31998     |
| _max_adv        | 3.31        |
| _max_discrew    | 1.08        |
| _max_obs        | 1.45        |
| _mean_act       | -0.010755   |
| _mean_adv       | 9.95e-18    |
| _mean_discrew   | 0.81        |
| _mean_obs       | 0.0411      |
| _min_adv        | -10.2       |
| _min_discrew    | -0.00373    |
| _min_obs        | -1.5        |
| _std_act        | 0.467955    |
| _std_adv        | 1           |
| _std_discrew    | 0.0623      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00313032  |
| Phi_loss        | 360.577     |
| PolicyEntropy   | 1.1209      |
| PolicyLoss      | -0.0102284  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00167     |
| _MeanReward     | 976         |
| _lr_multiplier  | 1           |
| _max_act        | 2.26346     |
| _max_adv        | 5           |
| _max_discrew    | 1.06        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00766204 |
| _mean_adv       | -1.85e-17   |
| _mean_discrew   | 0.811       |
| _mean_obs       | 0.0415      |
| _min_adv        | -13         |
| _min_discrew    | -0.00477    |
| _min_obs        | -1.62       |
| _std_act        | 0.469944    |
| _std_adv        | 1           |
| _std_discrew    | 0.0623      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.968       |
| KL              | 0.00919427  |
| Phi_loss        | 295.658     |
| PolicyEntropy   | 1.11148     |
| PolicyLoss      | -0.00274956 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00175     |
| _MeanReward     | 995         |
| _lr_multiplier  | 1           |
| _max_act        | 2.33995     |
| _max_adv        | 9.35        |
| _max_discrew    | 1.07        |
| _max_obs        | 1.43        |
| _mean_act       | -0.00831761 |
| _mean_adv       | 2.7e-17     |
| _mean_discrew   | 0.819       |
| _mean_obs       | 0.0415      |
| _min_adv        | -7.84       |
| _min_discrew    | -0.00684    |
| _min_obs        | -1.41       |
| _std_act        | 0.463798    |
| _std_adv        | 1           |
| _std_discrew    | 0.0605      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00160859  |
| Phi_loss        | 429.593     |
| PolicyEntropy   | 1.08221     |
| PolicyLoss      | 0.00653457  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000907    |
| _MeanReward     | 993         |
| _lr_multiplier  | 1           |
| _max_act        | 2.319       |
| _max_adv        | 7.13        |
| _max_discrew    | 1.1         |
| _max_obs        | 1.74        |
| _mean_act       | -0.00755078 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.82        |
| _mean_obs       | 0.0418      |
| _min_adv        | -8.36       |
| _min_discrew    | -0.00391    |
| _min_obs        | -1.47       |
| _std_act        | 0.474102    |
| _std_adv        | 1           |
| _std_discrew    | 0.0611      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00122106  |
| Phi_loss        | 458.188     |
| PolicyEntropy   | 1.05793     |
| PolicyLoss      | -0.015646   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00119     |
| _MeanReward     | 986         |
| _lr_multiplier  | 1           |
| _max_act        | 2.32243     |
| _max_adv        | 7.05        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00709273 |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | 0.813       |
| _mean_obs       | 0.0414      |
| _min_adv        | -10.2       |
| _min_discrew    | -0.00314    |
| _min_obs        | -1.42       |
| _std_act        | 0.466636    |
| _std_adv        | 1           |
| _std_discrew    | 0.0594      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00187742  |
| Phi_loss        | 491.071     |
| PolicyEntropy   | 1.03902     |
| PolicyLoss      | -0.0113256  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000916    |
| _MeanReward     | 1e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 2.25958     |
| _max_adv        | 3.65        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00510687 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.821       |
| _mean_obs       | 0.0417      |
| _min_adv        | -3.41       |
| _min_discrew    | -0.00336    |
| _min_obs        | -1.52       |
| _std_act        | 0.465869    |
| _std_adv        | 1           |
| _std_discrew    | 0.0626      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.978       |
| KL              | 0.00191833  |
| Phi_loss        | 545.033     |
| PolicyEntropy   | 1.00522     |
| PolicyLoss      | -0.0162215  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00131     |
| _MeanReward     | 1.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.46563     |
| _max_adv        | 7.03        |
| _max_discrew    | 1.13        |
| _max_obs        | 1.22        |
| _mean_act       | -0.00323986 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.837       |
| _mean_obs       | 0.042       |
| _min_adv        | -8.11       |
| _min_discrew    | -0.0026     |
| _min_obs        | -1.55       |
| _std_act        | 0.468155    |
| _std_adv        | 1           |
| _std_discrew    | 0.0648      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00213288  |
| Phi_loss        | 462.062     |
| PolicyEntropy   | 0.982376    |
| PolicyLoss      | -0.00522708 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00118     |
| _MeanReward     | 986         |
| _lr_multiplier  | 1           |
| _max_act        | 2.33478     |
| _max_adv        | 4.19        |
| _max_discrew    | 1.08        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00622128 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.818       |
| _mean_obs       | 0.0411      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.0038     |
| _min_obs        | -1.42       |
| _std_act        | 0.469519    |
| _std_adv        | 1           |
| _std_discrew    | 0.066       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.978       |
| KL              | 0.00256427  |
| Phi_loss        | 446.029     |
| PolicyEntropy   | 0.957575    |
| PolicyLoss      | 0.0237808   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00136     |
| _MeanReward     | 1.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.29569     |
| _max_adv        | 4.8         |
| _max_discrew    | 1.09        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00835234 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.838       |
| _mean_obs       | 0.0412      |
| _min_adv        | -7.08       |
| _min_discrew    | -0.00367    |
| _min_obs        | -1.41       |
| _std_act        | 0.465045    |
| _std_adv        | 1           |
| _std_discrew    | 0.0637      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00278976  |
| Phi_loss        | 522.201     |
| PolicyEntropy   | 0.927581    |
| PolicyLoss      | 0.00788754  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0012      |
| _MeanReward     | 1.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.20795     |
| _max_adv        | 5.85        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00477108 |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 0.837       |
| _mean_obs       | 0.0416      |
| _min_adv        | -13.3       |
| _min_discrew    | -0.00826    |
| _min_obs        | -1.48       |
| _std_act        | 0.46936     |
| _std_adv        | 1           |
| _std_discrew    | 0.0686      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.0032857   |
| Phi_loss        | 423.424     |
| PolicyEntropy   | 0.905982    |
| PolicyLoss      | -0.0243886  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00118     |
| _MeanReward     | 1.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.23851     |
| _max_adv        | 4.68        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00351847 |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 0.849       |
| _mean_obs       | 0.0418      |
| _min_adv        | -3.85       |
| _min_discrew    | -0.00334    |
| _min_obs        | -1.44       |
| _std_act        | 0.463213    |
| _std_adv        | 1           |
| _std_discrew    | 0.0686      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00228543  |
| Phi_loss        | 547.699     |
| PolicyEntropy   | 0.878787    |
| PolicyLoss      | -0.0119836  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0016      |
| _MeanReward     | 1.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.21848     |
| _max_adv        | 6.38        |
| _max_discrew    | 1.09        |
| _max_obs        | 1.36        |
| _mean_act       | 0.000181045 |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 0.837       |
| _mean_obs       | 0.0419      |
| _min_adv        | -11.2       |
| _min_discrew    | -0.00314    |
| _min_obs        | -1.53       |
| _std_act        | 0.463512    |
| _std_adv        | 1           |
| _std_discrew    | 0.0623      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.979        |
| ExplainedVarOld | 0.977        |
| KL              | 0.00275322   |
| Phi_loss        | 434.344      |
| PolicyEntropy   | 0.862644     |
| PolicyLoss      | 0.006089     |
| Steps           | 10000        |
| VarFuncLoss     | 0.0013       |
| _MeanReward     | 1.02e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.29933      |
| _max_adv        | 5.02         |
| _max_discrew    | 1.11         |
| _max_obs        | 1.27         |
| _mean_act       | -0.000715955 |
| _mean_adv       | 4.55e-17     |
| _mean_discrew   | 0.839        |
| _mean_obs       | 0.042        |
| _min_adv        | -11.2        |
| _min_discrew    | -0.00353     |
| _min_obs        | -1.43        |
| _std_act        | 0.468233     |
| _std_adv        | 1            |
| _std_discrew    | 0.0654       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00358802  |
| Phi_loss        | 509.652     |
| PolicyEntropy   | 0.835835    |
| PolicyLoss      | -0.00615407 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00153     |
| _MeanReward     | 1.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.38985     |
| _max_adv        | 4.97        |
| _max_discrew    | 1.14        |
| _max_obs        | 1.41        |
| _mean_act       | -0.00352721 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.851       |
| _mean_obs       | 0.0418      |
| _min_adv        | -4.14       |
| _min_discrew    | -0.00582    |
| _min_obs        | -1.55       |
| _std_act        | 0.465357    |
| _std_adv        | 1           |
| _std_discrew    | 0.0666      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.978       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00172008  |
| Phi_loss        | 568.621     |
| PolicyEntropy   | 0.811033    |
| PolicyLoss      | 0.0128793   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00151     |
| _MeanReward     | 1.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.26135     |
| _max_adv        | 5.99        |
| _max_discrew    | 1.13        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00258391 |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.857       |
| _mean_obs       | 0.0419      |
| _min_adv        | -9.51       |
| _min_discrew    | -0.00194    |
| _min_obs        | -1.5        |
| _std_act        | 0.46784     |
| _std_adv        | 1           |
| _std_discrew    | 0.0681      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00224913  |
| Phi_loss        | 525.329     |
| PolicyEntropy   | 0.792624    |
| PolicyLoss      | -0.0123714  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00111     |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.29013     |
| _max_adv        | 9.01        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.44        |
| _mean_act       | -0.00282092 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 0.861       |
| _mean_obs       | 0.0421      |
| _min_adv        | -8.32       |
| _min_discrew    | -0.00294    |
| _min_obs        | -1.56       |
| _std_act        | 0.464207    |
| _std_adv        | 1           |
| _std_discrew    | 0.0681      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00609825 |
| Phi_loss        | 588.469    |
| PolicyEntropy   | 0.777946   |
| PolicyLoss      | -0.043915  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00109    |
| _MeanReward     | 1.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35       |
| _max_adv        | 3.59       |
| _max_discrew    | 1.13       |
| _max_obs        | 1.28       |
| _mean_act       | 0.00127333 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.848      |
| _mean_obs       | 0.0417     |
| _min_adv        | -9.57      |
| _min_discrew    | -0.00166   |
| _min_obs        | -1.46      |
| _std_act        | 0.465554   |
| _std_adv        | 1          |
| _std_discrew    | 0.067      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.983        |
| ExplainedVarOld | 0.981        |
| KL              | 0.00146146   |
| Phi_loss        | 563.884      |
| PolicyEntropy   | 0.753496     |
| PolicyLoss      | 0.00814612   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0012       |
| _MeanReward     | 1.05e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.33693      |
| _max_adv        | 4.88         |
| _max_discrew    | 1.14         |
| _max_obs        | 1.35         |
| _mean_act       | -0.000128782 |
| _mean_adv       | 3.41e-17     |
| _mean_discrew   | 0.866        |
| _mean_obs       | 0.0422       |
| _min_adv        | -4           |
| _min_discrew    | -0.000614    |
| _min_obs        | -1.44        |
| _std_act        | 0.465331     |
| _std_adv        | 1            |
| _std_discrew    | 0.0687       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00208879  |
| Phi_loss        | 605.301     |
| PolicyEntropy   | 0.73309     |
| PolicyLoss      | 0.00112174  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00154     |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.3255      |
| _max_adv        | 6.86        |
| _max_discrew    | 1.14        |
| _max_obs        | 1.33        |
| _mean_act       | 0.000118918 |
| _mean_adv       | -4.41e-17   |
| _mean_discrew   | 0.866       |
| _mean_obs       | 0.0421      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.00365    |
| _min_obs        | -1.63       |
| _std_act        | 0.464859    |
| _std_adv        | 1           |
| _std_discrew    | 0.0695      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00257441  |
| Phi_loss        | 604.658     |
| PolicyEntropy   | 0.701565    |
| PolicyLoss      | -0.00290151 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000925    |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.18813     |
| _max_adv        | 5.54        |
| _max_discrew    | 1.14        |
| _max_obs        | 1.38        |
| _mean_act       | 0.000150765 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.865       |
| _mean_obs       | 0.0419      |
| _min_adv        | -8.92       |
| _min_discrew    | -0.00539    |
| _min_obs        | -1.47       |
| _std_act        | 0.46645     |
| _std_adv        | 1           |
| _std_discrew    | 0.0698      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.988        |
| ExplainedVarOld | 0.988        |
| KL              | 0.00355961   |
| Phi_loss        | 595.979      |
| PolicyEntropy   | 0.680513     |
| PolicyLoss      | 0.0145956    |
| Steps           | 10000        |
| VarFuncLoss     | 0.00084      |
| _MeanReward     | 1.05e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.23585      |
| _max_adv        | 4.61         |
| _max_discrew    | 1.14         |
| _max_obs        | 1.68         |
| _mean_act       | -0.000506494 |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | 0.87         |
| _mean_obs       | 0.0419       |
| _min_adv        | -15          |
| _min_discrew    | -6.97e-06    |
| _min_obs        | -1.61        |
| _std_act        | 0.467174     |
| _std_adv        | 1            |
| _std_discrew    | 0.0672       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00499425  |
| Phi_loss        | 582.8       |
| PolicyEntropy   | 0.660078    |
| PolicyLoss      | 0.0156153   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00154     |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.27886     |
| _max_adv        | 3.9         |
| _max_discrew    | 1.15        |
| _max_obs        | 1.18        |
| _mean_act       | 0.000879706 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.87        |
| _mean_obs       | 0.0419      |
| _min_adv        | -6.19       |
| _min_discrew    | -0.00226    |
| _min_obs        | -1.46       |
| _std_act        | 0.464779    |
| _std_adv        | 1           |
| _std_discrew    | 0.0702      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00222498  |
| Phi_loss        | 723.218     |
| PolicyEntropy   | 0.636696    |
| PolicyLoss      | -0.0143737  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000812    |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.15005     |
| _max_adv        | 7           |
| _max_discrew    | 1.14        |
| _max_obs        | 1.54        |
| _mean_act       | 0.000307661 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.873       |
| _mean_obs       | 0.0419      |
| _min_adv        | -3.95       |
| _min_discrew    | -0.00146    |
| _min_obs        | -1.45       |
| _std_act        | 0.461199    |
| _std_adv        | 1           |
| _std_discrew    | 0.0706      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00204539 |
| Phi_loss        | 671.507    |
| PolicyEntropy   | 0.615346   |
| PolicyLoss      | -0.010993  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00128    |
| _MeanReward     | 1.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.21255    |
| _max_adv        | 4.8        |
| _max_discrew    | 1.17       |
| _max_obs        | 1.4        |
| _mean_act       | 0.0022372  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.882      |
| _mean_obs       | 0.0421     |
| _min_adv        | -10        |
| _min_discrew    | -0.00222   |
| _min_obs        | -1.47      |
| _std_act        | 0.462322   |
| _std_adv        | 1          |
| _std_discrew    | 0.0722     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00272487  |
| Phi_loss        | 580.512     |
| PolicyEntropy   | 0.604839    |
| PolicyLoss      | -0.0202998  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00128     |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.47628     |
| _max_adv        | 6.23        |
| _max_discrew    | 1.15        |
| _max_obs        | 1.35        |
| _mean_act       | -0.00110473 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.875       |
| _mean_obs       | 0.0416      |
| _min_adv        | -4.21       |
| _min_discrew    | -0.00431    |
| _min_obs        | -1.47       |
| _std_act        | 0.463914    |
| _std_adv        | 1           |
| _std_discrew    | 0.071       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00244828 |
| Phi_loss        | 686.877    |
| PolicyEntropy   | 0.597433   |
| PolicyLoss      | -0.0339742 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00109    |
| _MeanReward     | 1.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.14045    |
| _max_adv        | 8.76       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.37       |
| _mean_act       | 0.00135671 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.886      |
| _mean_obs       | 0.0422     |
| _min_adv        | -3.75      |
| _min_discrew    | -0.00259   |
| _min_obs        | -1.46      |
| _std_act        | 0.461259   |
| _std_adv        | 1          |
| _std_discrew    | 0.0733     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00176211 |
| Phi_loss        | 691.784    |
| PolicyEntropy   | 0.575233   |
| PolicyLoss      | -0.0134233 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0012     |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.19972    |
| _max_adv        | 4.02       |
| _max_discrew    | 1.15       |
| _max_obs        | 1.46       |
| _mean_act       | 0.00300501 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.881      |
| _mean_obs       | 0.042      |
| _min_adv        | -12.6      |
| _min_discrew    | -0.0016    |
| _min_obs        | -1.47      |
| _std_act        | 0.462407   |
| _std_adv        | 1          |
| _std_discrew    | 0.0706     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.984       |
| KL              | 0.0024226   |
| Phi_loss        | 567.585     |
| PolicyEntropy   | 0.552723    |
| PolicyLoss      | -0.00930331 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00103     |
| _MeanReward     | 1.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.12991     |
| _max_adv        | 7.83        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00200037 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.893       |
| _mean_obs       | 0.0415      |
| _min_adv        | -10.1       |
| _min_discrew    | -0.00318    |
| _min_obs        | -1.58       |
| _std_act        | 0.465426    |
| _std_adv        | 1           |
| _std_discrew    | 0.0729      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00693651 |
| Phi_loss        | 692.54     |
| PolicyEntropy   | 0.528182   |
| PolicyLoss      | -0.0592998 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000965   |
| _MeanReward     | 1.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.12909    |
| _max_adv        | 5.15       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.44       |
| _mean_act       | 0.00254462 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.893      |
| _mean_obs       | 0.0422     |
| _min_adv        | -3.57      |
| _min_discrew    | -0.00396   |
| _min_obs        | -1.46      |
| _std_act        | 0.464874   |
| _std_adv        | 1          |
| _std_discrew    | 0.0746     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.986        |
| ExplainedVarOld | 0.986        |
| KL              | 0.00132304   |
| Phi_loss        | 747.191      |
| PolicyEntropy   | 0.502007     |
| PolicyLoss      | 0.0039234    |
| Steps           | 10000        |
| VarFuncLoss     | 0.00104      |
| _MeanReward     | 1.1e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 2.25024      |
| _max_adv        | 5.44         |
| _max_discrew    | 1.17         |
| _max_obs        | 1.53         |
| _mean_act       | -0.000155452 |
| _mean_adv       | 3.98e-17     |
| _mean_discrew   | 0.903        |
| _mean_obs       | 0.0419       |
| _min_adv        | -4.03        |
| _min_discrew    | -0.0014      |
| _min_obs        | -1.47        |
| _std_act        | 0.464432     |
| _std_adv        | 1            |
| _std_discrew    | 0.073        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00154685 |
| Phi_loss        | 780.021    |
| PolicyEntropy   | 0.477012   |
| PolicyLoss      | 0.00873402 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000937   |
| _MeanReward     | 1.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.11079    |
| _max_adv        | 2.92       |
| _max_discrew    | 1.21       |
| _max_obs        | 1.35       |
| _mean_act       | 0.00392844 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.897      |
| _mean_obs       | 0.0423     |
| _min_adv        | -3.43      |
| _min_discrew    | -0.00343   |
| _min_obs        | -1.55      |
| _std_act        | 0.467915   |
| _std_adv        | 1          |
| _std_discrew    | 0.0733     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00189179  |
| Phi_loss        | 810.022     |
| PolicyEntropy   | 0.470159    |
| PolicyLoss      | 0.00698323  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00116     |
| _MeanReward     | 1.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.26387     |
| _max_adv        | 3.36        |
| _max_discrew    | 1.18        |
| _max_obs        | 1.31        |
| _mean_act       | 0.000540243 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.91        |
| _mean_obs       | 0.0419      |
| _min_adv        | -4.64       |
| _min_discrew    | -0.00435    |
| _min_obs        | -1.49       |
| _std_act        | 0.460853    |
| _std_adv        | 1           |
| _std_discrew    | 0.0756      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00153852  |
| Phi_loss        | 740.268     |
| PolicyEntropy   | 0.464744    |
| PolicyLoss      | -0.0154632  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00113     |
| _MeanReward     | 1.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.17468     |
| _max_adv        | 3.78        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.5         |
| _mean_act       | 0.000474568 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.913       |
| _mean_obs       | 0.0422      |
| _min_adv        | -3.73       |
| _min_discrew    | -0.00308    |
| _min_obs        | -1.52       |
| _std_act        | 0.461805    |
| _std_adv        | 1           |
| _std_discrew    | 0.0738      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0029567  |
| Phi_loss        | 781.428    |
| PolicyEntropy   | 0.446408   |
| PolicyLoss      | 0.0146069  |
| Steps           | 10000      |
| VarFuncLoss     | 0.000979   |
| _MeanReward     | 1.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24123    |
| _max_adv        | 3.32       |
| _max_discrew    | 1.19       |
| _max_obs        | 1.4        |
| _mean_act       | 0.00277259 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 0.896      |
| _mean_obs       | 0.0418     |
| _min_adv        | -13.4      |
| _min_discrew    | -0.00243   |
| _min_obs        | -1.52      |
| _std_act        | 0.464126   |
| _std_adv        | 1          |
| _std_discrew    | 0.076      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00243733 |
| Phi_loss        | 648.862    |
| PolicyEntropy   | 0.415807   |
| PolicyLoss      | 0.0136545  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00133    |
| _MeanReward     | 1.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.1104     |
| _max_adv        | 4.37       |
| _max_discrew    | 1.2        |
| _max_obs        | 1.43       |
| _mean_act       | 0.00421442 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.927      |
| _mean_obs       | 0.0426     |
| _min_adv        | -3.73      |
| _min_discrew    | -0.00307   |
| _min_obs        | -1.5       |
| _std_act        | 0.462931   |
| _std_adv        | 1          |
| _std_discrew    | 0.0775     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00234604 |
| Phi_loss        | 801.133    |
| PolicyEntropy   | 0.391062   |
| PolicyLoss      | 0.013858   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00114    |
| _MeanReward     | 1.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.13162    |
| _max_adv        | 3.09       |
| _max_discrew    | 1.2        |
| _max_obs        | 1.32       |
| _mean_act       | 0.00232298 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.912      |
| _mean_obs       | 0.0417     |
| _min_adv        | -9.11      |
| _min_discrew    | -0.00354   |
| _min_obs        | -1.59      |
| _std_act        | 0.455334   |
| _std_adv        | 1          |
| _std_discrew    | 0.0807     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00284892  |
| Phi_loss        | 721.007     |
| PolicyEntropy   | 0.364799    |
| PolicyLoss      | -0.00978959 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000869    |
| _MeanReward     | 1.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.1841      |
| _max_adv        | 5.15        |
| _max_discrew    | 1.2         |
| _max_obs        | 1.41        |
| _mean_act       | 0.0048938   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.914       |
| _mean_obs       | 0.0421      |
| _min_adv        | -3.42       |
| _min_discrew    | -0.00394    |
| _min_obs        | -1.63       |
| _std_act        | 0.461188    |
| _std_adv        | 1           |
| _std_discrew    | 0.0775      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00231735 |
| Phi_loss        | 820.318    |
| PolicyEntropy   | 0.343055   |
| PolicyLoss      | 0.00811062 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000793   |
| _MeanReward     | 1.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.17279    |
| _max_adv        | 8.36       |
| _max_discrew    | 1.2        |
| _max_obs        | 1.42       |
| _mean_act       | 0.00441633 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.931      |
| _mean_obs       | 0.0424     |
| _min_adv        | -12.6      |
| _min_discrew    | -0.0046    |
| _min_obs        | -1.49      |
| _std_act        | 0.462865   |
| _std_adv        | 1          |
| _std_discrew    | 0.0828     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00545221 |
| Phi_loss        | 824.997    |
| PolicyEntropy   | 0.311559   |
| PolicyLoss      | -0.0134463 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000971   |
| _MeanReward     | 1.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.06281    |
| _max_adv        | 2.68       |
| _max_discrew    | 1.25       |
| _max_obs        | 1.37       |
| _mean_act       | 0.00421273 |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 0.934      |
| _mean_obs       | 0.0422     |
| _min_adv        | -11.2      |
| _min_discrew    | -0.000231  |
| _min_obs        | -1.5       |
| _std_act        | 0.45897    |
| _std_adv        | 1          |
| _std_discrew    | 0.0814     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00370439 |
| Phi_loss        | 572.45     |
| PolicyEntropy   | 0.299701   |
| PolicyLoss      | -0.0322903 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00138    |
| _MeanReward     | 1.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.1564     |
| _max_adv        | 9.61       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.43       |
| _mean_act       | 0.00396195 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.919      |
| _mean_obs       | 0.0418     |
| _min_adv        | -15.6      |
| _min_discrew    | -0.00342   |
| _min_obs        | -1.5       |
| _std_act        | 0.460975   |
| _std_adv        | 1          |
| _std_discrew    | 0.0771     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00338867 |
| Phi_loss        | 697.212    |
| PolicyEntropy   | 0.274501   |
| PolicyLoss      | 0.0157185  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00113    |
| _MeanReward     | 1.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.04649    |
| _max_adv        | 6.37       |
| _max_discrew    | 1.22       |
| _max_obs        | 1.46       |
| _mean_act       | 0.003037   |
| _mean_adv       | 0          |
| _mean_discrew   | 0.93       |
| _mean_obs       | 0.0419     |
| _min_adv        | -3.28      |
| _min_discrew    | 0.00264    |
| _min_obs        | -1.54      |
| _std_act        | 0.457185   |
| _std_adv        | 1          |
| _std_discrew    | 0.0784     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.989      |
| KL              | 0.0137435  |
| Phi_loss        | 839.375    |
| PolicyEntropy   | 0.259732   |
| PolicyLoss      | 0.109253   |
| Steps           | 10000      |
| VarFuncLoss     | 0.000763   |
| _MeanReward     | 1.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24529    |
| _max_adv        | 6.86       |
| _max_discrew    | 1.27       |
| _max_obs        | 1.62       |
| _mean_act       | 0.00183535 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 0.93       |
| _mean_obs       | 0.0419     |
| _min_adv        | -13.5      |
| _min_discrew    | -0.00282   |
| _min_obs        | -1.63      |
| _std_act        | 0.460125   |
| _std_adv        | 1          |
| _std_discrew    | 0.0839     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.978       |
| KL              | 0.00383227  |
| Phi_loss        | 638.961     |
| PolicyEntropy   | 0.252386    |
| PolicyLoss      | -0.00195224 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00162     |
| _MeanReward     | 1.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.08159     |
| _max_adv        | 11.2        |
| _max_discrew    | 1.25        |
| _max_obs        | 1.48        |
| _mean_act       | -0.00319056 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.93        |
| _mean_obs       | 0.0405      |
| _min_adv        | -12.1       |
| _min_discrew    | -0.00249    |
| _min_obs        | -1.6        |
| _std_act        | 0.461547    |
| _std_adv        | 1           |
| _std_discrew    | 0.0834      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00443145 |
| Phi_loss        | 663.736    |
| PolicyEntropy   | 0.245183   |
| PolicyLoss      | -0.0151682 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00158    |
| _MeanReward     | 1.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.26427    |
| _max_adv        | 11.8       |
| _max_discrew    | 1.22       |
| _max_obs        | 1.45       |
| _mean_act       | 0.0013049  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.941      |
| _mean_obs       | 0.0417     |
| _min_adv        | -11.6      |
| _min_discrew    | 0.00351    |
| _min_obs        | -1.53      |
| _std_act        | 0.463809   |
| _std_adv        | 1          |
| _std_discrew    | 0.081      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0168078  |
| Phi_loss        | 1041.99    |
| PolicyEntropy   | 0.240895   |
| PolicyLoss      | -0.223461  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00151    |
| _MeanReward     | 1.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.18569    |
| _max_adv        | 9.41       |
| _max_discrew    | 1.24       |
| _max_obs        | 1.42       |
| _mean_act       | 0.00217303 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.944      |
| _mean_obs       | 0.0418     |
| _min_adv        | -7.76      |
| _min_discrew    | -0.00191   |
| _min_obs        | -1.5       |
| _std_act        | 0.458267   |
| _std_adv        | 1          |
| _std_discrew    | 0.0811     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
---------------------------------
| Beta            | 1.5         |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.0149568   |
| Phi_loss        | 964.135     |
| PolicyEntropy   | 0.241948    |
| PolicyLoss      | -0.00143875 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000985    |
| _MeanReward     | 1.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.1148      |
| _max_adv        | 8.25        |
| _max_discrew    | 1.22        |
| _max_obs        | 1.31        |
| _mean_act       | 0.00708544  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.932       |
| _mean_obs       | 0.0423      |
| _min_adv        | -3.62       |
| _min_discrew    | -0.0048     |
| _min_obs        | -1.53       |
| _std_act        | 0.463968    |
| _std_adv        | 1           |
| _std_discrew    | 0.0793      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
-------------------------------
| Beta            | 2.25      |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.986     |
| KL              | 0.0296399 |
| Phi_loss        | 892.849   |
| PolicyEntropy   | 0.241895  |
| PolicyLoss      | 0.066995  |
| Steps           | 10000     |
| VarFuncLoss     | 0.000971  |
| _MeanReward     | 1.13e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.11227   |
| _max_adv        | 4.54      |
| _max_discrew    | 1.2       |
| _max_obs        | 1.48      |
| _mean_act       | 0.0110378 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 0.936     |
| _mean_obs       | 0.0435    |
| _min_adv        | -11.6     |
| _min_discrew    | -0.00353  |
| _min_obs        | -1.59     |
| _std_act        | 0.473633  |
| _std_adv        | 1         |
| _std_discrew    | 0.0815    |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
-------------------------------
| Beta            | 3.38      |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.987     |
| KL              | 0.0216845 |
| Phi_loss        | 1017.48   |
| PolicyEntropy   | 0.241465  |
| PolicyLoss      | 0.0772431 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00102   |
| _MeanReward     | 1.15e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.04989   |
| _max_adv        | 5.31      |
| _max_discrew    | 1.23      |
| _max_obs        | 1.41      |
| _mean_act       | 0.0177129 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 0.942     |
| _mean_obs       | 0.0446    |
| _min_adv        | -3.74     |
| _min_discrew    | -0.00277  |
| _min_obs        | -1.5      |
| _std_act        | 0.48335   |
| _std_adv        | 1         |
| _std_discrew    | 0.083     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
-------------------------------
| Beta            | 5.06      |
| ExplainedVarNew | 0.99      |
| ExplainedVarOld | 0.99      |
| KL              | 0.0165233 |
| Phi_loss        | 974.42    |
| PolicyEntropy   | 0.240556  |
| PolicyLoss      | 0.0473153 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00085   |
| _MeanReward     | 1.11e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.02378   |
| _max_adv        | 3.75      |
| _max_discrew    | 1.21      |
| _max_obs        | 1.37      |
| _mean_act       | 0.0198134 |
| _mean_adv       | 6.82e-17  |
| _mean_discrew   | 0.915     |
| _mean_obs       | 0.0447    |
| _min_adv        | -3.86     |
| _min_discrew    | -0.00319  |
| _min_obs        | -1.57     |
| _std_act        | 0.49228   |
| _std_adv        | 1         |
| _std_discrew    | 0.079     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
-------------------------------
| Beta            | 7.59      |
| ExplainedVarNew | 0.985     |
| ExplainedVarOld | 0.983     |
| KL              | 0.0126399 |
| Phi_loss        | 935.865   |
| PolicyEntropy   | 0.239319  |
| PolicyLoss      | 0.076788  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00139   |
| _MeanReward     | 1.11e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.07552   |
| _max_adv        | 5.22      |
| _max_discrew    | 1.24      |
| _max_obs        | 1.41      |
| _mean_act       | 0.0204812 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 0.911     |
| _mean_obs       | 0.045     |
| _min_adv        | -4.96     |
| _min_discrew    | -0.00127  |
| _min_obs        | -1.7      |
| _std_act        | 0.497768  |
| _std_adv        | 1         |
| _std_discrew    | 0.0765    |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
-------------------------------
| Beta            | 11.4      |
| ExplainedVarNew | 0.983     |
| ExplainedVarOld | 0.982     |
| KL              | 0.0923552 |
| Phi_loss        | 1080.2    |
| PolicyEntropy   | 0.238092  |
| PolicyLoss      | 1.05781   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0013    |
| _MeanReward     | 1.12e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.17396   |
| _max_adv        | 3.61      |
| _max_discrew    | 1.23      |
| _max_obs        | 1.56      |
| _mean_act       | 0.0121082 |
| _mean_adv       | 2.56e-17  |
| _mean_discrew   | 0.929     |
| _mean_obs       | 0.0433    |
| _min_adv        | -12.6     |
| _min_discrew    | -0.00106  |
| _min_obs        | -1.54     |
| _std_act        | 0.474147  |
| _std_adv        | 1         |
| _std_discrew    | 0.0813    |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
---------------------------------
| Beta            | 17.1        |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.127604    |
| Phi_loss        | 857.544     |
| PolicyEntropy   | 0.238301    |
| PolicyLoss      | 2.19935     |
| Steps           | 10000       |
| VarFuncLoss     | 0.00116     |
| _MeanReward     | 1.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.02849     |
| _max_adv        | 6.13        |
| _max_discrew    | 1.22        |
| _max_obs        | 1.54        |
| _mean_act       | 0.000865146 |
| _mean_adv       | -2.13e-17   |
| _mean_discrew   | 0.925       |
| _mean_obs       | 0.0406      |
| _min_adv        | -7.83       |
| _min_discrew    | -0.00474    |
| _min_obs        | -1.54       |
| _std_act        | 0.442752    |
| _std_adv        | 1           |
| _std_discrew    | 0.0824      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
--------------------------------
| Beta            | 25.6       |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.100897   |
| Phi_loss        | 1057.46    |
| PolicyEntropy   | 0.238115   |
| PolicyLoss      | 2.17468    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0015     |
| _MeanReward     | 1.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.10626    |
| _max_adv        | 6.32       |
| _max_discrew    | 1.17       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0138377 |
| _mean_adv       | 5.12e-17   |
| _mean_discrew   | 0.906      |
| _mean_obs       | 0.0374     |
| _min_adv        | -9.81      |
| _min_discrew    | -0.000923  |
| _min_obs        | -1.51      |
| _std_act        | 0.417838   |
| _std_adv        | 1          |
| _std_discrew    | 0.0756     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0770477  |
| Phi_loss        | 1050.0     |
| PolicyEntropy   | 0.237517   |
| PolicyLoss      | 2.19669    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00111    |
| _MeanReward     | 1.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.02083    |
| _max_adv        | 4.22       |
| _max_discrew    | 1.15       |
| _max_obs        | 1.49       |
| _mean_act       | -0.0260674 |
| _mean_adv       | -1.08e-16  |
| _mean_discrew   | 0.879      |
| _mean_obs       | 0.0346     |
| _min_adv        | -3.47      |
| _min_discrew    | -0.00213   |
| _min_obs        | -1.62      |
| _std_act        | 0.403124   |
| _std_adv        | 1          |
| _std_discrew    | 0.0729     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0598032  |
| Phi_loss        | 1024.72    |
| PolicyEntropy   | 0.236606   |
| PolicyLoss      | 2.20674    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00138    |
| _MeanReward     | 1.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.02204    |
| _max_adv        | 4.26       |
| _max_discrew    | 1.1        |
| _max_obs        | 1.37       |
| _mean_act       | -0.0377247 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 0.836      |
| _mean_obs       | 0.0314     |
| _min_adv        | -9.17      |
| _min_discrew    | -0.00186   |
| _min_obs        | -1.55      |
| _std_act        | 0.383684   |
| _std_adv        | 1          |
| _std_discrew    | 0.0632     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.977      |
| KL              | 0.0450177  |
| Phi_loss        | 937.07     |
| PolicyEntropy   | 0.23533    |
| PolicyLoss      | 1.63526    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00151    |
| _MeanReward     | 986        |
| _lr_multiplier  | 1          |
| _max_act        | 2.2342     |
| _max_adv        | 3.6        |
| _max_discrew    | 1.08       |
| _max_obs        | 1.46       |
| _mean_act       | -0.0508941 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 0.819      |
| _mean_obs       | 0.0289     |
| _min_adv        | -11.2      |
| _min_discrew    | -0.00349   |
| _min_obs        | -1.51      |
| _std_act        | 0.37495    |
| _std_adv        | 1          |
| _std_discrew    | 0.0664     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0340744  |
| Phi_loss        | 841.575    |
| PolicyEntropy   | 0.233846   |
| PolicyLoss      | 1.21743    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00116    |
| _MeanReward     | 924        |
| _lr_multiplier  | 1          |
| _max_act        | 2.07886    |
| _max_adv        | 5.25       |
| _max_discrew    | 1.06       |
| _max_obs        | 1.54       |
| _mean_act       | -0.0594331 |
| _mean_adv       | 8.81e-17   |
| _mean_discrew   | 0.774      |
| _mean_obs       | 0.0263     |
| _min_adv        | -11.7      |
| _min_discrew    | -0.0012    |
| _min_obs        | -1.52      |
| _std_act        | 0.364789   |
| _std_adv        | 1          |
| _std_discrew    | 0.056      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.966      |
| KL              | 0.0259726  |
| Phi_loss        | 634.754    |
| PolicyEntropy   | 0.232236   |
| PolicyLoss      | 0.925172   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00185    |
| _MeanReward     | 904        |
| _lr_multiplier  | 1          |
| _max_act        | 2.04633    |
| _max_adv        | 9.56       |
| _max_discrew    | 1.03       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0676143 |
| _mean_adv       | -7.96e-17  |
| _mean_discrew   | 0.746      |
| _mean_obs       | 0.0241     |
| _min_adv        | -7.18      |
| _min_discrew    | -0.00229   |
| _min_obs        | -1.5       |
| _std_act        | 0.354324   |
| _std_adv        | 1          |
| _std_discrew    | 0.053      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.971      |
| KL              | 0.0195722  |
| Phi_loss        | 843.057    |
| PolicyEntropy   | 0.230422   |
| PolicyLoss      | 0.668121   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0015     |
| _MeanReward     | 879        |
| _lr_multiplier  | 1          |
| _max_act        | 2.33459    |
| _max_adv        | 7.39       |
| _max_discrew    | 1          |
| _max_obs        | 1.45       |
| _mean_act       | -0.0743793 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 0.718      |
| _mean_obs       | 0.0227     |
| _min_adv        | -3.91      |
| _min_discrew    | -0.00315   |
| _min_obs        | -1.53      |
| _std_act        | 0.352843   |
| _std_adv        | 1          |
| _std_discrew    | 0.0513     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.97       |
| KL              | 0.0148441  |
| Phi_loss        | 917.106    |
| PolicyEntropy   | 0.228767   |
| PolicyLoss      | 0.493152   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0015     |
| _MeanReward     | 843        |
| _lr_multiplier  | 1          |
| _max_act        | 2.0425     |
| _max_adv        | 4.91       |
| _max_discrew    | 0.925      |
| _max_obs        | 1.48       |
| _mean_act       | -0.0791271 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 0.688      |
| _mean_obs       | 0.0213     |
| _min_adv        | -4.04      |
| _min_discrew    | -0.00309   |
| _min_obs        | -1.52      |
| _std_act        | 0.348056   |
| _std_adv        | 1          |
| _std_discrew    | 0.048      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.973      |
| KL              | 0.0656118  |
| Phi_loss        | 942.421    |
| PolicyEntropy   | 0.231107   |
| PolicyLoss      | 2.45309    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00142    |
| _MeanReward     | 908        |
| _lr_multiplier  | 1          |
| _max_act        | 2.17301    |
| _max_adv        | 3.98       |
| _max_discrew    | 0.988      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0681978 |
| _mean_adv       | 4.83e-17   |
| _mean_discrew   | 0.743      |
| _mean_obs       | 0.0244     |
| _min_adv        | -3.59      |
| _min_discrew    | -0.00342   |
| _min_obs        | -1.56      |
| _std_act        | 0.358324   |
| _std_adv        | 1          |
| _std_discrew    | 0.0526     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.108153   |
| Phi_loss        | 1111.07    |
| PolicyEntropy   | 0.23438    |
| PolicyLoss      | 4.29105    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00166    |
| _MeanReward     | 972        |
| _lr_multiplier  | 1          |
| _max_act        | 2.14179    |
| _max_adv        | 4.45       |
| _max_discrew    | 1.06       |
| _max_obs        | 1.56       |
| _mean_act       | -0.0524111 |
| _mean_adv       | 5.4e-17    |
| _mean_discrew   | 0.798      |
| _mean_obs       | 0.0283     |
| _min_adv        | -4.68      |
| _min_discrew    | -0.00415   |
| _min_obs        | -1.54      |
| _std_act        | 0.373045   |
| _std_adv        | 1          |
| _std_discrew    | 0.0614     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.975      |
| KL              | 0.0897599  |
| Phi_loss        | 892.873    |
| PolicyEntropy   | 0.237121   |
| PolicyLoss      | 3.46414    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00174    |
| _MeanReward     | 1.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.04205    |
| _max_adv        | 10.2       |
| _max_discrew    | 1.09       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0419938 |
| _mean_adv       | 7.39e-17   |
| _mean_discrew   | 0.829      |
| _mean_obs       | 0.0314     |
| _min_adv        | -4.08      |
| _min_discrew    | -0.000323  |
| _min_obs        | -1.66      |
| _std_act        | 0.386921   |
| _std_adv        | 1          |
| _std_discrew    | 0.0658     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0739334  |
| Phi_loss        | 783.175    |
| PolicyEntropy   | 0.239272   |
| PolicyLoss      | 2.81233    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00104    |
| _MeanReward     | 1.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.11397    |
| _max_adv        | 2.51       |
| _max_discrew    | 1.13       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0349518 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.863      |
| _mean_obs       | 0.0334     |
| _min_adv        | -13        |
| _min_discrew    | -0.00257   |
| _min_obs        | -1.56      |
| _std_act        | 0.404852   |
| _std_adv        | 1          |
| _std_discrew    | 0.0672     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.984      |
| KL              | 0.0596263  |
| Phi_loss        | 610.818    |
| PolicyEntropy   | 0.240825   |
| PolicyLoss      | 2.24039    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0011     |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37064    |
| _max_adv        | 6.73       |
| _max_discrew    | 1.14       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0224098 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 0.875      |
| _mean_obs       | 0.0359     |
| _min_adv        | -10.9      |
| _min_discrew    | -0.00242   |
| _min_obs        | -1.54      |
| _std_act        | 0.419801   |
| _std_adv        | 1          |
| _std_discrew    | 0.0731     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0490224  |
| Phi_loss        | 770.497    |
| PolicyEntropy   | 0.241996   |
| PolicyLoss      | 1.80102    |
| Steps           | 10000      |
| VarFuncLoss     | 0.000839   |
| _MeanReward     | 1.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31642    |
| _max_adv        | 6.34       |
| _max_discrew    | 1.15       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0153444 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.885      |
| _mean_obs       | 0.0376     |
| _min_adv        | -3.72      |
| _min_discrew    | 0.000548   |
| _min_obs        | -1.56      |
| _std_act        | 0.428559   |
| _std_adv        | 1          |
| _std_discrew    | 0.0724     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0394088  |
| Phi_loss        | 857.645    |
| PolicyEntropy   | 0.242647   |
| PolicyLoss      | 1.43478    |
| Steps           | 10000      |
| VarFuncLoss     | 0.000854   |
| _MeanReward     | 1.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.20455    |
| _max_adv        | 6.57       |
| _max_discrew    | 1.16       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0104655 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.895      |
| _mean_obs       | 0.0388     |
| _min_adv        | -5.42      |
| _min_discrew    | -0.0041    |
| _min_obs        | -1.56      |
| _std_act        | 0.444708   |
| _std_adv        | 1          |
| _std_discrew    | 0.0723     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.0319039   |
| Phi_loss        | 842.312     |
| PolicyEntropy   | 0.242978    |
| PolicyLoss      | 1.14486     |
| Steps           | 10000       |
| VarFuncLoss     | 0.000816    |
| _MeanReward     | 1.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.04477     |
| _max_adv        | 3.72        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.35        |
| _mean_act       | -0.00421094 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.884       |
| _mean_obs       | 0.0401      |
| _min_adv        | -4.16       |
| _min_discrew    | -0.00195    |
| _min_obs        | -1.55       |
| _std_act        | 0.455246    |
| _std_adv        | 1           |
| _std_discrew    | 0.0734      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.0254227   |
| Phi_loss        | 964.028     |
| PolicyEntropy   | 0.243131    |
| PolicyLoss      | 0.88917     |
| Steps           | 10000       |
| VarFuncLoss     | 0.00135     |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.19768     |
| _max_adv        | 2.89        |
| _max_discrew    | 1.15        |
| _max_obs        | 1.31        |
| _mean_act       | -0.00304754 |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 0.876       |
| _mean_obs       | 0.0401      |
| _min_adv        | -13.1       |
| _min_discrew    | -0.00253    |
| _min_obs        | -1.59       |
| _std_act        | 0.464418    |
| _std_adv        | 1           |
| _std_discrew    | 0.0747      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0202829  |
| Phi_loss        | 817.134    |
| PolicyEntropy   | 0.242952   |
| PolicyLoss      | 0.709531   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00107    |
| _MeanReward     | 1.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.21884    |
| _max_adv        | 6.43       |
| _max_discrew    | 1.14       |
| _max_obs        | 1.4        |
| _mean_act       | 0.00164197 |
| _mean_adv       | 4.83e-17   |
| _mean_discrew   | 0.863      |
| _mean_obs       | 0.0409     |
| _min_adv        | -3.29      |
| _min_discrew    | -0.00307   |
| _min_obs        | -1.56      |
| _std_act        | 0.471548   |
| _std_adv        | 1          |
| _std_discrew    | 0.0699     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0163209  |
| Phi_loss        | 917.614    |
| PolicyEntropy   | 0.242452   |
| PolicyLoss      | 0.587541   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00105    |
| _MeanReward     | 1.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.20894    |
| _max_adv        | 4.13       |
| _max_discrew    | 1.11       |
| _max_obs        | 1.35       |
| _mean_act       | 0.00364354 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.849      |
| _mean_obs       | 0.0411     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.000858   |
| _min_obs        | -1.55      |
| _std_act        | 0.48094    |
| _std_adv        | 1          |
| _std_discrew    | 0.0686     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0130483  |
| Phi_loss        | 853.289    |
| PolicyEntropy   | 0.241699   |
| PolicyLoss      | 0.474823   |
| Steps           | 10000      |
| VarFuncLoss     | 0.000965   |
| _MeanReward     | 1.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.11714    |
| _max_adv        | 5.4        |
| _max_discrew    | 1.13       |
| _max_obs        | 1.31       |
| _mean_act       | 0.00716735 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 0.858      |
| _mean_obs       | 0.0419     |
| _min_adv        | -3.54      |
| _min_discrew    | 0.00102    |
| _min_obs        | -1.6       |
| _std_act        | 0.490843   |
| _std_adv        | 1          |
| _std_discrew    | 0.0719     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0270214  |
| Phi_loss        | 915.328    |
| PolicyEntropy   | 0.243861   |
| PolicyLoss      | 0.993803   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00087    |
| _MeanReward     | 1.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.15111    |
| _max_adv        | 10.2       |
| _max_discrew    | 1.14       |
| _max_obs        | 1.34       |
| _mean_act       | 0.00251679 |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 0.863      |
| _mean_obs       | 0.041      |
| _min_adv        | -3.23      |
| _min_discrew    | -0.0033    |
| _min_obs        | -1.67      |
| _std_act        | 0.477062   |
| _std_adv        | 1          |
| _std_discrew    | 0.0708     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.0531742   |
| Phi_loss        | 960.153     |
| PolicyEntropy   | 0.246396    |
| PolicyLoss      | 1.97641     |
| Steps           | 10000       |
| VarFuncLoss     | 0.00105     |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.1578      |
| _max_adv        | 3.18        |
| _max_discrew    | 1.18        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00522451 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.877       |
| _mean_obs       | 0.0397      |
| _min_adv        | -3.32       |
| _min_discrew    | -0.003      |
| _min_obs        | -1.57       |
| _std_act        | 0.459729    |
| _std_adv        | 1           |
| _std_discrew    | 0.0718      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.0417206   |
| Phi_loss        | 992.188     |
| PolicyEntropy   | 0.248466    |
| PolicyLoss      | 1.50786     |
| Steps           | 10000       |
| VarFuncLoss     | 0.00106     |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.0108      |
| _max_adv        | 3.74        |
| _max_discrew    | 1.15        |
| _max_obs        | 1.4         |
| _mean_act       | -0.00734549 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.885       |
| _mean_obs       | 0.0393      |
| _min_adv        | -10.6       |
| _min_discrew    | -0.00182    |
| _min_obs        | -1.56       |
| _std_act        | 0.44855     |
| _std_adv        | 1           |
| _std_discrew    | 0.0756      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.0325158   |
| Phi_loss        | 821.076     |
| PolicyEntropy   | 0.250186    |
| PolicyLoss      | 1.16195     |
| Steps           | 10000       |
| VarFuncLoss     | 0.000923    |
| _MeanReward     | 1.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.11706     |
| _max_adv        | 3.97        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.38        |
| _mean_act       | -0.00933656 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.886       |
| _mean_obs       | 0.0388      |
| _min_adv        | -3.74       |
| _min_discrew    | 0.00144     |
| _min_obs        | -1.59       |
| _std_act        | 0.433775    |
| _std_adv        | 1           |
| _std_discrew    | 0.0739      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.025513   |
| Phi_loss        | 879.21     |
| PolicyEntropy   | 0.251475   |
| PolicyLoss      | 0.889718   |
| Steps           | 10000      |
| VarFuncLoss     | 0.000731   |
| _MeanReward     | 1.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.07919    |
| _max_adv        | 3.78       |
| _max_discrew    | 1.15       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0165608 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.88       |
| _mean_obs       | 0.0374     |
| _min_adv        | -4.5       |
| _min_discrew    | 0.000363   |
| _min_obs        | -1.56      |
| _std_act        | 0.424379   |
| _std_adv        | 1          |
| _std_discrew    | 0.0731     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.989     |
| ExplainedVarOld | 0.989     |
| KL              | 0.0199976 |
| Phi_loss        | 948.45    |
| PolicyEntropy   | 0.252383  |
| PolicyLoss      | 0.687802  |
| Steps           | 10000     |
| VarFuncLoss     | 0.000832  |
| _MeanReward     | 1.07e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.16255   |
| _max_adv        | 3.82      |
| _max_discrew    | 1.18      |
| _max_obs        | 1.4       |
| _mean_act       | -0.018824 |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 0.879     |
| _mean_obs       | 0.0367    |
| _min_adv        | -11.4     |
| _min_discrew    | -0.00448  |
| _min_obs        | -1.56     |
| _std_act        | 0.417964  |
| _std_adv        | 1         |
| _std_discrew    | 0.0718    |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.0156379  |
| Phi_loss        | 878.181    |
| PolicyEntropy   | 0.252839   |
| PolicyLoss      | 0.538279   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00124    |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.99418    |
| _max_adv        | 5.47       |
| _max_discrew    | 1.21       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0271304 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.878      |
| _mean_obs       | 0.0353     |
| _min_adv        | -10.5      |
| _min_discrew    | -0.00144   |
| _min_obs        | -1.56      |
| _std_act        | 0.407456   |
| _std_adv        | 1          |
| _std_discrew    | 0.0772     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.0121825  |
| Phi_loss        | 826.489    |
| PolicyEntropy   | 0.252986   |
| PolicyLoss      | 0.408334   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00107    |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.08134    |
| _max_adv        | 3.22       |
| _max_discrew    | 1.17       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0269777 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.872      |
| _mean_obs       | 0.0349     |
| _min_adv        | -4.09      |
| _min_discrew    | -0.00362   |
| _min_obs        | -1.57      |
| _std_act        | 0.397255   |
| _std_adv        | 1          |
| _std_discrew    | 0.0727     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
--------------------------------
| Beta            | 23.3       |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0014207  |
| Phi_loss        | 907.871    |
| PolicyEntropy   | 0.250746   |
| PolicyLoss      | 0.00551147 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00101    |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92044    |
| _max_adv        | 4.56       |
| _max_discrew    | 1.17       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0257554 |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 0.877      |
| _mean_obs       | 0.0351     |
| _min_adv        | -9.38      |
| _min_discrew    | -0.00118   |
| _min_obs        | -1.63      |
| _std_act        | 0.403157   |
| _std_adv        | 1          |
| _std_discrew    | 0.0717     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
--------------------------------
| Beta            | 15.6       |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00010401 |
| Phi_loss        | 847.036    |
| PolicyEntropy   | 0.249462   |
| PolicyLoss      | -0.0244139 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00102    |
| _MeanReward     | 1.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.93094    |
| _max_adv        | 3.37       |
| _max_discrew    | 1.13       |
| _max_obs        | 1.51       |
| _mean_act       | -0.0239524 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.867      |
| _mean_obs       | 0.035      |
| _min_adv        | -3.65      |
| _min_discrew    | -0.00134   |
| _min_obs        | -1.56      |
| _std_act        | 0.400379   |
| _std_adv        | 1          |
| _std_discrew    | 0.0697     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 1.70299e-05 |
| Phi_loss        | 862.13      |
| PolicyEntropy   | 0.248857    |
| PolicyLoss      | -0.0192635  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000912    |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.01728     |
| _max_adv        | 4.5         |
| _max_discrew    | 1.17        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0250554  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.877       |
| _mean_obs       | 0.0352      |
| _min_adv        | -3.54       |
| _min_discrew    | -0.000272   |
| _min_obs        | -1.56       |
| _std_act        | 0.402601    |
| _std_adv        | 1           |
| _std_discrew    | 0.0743      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
--------------------------------
| Beta            | 6.91       |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 4.0581e-06 |
| Phi_loss        | 890.219    |
| PolicyEntropy   | 0.247408   |
| PolicyLoss      | -0.0300407 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0012     |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.10929    |
| _max_adv        | 2.97       |
| _max_discrew    | 1.17       |
| _max_obs        | 1.55       |
| _mean_act       | -0.0254193 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.878      |
| _mean_obs       | 0.0351     |
| _min_adv        | -12.6      |
| _min_discrew    | -0.00408   |
| _min_obs        | -1.58      |
| _std_act        | 0.402919   |
| _std_adv        | 1          |
| _std_discrew    | 0.0731     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 1.52343e-05 |
| Phi_loss        | 738.995     |
| PolicyEntropy   | 0.245353    |
| PolicyLoss      | -0.0109137  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00103     |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.01315     |
| _max_adv        | 4.85        |
| _max_discrew    | 1.15        |
| _max_obs        | 1.33        |
| _mean_act       | -0.026689   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.863       |
| _mean_obs       | 0.0345      |
| _min_adv        | -5.88       |
| _min_discrew    | -0.00418    |
| _min_obs        | -1.59       |
| _std_act        | 0.39671     |
| _std_adv        | 1           |
| _std_discrew    | 0.0723      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 1.09252e-05 |
| Phi_loss        | 946.472     |
| PolicyEntropy   | 0.242892    |
| PolicyLoss      | -0.0246968  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000933    |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.15014     |
| _max_adv        | 6.39        |
| _max_discrew    | 1.13        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0263934  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.868       |
| _mean_obs       | 0.0348      |
| _min_adv        | -5.73       |
| _min_discrew    | -0.00345    |
| _min_obs        | -1.57       |
| _std_act        | 0.403862    |
| _std_adv        | 1           |
| _std_discrew    | 0.0724      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
---------------------------------
| Beta            | 2.05        |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 2.95835e-05 |
| Phi_loss        | 898.944     |
| PolicyEntropy   | 0.237855    |
| PolicyLoss      | -0.0177036  |
| Steps           | 10000       |
| VarFuncLoss     | 0.000657    |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.05656     |
| _max_adv        | 4.28        |
| _max_discrew    | 1.15        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0262711  |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 0.869       |
| _mean_obs       | 0.0348      |
| _min_adv        | -3.82       |
| _min_discrew    | -0.00432    |
| _min_obs        | -1.59       |
| _std_act        | 0.399413    |
| _std_adv        | 1           |
| _std_discrew    | 0.0746      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 3.35897e-05 |
| Phi_loss        | 902.897     |
| PolicyEntropy   | 0.234359    |
| PolicyLoss      | -0.0196794  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00113     |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.91826     |
| _max_adv        | 5.28        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0244592  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.873       |
| _mean_obs       | 0.0349      |
| _min_adv        | -3.72       |
| _min_discrew    | -0.00163    |
| _min_obs        | -1.59       |
| _std_act        | 0.402426    |
| _std_adv        | 1           |
| _std_discrew    | 0.073       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 5.83408e-05 |
| Phi_loss        | 932.003     |
| PolicyEntropy   | 0.230912    |
| PolicyLoss      | -0.031885   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00112     |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.00343     |
| _max_adv        | 3.64        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.45        |
| _mean_act       | -0.0239446  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.88        |
| _mean_obs       | 0.0352      |
| _min_adv        | -3.84       |
| _min_discrew    | -0.00407    |
| _min_obs        | -1.59       |
| _std_act        | 0.404563    |
| _std_adv        | 1           |
| _std_discrew    | 0.0725      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.000199179 |
| Phi_loss        | 921.603     |
| PolicyEntropy   | 0.209794    |
| PolicyLoss      | -0.00944101 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000746    |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.11167     |
| _max_adv        | 3.69        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.44        |
| _mean_act       | -0.0233763  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.883       |
| _mean_obs       | 0.0353      |
| _min_adv        | -5.3        |
| _min_discrew    | 0.00449     |
| _min_obs        | -1.6        |
| _std_act        | 0.401648    |
| _std_adv        | 1           |
| _std_discrew    | 0.0708      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
---------------------------------
| Beta            | 0.405       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.000150027 |
| Phi_loss        | 922.553     |
| PolicyEntropy   | 0.20342     |
| PolicyLoss      | -0.0308481  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00105     |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.93996     |
| _max_adv        | 7.31        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0261751  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.882       |
| _mean_obs       | 0.0349      |
| _min_adv        | -4.09       |
| _min_discrew    | -0.00522    |
| _min_obs        | -1.58       |
| _std_act        | 0.402942    |
| _std_adv        | 1           |
| _std_discrew    | 0.0744      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.000532565 |
| Phi_loss        | 914.828     |
| PolicyEntropy   | 0.183476    |
| PolicyLoss      | -0.00636229 |
| Steps           | 10000       |
| VarFuncLoss     | 0.000849    |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.90922     |
| _max_adv        | 3.56        |
| _max_discrew    | 1.2         |
| _max_obs        | 1.58        |
| _mean_act       | -0.022259   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.877       |
| _mean_obs       | 0.0355      |
| _min_adv        | -3.59       |
| _min_discrew    | -0.00416    |
| _min_obs        | -1.58       |
| _std_act        | 0.402073    |
| _std_adv        | 1           |
| _std_discrew    | 0.0747      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.000965452 |
| Phi_loss        | 865.785     |
| PolicyEntropy   | 0.174166    |
| PolicyLoss      | -0.0293737  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00119     |
| _MeanReward     | 1.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.34347     |
| _max_adv        | 3.2         |
| _max_discrew    | 1.16        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0225824  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.889       |
| _mean_obs       | 0.0356      |
| _min_adv        | -4.06       |
| _min_discrew    | -0.000164   |
| _min_obs        | -1.59       |
| _std_act        | 0.405657    |
| _std_adv        | 1           |
| _std_discrew    | 0.0732      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00123727 |
| Phi_loss        | 929.389    |
| PolicyEntropy   | 0.156219   |
| PolicyLoss      | -0.0322399 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00119    |
| _MeanReward     | 1.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.99826    |
| _max_adv        | 7.38       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0250091 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.894      |
| _mean_obs       | 0.0354     |
| _min_adv        | -7.3       |
| _min_discrew    | -0.00199   |
| _min_obs        | -1.62      |
| _std_act        | 0.408894   |
| _std_adv        | 1          |
| _std_discrew    | 0.073      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00199204 |
| Phi_loss        | 927.3      |
| PolicyEntropy   | 0.13563    |
| PolicyLoss      | -0.0286011 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000726   |
| _MeanReward     | 1.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.29367    |
| _max_adv        | 3.36       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0202837 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.9        |
| _mean_obs       | 0.036      |
| _min_adv        | -4.47      |
| _min_discrew    | -0.00359   |
| _min_obs        | -1.6       |
| _std_act        | 0.412064   |
| _std_adv        | 1          |
| _std_discrew    | 0.0763     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00205944 |
| Phi_loss        | 968.515    |
| PolicyEntropy   | 0.105556   |
| PolicyLoss      | -0.0155905 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000853   |
| _MeanReward     | 1.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.97487    |
| _max_adv        | 5.42       |
| _max_discrew    | 1.16       |
| _max_obs        | 1.42       |
| _mean_act       | -0.023002  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.901      |
| _mean_obs       | 0.0359     |
| _min_adv        | -5.26      |
| _min_discrew    | -0.0038    |
| _min_obs        | -1.6       |
| _std_act        | 0.416956   |
| _std_adv        | 1          |
| _std_discrew    | 0.0752     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00104496 |
| Phi_loss        | 987.413    |
| PolicyEntropy   | 0.077426   |
| PolicyLoss      | -0.0215688 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000998   |
| _MeanReward     | 1.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.07566    |
| _max_adv        | 3.23       |
| _max_discrew    | 1.21       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0188711 |
| _mean_adv       | 1.88e-17   |
| _mean_discrew   | 0.905      |
| _mean_obs       | 0.0365     |
| _min_adv        | -3.53      |
| _min_discrew    | -0.00161   |
| _min_obs        | -1.6       |
| _std_act        | 0.415674   |
| _std_adv        | 1          |
| _std_discrew    | 0.0817     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00130059  |
| Phi_loss        | 915.904     |
| PolicyEntropy   | 0.0611982   |
| PolicyLoss      | -0.00563503 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00092     |
| _MeanReward     | 1.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.97884     |
| _max_adv        | 3.58        |
| _max_discrew    | 1.22        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0182662  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.914       |
| _mean_obs       | 0.0367      |
| _min_adv        | -3.84       |
| _min_discrew    | -0.00257    |
| _min_obs        | -1.6        |
| _std_act        | 0.41299     |
| _std_adv        | 1           |
| _std_discrew    | 0.0799      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00396882 |
| Phi_loss        | 1020.4     |
| PolicyEntropy   | 0.0324688  |
| PolicyLoss      | -0.0440351 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00113    |
| _MeanReward     | 1.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.97131    |
| _max_adv        | 4.18       |
| _max_discrew    | 1.24       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0160168 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 0.933      |
| _mean_obs       | 0.0375     |
| _min_adv        | -4.07      |
| _min_discrew    | -0.00176   |
| _min_obs        | -1.59      |
| _std_act        | 0.419316   |
| _std_adv        | 1          |
| _std_discrew    | 0.0802     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00296264 |
| Phi_loss        | 971.468    |
| PolicyEntropy   | 0.0160799  |
| PolicyLoss      | -0.0186298 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000868   |
| _MeanReward     | 1.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.97283    |
| _max_adv        | 3.2        |
| _max_discrew    | 1.23       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0174789 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 0.936      |
| _mean_obs       | 0.0372     |
| _min_adv        | -3.83      |
| _min_discrew    | -0.00192   |
| _min_obs        | -1.59      |
| _std_act        | 0.422649   |
| _std_adv        | 1          |
| _std_discrew    | 0.083      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.988      |
| KL              | 0.00176628 |
| Phi_loss        | 913.21     |
| PolicyEntropy   | 0.00424099 |
| PolicyLoss      | -0.0236753 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000857   |
| _MeanReward     | 1.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.09969    |
| _max_adv        | 3.03       |
| _max_discrew    | 1.21       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0163862 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 0.936      |
| _mean_obs       | 0.0374     |
| _min_adv        | -4.82      |
| _min_discrew    | -0.00276   |
| _min_obs        | -1.61      |
| _std_act        | 0.429775   |
| _std_adv        | 1          |
| _std_discrew    | 0.0808     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00156495  |
| Phi_loss        | 1041.45     |
| PolicyEntropy   | -0.0405035  |
| PolicyLoss      | -0.00832674 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00121     |
| _MeanReward     | 1.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.04959     |
| _max_adv        | 3.48        |
| _max_discrew    | 1.25        |
| _max_obs        | 1.36        |
| _mean_act       | -0.013383   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.939       |
| _mean_obs       | 0.038       |
| _min_adv        | -3.51       |
| _min_discrew    | -0.00198    |
| _min_obs        | -1.61       |
| _std_act        | 0.430608    |
| _std_adv        | 1           |
| _std_discrew    | 0.0841      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00239159 |
| Phi_loss        | 1113.72    |
| PolicyEntropy   | -0.0737371 |
| PolicyLoss      | -0.0176363 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0012     |
| _MeanReward     | 1.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.95134    |
| _max_adv        | 3.22       |
| _max_discrew    | 1.25       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0117281 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.94       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.67      |
| _min_discrew    | -0.00207   |
| _min_obs        | -1.62      |
| _std_act        | 0.429563   |
| _std_adv        | 1          |
| _std_discrew    | 0.0771     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00276215  |
| Phi_loss        | 1027.28     |
| PolicyEntropy   | -0.112871   |
| PolicyLoss      | -0.00984154 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00125     |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.9972      |
| _max_adv        | 2.94        |
| _max_discrew    | 1.27        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0129899  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.943       |
| _mean_obs       | 0.0381      |
| _min_adv        | -3.96       |
| _min_discrew    | -0.0018     |
| _min_obs        | -1.6        |
| _std_act        | 0.437306    |
| _std_adv        | 1           |
| _std_discrew    | 0.0854      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00206554  |
| Phi_loss        | 1143.36     |
| PolicyEntropy   | -0.14135    |
| PolicyLoss      | -0.0127638  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00163     |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.01169     |
| _max_adv        | 3.6         |
| _max_discrew    | 1.25        |
| _max_obs        | 1.46        |
| _mean_act       | -0.00956027 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 0.945       |
| _mean_obs       | 0.0386      |
| _min_adv        | -3.83       |
| _min_discrew    | -0.00337    |
| _min_obs        | -1.59       |
| _std_act        | 0.440028    |
| _std_adv        | 1           |
| _std_discrew    | 0.0833      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00157657  |
| Phi_loss        | 1086.92     |
| PolicyEntropy   | -0.183691   |
| PolicyLoss      | -0.00338402 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00107     |
| _MeanReward     | 1.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.90833     |
| _max_adv        | 3.93        |
| _max_discrew    | 1.25        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00986636 |
| _mean_adv       | 4.26e-17    |
| _mean_discrew   | 0.964       |
| _mean_obs       | 0.0388      |
| _min_adv        | -4.15       |
| _min_discrew    | -0.00186    |
| _min_obs        | -1.61       |
| _std_act        | 0.440412    |
| _std_adv        | 1           |
| _std_discrew    | 0.0854      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00170427 |
| Phi_loss        | 1097.35    |
| PolicyEntropy   | -0.208989  |
| PolicyLoss      | -0.0206577 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00105    |
| _MeanReward     | 1.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.12574    |
| _max_adv        | 3.19       |
| _max_discrew    | 1.24       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0116893 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 0.964      |
| _mean_obs       | 0.0384     |
| _min_adv        | -4.01      |
| _min_discrew    | -0.00253   |
| _min_obs        | -1.63      |
| _std_act        | 0.439068   |
| _std_adv        | 1          |
| _std_discrew    | 0.0824     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00147689 |
| Phi_loss        | 1095.75    |
| PolicyEntropy   | -0.220965  |
| PolicyLoss      | 0.0104544  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00144    |
| _MeanReward     | 1.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.22373    |
| _max_adv        | 2.88       |
| _max_discrew    | 1.24       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0116964 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 0.964      |
| _mean_obs       | 0.0383     |
| _min_adv        | -12.6      |
| _min_discrew    | 0.00249    |
| _min_obs        | -1.62      |
| _std_act        | 0.439364   |
| _std_adv        | 1          |
| _std_discrew    | 0.084      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00320274  |
| Phi_loss        | 1005.22     |
| PolicyEntropy   | -0.25449    |
| PolicyLoss      | 0.0328312   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0011      |
| _MeanReward     | 1.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.95264     |
| _max_adv        | 6.43        |
| _max_discrew    | 1.24        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00762148 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.965       |
| _mean_obs       | 0.0389      |
| _min_adv        | -3.68       |
| _min_discrew    | -0.00333    |
| _min_obs        | -1.62       |
| _std_act        | 0.437076    |
| _std_adv        | 1           |
| _std_discrew    | 0.0854      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00228751  |
| Phi_loss        | 1138.37     |
| PolicyEntropy   | -0.293023   |
| PolicyLoss      | 0.0170543   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00122     |
| _MeanReward     | 1.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.95949     |
| _max_adv        | 3.14        |
| _max_discrew    | 1.27        |
| _max_obs        | 1.41        |
| _mean_act       | -0.00490748 |
| _mean_adv       | -2.52e-17   |
| _mean_discrew   | 0.975       |
| _mean_obs       | 0.0393      |
| _min_adv        | -4.17       |
| _min_discrew    | -0.00329    |
| _min_obs        | -1.61       |
| _std_act        | 0.436708    |
| _std_adv        | 1           |
| _std_discrew    | 0.0868      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00258043  |
| Phi_loss        | 1219.07     |
| PolicyEntropy   | -0.345344   |
| PolicyLoss      | 0.0054474   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00131     |
| _MeanReward     | 1.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.99205     |
| _max_adv        | 3.69        |
| _max_discrew    | 1.29        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00383001 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.98        |
| _mean_obs       | 0.0398      |
| _min_adv        | -4.18       |
| _min_discrew    | -0.0034     |
| _min_obs        | -1.65       |
| _std_act        | 0.437205    |
| _std_adv        | 1           |
| _std_discrew    | 0.0901      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00269426 |
| Phi_loss        | 1125.33    |
| PolicyEntropy   | -0.393652  |
| PolicyLoss      | -0.0115648 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00104    |
| _MeanReward     | 1.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.09199    |
| _max_adv        | 4.94       |
| _max_discrew    | 1.28       |
| _max_obs        | 1.28       |
| _mean_act       | 0.0023688  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.966      |
| _mean_obs       | 0.0401     |
| _min_adv        | -12.8      |
| _min_discrew    | -0.00162   |
| _min_obs        | -1.64      |
| _std_act        | 0.441944   |
| _std_adv        | 1          |
| _std_discrew    | 0.0926     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.981        |
| ExplainedVarOld | 0.979        |
| KL              | 0.00345334   |
| Phi_loss        | 1031.49      |
| PolicyEntropy   | -0.428126    |
| PolicyLoss      | -0.0254989   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00182      |
| _MeanReward     | 1.2e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 1.99491      |
| _max_adv        | 4.41         |
| _max_discrew    | 1.28         |
| _max_obs        | 1.34         |
| _mean_act       | -0.000510124 |
| _mean_adv       | 1.71e-17     |
| _mean_discrew   | 0.99         |
| _mean_obs       | 0.0403       |
| _min_adv        | -3.98        |
| _min_discrew    | -0.00285     |
| _min_obs        | -1.65        |
| _std_act        | 0.441555     |
| _std_adv        | 1            |
| _std_discrew    | 0.0882       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00358778 |
| Phi_loss        | 1197.7     |
| PolicyEntropy   | -0.452132  |
| PolicyLoss      | -0.0155169 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00119    |
| _MeanReward     | 1.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.94627    |
| _max_adv        | 4.84       |
| _max_discrew    | 1.29       |
| _max_obs        | 1.37       |
| _mean_act       | 0.00175408 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.992      |
| _mean_obs       | 0.0407     |
| _min_adv        | -12.1      |
| _min_discrew    | -0.00107   |
| _min_obs        | -1.61      |
| _std_act        | 0.448425   |
| _std_adv        | 1          |
| _std_discrew    | 0.0952     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00277966 |
| Phi_loss        | 1200.89    |
| PolicyEntropy   | -0.48573   |
| PolicyLoss      | -0.0188172 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000948   |
| _MeanReward     | 1.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.01122    |
| _max_adv        | 6.37       |
| _max_discrew    | 1.32       |
| _max_obs        | 1.33       |
| _mean_act       | 0.00175965 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 0.988      |
| _mean_obs       | 0.0407     |
| _min_adv        | -3.2       |
| _min_discrew    | -0.00359   |
| _min_obs        | -1.63      |
| _std_act        | 0.447622   |
| _std_adv        | 1          |
| _std_discrew    | 0.0919     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00303772 |
| Phi_loss        | 1206.37    |
| PolicyEntropy   | -0.515502  |
| PolicyLoss      | -0.0138164 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00108    |
| _MeanReward     | 1.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.98189    |
| _max_adv        | 3.7        |
| _max_discrew    | 1.32       |
| _max_obs        | 1.34       |
| _mean_act       | 0.00209438 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.988      |
| _mean_obs       | 0.0405     |
| _min_adv        | -4.43      |
| _min_discrew    | 0.00427    |
| _min_obs        | -1.6       |
| _std_act        | 0.447312   |
| _std_adv        | 1          |
| _std_discrew    | 0.089      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.984        |
| ExplainedVarOld | 0.982        |
| KL              | 0.00214067   |
| Phi_loss        | 1303.93      |
| PolicyEntropy   | -0.539882    |
| PolicyLoss      | -0.000877357 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00144      |
| _MeanReward     | 1.22e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.1466       |
| _max_adv        | 3.7          |
| _max_discrew    | 1.31         |
| _max_obs        | 1.35         |
| _mean_act       | -0.00163733  |
| _mean_adv       | 3.98e-17     |
| _mean_discrew   | 1            |
| _mean_obs       | 0.0405       |
| _min_adv        | -9.26        |
| _min_discrew    | -0.00344     |
| _min_obs        | -1.63        |
| _std_act        | 0.444994     |
| _std_adv        | 1            |
| _std_discrew    | 0.0922       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.986        |
| ExplainedVarOld | 0.986        |
| KL              | 0.00278018   |
| Phi_loss        | 1315.96      |
| PolicyEntropy   | -0.577228    |
| PolicyLoss      | -0.0106199   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00133      |
| _MeanReward     | 1.21e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.16086      |
| _max_adv        | 3.81         |
| _max_discrew    | 1.3          |
| _max_obs        | 1.27         |
| _mean_act       | -0.000162184 |
| _mean_adv       | -7.11e-18    |
| _mean_discrew   | 1            |
| _mean_obs       | 0.0404       |
| _min_adv        | -13.1        |
| _min_discrew    | -0.00319     |
| _min_obs        | -1.64        |
| _std_act        | 0.447952     |
| _std_adv        | 1            |
| _std_discrew    | 0.0901       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.992        |
| ExplainedVarOld | 0.991        |
| KL              | 0.0025604    |
| Phi_loss        | 1123.55      |
| PolicyEntropy   | -0.593294    |
| PolicyLoss      | -0.0068006   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00074      |
| _MeanReward     | 1.22e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 1.83167      |
| _max_adv        | 4.61         |
| _max_discrew    | 1.35         |
| _max_obs        | 1.38         |
| _mean_act       | -0.000215649 |
| _mean_adv       | 0            |
| _mean_discrew   | 1            |
| _mean_obs       | 0.0406       |
| _min_adv        | -3.54        |
| _min_discrew    | -0.00451     |
| _min_obs        | -1.62        |
| _std_act        | 0.448018     |
| _std_adv        | 1            |
| _std_discrew    | 0.0919       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.98         |
| ExplainedVarOld | 0.98         |
| KL              | 0.00339635   |
| Phi_loss        | 1336.71      |
| PolicyEntropy   | -0.608401    |
| PolicyLoss      | -0.0230666   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0018       |
| _MeanReward     | 1.22e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 1.98945      |
| _max_adv        | 5.09         |
| _max_discrew    | 1.36         |
| _max_obs        | 1.54         |
| _mean_act       | -0.000455279 |
| _mean_adv       | -2.56e-17    |
| _mean_discrew   | 1.01         |
| _mean_obs       | 0.0406       |
| _min_adv        | -13.9        |
| _min_discrew    | -0.00199     |
| _min_obs        | -1.64        |
| _std_act        | 0.454538     |
| _std_adv        | 1            |
| _std_discrew    | 0.0963       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.989        |
| ExplainedVarOld | 0.988        |
| KL              | 0.00403804   |
| Phi_loss        | 1136.97      |
| PolicyEntropy   | -0.630899    |
| PolicyLoss      | -0.0302708   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00104      |
| _MeanReward     | 1.25e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 1.88648      |
| _max_adv        | 4.84         |
| _max_discrew    | 1.33         |
| _max_obs        | 1.46         |
| _mean_act       | -3.89737e-05 |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 1.03         |
| _mean_obs       | 0.041        |
| _min_adv        | -3.21        |
| _min_discrew    | -0.00243     |
| _min_obs        | -1.63        |
| _std_act        | 0.455076     |
| _std_adv        | 1            |
| _std_discrew    | 0.0966       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00389562  |
| Phi_loss        | 1397.01     |
| PolicyEntropy   | -0.646628   |
| PolicyLoss      | -0.0211436  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00134     |
| _MeanReward     | 1.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.05342     |
| _max_adv        | 5.88        |
| _max_discrew    | 1.32        |
| _max_obs        | 1.37        |
| _mean_act       | 0.000588502 |
| _mean_adv       | 0           |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.0408      |
| _min_adv        | -4.18       |
| _min_discrew    | -0.00361    |
| _min_obs        | -1.64       |
| _std_act        | 0.459069    |
| _std_adv        | 1           |
| _std_discrew    | 0.0953      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00218536 |
| Phi_loss        | 1444.7     |
| PolicyEntropy   | -0.679164  |
| PolicyLoss      | 0.00649495 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00161    |
| _MeanReward     | 1.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.98657    |
| _max_adv        | 3.69       |
| _max_discrew    | 1.36       |
| _max_obs        | 1.46       |
| _mean_act       | 0.0034583  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0413     |
| _min_adv        | -4.13      |
| _min_discrew    | -0.00666   |
| _min_obs        | -1.61      |
| _std_act        | 0.454629   |
| _std_adv        | 1          |
| _std_discrew    | 0.0969     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00400115  |
| Phi_loss        | 1533.16     |
| PolicyEntropy   | -0.713836   |
| PolicyLoss      | -0.0191053  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00186     |
| _MeanReward     | 1.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.99951     |
| _max_adv        | 4.11        |
| _max_discrew    | 1.34        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00338116 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0406      |
| _min_adv        | -4.03       |
| _min_discrew    | -0.00307    |
| _min_obs        | -1.65       |
| _std_act        | 0.460013    |
| _std_adv        | 1           |
| _std_discrew    | 0.0968      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00470041  |
| Phi_loss        | 1461.02     |
| PolicyEntropy   | -0.735641   |
| PolicyLoss      | 0.0173881   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00137     |
| _MeanReward     | 1.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.01956     |
| _max_adv        | 7.23        |
| _max_discrew    | 1.34        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00462809 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.0406      |
| _min_adv        | -5.79       |
| _min_discrew    | -0.0032     |
| _min_obs        | -1.63       |
| _std_act        | 0.459361    |
| _std_adv        | 1           |
| _std_discrew    | 0.103       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00388125  |
| Phi_loss        | 1381.74     |
| PolicyEntropy   | -0.75517    |
| PolicyLoss      | -0.0229232  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00118     |
| _MeanReward     | 1.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.91369     |
| _max_adv        | 4.01        |
| _max_discrew    | 1.36        |
| _max_obs        | 1.38        |
| _mean_act       | -0.00364385 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0404      |
| _min_adv        | -3.57       |
| _min_discrew    | -0.00423    |
| _min_obs        | -1.65       |
| _std_act        | 0.452895    |
| _std_adv        | 1           |
| _std_discrew    | 0.0995      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00327588  |
| Phi_loss        | 1558.7      |
| PolicyEntropy   | -0.778986   |
| PolicyLoss      | -0.00788026 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00117     |
| _MeanReward     | 1.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.01171     |
| _max_adv        | 4.01        |
| _max_discrew    | 1.32        |
| _max_obs        | 1.45        |
| _mean_act       | -0.004561   |
| _mean_adv       | -3.69e-17   |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.0402      |
| _min_adv        | -3.72       |
| _min_discrew    | -0.00361    |
| _min_obs        | -1.64       |
| _std_act        | 0.456198    |
| _std_adv        | 1           |
| _std_discrew    | 0.0961      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00235445  |
| Phi_loss        | 1467.02     |
| PolicyEntropy   | -0.794776   |
| PolicyLoss      | -0.0273053  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00123     |
| _MeanReward     | 1.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.2419      |
| _max_adv        | 4.04        |
| _max_discrew    | 1.35        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00915413 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0397      |
| _min_adv        | -12.3       |
| _min_discrew    | -0.00305    |
| _min_obs        | -1.65       |
| _std_act        | 0.461538    |
| _std_adv        | 1           |
| _std_discrew    | 0.0958      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.0028566   |
| Phi_loss        | 1325.95     |
| PolicyEntropy   | -0.811725   |
| PolicyLoss      | 0.00378896  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00119     |
| _MeanReward     | 1.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.92513     |
| _max_adv        | 3.63        |
| _max_discrew    | 1.37        |
| _max_obs        | 1.47        |
| _mean_act       | -0.00520355 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0403      |
| _min_adv        | -3.43       |
| _min_discrew    | -0.0049     |
| _min_obs        | -1.63       |
| _std_act        | 0.461965    |
| _std_adv        | 1           |
| _std_discrew    | 0.0975      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00130408  |
| Phi_loss        | 1556.12     |
| PolicyEntropy   | -0.827005   |
| PolicyLoss      | -0.00399581 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00147     |
| _MeanReward     | 1.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.82551     |
| _max_adv        | 3.93        |
| _max_discrew    | 1.38        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00620503 |
| _mean_adv       | -5.4e-17    |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.0403      |
| _min_adv        | -3.59       |
| _min_discrew    | 0.00202     |
| _min_obs        | -1.64       |
| _std_act        | 0.457762    |
| _std_adv        | 1           |
| _std_discrew    | 0.102       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00303495  |
| Phi_loss        | 1579.14     |
| PolicyEntropy   | -0.855416   |
| PolicyLoss      | -0.0103997  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00153     |
| _MeanReward     | 1.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.85718     |
| _max_adv        | 3.2         |
| _max_discrew    | 1.33        |
| _max_obs        | 1.51        |
| _mean_act       | -0.00511841 |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0402      |
| _min_adv        | -3.88       |
| _min_discrew    | -0.00267    |
| _min_obs        | -1.65       |
| _std_act        | 0.461271    |
| _std_adv        | 1           |
| _std_discrew    | 0.0989      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00776884 |
| Phi_loss        | 1583.63    |
| PolicyEntropy   | -0.897046  |
| PolicyLoss      | 0.00653983 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00103    |
| _MeanReward     | 1.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.9682     |
| _max_adv        | 4.03       |
| _max_discrew    | 1.33       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0102548 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.0397     |
| _min_adv        | -3.48      |
| _min_discrew    | -0.00247   |
| _min_obs        | -1.64      |
| _std_act        | 0.455262   |
| _std_adv        | 1          |
| _std_discrew    | 0.0968     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00246838 |
| Phi_loss        | 1631.5     |
| PolicyEntropy   | -0.918673  |
| PolicyLoss      | 0.00325021 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00118    |
| _MeanReward     | 1.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92218    |
| _max_adv        | 3.51       |
| _max_discrew    | 1.39       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0118004 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.0395     |
| _min_adv        | -3.61      |
| _min_discrew    | -0.00465   |
| _min_obs        | -1.64      |
| _std_act        | 0.45164    |
| _std_adv        | 1          |
| _std_discrew    | 0.0988     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00246044 |
| Phi_loss        | 1533.14    |
| PolicyEntropy   | -0.928668  |
| PolicyLoss      | -0.0105761 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00143    |
| _MeanReward     | 1.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.02639    |
| _max_adv        | 3.46       |
| _max_discrew    | 1.38       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0120964 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.0396     |
| _min_adv        | -4.09      |
| _min_discrew    | -0.00438   |
| _min_obs        | -1.64      |
| _std_act        | 0.453174   |
| _std_adv        | 1          |
| _std_discrew    | 0.0985     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00156572  |
| Phi_loss        | 1644.09     |
| PolicyEntropy   | -0.936955   |
| PolicyLoss      | 0.000129855 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0012      |
| _MeanReward     | 1.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.91061     |
| _max_adv        | 3.09        |
| _max_discrew    | 1.42        |
| _max_obs        | 1.4         |
| _mean_act       | -0.00908151 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.0399      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.0028     |
| _min_obs        | -1.67       |
| _std_act        | 0.451786    |
| _std_adv        | 1           |
| _std_discrew    | 0.102       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00245325 |
| Phi_loss        | 1625.11    |
| PolicyEntropy   | -0.950047  |
| PolicyLoss      | 0.0134388  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00199    |
| _MeanReward     | 1.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.87538    |
| _max_adv        | 3.99       |
| _max_discrew    | 1.38       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0102531 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.05       |
| _mean_obs       | 0.0399     |
| _min_adv        | -3.68      |
| _min_discrew    | -0.0041    |
| _min_obs        | -1.65      |
| _std_act        | 0.450736   |
| _std_adv        | 1          |
| _std_discrew    | 0.0988     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00679396 |
| Phi_loss        | 1732.52    |
| PolicyEntropy   | -0.955678  |
| PolicyLoss      | -0.0168209 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00148    |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.91758    |
| _max_adv        | 3.38       |
| _max_discrew    | 1.38       |
| _max_obs        | 1.46       |
| _mean_act       | -0.012403  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0398     |
| _min_adv        | -2.89      |
| _min_discrew    | -0.00492   |
| _min_obs        | -1.68      |
| _std_act        | 0.449086   |
| _std_adv        | 1          |
| _std_discrew    | 0.106      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00272878 |
| Phi_loss        | 1704.05    |
| PolicyEntropy   | -0.969884  |
| PolicyLoss      | 0.00188336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00152    |
| _MeanReward     | 1.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.90183    |
| _max_adv        | 3.51       |
| _max_discrew    | 1.35       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0140217 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0395     |
| _min_adv        | -3.52      |
| _min_discrew    | -0.00158   |
| _min_obs        | -1.67      |
| _std_act        | 0.450385   |
| _std_adv        | 1          |
| _std_discrew    | 0.0982     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00348635 |
| Phi_loss        | 1653.79    |
| PolicyEntropy   | -0.992994  |
| PolicyLoss      | 0.00881225 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0019     |
| _MeanReward     | 1.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.00015    |
| _max_adv        | 3.83       |
| _max_discrew    | 1.38       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0167954 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.039      |
| _min_adv        | -3.33      |
| _min_discrew    | -0.00276   |
| _min_obs        | -1.65      |
| _std_act        | 0.451604   |
| _std_adv        | 1          |
| _std_discrew    | 0.102      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00367036 |
| Phi_loss        | 1695.21    |
| PolicyEntropy   | -0.995483  |
| PolicyLoss      | -0.0411402 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00145    |
| _MeanReward     | 1.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92927    |
| _max_adv        | 5.07       |
| _max_discrew    | 1.35       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0134624 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.05       |
| _mean_obs       | 0.0393     |
| _min_adv        | -4.49      |
| _min_discrew    | -0.000838  |
| _min_obs        | -1.66      |
| _std_act        | 0.455122   |
| _std_adv        | 1          |
| _std_discrew    | 0.105      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00489911 |
| Phi_loss        | 1576.54    |
| PolicyEntropy   | -0.99793   |
| PolicyLoss      | -0.0153009 |
| Steps           | 10000      |
| VarFuncLoss     | 0.000866   |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.97033    |
| _max_adv        | 3.39       |
| _max_discrew    | 1.41       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0130068 |
| _mean_adv       | 5.12e-17   |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0393     |
| _min_adv        | -3.52      |
| _min_discrew    | -0.00339   |
| _min_obs        | -1.67      |
| _std_act        | 0.45566    |
| _std_adv        | 1          |
| _std_discrew    | 0.106      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.0018201  |
| Phi_loss        | 1691.49    |
| PolicyEntropy   | -1.00314   |
| PolicyLoss      | 0.0177306  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00212    |
| _MeanReward     | 1.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92168    |
| _max_adv        | 4.21       |
| _max_discrew    | 1.37       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0138188 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0392     |
| _min_adv        | -3.52      |
| _min_discrew    | -0.00101   |
| _min_obs        | -1.66      |
| _std_act        | 0.454476   |
| _std_adv        | 1          |
| _std_discrew    | 0.105      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.0043554   |
| Phi_loss        | 1693.76     |
| PolicyEntropy   | -1.01851    |
| PolicyLoss      | 0.000758378 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00134     |
| _MeanReward     | 1.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.87315     |
| _max_adv        | 3.14        |
| _max_discrew    | 1.38        |
| _max_obs        | 1.32        |
| _mean_act       | -0.010448   |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.0395      |
| _min_adv        | -3.57       |
| _min_discrew    | -0.00444    |
| _min_obs        | -1.66       |
| _std_act        | 0.456937    |
| _std_adv        | 1           |
| _std_discrew    | 0.103       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00339843  |
| Phi_loss        | 1722.57     |
| PolicyEntropy   | -1.0538     |
| PolicyLoss      | 0.00369908  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00111     |
| _MeanReward     | 1.29e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.83624     |
| _max_adv        | 3.62        |
| _max_discrew    | 1.4         |
| _max_obs        | 1.34        |
| _mean_act       | -0.00983214 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.0396      |
| _min_adv        | -3.91       |
| _min_discrew    | -0.000148   |
| _min_obs        | -1.66       |
| _std_act        | 0.453326    |
| _std_adv        | 1           |
| _std_discrew    | 0.107       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00380336 |
| Phi_loss        | 1781.47    |
| PolicyEntropy   | -1.08342   |
| PolicyLoss      | 0.0107552  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00146    |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92791    |
| _max_adv        | 3.09       |
| _max_discrew    | 1.39       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0106777 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0394     |
| _min_adv        | -3.59      |
| _min_discrew    | -0.00415   |
| _min_obs        | -1.67      |
| _std_act        | 0.453402   |
| _std_adv        | 1          |
| _std_discrew    | 0.102      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.0021384  |
| Phi_loss        | 1874.75    |
| PolicyEntropy   | -1.0991    |
| PolicyLoss      | -0.0103001 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00157    |
| _MeanReward     | 1.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.8676     |
| _max_adv        | 3.66       |
| _max_discrew    | 1.36       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0164493 |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 1.05       |
| _mean_obs       | 0.0385     |
| _min_adv        | -4.24      |
| _min_discrew    | 0.000549   |
| _min_obs        | -1.69      |
| _std_act        | 0.447751   |
| _std_adv        | 1          |
| _std_discrew    | 0.0983     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
----------------------------------
| Beta            | 0.0643       |
| ExplainedVarNew | 0.991        |
| ExplainedVarOld | 0.99         |
| KL              | 0.00379229   |
| Phi_loss        | 1733.71      |
| PolicyEntropy   | -1.10742     |
| PolicyLoss      | -0.000626272 |
| Steps           | 10000        |
| VarFuncLoss     | 0.000929     |
| _MeanReward     | 1.29e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 1.92448      |
| _max_adv        | 3.01         |
| _max_discrew    | 1.39         |
| _max_obs        | 1.31         |
| _mean_act       | -0.0188473   |
| _mean_adv       | -1.71e-17    |
| _mean_discrew   | 1.07         |
| _mean_obs       | 0.0383       |
| _min_adv        | -5.95        |
| _min_discrew    | -0.00124     |
| _min_obs        | -1.66        |
| _std_act        | 0.445963     |
| _std_adv        | 1            |
| _std_discrew    | 0.107        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00647809 |
| Phi_loss        | 1687.61    |
| PolicyEntropy   | -1.11903   |
| PolicyLoss      | 0.011629   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00153    |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.89265    |
| _max_adv        | 3.37       |
| _max_discrew    | 1.39       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0184475 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.17      |
| _min_discrew    | -0.00249   |
| _min_obs        | -1.66      |
| _std_act        | 0.444615   |
| _std_adv        | 1          |
| _std_discrew    | 0.102      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00234525 |
| Phi_loss        | 1747.54    |
| PolicyEntropy   | -1.12282   |
| PolicyLoss      | 0.00236128 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00183    |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80186    |
| _max_adv        | 4.19       |
| _max_discrew    | 1.39       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0181024 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.83      |
| _min_discrew    | -0.00467   |
| _min_obs        | -1.69      |
| _std_act        | 0.442248   |
| _std_adv        | 1          |
| _std_discrew    | 0.0993     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00477139 |
| Phi_loss        | 1798.48    |
| PolicyEntropy   | -1.15099   |
| PolicyLoss      | -0.0109077 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00175    |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92165    |
| _max_adv        | 3.46       |
| _max_discrew    | 1.43       |
| _max_obs        | 1.35       |
| _mean_act       | -0.019785  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.78      |
| _min_discrew    | -0.0054    |
| _min_obs        | -1.69      |
| _std_act        | 0.446145   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00331482 |
| Phi_loss        | 1858.08    |
| PolicyEntropy   | -1.17938   |
| PolicyLoss      | -0.0126192 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00181    |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.89385    |
| _max_adv        | 3.08       |
| _max_discrew    | 1.41       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0197555 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.07       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.44      |
| _min_discrew    | -0.00337   |
| _min_obs        | -1.68      |
| _std_act        | 0.447902   |
| _std_adv        | 1          |
| _std_discrew    | 0.105      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00371468  |
| Phi_loss        | 1870.34     |
| PolicyEntropy   | -1.18878    |
| PolicyLoss      | -0.00620873 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00191     |
| _MeanReward     | 1.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.93685     |
| _max_adv        | 3.34        |
| _max_discrew    | 1.4         |
| _max_obs        | 1.5         |
| _mean_act       | -0.017101   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.08        |
| _mean_obs       | 0.0387      |
| _min_adv        | -3.5        |
| _min_discrew    | -0.00149    |
| _min_obs        | -1.68       |
| _std_act        | 0.450241    |
| _std_adv        | 1           |
| _std_discrew    | 0.103       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00208813 |
| Phi_loss        | 1952.56    |
| PolicyEntropy   | -1.20606   |
| PolicyLoss      | -0.0122411 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00139    |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.05035    |
| _max_adv        | 3.11       |
| _max_discrew    | 1.45       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0187251 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0386     |
| _min_adv        | -4.47      |
| _min_discrew    | -0.00368   |
| _min_obs        | -1.69      |
| _std_act        | 0.45       |
| _std_adv        | 1          |
| _std_discrew    | 0.108      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00271729  |
| Phi_loss        | 1976.24     |
| PolicyEntropy   | -1.22417    |
| PolicyLoss      | -0.00985356 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00207     |
| _MeanReward     | 1.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.05223     |
| _max_adv        | 3.16        |
| _max_discrew    | 1.43        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0170787  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 1.09        |
| _mean_obs       | 0.0389      |
| _min_adv        | -11.6       |
| _min_discrew    | -0.00262    |
| _min_obs        | -1.69       |
| _std_act        | 0.451095    |
| _std_adv        | 1           |
| _std_discrew    | 0.106       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00216319  |
| Phi_loss        | 1874.21     |
| PolicyEntropy   | -1.25723    |
| PolicyLoss      | -0.00148332 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00147     |
| _MeanReward     | 1.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 1.96005     |
| _max_adv        | 3.97        |
| _max_discrew    | 1.44        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0191811  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 1.07        |
| _mean_obs       | 0.0385      |
| _min_adv        | -3.47       |
| _min_discrew    | -0.00383    |
| _min_obs        | -1.68       |
| _std_act        | 0.448182    |
| _std_adv        | 1           |
| _std_discrew    | 0.107       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00319837 |
| Phi_loss        | 2022.74    |
| PolicyEntropy   | -1.2729    |
| PolicyLoss      | -0.0408096 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00238    |
| _MeanReward     | 1.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.0051     |
| _max_adv        | 4.4        |
| _max_discrew    | 1.41       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0163609 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.07       |
| _mean_obs       | 0.0389     |
| _min_adv        | -3.47      |
| _min_discrew    | -0.00462   |
| _min_obs        | -1.67      |
| _std_act        | 0.452434   |
| _std_adv        | 1          |
| _std_discrew    | 0.105      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00228244 |
| Phi_loss        | 2145.33    |
| PolicyEntropy   | -1.29955   |
| PolicyLoss      | -0.0275828 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00204    |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83967    |
| _max_adv        | 3.56       |
| _max_discrew    | 1.45       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0178565 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.07       |
| _mean_obs       | 0.0386     |
| _min_adv        | -3.63      |
| _min_discrew    | -0.00355   |
| _min_obs        | -1.69      |
| _std_act        | 0.455864   |
| _std_adv        | 1          |
| _std_discrew    | 0.107      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00535754  |
| Phi_loss        | 2253.91     |
| PolicyEntropy   | -1.31094    |
| PolicyLoss      | -0.00279465 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00204     |
| _MeanReward     | 1.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.87611     |
| _max_adv        | 4.25        |
| _max_discrew    | 1.41        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0173435  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.08        |
| _mean_obs       | 0.0387      |
| _min_adv        | -3.36       |
| _min_discrew    | -0.00195    |
| _min_obs        | -1.67       |
| _std_act        | 0.454034    |
| _std_adv        | 1           |
| _std_discrew    | 0.109       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00446673 |
| Phi_loss        | 2039.43    |
| PolicyEntropy   | -1.31474   |
| PolicyLoss      | 0.00494227 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0023     |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83731    |
| _max_adv        | 3.61       |
| _max_discrew    | 1.41       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0216435 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.8       |
| _min_discrew    | -0.0041    |
| _min_obs        | -1.69      |
| _std_act        | 0.455133   |
| _std_adv        | 1          |
| _std_discrew    | 0.109      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00522151 |
| Phi_loss        | 2078.38    |
| PolicyEntropy   | -1.32146   |
| PolicyLoss      | -0.0383882 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00148    |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.8667     |
| _max_adv        | 3.42       |
| _max_discrew    | 1.4        |
| _max_obs        | 1.38       |
| _mean_act       | -0.0214785 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.00104   |
| _min_obs        | -1.68      |
| _std_act        | 0.456183   |
| _std_adv        | 1          |
| _std_discrew    | 0.106      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0044624  |
| Phi_loss        | 2247.6     |
| PolicyEntropy   | -1.3419    |
| PolicyLoss      | -0.0117435 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00195    |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.94428    |
| _max_adv        | 3.49       |
| _max_discrew    | 1.41       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0197846 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0385     |
| _min_adv        | -3.82      |
| _min_discrew    | 0.00136    |
| _min_obs        | -1.7       |
| _std_act        | 0.458315   |
| _std_adv        | 1          |
| _std_discrew    | 0.108      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00434086 |
| Phi_loss        | 2387.48    |
| PolicyEntropy   | -1.35225   |
| PolicyLoss      | 0.00303497 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00113    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.89216    |
| _max_adv        | 2.88       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.4        |
| _mean_act       | -0.018957  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.039      |
| _min_adv        | -10.8      |
| _min_discrew    | -0.0028    |
| _min_obs        | -1.69      |
| _std_act        | 0.464243   |
| _std_adv        | 1          |
| _std_discrew    | 0.114      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00398541 |
| Phi_loss        | 1974.84    |
| PolicyEntropy   | -1.3598    |
| PolicyLoss      | -0.0366395 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00307    |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.11569    |
| _max_adv        | 3.27       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0230041 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0381     |
| _min_adv        | -10.8      |
| _min_discrew    | -0.00355   |
| _min_obs        | -1.69      |
| _std_act        | 0.461903   |
| _std_adv        | 1          |
| _std_discrew    | 0.109      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00283073 |
| Phi_loss        | 2002.81    |
| PolicyEntropy   | -1.36281   |
| PolicyLoss      | -0.0196157 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00175    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.8383     |
| _max_adv        | 3.52       |
| _max_discrew    | 1.42       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0193904 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0389     |
| _min_adv        | -4.02      |
| _min_discrew    | -0.00287   |
| _min_obs        | -1.71      |
| _std_act        | 0.466539   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00360673 |
| Phi_loss        | 2197.18    |
| PolicyEntropy   | -1.38015   |
| PolicyLoss      | -0.0146388 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00171    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.86731    |
| _max_adv        | 3.88       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0212659 |
| _mean_adv       | -3.69e-17  |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0386     |
| _min_adv        | -3.58      |
| _min_discrew    | -0.0034    |
| _min_obs        | -1.71      |
| _std_act        | 0.464046   |
| _std_adv        | 1          |
| _std_discrew    | 0.106      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00202581 |
| Phi_loss        | 2349.33    |
| PolicyEntropy   | -1.39915   |
| PolicyLoss      | -0.0243024 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0017     |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.98167    |
| _max_adv        | 4.4        |
| _max_discrew    | 1.43       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0211678 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.19      |
| _min_discrew    | -0.00375   |
| _min_obs        | -1.71      |
| _std_act        | 0.469898   |
| _std_adv        | 1          |
| _std_discrew    | 0.109      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00273289 |
| Phi_loss        | 2293.25    |
| PolicyEntropy   | -1.41572   |
| PolicyLoss      | 0.0113188  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00187    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.91535    |
| _max_adv        | 4.06       |
| _max_discrew    | 1.52       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0175052 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0389     |
| _min_adv        | -3.46      |
| _min_discrew    | -0.00225   |
| _min_obs        | -1.71      |
| _std_act        | 0.471634   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00245976 |
| Phi_loss        | 2292.87    |
| PolicyEntropy   | -1.42295   |
| PolicyLoss      | 0.0043619  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0021     |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.93699    |
| _max_adv        | 3.81       |
| _max_discrew    | 1.53       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0193573 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0388     |
| _min_adv        | -4.16      |
| _min_discrew    | -0.00456   |
| _min_obs        | -1.69      |
| _std_act        | 0.470061   |
| _std_adv        | 1          |
| _std_discrew    | 0.114      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00311862 |
| Phi_loss        | 2284.36    |
| PolicyEntropy   | -1.4373    |
| PolicyLoss      | -0.0108852 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00288    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.96251    |
| _max_adv        | 7.9        |
| _max_discrew    | 1.46       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0181568 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.039      |
| _min_adv        | -4.33      |
| _min_discrew    | -0.00757   |
| _min_obs        | -1.7       |
| _std_act        | 0.469975   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00486662 |
| Phi_loss        | 2430.53    |
| PolicyEntropy   | -1.45968   |
| PolicyLoss      | 0.0176062  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00157    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.7361     |
| _max_adv        | 3.29       |
| _max_discrew    | 1.42       |
| _max_obs        | 1.34       |
| _mean_act       | -0.015216  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0393     |
| _min_adv        | -3.54      |
| _min_discrew    | -0.00387   |
| _min_obs        | -1.7       |
| _std_act        | 0.468802   |
| _std_adv        | 1          |
| _std_discrew    | 0.112      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0029004  |
| Phi_loss        | 2523.46    |
| PolicyEntropy   | -1.46857   |
| PolicyLoss      | 0.0102541  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00208    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92306    |
| _max_adv        | 3.55       |
| _max_discrew    | 1.42       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0162579 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0389     |
| _min_adv        | -9.65      |
| _min_discrew    | -0.00584   |
| _min_obs        | -1.72      |
| _std_act        | 0.467338   |
| _std_adv        | 1          |
| _std_discrew    | 0.105      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00389061 |
| Phi_loss        | 2243.33    |
| PolicyEntropy   | -1.48866   |
| PolicyLoss      | 0.00494189 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00188    |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.78873    |
| _max_adv        | 3.69       |
| _max_discrew    | 1.5        |
| _max_obs        | 1.38       |
| _mean_act       | -0.0144268 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0391     |
| _min_adv        | -4         |
| _min_discrew    | -0.0036    |
| _min_obs        | -1.7       |
| _std_act        | 0.465402   |
| _std_adv        | 1          |
| _std_discrew    | 0.106      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00321469 |
| Phi_loss        | 2529.13    |
| PolicyEntropy   | -1.5097    |
| PolicyLoss      | 0.0190195  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00231    |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.87672    |
| _max_adv        | 3.23       |
| _max_discrew    | 1.4        |
| _max_obs        | 1.36       |
| _mean_act       | -0.0137826 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0392     |
| _min_adv        | -3.4       |
| _min_discrew    | -0.00324   |
| _min_obs        | -1.69      |
| _std_act        | 0.461848   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00484998 |
| Phi_loss        | 2399.64    |
| PolicyEntropy   | -1.52303   |
| PolicyLoss      | -0.0288169 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00144    |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.95424    |
| _max_adv        | 3.81       |
| _max_discrew    | 1.48       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0181907 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0392     |
| _min_adv        | -4.07      |
| _min_discrew    | 0.00174    |
| _min_obs        | -1.69      |
| _std_act        | 0.467143   |
| _std_adv        | 1          |
| _std_discrew    | 0.114      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00398889 |
| Phi_loss        | 2798.23    |
| PolicyEntropy   | -1.53671   |
| PolicyLoss      | -0.0216411 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00239    |
| _MeanReward     | 1.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.84368    |
| _max_adv        | 3.64       |
| _max_discrew    | 1.46       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0173625 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0391     |
| _min_adv        | -10.9      |
| _min_discrew    | -0.00368   |
| _min_obs        | -1.71      |
| _std_act        | 0.470798   |
| _std_adv        | 1          |
| _std_discrew    | 0.115      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0035534  |
| Phi_loss        | 2306.72    |
| PolicyEntropy   | -1.55288   |
| PolicyLoss      | 0.053326   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00215    |
| _MeanReward     | 1.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.82159    |
| _max_adv        | 3.54       |
| _max_discrew    | 1.49       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0166979 |
| _mean_adv       | -1.92e-17  |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0394     |
| _min_adv        | -3.24      |
| _min_discrew    | -0.00306   |
| _min_obs        | -1.71      |
| _std_act        | 0.465314   |
| _std_adv        | 1          |
| _std_discrew    | 0.119      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00376519  |
| Phi_loss        | 2834.77     |
| PolicyEntropy   | -1.56283    |
| PolicyLoss      | -0.00555808 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00153     |
| _MeanReward     | 1.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.00942     |
| _max_adv        | 3.4         |
| _max_discrew    | 1.5         |
| _max_obs        | 1.31        |
| _mean_act       | -0.0175656  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 1.12        |
| _mean_obs       | 0.0392      |
| _min_adv        | -3.78       |
| _min_discrew    | -0.00668    |
| _min_obs        | -1.71       |
| _std_act        | 0.464977    |
| _std_adv        | 1           |
| _std_discrew    | 0.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.98        |
| KL              | 0.00411559  |
| Phi_loss        | 2600.11     |
| PolicyEntropy   | -1.57922    |
| PolicyLoss      | -0.00081778 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0024      |
| _MeanReward     | 1.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.80616     |
| _max_adv        | 4.07        |
| _max_discrew    | 1.46        |
| _max_obs        | 1.27        |
| _mean_act       | -0.0186694  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0388      |
| _min_adv        | -3.8        |
| _min_discrew    | -0.000985   |
| _min_obs        | -1.71       |
| _std_act        | 0.46599     |
| _std_adv        | 1           |
| _std_discrew    | 0.116       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00446333 |
| Phi_loss        | 2645.42    |
| PolicyEntropy   | -1.60195   |
| PolicyLoss      | -0.0327186 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00164    |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80623    |
| _max_adv        | 3.68       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.32       |
| _mean_act       | -0.013969  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0394     |
| _min_adv        | -3.85      |
| _min_discrew    | -0.00275   |
| _min_obs        | -1.72      |
| _std_act        | 0.468318   |
| _std_adv        | 1          |
| _std_discrew    | 0.113      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00503873 |
| Phi_loss        | 2627.39    |
| PolicyEntropy   | -1.63716   |
| PolicyLoss      | -0.0154406 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00216    |
| _MeanReward     | 1.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.97115    |
| _max_adv        | 3.45       |
| _max_discrew    | 1.45       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0187437 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.11       |
| _mean_obs       | 0.0387     |
| _min_adv        | -10.7      |
| _min_discrew    | -0.00407   |
| _min_obs        | -1.73      |
| _std_act        | 0.474309   |
| _std_adv        | 1          |
| _std_discrew    | 0.117      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00526804 |
| Phi_loss        | 2509.94    |
| PolicyEntropy   | -1.67225   |
| PolicyLoss      | 0.0120202  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00212    |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.912      |
| _max_adv        | 3.98       |
| _max_discrew    | 1.46       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0223732 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0384     |
| _min_adv        | -3.89      |
| _min_discrew    | -0.00336   |
| _min_obs        | -1.73      |
| _std_act        | 0.469235   |
| _std_adv        | 1          |
| _std_discrew    | 0.118      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00651216 |
| Phi_loss        | 2818.87    |
| PolicyEntropy   | -1.69018   |
| PolicyLoss      | 0.00591142 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00175    |
| _MeanReward     | 1.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.8923     |
| _max_adv        | 3.41       |
| _max_discrew    | 1.46       |
| _max_obs        | 1.33       |
| _mean_act       | -0.027113  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0376     |
| _min_adv        | -4.07      |
| _min_discrew    | -0.00286   |
| _min_obs        | -1.73      |
| _std_act        | 0.465993   |
| _std_adv        | 1          |
| _std_discrew    | 0.117      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00335595  |
| Phi_loss        | 2875.31     |
| PolicyEntropy   | -1.69298    |
| PolicyLoss      | -0.00335042 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00208     |
| _MeanReward     | 1.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.85684     |
| _max_adv        | 3.02        |
| _max_discrew    | 1.44        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0284322  |
| _mean_adv       | -4.69e-17   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0374      |
| _min_adv        | -3.7        |
| _min_discrew    | -0.00238    |
| _min_obs        | -1.71       |
| _std_act        | 0.466666    |
| _std_adv        | 1           |
| _std_discrew    | 0.117       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00459133 |
| Phi_loss        | 2768.14    |
| PolicyEntropy   | -1.7177    |
| PolicyLoss      | 0.0232445  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00168    |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.82291    |
| _max_adv        | 4.07       |
| _max_discrew    | 1.52       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0298463 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.037      |
| _min_adv        | -2.97      |
| _min_discrew    | -0.00319   |
| _min_obs        | -1.72      |
| _std_act        | 0.461432   |
| _std_adv        | 1          |
| _std_discrew    | 0.113      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00184909 |
| Phi_loss        | 2918.39    |
| PolicyEntropy   | -1.74251   |
| PolicyLoss      | -0.0135488 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00176    |
| _MeanReward     | 1.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83125    |
| _max_adv        | 3.61       |
| _max_discrew    | 1.5        |
| _max_obs        | 1.25       |
| _mean_act       | -0.0284427 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.17      |
| _min_discrew    | -0.00397   |
| _min_obs        | -1.73      |
| _std_act        | 0.466629   |
| _std_adv        | 1          |
| _std_discrew    | 0.115      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00382607 |
| Phi_loss        | 2563.41    |
| PolicyEntropy   | -1.77345   |
| PolicyLoss      | 0.0281743  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00223    |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.96289    |
| _max_adv        | 3.56       |
| _max_discrew    | 1.52       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0278334 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0373     |
| _min_adv        | -10.4      |
| _min_discrew    | -0.00387   |
| _min_obs        | -1.75      |
| _std_act        | 0.464226   |
| _std_adv        | 1          |
| _std_discrew    | 0.119      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00300235 |
| Phi_loss        | 2922.43    |
| PolicyEntropy   | -1.79743   |
| PolicyLoss      | -0.0281423 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00239    |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.74859    |
| _max_adv        | 3.91       |
| _max_discrew    | 1.47       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0293866 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0373     |
| _min_adv        | -3.54      |
| _min_discrew    | -0.00382   |
| _min_obs        | -1.74      |
| _std_act        | 0.466901   |
| _std_adv        | 1          |
| _std_discrew    | 0.115      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00322565 |
| Phi_loss        | 2869.87    |
| PolicyEntropy   | -1.83026   |
| PolicyLoss      | 0.0229896  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00172    |
| _MeanReward     | 1.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83385    |
| _max_adv        | 3.58       |
| _max_discrew    | 1.49       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0319556 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.037      |
| _min_adv        | -6.32      |
| _min_discrew    | -0.00688   |
| _min_obs        | -1.72      |
| _std_act        | 0.46226    |
| _std_adv        | 1          |
| _std_discrew    | 0.118      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00533321 |
| Phi_loss        | 3099.91    |
| PolicyEntropy   | -1.84326   |
| PolicyLoss      | -0.0358197 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00237    |
| _MeanReward     | 1.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.74439    |
| _max_adv        | 3.18       |
| _max_discrew    | 1.52       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0282143 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0378     |
| _min_adv        | -4.15      |
| _min_discrew    | -0.00377   |
| _min_obs        | -1.76      |
| _std_act        | 0.463793   |
| _std_adv        | 1          |
| _std_discrew    | 0.117      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00383948 |
| Phi_loss        | 3083.59    |
| PolicyEntropy   | -1.86528   |
| PolicyLoss      | 0.00684106 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00242    |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.89736    |
| _max_adv        | 4.3        |
| _max_discrew    | 1.5        |
| _max_obs        | 1.29       |
| _mean_act       | -0.029098  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0374     |
| _min_adv        | -3.93      |
| _min_discrew    | -0.00389   |
| _min_obs        | -1.73      |
| _std_act        | 0.45988    |
| _std_adv        | 1          |
| _std_discrew    | 0.121      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00426888 |
| Phi_loss        | 2934.96    |
| PolicyEntropy   | -1.87714   |
| PolicyLoss      | -0.0367466 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00209    |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.69022    |
| _max_adv        | 3.96       |
| _max_discrew    | 1.5        |
| _max_obs        | 1.31       |
| _mean_act       | -0.0286588 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0378     |
| _min_adv        | -3.52      |
| _min_discrew    | -0.00478   |
| _min_obs        | -1.73      |
| _std_act        | 0.466066   |
| _std_adv        | 1          |
| _std_discrew    | 0.123      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00247739 |
| Phi_loss        | 3194.62    |
| PolicyEntropy   | -1.89068   |
| PolicyLoss      | -0.0126228 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00163    |
| _MeanReward     | 1.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.16802    |
| _max_adv        | 4.23       |
| _max_discrew    | 1.48       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0253524 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0379     |
| _min_adv        | -11.7      |
| _min_discrew    | -0.00401   |
| _min_obs        | -1.73      |
| _std_act        | 0.467963   |
| _std_adv        | 1          |
| _std_discrew    | 0.117      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00295552 |
| Phi_loss        | 2950.22    |
| PolicyEntropy   | -1.87872   |
| PolicyLoss      | -0.0304448 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00241    |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.04664    |
| _max_adv        | 6.54       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0265096 |
| _mean_adv       | 6.54e-17   |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0382     |
| _min_adv        | -5.16      |
| _min_discrew    | -0.00199   |
| _min_obs        | -1.74      |
| _std_act        | 0.471815   |
| _std_adv        | 1          |
| _std_discrew    | 0.118      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00458588 |
| Phi_loss        | 3053.23    |
| PolicyEntropy   | -1.87663   |
| PolicyLoss      | -0.0768201 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00245    |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.82058    |
| _max_adv        | 5.22       |
| _max_discrew    | 1.49       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0267114 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.35      |
| _min_discrew    | -0.00258   |
| _min_obs        | -1.75      |
| _std_act        | 0.471079   |
| _std_adv        | 1          |
| _std_discrew    | 0.118      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00325632  |
| Phi_loss        | 3207.12     |
| PolicyEntropy   | -1.89093    |
| PolicyLoss      | -0.00193473 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00173     |
| _MeanReward     | 1.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.85385     |
| _max_adv        | 3.78        |
| _max_discrew    | 1.53        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0267573  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.15        |
| _mean_obs       | 0.038       |
| _min_adv        | -3.46       |
| _min_discrew    | -0.00224    |
| _min_obs        | -1.75       |
| _std_act        | 0.472926    |
| _std_adv        | 1           |
| _std_discrew    | 0.119       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00388857 |
| Phi_loss        | 3183.28    |
| PolicyEntropy   | -1.8918    |
| PolicyLoss      | -0.0474305 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00235    |
| _MeanReward     | 1.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.91667    |
| _max_adv        | 3.71       |
| _max_discrew    | 1.47       |
| _max_obs        | 1.33       |
| _mean_act       | -0.025926  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.59      |
| _min_discrew    | -0.00446   |
| _min_obs        | -1.75      |
| _std_act        | 0.474387   |
| _std_adv        | 1          |
| _std_discrew    | 0.117      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.002705   |
| Phi_loss        | 3179.76    |
| PolicyEntropy   | -1.89029   |
| PolicyLoss      | 0.00825612 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0017     |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.84779    |
| _max_adv        | 3.86       |
| _max_discrew    | 1.53       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0254815 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0384     |
| _min_adv        | -10.6      |
| _min_discrew    | -0.0029    |
| _min_obs        | -1.75      |
| _std_act        | 0.479106   |
| _std_adv        | 1          |
| _std_discrew    | 0.114      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00294141  |
| Phi_loss        | 2922.12     |
| PolicyEntropy   | -1.88727    |
| PolicyLoss      | -0.00475021 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00249     |
| _MeanReward     | 1.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.83444     |
| _max_adv        | 3.07        |
| _max_discrew    | 1.52        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0264605  |
| _mean_adv       | -2.13e-17   |
| _mean_discrew   | 1.13        |
| _mean_obs       | 0.0382      |
| _min_adv        | -3.51       |
| _min_discrew    | -0.00335    |
| _min_obs        | -1.73       |
| _std_act        | 0.474838    |
| _std_adv        | 1           |
| _std_discrew    | 0.119       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00335957 |
| Phi_loss        | 3191.9     |
| PolicyEntropy   | -1.91763   |
| PolicyLoss      | -0.010861  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00337    |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.89809    |
| _max_adv        | 5.59       |
| _max_discrew    | 1.52       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0271494 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.0383     |
| _min_adv        | -5.84      |
| _min_discrew    | -0.00303   |
| _min_obs        | -1.76      |
| _std_act        | 0.482102   |
| _std_adv        | 1          |
| _std_discrew    | 0.121      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00241388 |
| Phi_loss        | 3189.33    |
| PolicyEntropy   | -1.93607   |
| PolicyLoss      | 0.00862526 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00244    |
| _MeanReward     | 1.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.81208    |
| _max_adv        | 3.65       |
| _max_discrew    | 1.53       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0289775 |
| _mean_adv       | 5.12e-17   |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0375     |
| _min_adv        | -8.69      |
| _min_discrew    | -0.00795   |
| _min_obs        | -1.77      |
| _std_act        | 0.47799    |
| _std_adv        | 1          |
| _std_discrew    | 0.114      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00278434 |
| Phi_loss        | 3039.92    |
| PolicyEntropy   | -1.95843   |
| PolicyLoss      | 0.0501359  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0027     |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.87406    |
| _max_adv        | 2.96       |
| _max_discrew    | 1.5        |
| _max_obs        | 1.21       |
| _mean_act       | -0.0276857 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0378     |
| _min_adv        | -3.88      |
| _min_discrew    | -0.0014    |
| _min_obs        | -1.77      |
| _std_act        | 0.47381    |
| _std_adv        | 1          |
| _std_discrew    | 0.124      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00310066 |
| Phi_loss        | 3149.73    |
| PolicyEntropy   | -1.96617   |
| PolicyLoss      | 0.00332753 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00183    |
| _MeanReward     | 1.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92421    |
| _max_adv        | 4.99       |
| _max_discrew    | 1.54       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0223849 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0385     |
| _min_adv        | -3.29      |
| _min_discrew    | -0.00421   |
| _min_obs        | -1.77      |
| _std_act        | 0.47314    |
| _std_adv        | 1          |
| _std_discrew    | 0.117      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00348238  |
| Phi_loss        | 3331.12     |
| PolicyEntropy   | -1.97799    |
| PolicyLoss      | -0.00640727 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00209     |
| _MeanReward     | 1.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.82027     |
| _max_adv        | 5.13        |
| _max_discrew    | 1.56        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0279998  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.14        |
| _mean_obs       | 0.0374      |
| _min_adv        | -3.91       |
| _min_discrew    | 0.00202     |
| _min_obs        | -1.73       |
| _std_act        | 0.470018    |
| _std_adv        | 1           |
| _std_discrew    | 0.121       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00161324 |
| Phi_loss        | 3385.4     |
| PolicyEntropy   | -1.98735   |
| PolicyLoss      | -0.017156  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00279    |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.86821    |
| _max_adv        | 3.77       |
| _max_discrew    | 1.54       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0265462 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.04      |
| _min_discrew    | -0.0048    |
| _min_obs        | -1.74      |
| _std_act        | 0.474459   |
| _std_adv        | 1          |
| _std_discrew    | 0.124      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00137538  |
| Phi_loss        | 3320.28     |
| PolicyEntropy   | -1.98822    |
| PolicyLoss      | -0.00189854 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00239     |
| _MeanReward     | 1.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.83602     |
| _max_adv        | 3.13        |
| _max_discrew    | 1.57        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0271542  |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 1.17        |
| _mean_obs       | 0.038       |
| _min_adv        | -3.39       |
| _min_discrew    | -0.00304    |
| _min_obs        | -1.78       |
| _std_act        | 0.473133    |
| _std_adv        | 1           |
| _std_discrew    | 0.124       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00298255 |
| Phi_loss        | 3636.1     |
| PolicyEntropy   | -1.99673   |
| PolicyLoss      | -0.0143195 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0027     |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.74773    |
| _max_adv        | 3.69       |
| _max_discrew    | 1.56       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0267511 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.46      |
| _min_discrew    | -0.0034    |
| _min_obs        | -1.76      |
| _std_act        | 0.472106   |
| _std_adv        | 1          |
| _std_discrew    | 0.127      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00546056 |
| Phi_loss        | 3433.29    |
| PolicyEntropy   | -2.00145   |
| PolicyLoss      | 0.0141371  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00261    |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.84565    |
| _max_adv        | 3.48       |
| _max_discrew    | 1.55       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0264954 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.62      |
| _min_discrew    | -0.00413   |
| _min_obs        | -1.75      |
| _std_act        | 0.468624   |
| _std_adv        | 1          |
| _std_discrew    | 0.127      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00475748 |
| Phi_loss        | 3477.95    |
| PolicyEntropy   | -2.00313   |
| PolicyLoss      | -0.0212356 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00237    |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.15918    |
| _max_adv        | 3.6        |
| _max_discrew    | 1.55       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0273664 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.36      |
| _min_discrew    | -0.00282   |
| _min_obs        | -1.74      |
| _std_act        | 0.470934   |
| _std_adv        | 1          |
| _std_discrew    | 0.123      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00544922 |
| Phi_loss        | 3428.9     |
| PolicyEntropy   | -2.01181   |
| PolicyLoss      | 0.00278954 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00196    |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.1267     |
| _max_adv        | 3.54       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0321249 |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0372     |
| _min_adv        | -3.58      |
| _min_discrew    | -0.0041    |
| _min_obs        | -1.77      |
| _std_act        | 0.471388   |
| _std_adv        | 1          |
| _std_discrew    | 0.122      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00580441 |
| Phi_loss        | 3458.91    |
| PolicyEntropy   | -2.0332    |
| PolicyLoss      | -0.0276673 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00193    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.77961    |
| _max_adv        | 3.09       |
| _max_discrew    | 1.58       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0326469 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0373     |
| _min_adv        | -3.45      |
| _min_discrew    | -0.00348   |
| _min_obs        | -1.78      |
| _std_act        | 0.47053    |
| _std_adv        | 1          |
| _std_discrew    | 0.129      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00567875 |
| Phi_loss        | 3734.23    |
| PolicyEntropy   | -2.05341   |
| PolicyLoss      | 0.00270579 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00255    |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.78684    |
| _max_adv        | 3.61       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0352108 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.0369     |
| _min_adv        | -3.28      |
| _min_discrew    | -0.00436   |
| _min_obs        | -1.74      |
| _std_act        | 0.468314   |
| _std_adv        | 1          |
| _std_discrew    | 0.125      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00595979 |
| Phi_loss        | 3642.2     |
| PolicyEntropy   | -2.07483   |
| PolicyLoss      | -0.0225385 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0025     |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80162    |
| _max_adv        | 3.26       |
| _max_discrew    | 1.57       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0366926 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0368     |
| _min_adv        | -3.91      |
| _min_discrew    | -0.0046    |
| _min_obs        | -1.78      |
| _std_act        | 0.466164   |
| _std_adv        | 1          |
| _std_discrew    | 0.121      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00465816 |
| Phi_loss        | 3581.05    |
| PolicyEntropy   | -2.07942   |
| PolicyLoss      | 0.0204346  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00258    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80769    |
| _max_adv        | 3.29       |
| _max_discrew    | 1.53       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0359797 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0369     |
| _min_adv        | -3.95      |
| _min_discrew    | -0.00469   |
| _min_obs        | -1.77      |
| _std_act        | 0.464244   |
| _std_adv        | 1          |
| _std_discrew    | 0.132      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00607042 |
| Phi_loss        | 3586.31    |
| PolicyEntropy   | -2.11946   |
| PolicyLoss      | 0.0308782  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00205    |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.79198    |
| _max_adv        | 3.44       |
| _max_discrew    | 1.64       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0363309 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.0366     |
| _min_adv        | -3.49      |
| _min_discrew    | -0.0047    |
| _min_obs        | -1.77      |
| _std_act        | 0.463389   |
| _std_adv        | 1          |
| _std_discrew    | 0.126      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00278543  |
| Phi_loss        | 3878.42     |
| PolicyEntropy   | -2.14312    |
| PolicyLoss      | -0.00996445 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00342     |
| _MeanReward     | 1.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.87907     |
| _max_adv        | 4.41        |
| _max_discrew    | 1.55        |
| _max_obs        | 1.37        |
| _mean_act       | -0.035027   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.17        |
| _mean_obs       | 0.0372      |
| _min_adv        | -3.44       |
| _min_discrew    | 0.00329     |
| _min_obs        | -1.76       |
| _std_act        | 0.469464    |
| _std_adv        | 1           |
| _std_discrew    | 0.129       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00385223 |
| Phi_loss        | 3886.32    |
| PolicyEntropy   | -2.15309   |
| PolicyLoss      | -0.0334579 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00296    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.79828    |
| _max_adv        | 3.86       |
| _max_discrew    | 1.53       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0333863 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0373     |
| _min_adv        | -3.88      |
| _min_discrew    | -0.00339   |
| _min_obs        | -1.75      |
| _std_act        | 0.472011   |
| _std_adv        | 1          |
| _std_discrew    | 0.125      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00260363  |
| Phi_loss        | 3680.47     |
| PolicyEntropy   | -2.15809    |
| PolicyLoss      | -0.00493113 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00138     |
| _MeanReward     | 1.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.82364     |
| _max_adv        | 3.96        |
| _max_discrew    | 1.65        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0342281  |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 1.19        |
| _mean_obs       | 0.0376      |
| _min_adv        | -3.34       |
| _min_discrew    | -0.00433    |
| _min_obs        | -1.75       |
| _std_act        | 0.474353    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00290626  |
| Phi_loss        | 3914.22     |
| PolicyEntropy   | -2.17532    |
| PolicyLoss      | -0.00405337 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00237     |
| _MeanReward     | 1.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.92368     |
| _max_adv        | 3.54        |
| _max_discrew    | 1.55        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0346932  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.18        |
| _mean_obs       | 0.0374      |
| _min_adv        | -9.16       |
| _min_discrew    | -0.000929   |
| _min_obs        | -1.76       |
| _std_act        | 0.473969    |
| _std_adv        | 1           |
| _std_discrew    | 0.129       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00318129 |
| Phi_loss        | 3800.67    |
| PolicyEntropy   | -2.20014   |
| PolicyLoss      | 0.0136959  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00215    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.00969    |
| _max_adv        | 3.45       |
| _max_discrew    | 1.55       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0342165 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0372     |
| _min_adv        | -11.1      |
| _min_discrew    | -0.00123   |
| _min_obs        | -1.8       |
| _std_act        | 0.474231   |
| _std_adv        | 1          |
| _std_discrew    | 0.127      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00271335 |
| Phi_loss        | 3832.75    |
| PolicyEntropy   | -2.21746   |
| PolicyLoss      | -0.0214464 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00151    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.88392    |
| _max_adv        | 7.24       |
| _max_discrew    | 1.53       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0294801 |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.00433   |
| _min_obs        | -1.79      |
| _std_act        | 0.474117   |
| _std_adv        | 1          |
| _std_discrew    | 0.126      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00429065 |
| Phi_loss        | 3855.42    |
| PolicyEntropy   | -2.23934   |
| PolicyLoss      | 0.0274481  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00161    |
| _MeanReward     | 1.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.8008     |
| _max_adv        | 5.73       |
| _max_discrew    | 1.6        |
| _max_obs        | 1.3        |
| _mean_act       | -0.0309874 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.2        |
| _mean_obs       | 0.038      |
| _min_adv        | -3.18      |
| _min_discrew    | -0.00527   |
| _min_obs        | -1.8       |
| _std_act        | 0.477124   |
| _std_adv        | 1          |
| _std_discrew    | 0.136      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00283916 |
| Phi_loss        | 3987.37    |
| PolicyEntropy   | -2.24394   |
| PolicyLoss      | -0.0243561 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00318    |
| _MeanReward     | 1.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.87039    |
| _max_adv        | 6.15       |
| _max_discrew    | 1.54       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0324039 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.18       |
| _mean_obs       | 0.0374     |
| _min_adv        | -8.41      |
| _min_discrew    | -0.00151   |
| _min_obs        | -1.78      |
| _std_act        | 0.476837   |
| _std_adv        | 1          |
| _std_discrew    | 0.127      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00307313 |
| Phi_loss        | 3995.05    |
| PolicyEntropy   | -2.25593   |
| PolicyLoss      | 0.0268218  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00197    |
| _MeanReward     | 1.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.7853     |
| _max_adv        | 4.05       |
| _max_discrew    | 1.54       |
| _max_obs        | 1.24       |
| _mean_act       | -0.029154  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.64      |
| _min_discrew    | -0.00498   |
| _min_obs        | -1.8       |
| _std_act        | 0.474212   |
| _std_adv        | 1          |
| _std_discrew    | 0.131      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00364092 |
| Phi_loss        | 4312.09    |
| PolicyEntropy   | -2.29668   |
| PolicyLoss      | -0.0420712 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00186    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.73462    |
| _max_adv        | 4.52       |
| _max_discrew    | 1.6        |
| _max_obs        | 1.26       |
| _mean_act       | -0.0330186 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.18       |
| _mean_obs       | 0.0373     |
| _min_adv        | -3.25      |
| _min_discrew    | -0.00359   |
| _min_obs        | -1.78      |
| _std_act        | 0.478445   |
| _std_adv        | 1          |
| _std_discrew    | 0.125      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00330248 |
| Phi_loss        | 4270.61    |
| PolicyEntropy   | -2.32547   |
| PolicyLoss      | -0.033001  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0028     |
| _MeanReward     | 1.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.9212     |
| _max_adv        | 3.61       |
| _max_discrew    | 1.57       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0334348 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.68      |
| _min_discrew    | -0.00386   |
| _min_obs        | -1.8       |
| _std_act        | 0.479624   |
| _std_adv        | 1          |
| _std_discrew    | 0.136      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00305797 |
| Phi_loss        | 4044.0     |
| PolicyEntropy   | -2.33152   |
| PolicyLoss      | -0.0039306 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00208    |
| _MeanReward     | 1.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.86222    |
| _max_adv        | 3.17       |
| _max_discrew    | 1.61       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0336802 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0372     |
| _min_adv        | -3.53      |
| _min_discrew    | -0.00348   |
| _min_obs        | -1.79      |
| _std_act        | 0.477859   |
| _std_adv        | 1          |
| _std_discrew    | 0.125      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00310087 |
| Phi_loss        | 4300.86    |
| PolicyEntropy   | -2.34788   |
| PolicyLoss      | 0.00415605 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00343    |
| _MeanReward     | 1.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.81882    |
| _max_adv        | 4.15       |
| _max_discrew    | 1.58       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0343169 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.037      |
| _min_adv        | -3.44      |
| _min_discrew    | -0.00144   |
| _min_obs        | -1.79      |
| _std_act        | 0.476624   |
| _std_adv        | 1          |
| _std_discrew    | 0.133      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00234292 |
| Phi_loss        | 4570.33    |
| PolicyEntropy   | -2.37111   |
| PolicyLoss      | 0.0149903  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00281    |
| _MeanReward     | 1.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.92475    |
| _max_adv        | 4.03       |
| _max_discrew    | 1.58       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0339212 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0373     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.00187   |
| _min_obs        | -1.78      |
| _std_act        | 0.478546   |
| _std_adv        | 1          |
| _std_discrew    | 0.129      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00221194 |
| Phi_loss        | 4378.34    |
| PolicyEntropy   | -2.37627   |
| PolicyLoss      | -0.0254822 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00187    |
| _MeanReward     | 1.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.82365    |
| _max_adv        | 3.21       |
| _max_discrew    | 1.55       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0356605 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0366     |
| _min_adv        | -3.69      |
| _min_discrew    | -0.00599   |
| _min_obs        | -1.78      |
| _std_act        | 0.476519   |
| _std_adv        | 1          |
| _std_discrew    | 0.133      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00272585 |
| Phi_loss        | 4576.94    |
| PolicyEntropy   | -2.38244   |
| PolicyLoss      | 0.00849105 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00232    |
| _MeanReward     | 1.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.78587    |
| _max_adv        | 3.51       |
| _max_discrew    | 1.64       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0363426 |
| _mean_adv       | 6.25e-17   |
| _mean_discrew   | 1.2        |
| _mean_obs       | 0.0372     |
| _min_adv        | -3.79      |
| _min_discrew    | 0.00131    |
| _min_obs        | -1.79      |
| _std_act        | 0.481089   |
| _std_adv        | 1          |
| _std_discrew    | 0.132      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00261748  |
| Phi_loss        | 4120.28     |
| PolicyEntropy   | -2.38402    |
| PolicyLoss      | 0.000728911 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0024      |
| _MeanReward     | 1.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.94552     |
| _max_adv        | 2.88        |
| _max_discrew    | 1.57        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0375231  |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 1.18        |
| _mean_obs       | 0.0367      |
| _min_adv        | -9.93       |
| _min_discrew    | 0.00122     |
| _min_obs        | -1.82       |
| _std_act        | 0.479661    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.0031783   |
| Phi_loss        | 3614.74     |
| PolicyEntropy   | -2.3943     |
| PolicyLoss      | -0.00831445 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00222     |
| _MeanReward     | 1.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.78242     |
| _max_adv        | 3.99        |
| _max_discrew    | 1.65        |
| _max_obs        | 1.21        |
| _mean_act       | -0.038266   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.19        |
| _mean_obs       | 0.0368      |
| _min_adv        | -4.06       |
| _min_discrew    | -0.00241    |
| _min_obs        | -1.77       |
| _std_act        | 0.479288    |
| _std_adv        | 1           |
| _std_discrew    | 0.136       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00267182 |
| Phi_loss        | 4603.25    |
| PolicyEntropy   | -2.4148    |
| PolicyLoss      | 0.00187057 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00262    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.77695    |
| _max_adv        | 4.31       |
| _max_discrew    | 1.59       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0389443 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.037      |
| _min_adv        | -3.84      |
| _min_discrew    | -0.00391   |
| _min_obs        | -1.77      |
| _std_act        | 0.479871   |
| _std_adv        | 1          |
| _std_discrew    | 0.139      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00297803 |
| Phi_loss        | 4490.55    |
| PolicyEntropy   | -2.41748   |
| PolicyLoss      | 0.0120222  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0028     |
| _MeanReward     | 1.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.86077    |
| _max_adv        | 4.35       |
| _max_discrew    | 1.61       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0387914 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0364     |
| _min_adv        | -3.44      |
| _min_discrew    | -0.00238   |
| _min_obs        | -1.8       |
| _std_act        | 0.47987    |
| _std_adv        | 1          |
| _std_discrew    | 0.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.003516    |
| Phi_loss        | 4642.3      |
| PolicyEntropy   | -2.44267    |
| PolicyLoss      | -0.00258985 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00244     |
| _MeanReward     | 1.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.75727     |
| _max_adv        | 6.72        |
| _max_discrew    | 1.62        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0363803  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.19        |
| _mean_obs       | 0.0369      |
| _min_adv        | -3.61       |
| _min_discrew    | -0.0038     |
| _min_obs        | -1.79       |
| _std_act        | 0.477687    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00270544 |
| Phi_loss        | 5045.95    |
| PolicyEntropy   | -2.4751    |
| PolicyLoss      | 0.0223574  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00203    |
| _MeanReward     | 1.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.75707    |
| _max_adv        | 3.21       |
| _max_discrew    | 1.56       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0370788 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0368     |
| _min_adv        | -3.88      |
| _min_discrew    | -0.00446   |
| _min_obs        | -1.78      |
| _std_act        | 0.476961   |
| _std_adv        | 1          |
| _std_discrew    | 0.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00295089 |
| Phi_loss        | 4552.18    |
| PolicyEntropy   | -2.50128   |
| PolicyLoss      | -0.0264248 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00176    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.73298    |
| _max_adv        | 4.03       |
| _max_discrew    | 1.6        |
| _max_obs        | 1.28       |
| _mean_act       | -0.0385529 |
| _mean_adv       | 7.39e-17   |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.0371     |
| _min_adv        | -3.22      |
| _min_discrew    | -0.00208   |
| _min_obs        | -1.77      |
| _std_act        | 0.479252   |
| _std_adv        | 1          |
| _std_discrew    | 0.134      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
----------------------------------
| Beta            | 0.145        |
| ExplainedVarNew | 0.987        |
| ExplainedVarOld | 0.986        |
| KL              | 0.00358689   |
| Phi_loss        | 4873.26      |
| PolicyEntropy   | -2.51988     |
| PolicyLoss      | -0.000985095 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00192      |
| _MeanReward     | 1.47e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 1.88151      |
| _max_adv        | 2.84         |
| _max_discrew    | 1.6          |
| _max_obs        | 1.34         |
| _mean_act       | -0.0375118   |
| _mean_adv       | 0            |
| _mean_discrew   | 1.21         |
| _mean_obs       | 0.0372       |
| _min_adv        | -3.14        |
| _min_discrew    | -0.00227     |
| _min_obs        | -1.81        |
| _std_act        | 0.481346     |
| _std_adv        | 1            |
| _std_discrew    | 0.137        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00414859 |
| Phi_loss        | 5112.49    |
| PolicyEntropy   | -2.52963   |
| PolicyLoss      | -0.0353065 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00276    |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83339    |
| _max_adv        | 5.59       |
| _max_discrew    | 1.59       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0366431 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.037      |
| _min_adv        | -11.1      |
| _min_discrew    | -0.00415   |
| _min_obs        | -1.8       |
| _std_act        | 0.479351   |
| _std_adv        | 1          |
| _std_discrew    | 0.134      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00492724 |
| Phi_loss        | 4641.94    |
| PolicyEntropy   | -2.52958   |
| PolicyLoss      | 0.0169343  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00285    |
| _MeanReward     | 1.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71168    |
| _max_adv        | 3.59       |
| _max_discrew    | 1.61       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0351453 |
| _mean_adv       | 2.98e-17   |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0376     |
| _min_adv        | -3.27      |
| _min_discrew    | -0.000598  |
| _min_obs        | -1.82      |
| _std_act        | 0.478507   |
| _std_adv        | 1          |
| _std_discrew    | 0.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00353911 |
| Phi_loss        | 4891.61    |
| PolicyEntropy   | -2.54475   |
| PolicyLoss      | -0.0132754 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00215    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.06289    |
| _max_adv        | 3.51       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0366367 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0374     |
| _min_adv        | -3.52      |
| _min_discrew    | -0.00487   |
| _min_obs        | -1.79      |
| _std_act        | 0.479899   |
| _std_adv        | 1          |
| _std_discrew    | 0.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00288412 |
| Phi_loss        | 4620.77    |
| PolicyEntropy   | -2.5446    |
| PolicyLoss      | -0.0485871 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00279    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83225    |
| _max_adv        | 5.79       |
| _max_discrew    | 1.62       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0376367 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0374     |
| _min_adv        | -3.71      |
| _min_discrew    | -0.000829  |
| _min_obs        | -1.8       |
| _std_act        | 0.482123   |
| _std_adv        | 1          |
| _std_discrew    | 0.136      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00454336 |
| Phi_loss        | 4256.15    |
| PolicyEntropy   | -2.54953   |
| PolicyLoss      | 0.0186283  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00191    |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.0779     |
| _max_adv        | 3.01       |
| _max_discrew    | 1.62       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0353498 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.0374     |
| _min_adv        | -11.5      |
| _min_discrew    | 0.00222    |
| _min_obs        | -1.79      |
| _std_act        | 0.482095   |
| _std_adv        | 1          |
| _std_discrew    | 0.139      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.978       |
| KL              | 0.00583116  |
| Phi_loss        | 4605.63     |
| PolicyEntropy   | -2.54765    |
| PolicyLoss      | -0.00818494 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0028      |
| _MeanReward     | 1.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.85645     |
| _max_adv        | 4.76        |
| _max_discrew    | 1.58        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0358343  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.2         |
| _mean_obs       | 0.0371      |
| _min_adv        | -13         |
| _min_discrew    | -0.00163    |
| _min_obs        | -1.79       |
| _std_act        | 0.475763    |
| _std_adv        | 1           |
| _std_discrew    | 0.136       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00494356 |
| Phi_loss        | 4843.52    |
| PolicyEntropy   | -2.55415   |
| PolicyLoss      | 0.0018545  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00237    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.67081    |
| _max_adv        | 3.21       |
| _max_discrew    | 1.61       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0348526 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.0373     |
| _min_adv        | -3.45      |
| _min_discrew    | -0.00371   |
| _min_obs        | -1.75      |
| _std_act        | 0.478387   |
| _std_adv        | 1          |
| _std_discrew    | 0.132      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00259214 |
| Phi_loss        | 4792.76    |
| PolicyEntropy   | -2.58758   |
| PolicyLoss      | 0.00154584 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00276    |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.69807    |
| _max_adv        | 3.36       |
| _max_discrew    | 1.62       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0335435 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.2        |
| _mean_obs       | 0.0375     |
| _min_adv        | -3.67      |
| _min_discrew    | -0.00409   |
| _min_obs        | -1.79      |
| _std_act        | 0.47949    |
| _std_adv        | 1          |
| _std_discrew    | 0.144      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00384908  |
| Phi_loss        | 5239.11     |
| PolicyEntropy   | -2.61473    |
| PolicyLoss      | -0.00618457 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00267     |
| _MeanReward     | 1.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.77328     |
| _max_adv        | 2.93        |
| _max_discrew    | 1.6         |
| _max_obs        | 1.33        |
| _mean_act       | -0.0343737  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.22        |
| _mean_obs       | 0.0376      |
| _min_adv        | -14         |
| _min_discrew    | -0.00441    |
| _min_obs        | -1.81       |
| _std_act        | 0.481062    |
| _std_adv        | 1           |
| _std_discrew    | 0.139       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00376155 |
| Phi_loss        | 4556.47    |
| PolicyEntropy   | -2.63518   |
| PolicyLoss      | 0.023749   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00221    |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.88237    |
| _max_adv        | 6.36       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0315867 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0377     |
| _min_adv        | -12.6      |
| _min_discrew    | -0.00652   |
| _min_obs        | -1.81      |
| _std_act        | 0.481348   |
| _std_adv        | 1          |
| _std_discrew    | 0.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00493276 |
| Phi_loss        | 5374.52    |
| PolicyEntropy   | -2.65943   |
| PolicyLoss      | 0.00122248 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00224    |
| _MeanReward     | 1.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.94087    |
| _max_adv        | 7.73       |
| _max_discrew    | 1.61       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0308367 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.36      |
| _min_discrew    | -0.00434   |
| _min_obs        | -1.8       |
| _std_act        | 0.483802   |
| _std_adv        | 1          |
| _std_discrew    | 0.142      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00405183 |
| Phi_loss        | 5788.01    |
| PolicyEntropy   | -2.65915   |
| PolicyLoss      | -0.0063051 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00182    |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71227    |
| _max_adv        | 3.59       |
| _max_discrew    | 1.62       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0302958 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.92      |
| _min_discrew    | 5.36e-05   |
| _min_obs        | -1.8       |
| _std_act        | 0.479726   |
| _std_adv        | 1          |
| _std_discrew    | 0.141      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00273247 |
| Phi_loss        | 5741.93    |
| PolicyEntropy   | -2.66775   |
| PolicyLoss      | 0.028954   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00306    |
| _MeanReward     | 1.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.82274    |
| _max_adv        | 3.17       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0311173 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.94      |
| _min_discrew    | -0.00487   |
| _min_obs        | -1.82      |
| _std_act        | 0.481364   |
| _std_adv        | 1          |
| _std_discrew    | 0.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00282004 |
| Phi_loss        | 5581.37    |
| PolicyEntropy   | -2.68631   |
| PolicyLoss      | -0.0191947 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00243    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71557    |
| _max_adv        | 3.3        |
| _max_discrew    | 1.62       |
| _max_obs        | 1.28       |
| _mean_act       | -0.030759  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0378     |
| _min_adv        | -6.72      |
| _min_discrew    | -0.00392   |
| _min_obs        | -1.81      |
| _std_act        | 0.481218   |
| _std_adv        | 1          |
| _std_discrew    | 0.145      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00284694 |
| Phi_loss        | 5390.0     |
| PolicyEntropy   | -2.6951    |
| PolicyLoss      | -0.011488  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00219    |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80621    |
| _max_adv        | 3.32       |
| _max_discrew    | 1.58       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0302639 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0378     |
| _min_adv        | -4.27      |
| _min_discrew    | -0.00329   |
| _min_obs        | -1.82      |
| _std_act        | 0.479663   |
| _std_adv        | 1          |
| _std_discrew    | 0.138      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.0035648  |
| Phi_loss        | 5913.88    |
| PolicyEntropy   | -2.69018   |
| PolicyLoss      | -0.0136023 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00237    |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.94884    |
| _max_adv        | 3.56       |
| _max_discrew    | 1.61       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0309659 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0378     |
| _min_adv        | -11.4      |
| _min_discrew    | -0.00277   |
| _min_obs        | -1.84      |
| _std_act        | 0.480387   |
| _std_adv        | 1          |
| _std_discrew    | 0.143      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00378517 |
| Phi_loss        | 5634.31    |
| PolicyEntropy   | -2.7114    |
| PolicyLoss      | 0.0210428  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0018     |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.82172    |
| _max_adv        | 4.98       |
| _max_discrew    | 1.63       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0314597 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.24       |
| _mean_obs       | 0.0378     |
| _min_adv        | -4.93      |
| _min_discrew    | -0.00384   |
| _min_obs        | -1.83      |
| _std_act        | 0.479318   |
| _std_adv        | 1          |
| _std_discrew    | 0.139      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00619048 |
| Phi_loss        | 5933.71    |
| PolicyEntropy   | -2.72004   |
| PolicyLoss      | -0.0157888 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00231    |
| _MeanReward     | 1.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.7586     |
| _max_adv        | 3.41       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0310134 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.74      |
| _min_discrew    | -0.00576   |
| _min_obs        | -1.82      |
| _std_act        | 0.480447   |
| _std_adv        | 1          |
| _std_discrew    | 0.144      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00179444 |
| Phi_loss        | 6058.54    |
| PolicyEntropy   | -2.73008   |
| PolicyLoss      | -0.0059697 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00277    |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.73355    |
| _max_adv        | 4.15       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0336384 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.51      |
| _min_discrew    | -0.00256   |
| _min_obs        | -1.83      |
| _std_act        | 0.4801     |
| _std_adv        | 1          |
| _std_discrew    | 0.143      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.0017694   |
| Phi_loss        | 6110.73     |
| PolicyEntropy   | -2.75744    |
| PolicyLoss      | -0.00533114 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00196     |
| _MeanReward     | 1.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 1.74126     |
| _max_adv        | 2.94        |
| _max_discrew    | 1.65        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0332518  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.24        |
| _mean_obs       | 0.0376      |
| _min_adv        | -4.58       |
| _min_discrew    | -0.00538    |
| _min_obs        | -1.82       |
| _std_act        | 0.480764    |
| _std_adv        | 1           |
| _std_discrew    | 0.146       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00170573  |
| Phi_loss        | 6426.59     |
| PolicyEntropy   | -2.76911    |
| PolicyLoss      | -0.00635708 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00249     |
| _MeanReward     | 1.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 1.73381     |
| _max_adv        | 3.42        |
| _max_discrew    | 1.69        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0304286  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 1.23        |
| _mean_obs       | 0.038       |
| _min_adv        | -4.32       |
| _min_discrew    | -0.00454    |
| _min_obs        | -1.85       |
| _std_act        | 0.4793      |
| _std_adv        | 1           |
| _std_discrew    | 0.147       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00203718 |
| Phi_loss        | 6205.2     |
| PolicyEntropy   | -2.7977    |
| PolicyLoss      | -0.0233342 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00245    |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.71184    |
| _max_adv        | 3.07       |
| _max_discrew    | 1.64       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0300885 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.82      |
| _min_discrew    | -0.00167   |
| _min_obs        | -1.81      |
| _std_act        | 0.481331   |
| _std_adv        | 1          |
| _std_discrew    | 0.141      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00233261 |
| Phi_loss        | 6198.6     |
| PolicyEntropy   | -2.81608   |
| PolicyLoss      | 0.00306777 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00213    |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.7623     |
| _max_adv        | 2.8        |
| _max_discrew    | 1.65       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0286205 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 1.24       |
| _mean_obs       | 0.0381     |
| _min_adv        | -7.48      |
| _min_discrew    | -0.00266   |
| _min_obs        | -1.83      |
| _std_act        | 0.481093   |
| _std_adv        | 1          |
| _std_discrew    | 0.145      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00367364 |
| Phi_loss        | 5542.8     |
| PolicyEntropy   | -2.82722   |
| PolicyLoss      | 0.0132306  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00256    |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.76905    |
| _max_adv        | 4.1        |
| _max_discrew    | 1.62       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0300086 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.24       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.87      |
| _min_discrew    | -0.00383   |
| _min_obs        | -1.82      |
| _std_act        | 0.48035    |
| _std_adv        | 1          |
| _std_discrew    | 0.142      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00151844 |
| Phi_loss        | 6441.14    |
| PolicyEntropy   | -2.85289   |
| PolicyLoss      | 0.0145093  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00252    |
| _MeanReward     | 1.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.74061    |
| _max_adv        | 3.89       |
| _max_discrew    | 1.64       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0315208 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.39      |
| _min_discrew    | -0.00416   |
| _min_obs        | -1.8       |
| _std_act        | 0.479203   |
| _std_adv        | 1          |
| _std_discrew    | 0.143      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
-------------------------------
| Beta            | 0.217     |
| ExplainedVarNew | 0.981     |
| ExplainedVarOld | 0.981     |
| KL              | 0.0027146 |
| Phi_loss        | 6579.06   |
| PolicyEntropy   | -2.87554  |
| PolicyLoss      | -0.014021 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00267   |
| _MeanReward     | 1.51e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 1.79157   |
| _max_adv        | 3.23      |
| _max_discrew    | 1.65      |
| _max_obs        | 1.3       |
| _mean_act       | -0.028944 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 1.24      |
| _mean_obs       | 0.0379    |
| _min_adv        | -3.37     |
| _min_discrew    | -0.000892 |
| _min_obs        | -1.83     |
| _std_act        | 0.479712  |
| _std_adv        | 1         |
| _std_discrew    | 0.148     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00260664 |
| Phi_loss        | 6735.77    |
| PolicyEntropy   | -2.90047   |
| PolicyLoss      | -0.0137907 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00226    |
| _MeanReward     | 1.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.79628    |
| _max_adv        | 3.11       |
| _max_discrew    | 1.68       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0320767 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.51      |
| _min_discrew    | -0.00466   |
| _min_obs        | -1.82      |
| _std_act        | 0.481599   |
| _std_adv        | 1          |
| _std_discrew    | 0.149      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00259197 |
| Phi_loss        | 6791.57    |
| PolicyEntropy   | -2.91555   |
| PolicyLoss      | -0.0200642 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00245    |
| _MeanReward     | 1.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.86445    |
| _max_adv        | 3.35       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0296899 |
| _mean_adv       | 2.63e-17   |
| _mean_discrew   | 1.24       |
| _mean_obs       | 0.0378     |
| _min_adv        | -3.58      |
| _min_discrew    | -0.00335   |
| _min_obs        | -1.83      |
| _std_act        | 0.481509   |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00268499 |
| Phi_loss        | 6848.56    |
| PolicyEntropy   | -2.93729   |
| PolicyLoss      | -0.0352925 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00216    |
| _MeanReward     | 1.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.76153    |
| _max_adv        | 4.27       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0294603 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.34      |
| _min_discrew    | -0.00124   |
| _min_obs        | -1.83      |
| _std_act        | 0.483412   |
| _std_adv        | 1          |
| _std_discrew    | 0.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00271949 |
| Phi_loss        | 6714.97    |
| PolicyEntropy   | -2.96519   |
| PolicyLoss      | 0.0157592  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00187    |
| _MeanReward     | 1.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.69854    |
| _max_adv        | 2.98       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0282941 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.64      |
| _min_discrew    | -0.00289   |
| _min_obs        | -1.84      |
| _std_act        | 0.484653   |
| _std_adv        | 1          |
| _std_discrew    | 0.145      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00190735 |
| Phi_loss        | 6907.02    |
| PolicyEntropy   | -2.99411   |
| PolicyLoss      | 0.0105019  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00233    |
| _MeanReward     | 1.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.73037    |
| _max_adv        | 2.96       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.28       |
| _mean_act       | -0.027949  |
| _mean_adv       | 5.68e-17   |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.69      |
| _min_discrew    | -0.00431   |
| _min_obs        | -1.85      |
| _std_act        | 0.482102   |
| _std_adv        | 1          |
| _std_discrew    | 0.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00274648  |
| Phi_loss        | 7065.51     |
| PolicyEntropy   | -3.0187     |
| PolicyLoss      | 0.000832134 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0024      |
| _MeanReward     | 1.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.70314     |
| _max_adv        | 3.69        |
| _max_discrew    | 1.66        |
| _max_obs        | 1.23        |
| _mean_act       | -0.0273106  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.25        |
| _mean_obs       | 0.0382      |
| _min_adv        | -3.41       |
| _min_discrew    | -0.00255    |
| _min_obs        | -1.83       |
| _std_act        | 0.483148    |
| _std_adv        | 1           |
| _std_discrew    | 0.147       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00192068 |
| Phi_loss        | 7028.55    |
| PolicyEntropy   | -3.02248   |
| PolicyLoss      | 0.0279288  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00284    |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.70726    |
| _max_adv        | 3.55       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0268332 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.55      |
| _min_discrew    | -0.00256   |
| _min_obs        | -1.83      |
| _std_act        | 0.478419   |
| _std_adv        | 1          |
| _std_discrew    | 0.146      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00183817 |
| Phi_loss        | 7145.56    |
| PolicyEntropy   | -3.03435   |
| PolicyLoss      | -0.0352606 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0025     |
| _MeanReward     | 1.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71343    |
| _max_adv        | 3.39       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.36       |
| _mean_act       | -0.026628  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0382     |
| _min_adv        | -2.94      |
| _min_discrew    | -0.00316   |
| _min_obs        | -1.84      |
| _std_act        | 0.484645   |
| _std_adv        | 1          |
| _std_discrew    | 0.142      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00302531  |
| Phi_loss        | 7184.37     |
| PolicyEntropy   | -3.04995    |
| PolicyLoss      | -0.00252258 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00208     |
| _MeanReward     | 1.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.7762      |
| _max_adv        | 3.15        |
| _max_discrew    | 1.69        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0262883  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.27        |
| _mean_obs       | 0.0386      |
| _min_adv        | -3.36       |
| _min_discrew    | -0.00601    |
| _min_obs        | -1.84       |
| _std_act        | 0.482518    |
| _std_adv        | 1           |
| _std_discrew    | 0.152       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.0023019  |
| Phi_loss        | 7461.56    |
| PolicyEntropy   | -3.06355   |
| PolicyLoss      | -0.0260027 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00276    |
| _MeanReward     | 1.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.87944    |
| _max_adv        | 3.27       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0256192 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0388     |
| _min_adv        | -4.07      |
| _min_discrew    | -0.00116   |
| _min_obs        | -1.83      |
| _std_act        | 0.484993   |
| _std_adv        | 1          |
| _std_discrew    | 0.152      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00161008 |
| Phi_loss        | 7537.25    |
| PolicyEntropy   | -3.0856    |
| PolicyLoss      | 0.00953859 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00228    |
| _MeanReward     | 1.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.7045     |
| _max_adv        | 3.76       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0267794 |
| _mean_adv       | -4.83e-17  |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0383     |
| _min_adv        | -3.29      |
| _min_discrew    | -0.00384   |
| _min_obs        | -1.8       |
| _std_act        | 0.483629   |
| _std_adv        | 1          |
| _std_discrew    | 0.148      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00209439 |
| Phi_loss        | 7537.32    |
| PolicyEntropy   | -3.12531   |
| PolicyLoss      | 0.0171091  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00203    |
| _MeanReward     | 1.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.79406    |
| _max_adv        | 3.87       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.34       |
| _mean_act       | -0.02913   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0383     |
| _min_adv        | -5.14      |
| _min_discrew    | -0.00587   |
| _min_obs        | -1.84      |
| _std_act        | 0.484247   |
| _std_adv        | 1          |
| _std_discrew    | 0.151      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00237909 |
| Phi_loss        | 7327.58    |
| PolicyEntropy   | -3.14848   |
| PolicyLoss      | 0.00966616 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00236    |
| _MeanReward     | 1.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.73821    |
| _max_adv        | 2.9        |
| _max_discrew    | 1.62       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0285612 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0379     |
| _min_adv        | -4.41      |
| _min_discrew    | -0.00348   |
| _min_obs        | -1.82      |
| _std_act        | 0.480364   |
| _std_adv        | 1          |
| _std_discrew    | 0.151      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.002244    |
| Phi_loss        | 7565.53     |
| PolicyEntropy   | -3.14896    |
| PolicyLoss      | -0.00267077 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00186     |
| _MeanReward     | 1.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.7169      |
| _max_adv        | 3.78        |
| _max_discrew    | 1.7         |
| _max_obs        | 1.21        |
| _mean_act       | -0.0291431  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.29        |
| _mean_obs       | 0.0383      |
| _min_adv        | -3.23       |
| _min_discrew    | -0.00424    |
| _min_obs        | -1.83       |
| _std_act        | 0.486352    |
| _std_adv        | 1           |
| _std_discrew    | 0.156       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00183089 |
| Phi_loss        | 7915.68    |
| PolicyEntropy   | -3.15595   |
| PolicyLoss      | -0.0412344 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00266    |
| _MeanReward     | 1.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.88739    |
| _max_adv        | 3.91       |
| _max_discrew    | 1.69       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0302384 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.27       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.56      |
| _min_discrew    | 0.000109   |
| _min_obs        | -1.86      |
| _std_act        | 0.484788   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.002794   |
| Phi_loss        | 8280.07    |
| PolicyEntropy   | -3.18866   |
| PolicyLoss      | 0.00433554 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00211    |
| _MeanReward     | 1.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.78459    |
| _max_adv        | 3.53       |
| _max_discrew    | 1.68       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0296882 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.27       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.32      |
| _min_discrew    | -0.00612   |
| _min_obs        | -1.83      |
| _std_act        | 0.483901   |
| _std_adv        | 1          |
| _std_discrew    | 0.151      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00236317 |
| Phi_loss        | 7764.99    |
| PolicyEntropy   | -3.19523   |
| PolicyLoss      | -0.0166977 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00238    |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.64958    |
| _max_adv        | 3.44       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0294449 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0385     |
| _min_adv        | -4.04      |
| _min_discrew    | -0.00232   |
| _min_obs        | -1.85      |
| _std_act        | 0.485247   |
| _std_adv        | 1          |
| _std_discrew    | 0.158      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00316352 |
| Phi_loss        | 8006.23    |
| PolicyEntropy   | -3.17875   |
| PolicyLoss      | 0.032765   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00212    |
| _MeanReward     | 1.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.70812    |
| _max_adv        | 3.07       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0292782 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0381     |
| _min_adv        | -4.64      |
| _min_discrew    | -0.00372   |
| _min_obs        | -1.84      |
| _std_act        | 0.484694   |
| _std_adv        | 1          |
| _std_discrew    | 0.154      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00249448 |
| Phi_loss        | 8359.2     |
| PolicyEntropy   | -3.19644   |
| PolicyLoss      | 0.0181367  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00197    |
| _MeanReward     | 1.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80121    |
| _max_adv        | 4.3        |
| _max_discrew    | 1.64       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0275731 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.78      |
| _min_discrew    | -0.00311   |
| _min_obs        | -1.85      |
| _std_act        | 0.487145   |
| _std_adv        | 1          |
| _std_discrew    | 0.154      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00260289 |
| Phi_loss        | 8313.74    |
| PolicyEntropy   | -3.21641   |
| PolicyLoss      | 0.00979875 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00187    |
| _MeanReward     | 1.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80267    |
| _max_adv        | 2.92       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0284459 |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0379     |
| _min_adv        | -9.04      |
| _min_discrew    | -0.00347   |
| _min_obs        | -1.86      |
| _std_act        | 0.48498    |
| _std_adv        | 1          |
| _std_discrew    | 0.144      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
----------------------------------
| Beta            | 0.217        |
| ExplainedVarNew | 0.982        |
| ExplainedVarOld | 0.98         |
| KL              | 0.00340862   |
| Phi_loss        | 7535.49      |
| PolicyEntropy   | -3.23884     |
| PolicyLoss      | -0.000734577 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00276      |
| _MeanReward     | 1.55e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 1.81817      |
| _max_adv        | 5.98         |
| _max_discrew    | 1.64         |
| _max_obs        | 1.35         |
| _mean_act       | -0.0298403   |
| _mean_adv       | 0            |
| _mean_discrew   | 1.27         |
| _mean_obs       | 0.0379       |
| _min_adv        | -11.2        |
| _min_discrew    | -0.00282     |
| _min_obs        | -1.81        |
| _std_act        | 0.486531     |
| _std_adv        | 1            |
| _std_discrew    | 0.151        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00755684 |
| Phi_loss        | 7996.9     |
| PolicyEntropy   | -3.24713   |
| PolicyLoss      | 0.0171555  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0016     |
| _MeanReward     | 1.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80109    |
| _max_adv        | 3.23       |
| _max_discrew    | 1.67       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0285115 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.27       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.29      |
| _min_discrew    | -0.00266   |
| _min_obs        | -1.82      |
| _std_act        | 0.485168   |
| _std_adv        | 1          |
| _std_discrew    | 0.152      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00157513 |
| Phi_loss        | 9222.86    |
| PolicyEntropy   | -3.24283   |
| PolicyLoss      | 0.0170137  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00222    |
| _MeanReward     | 1.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.6966     |
| _max_adv        | 3.34       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0293691 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.27       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.17      |
| _min_discrew    | -0.00168   |
| _min_obs        | -1.84      |
| _std_act        | 0.48688    |
| _std_adv        | 1          |
| _std_discrew    | 0.146      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00130278 |
| Phi_loss        | 8527.85    |
| PolicyEntropy   | -3.25911   |
| PolicyLoss      | 0.00224753 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00213    |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.83562    |
| _max_adv        | 3.35       |
| _max_discrew    | 1.7        |
| _max_obs        | 1.28       |
| _mean_act       | -0.030498  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.28       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.31      |
| _min_discrew    | -0.00209   |
| _min_obs        | -1.83      |
| _std_act        | 0.484411   |
| _std_adv        | 1          |
| _std_discrew    | 0.157      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00243761 |
| Phi_loss        | 8084.44    |
| PolicyEntropy   | -3.29049   |
| PolicyLoss      | 0.00645543 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00179    |
| _MeanReward     | 1.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.85429    |
| _max_adv        | 3.08       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0281347 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.28       |
| _mean_obs       | 0.0383     |
| _min_adv        | -3.23      |
| _min_discrew    | -0.00263   |
| _min_obs        | -1.86      |
| _std_act        | 0.486077   |
| _std_adv        | 1          |
| _std_discrew    | 0.154      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00351354 |
| Phi_loss        | 9107.87    |
| PolicyEntropy   | -3.31458   |
| PolicyLoss      | 0.0220054  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00196    |
| _MeanReward     | 1.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.93098    |
| _max_adv        | 3.21       |
| _max_discrew    | 1.71       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0294169 |
| _mean_adv       | -1.35e-17  |
| _mean_discrew   | 1.28       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.94      |
| _min_discrew    | -0.00223   |
| _min_obs        | -1.86      |
| _std_act        | 0.483026   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00244848 |
| Phi_loss        | 8748.26    |
| PolicyEntropy   | -3.31979   |
| PolicyLoss      | 0.0291428  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00192    |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.84042    |
| _max_adv        | 3.53       |
| _max_discrew    | 1.71       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0289431 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.28       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.36      |
| _min_discrew    | -0.00278   |
| _min_obs        | -1.85      |
| _std_act        | 0.482921   |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00392219 |
| Phi_loss        | 8136.61    |
| PolicyEntropy   | -3.35419   |
| PolicyLoss      | 0.00689744 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00212    |
| _MeanReward     | 1.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.75185    |
| _max_adv        | 3.13       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0286591 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.27       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.33      |
| _min_discrew    | -0.00233   |
| _min_obs        | -1.87      |
| _std_act        | 0.483262   |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00385364 |
| Phi_loss        | 9536.56    |
| PolicyEntropy   | -3.3993    |
| PolicyLoss      | 0.0343226  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00213    |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.77404    |
| _max_adv        | 3.51       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0280916 |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 1.28       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.9       |
| _min_discrew    | -0.00325   |
| _min_obs        | -1.85      |
| _std_act        | 0.484535   |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00252837 |
| Phi_loss        | 8577.7     |
| PolicyEntropy   | -3.42794   |
| PolicyLoss      | 0.0223636  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00314    |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80903    |
| _max_adv        | 3.71       |
| _max_discrew    | 1.72       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0289958 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0383     |
| _min_adv        | -5.58      |
| _min_discrew    | -0.0017    |
| _min_obs        | -1.88      |
| _std_act        | 0.484862   |
| _std_adv        | 1          |
| _std_discrew    | 0.164      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00323233  |
| Phi_loss        | 9413.27     |
| PolicyEntropy   | -3.43297    |
| PolicyLoss      | -0.00415028 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00222     |
| _MeanReward     | 1.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.93145     |
| _max_adv        | 3.86        |
| _max_discrew    | 1.68        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0278886  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.29        |
| _mean_obs       | 0.0383      |
| _min_adv        | -9.32       |
| _min_discrew    | -0.00236    |
| _min_obs        | -1.87       |
| _std_act        | 0.486657    |
| _std_adv        | 1           |
| _std_discrew    | 0.157       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00346452 |
| Phi_loss        | 9547.0     |
| PolicyEntropy   | -3.46168   |
| PolicyLoss      | 0.0363147  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00268    |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.78935    |
| _max_adv        | 3.92       |
| _max_discrew    | 1.69       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0301913 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.25      |
| _min_discrew    | -0.00192   |
| _min_obs        | -1.87      |
| _std_act        | 0.483298   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00283657  |
| Phi_loss        | 9474.35     |
| PolicyEntropy   | -3.46437    |
| PolicyLoss      | -0.00516617 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00306     |
| _MeanReward     | 1.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.66658     |
| _max_adv        | 5.13        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0293116  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.3         |
| _mean_obs       | 0.0382      |
| _min_adv        | -3.7        |
| _min_discrew    | 9.8e-05     |
| _min_obs        | -1.84       |
| _std_act        | 0.484053    |
| _std_adv        | 1           |
| _std_discrew    | 0.162       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
-------------------------------
| Beta            | 0.217     |
| ExplainedVarNew | 0.983     |
| ExplainedVarOld | 0.981     |
| KL              | 0.002736  |
| Phi_loss        | 9629.76   |
| PolicyEntropy   | -3.45054  |
| PolicyLoss      | 0.0377058 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00286   |
| _MeanReward     | 1.58e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 1.65346   |
| _max_adv        | 3.61      |
| _max_discrew    | 1.69      |
| _max_obs        | 1.4       |
| _mean_act       | -0.03018  |
| _mean_adv       | -2.56e-17 |
| _mean_discrew   | 1.29      |
| _mean_obs       | 0.0382    |
| _min_adv        | -3.9      |
| _min_discrew    | -0.00198  |
| _min_obs        | -1.86     |
| _std_act        | 0.482611  |
| _std_adv        | 1         |
| _std_discrew    | 0.159     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00316711 |
| Phi_loss        | 9382.08    |
| PolicyEntropy   | -3.43922   |
| PolicyLoss      | -0.0243826 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00209    |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.82599    |
| _max_adv        | 3.38       |
| _max_discrew    | 1.7        |
| _max_obs        | 1.4        |
| _mean_act       | -0.027919  |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.78      |
| _min_discrew    | -0.00392   |
| _min_obs        | -1.88      |
| _std_act        | 0.483463   |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00323893 |
| Phi_loss        | 9331.35    |
| PolicyEntropy   | -3.43569   |
| PolicyLoss      | 0.0425905  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00201    |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.77199    |
| _max_adv        | 3.53       |
| _max_discrew    | 1.75       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0297715 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.038      |
| _min_adv        | -3.28      |
| _min_discrew    | -0.00307   |
| _min_obs        | -1.85      |
| _std_act        | 0.481867   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00349619 |
| Phi_loss        | 9507.28    |
| PolicyEntropy   | -3.43879   |
| PolicyLoss      | 0.0532731  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00225    |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.77475    |
| _max_adv        | 3.26       |
| _max_discrew    | 1.71       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0285204 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.03      |
| _min_discrew    | -0.00532   |
| _min_obs        | -1.85      |
| _std_act        | 0.480967   |
| _std_adv        | 1          |
| _std_discrew    | 0.164      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00332583 |
| Phi_loss        | 9438.5     |
| PolicyEntropy   | -3.44319   |
| PolicyLoss      | 0.0196147  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00165    |
| _MeanReward     | 1.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.02049    |
| _max_adv        | 2.11       |
| _max_discrew    | 1.72       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0282718 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0376     |
| _min_adv        | -10.4      |
| _min_discrew    | -0.00271   |
| _min_obs        | -1.87      |
| _std_act        | 0.482643   |
| _std_adv        | 1          |
| _std_discrew    | 0.164      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.968      |
| KL              | 0.00657001 |
| Phi_loss        | 4005.65    |
| PolicyEntropy   | -3.4559    |
| PolicyLoss      | 0.0252767  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00289    |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.78578    |
| _max_adv        | 8.14       |
| _max_discrew    | 1.76       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0277894 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0384     |
| _min_adv        | -3.87      |
| _min_discrew    | -0.000477  |
| _min_obs        | -1.83      |
| _std_act        | 0.481683   |
| _std_adv        | 1          |
| _std_discrew    | 0.165      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00653253 |
| Phi_loss        | 8449.92    |
| PolicyEntropy   | -3.47844   |
| PolicyLoss      | -0.0256017 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00222    |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.81123    |
| _max_adv        | 7.01       |
| _max_discrew    | 1.69       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0259343 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.68      |
| _min_discrew    | -0.00848   |
| _min_obs        | -1.84      |
| _std_act        | 0.480895   |
| _std_adv        | 1          |
| _std_discrew    | 0.152      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00106515 |
| Phi_loss        | 9059.8     |
| PolicyEntropy   | -3.4818    |
| PolicyLoss      | 0.0340134  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00258    |
| _MeanReward     | 1.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71966    |
| _max_adv        | 5.41       |
| _max_discrew    | 1.72       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0258928 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.0381     |
| _min_adv        | -4.2       |
| _min_discrew    | -0.00373   |
| _min_obs        | -1.89      |
| _std_act        | 0.479598   |
| _std_adv        | 1          |
| _std_discrew    | 0.164      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00292132  |
| Phi_loss        | 10309.3     |
| PolicyEntropy   | -3.5129     |
| PolicyLoss      | -0.00932548 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0029      |
| _MeanReward     | 1.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.81825     |
| _max_adv        | 3.36        |
| _max_discrew    | 1.69        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0268127  |
| _mean_adv       | 1.28e-17    |
| _mean_discrew   | 1.3         |
| _mean_obs       | 0.0381      |
| _min_adv        | -4.25       |
| _min_discrew    | -0.00187    |
| _min_obs        | -1.88       |
| _std_act        | 0.479224    |
| _std_adv        | 1           |
| _std_discrew    | 0.155       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00176337 |
| Phi_loss        | 10894.6    |
| PolicyEntropy   | -3.53788   |
| PolicyLoss      | -0.0416609 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0019     |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.79401    |
| _max_adv        | 2.98       |
| _max_discrew    | 1.75       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0256113 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0385     |
| _min_adv        | -3.23      |
| _min_discrew    | 0.00263    |
| _min_obs        | -1.87      |
| _std_act        | 0.482529   |
| _std_adv        | 1          |
| _std_discrew    | 0.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.987      |
| KL              | 0.0016882  |
| Phi_loss        | 9869.54    |
| PolicyEntropy   | -3.55554   |
| PolicyLoss      | 0.0136065  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00178    |
| _MeanReward     | 1.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.73452    |
| _max_adv        | 3.12       |
| _max_discrew    | 1.71       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0267023 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.53      |
| _min_discrew    | -0.00319   |
| _min_obs        | -1.85      |
| _std_act        | 0.483451   |
| _std_adv        | 1          |
| _std_discrew    | 0.161      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00168107 |
| Phi_loss        | 11022.1    |
| PolicyEntropy   | -3.55299   |
| PolicyLoss      | -0.0335448 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0029     |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.00422    |
| _max_adv        | 3.88       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.25       |
| _mean_act       | -0.026608  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0382     |
| _min_adv        | -2.96      |
| _min_discrew    | -0.002     |
| _min_obs        | -1.86      |
| _std_act        | 0.481219   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00113137 |
| Phi_loss        | 10039.8    |
| PolicyEntropy   | -3.55684   |
| PolicyLoss      | -0.019855  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00169    |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.89942    |
| _max_adv        | 3.38       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0273243 |
| _mean_adv       | 1.85e-17   |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.038      |
| _min_adv        | -3.43      |
| _min_discrew    | -0.00343   |
| _min_obs        | -1.86      |
| _std_act        | 0.480891   |
| _std_adv        | 1          |
| _std_discrew    | 0.158      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00258234 |
| Phi_loss        | 10853.8    |
| PolicyEntropy   | -3.59651   |
| PolicyLoss      | -0.0439022 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00255    |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.70736    |
| _max_adv        | 3.42       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.23       |
| _mean_act       | -0.026687  |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0383     |
| _min_adv        | -3.52      |
| _min_discrew    | 0.00286    |
| _min_obs        | -1.85      |
| _std_act        | 0.483338   |
| _std_adv        | 1          |
| _std_discrew    | 0.163      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0027286  |
| Phi_loss        | 10675.9    |
| PolicyEntropy   | -3.61733   |
| PolicyLoss      | 0.0283725  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00241    |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.74372    |
| _max_adv        | 3.36       |
| _max_discrew    | 1.78       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0269064 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0384     |
| _min_adv        | -3.28      |
| _min_discrew    | -0.00471   |
| _min_obs        | -1.85      |
| _std_act        | 0.484461   |
| _std_adv        | 1          |
| _std_discrew    | 0.161      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.0028182  |
| Phi_loss        | 11268.3    |
| PolicyEntropy   | -3.65149   |
| PolicyLoss      | 0.0152227  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00253    |
| _MeanReward     | 1.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.68579    |
| _max_adv        | 3.32       |
| _max_discrew    | 1.7        |
| _max_obs        | 1.2        |
| _mean_act       | -0.0283472 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.038      |
| _min_adv        | -3.85      |
| _min_discrew    | -0.00372   |
| _min_obs        | -1.88      |
| _std_act        | 0.481088   |
| _std_adv        | 1          |
| _std_discrew    | 0.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00266149 |
| Phi_loss        | 10831.5    |
| PolicyEntropy   | -3.67008   |
| PolicyLoss      | 0.0155222  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00225    |
| _MeanReward     | 1.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.80495    |
| _max_adv        | 3.85       |
| _max_discrew    | 1.77       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0287541 |
| _mean_adv       | 2.98e-17   |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.0378     |
| _min_adv        | -3.55      |
| _min_discrew    | -0.00289   |
| _min_obs        | -1.85      |
| _std_act        | 0.481777   |
| _std_adv        | 1          |
| _std_discrew    | 0.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00359536 |
| Phi_loss        | 12284.6    |
| PolicyEntropy   | -3.67845   |
| PolicyLoss      | -0.10125   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0022     |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.0597     |
| _max_adv        | 7.68       |
| _max_discrew    | 1.75       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0293542 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.0377     |
| _min_adv        | -13.6      |
| _min_discrew    | -0.00499   |
| _min_obs        | -1.87      |
| _std_act        | 0.480832   |
| _std_adv        | 1          |
| _std_discrew    | 0.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00385464 |
| Phi_loss        | 10039.9    |
| PolicyEntropy   | -3.67793   |
| PolicyLoss      | 0.0139723  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00263    |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.91379    |
| _max_adv        | 5.87       |
| _max_discrew    | 1.71       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0281018 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0378     |
| _min_adv        | -5.3       |
| _min_discrew    | -0.00323   |
| _min_obs        | -1.89      |
| _std_act        | 0.48219    |
| _std_adv        | 1          |
| _std_discrew    | 0.151      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00447124 |
| Phi_loss        | 11719.1    |
| PolicyEntropy   | -3.67324   |
| PolicyLoss      | -0.0261017 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00278    |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.8229     |
| _max_adv        | 10.1       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0269039 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0382     |
| _min_adv        | -10.3      |
| _min_discrew    | -0.000466  |
| _min_obs        | -1.89      |
| _std_act        | 0.484253   |
| _std_adv        | 1          |
| _std_discrew    | 0.168      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.983      |
| KL              | 0.0126558  |
| Phi_loss        | 9947.0     |
| PolicyEntropy   | -3.69516   |
| PolicyLoss      | -0.0825374 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00237    |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.76546    |
| _max_adv        | 3.25       |
| _max_discrew    | 1.75       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0302426 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.61      |
| _min_discrew    | 0.000113   |
| _min_obs        | -1.88      |
| _std_act        | 0.482829   |
| _std_adv        | 1          |
| _std_discrew    | 0.162      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00269688 |
| Phi_loss        | 12364.4    |
| PolicyEntropy   | -3.69409   |
| PolicyLoss      | 0.00967535 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0036     |
| _MeanReward     | 1.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.88479    |
| _max_adv        | 4.1        |
| _max_discrew    | 1.7        |
| _max_obs        | 1.14       |
| _mean_act       | -0.0268903 |
| _mean_adv       | 1.35e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0379     |
| _min_adv        | -7.14      |
| _min_discrew    | -0.00369   |
| _min_obs        | -1.9       |
| _std_act        | 0.483126   |
| _std_adv        | 1          |
| _std_discrew    | 0.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00182148 |
| Phi_loss        | 12261.2    |
| PolicyEntropy   | -3.70809   |
| PolicyLoss      | 0.00955274 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00206    |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.80954    |
| _max_adv        | 3.56       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0278216 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.96      |
| _min_discrew    | -0.00262   |
| _min_obs        | -1.86      |
| _std_act        | 0.48032    |
| _std_adv        | 1          |
| _std_discrew    | 0.166      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 477
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00235089 |
| Phi_loss        | 11960.8    |
| PolicyEntropy   | -3.71809   |
| PolicyLoss      | -0.0226838 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00195    |
| _MeanReward     | 1.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71337    |
| _max_adv        | 3.97       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0297246 |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0382     |
| _min_adv        | -3.42      |
| _min_discrew    | -0.000434  |
| _min_obs        | -1.9       |
| _std_act        | 0.481979   |
| _std_adv        | 1          |
| _std_discrew    | 0.164      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 478
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00181181  |
| Phi_loss        | 11946.3     |
| PolicyEntropy   | -3.73381    |
| PolicyLoss      | -0.00251845 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00303     |
| _MeanReward     | 1.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 1.72649     |
| _max_adv        | 3.77        |
| _max_discrew    | 1.8         |
| _max_obs        | 1.19        |
| _mean_act       | -0.0298343  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 1.31        |
| _mean_obs       | 0.0377      |
| _min_adv        | -3.18       |
| _min_discrew    | 0.000774    |
| _min_obs        | -1.88       |
| _std_act        | 0.481379    |
| _std_adv        | 1           |
| _std_discrew    | 0.156       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 479
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00131998 |
| Phi_loss        | 12193.0    |
| PolicyEntropy   | -3.74766   |
| PolicyLoss      | 0.0485845  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00224    |
| _MeanReward     | 1.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.71593    |
| _max_adv        | 3.5        |
| _max_discrew    | 1.76       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0308107 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 1.33       |
| _mean_obs       | 0.0376     |
| _min_adv        | -4.39      |
| _min_discrew    | -0.0034    |
| _min_obs        | -1.9       |
| _std_act        | 0.481029   |
| _std_adv        | 1          |
| _std_discrew    | 0.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 480
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00499934  |
| Phi_loss        | 12287.0     |
| PolicyEntropy   | -3.78327    |
| PolicyLoss      | -0.00261791 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00199     |
| _MeanReward     | 1.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 1.7445      |
| _max_adv        | 2.9         |
| _max_discrew    | 1.73        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0312449  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.31        |
| _mean_obs       | 0.0377      |
| _min_adv        | -3.93       |
| _min_discrew    | -0.00446    |
| _min_obs        | -1.88       |
| _std_act        | 0.478452    |
| _std_adv        | 1           |
| _std_discrew    | 0.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 481
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00256705 |
| Phi_loss        | 12956.8    |
| PolicyEntropy   | -3.78435   |
| PolicyLoss      | 0.0147425  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00195    |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.72627    |
| _max_adv        | 3.48       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0298704 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0378     |
| _min_adv        | -3.01      |
| _min_discrew    | -0.00419   |
| _min_obs        | -1.83      |
| _std_act        | 0.48278    |
| _std_adv        | 1          |
| _std_discrew    | 0.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 482
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00259035 |
| Phi_loss        | 13049.7    |
| PolicyEntropy   | -3.80869   |
| PolicyLoss      | 0.0038813  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00212    |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.79308    |
| _max_adv        | 3.52       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0288139 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0376     |
| _min_adv        | -3.55      |
| _min_discrew    | -0.00282   |
| _min_obs        | -1.86      |
| _std_act        | 0.482019   |
| _std_adv        | 1          |
| _std_discrew    | 0.159      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 483
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00258142 |
| Phi_loss        | 13884.3    |
| PolicyEntropy   | -3.80657   |
| PolicyLoss      | 0.0339878  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00264    |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.67401    |
| _max_adv        | 3.21       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0291331 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.35      |
| _min_discrew    | 8.04e-05   |
| _min_obs        | -1.87      |
| _std_act        | 0.479959   |
| _std_adv        | 1          |
| _std_discrew    | 0.167      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 484
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00496231  |
| Phi_loss        | 13868.3     |
| PolicyEntropy   | -3.7997     |
| PolicyLoss      | -0.00415027 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00231     |
| _MeanReward     | 1.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 1.78566     |
| _max_adv        | 3.27        |
| _max_discrew    | 1.73        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0296463  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.32        |
| _mean_obs       | 0.0377      |
| _min_adv        | -3.6        |
| _min_discrew    | -0.00376    |
| _min_obs        | -1.88       |
| _std_act        | 0.482208    |
| _std_adv        | 1           |
| _std_discrew    | 0.164       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 485
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00352347 |
| Phi_loss        | 13266.7    |
| PolicyEntropy   | -3.80968   |
| PolicyLoss      | 0.0188658  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00188    |
| _MeanReward     | 1.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.76523    |
| _max_adv        | 3.35       |
| _max_discrew    | 1.82       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0313783 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.33       |
| _mean_obs       | 0.0375     |
| _min_adv        | -4.4       |
| _min_discrew    | -0.0046    |
| _min_obs        | -1.89      |
| _std_act        | 0.481691   |
| _std_adv        | 1          |
| _std_discrew    | 0.172      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 486
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.0025106  |
| Phi_loss        | 14023.6    |
| PolicyEntropy   | -3.81357   |
| PolicyLoss      | -0.0374107 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00277    |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 1.65422    |
| _max_adv        | 3.71       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0310586 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0376     |
| _min_adv        | -3.53      |
| _min_discrew    | -0.00302   |
| _min_obs        | -1.88      |
| _std_act        | 0.480644   |
| _std_adv        | 1          |
| _std_discrew    | 0.165      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 487
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00299821 |
| Phi_loss        | 13543.2    |
| PolicyEntropy   | -3.81225   |
| PolicyLoss      | 0.0018351  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00252    |
| _MeanReward     | 1.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 1.94338    |
| _max_adv        | 3.65       |
| _max_discrew    | 1.76       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0288397 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.34       |
| _mean_obs       | 0.038      |
| _min_adv        | -13.3      |
| _min_discrew    | -0.0024    |
| _min_obs        | -1.86      |
| _std_act        | 0.482472   |
| _std_adv        | 1          |
| _std_discrew    | 0.169      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 488
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00391372  |
| Phi_loss        | 11679.8     |
| PolicyEntropy   | -3.83034    |
| PolicyLoss      | -0.00203599 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00221     |
| _MeanReward     | 1.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 1.63149     |
| _max_adv        | 7.02        |
| _max_discrew    | 1.75        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0313879  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.31        |
| _mean_obs       | 0.0372      |
| _min_adv        | -3.77       |
| _min_discrew    | -0.00211    |
| _min_obs        | -1.89       |
| _std_act        | 0.481709    |
| _std_adv        | 1           |
| _std_discrew    | 0.165       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
