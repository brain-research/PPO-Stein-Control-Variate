Logging to halfcheetah_unbiased_225
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
-----------------------------
| Steps         | 10000     |
| _MeanReward   | -288      |
| _max_act      | 2.81612   |
| _max_adv      | 3.09      |
| _max_discrew  | 0.0167    |
| _max_obs      | 2.5       |
| _mean_act     | 0.0390142 |
| _mean_adv     | -1.14e-17 |
| _mean_discrew | -0.234    |
| _mean_obs     | 0.0481    |
| _min_adv      | -3.61     |
| _min_discrew  | -0.553    |
| _min_obs      | -1.15     |
| _std_act      | 0.422751  |
| _std_adv      | 1         |
| _std_discrew  | 0.0121    |
-----------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.219       |
| ExplainedVarOld | -4.83       |
| KL              | 0.0001993   |
| Phi_loss        | 1.73507     |
| PolicyEntropy   | 5.51375     |
| PolicyLoss      | -0.00221529 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0095      |
| _MeanReward     | -282        |
| _lr_multiplier  | 1           |
| _max_act        | 2.67642     |
| _max_adv        | 4.68        |
| _max_discrew    | 0.0334      |
| _max_obs        | 1.26        |
| _mean_act       | 0.0431771   |
| _mean_adv       | 0           |
| _mean_discrew   | -0.231      |
| _mean_obs       | 0.0343      |
| _min_adv        | -3.23       |
| _min_discrew    | -0.468      |
| _min_obs        | -1.37       |
| _std_act        | 0.426514    |
| _std_adv        | 1           |
| _std_discrew    | 0.00739     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.428      |
| ExplainedVarOld | 0.21       |
| KL              | 0.00112055 |
| Phi_loss        | 18.0652    |
| PolicyEntropy   | 5.51175    |
| PolicyLoss      | 0.00219262 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00424    |
| _MeanReward     | -253       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75611    |
| _max_adv        | 4.02       |
| _max_discrew    | 0.0716     |
| _max_obs        | 1.34       |
| _mean_act       | 0.0502607  |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | -0.206     |
| _mean_obs       | 0.0311     |
| _min_adv        | -4.07      |
| _min_discrew    | -0.49      |
| _min_obs        | -1.42      |
| _std_act        | 0.425707   |
| _std_adv        | 1          |
| _std_discrew    | 0.0104     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.44       |
| ExplainedVarOld | 0.285      |
| KL              | 0.00134357 |
| Phi_loss        | 18.3128    |
| PolicyEntropy   | 5.49936    |
| PolicyLoss      | 0.00599985 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00594    |
| _MeanReward     | -299       |
| _lr_multiplier  | 1          |
| _max_act        | 2.68421    |
| _max_adv        | 3.39       |
| _max_discrew    | 0.062      |
| _max_obs        | 1.46       |
| _mean_act       | 0.0482333  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | -0.239     |
| _mean_obs       | 0.0233     |
| _min_adv        | -3.93      |
| _min_discrew    | -0.491     |
| _min_obs        | -1.31      |
| _std_act        | 0.421089   |
| _std_adv        | 1          |
| _std_discrew    | 0.0118     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.394        |
| ExplainedVarOld | 0.347        |
| KL              | 0.00283929   |
| Phi_loss        | 19.0306      |
| PolicyEntropy   | 5.49515      |
| PolicyLoss      | -0.000550575 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00742      |
| _MeanReward     | -252         |
| _lr_multiplier  | 1            |
| _max_act        | 2.87551      |
| _max_adv        | 3.92         |
| _max_discrew    | 0.0814       |
| _max_obs        | 1.4          |
| _mean_act       | 0.0506088    |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | -0.212       |
| _mean_obs       | 0.0351       |
| _min_adv        | -4.08        |
| _min_discrew    | -0.669       |
| _min_obs        | -1.47        |
| _std_act        | 0.423374     |
| _std_adv        | 1            |
| _std_discrew    | 0.0132       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.341      |
| ExplainedVarOld | 0.318      |
| KL              | 0.00322964 |
| Phi_loss        | 17.5876    |
| PolicyEntropy   | 5.46501    |
| PolicyLoss      | 0.00830123 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0088     |
| _MeanReward     | -246       |
| _lr_multiplier  | 1          |
| _max_act        | 2.66598    |
| _max_adv        | 3.25       |
| _max_discrew    | 0.0264     |
| _max_obs        | 1.64       |
| _mean_act       | 0.0517246  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.202     |
| _mean_obs       | 0.0351     |
| _min_adv        | -4.97      |
| _min_discrew    | -0.573     |
| _min_obs        | -1.36      |
| _std_act        | 0.419073   |
| _std_adv        | 1          |
| _std_discrew    | 0.0107     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.448      |
| ExplainedVarOld | 0.413      |
| KL              | 0.00280338 |
| Phi_loss        | 17.4659    |
| PolicyEntropy   | 5.44335    |
| PolicyLoss      | 0.00348327 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00602    |
| _MeanReward     | -241       |
| _lr_multiplier  | 1          |
| _max_act        | 2.67041    |
| _max_adv        | 3.85       |
| _max_discrew    | 0.0607     |
| _max_obs        | 1.37       |
| _mean_act       | 0.0496329  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | -0.192     |
| _mean_obs       | 0.0326     |
| _min_adv        | -3.93      |
| _min_discrew    | -0.449     |
| _min_obs        | -1.32      |
| _std_act        | 0.410679   |
| _std_adv        | 1          |
| _std_discrew    | 0.0101     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.381      |
| ExplainedVarOld | 0.368      |
| KL              | 0.00280331 |
| Phi_loss        | 17.8534    |
| PolicyEntropy   | 5.42985    |
| PolicyLoss      | 0.00101046 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00625    |
| _MeanReward     | -197       |
| _lr_multiplier  | 1          |
| _max_act        | 2.5202     |
| _max_adv        | 4.1        |
| _max_discrew    | 0.135      |
| _max_obs        | 1.29       |
| _mean_act       | 0.0530206  |
| _mean_adv       | 4.26e-17   |
| _mean_discrew   | -0.166     |
| _mean_obs       | 0.0384     |
| _min_adv        | -4.57      |
| _min_discrew    | -0.379     |
| _min_obs        | -1.33      |
| _std_act        | 0.411839   |
| _std_adv        | 1          |
| _std_discrew    | 0.00868    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.525       |
| ExplainedVarOld | 0.428       |
| KL              | 0.00326581  |
| Phi_loss        | 17.2034     |
| PolicyEntropy   | 5.42667     |
| PolicyLoss      | -0.00309137 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00437     |
| _MeanReward     | -216        |
| _lr_multiplier  | 1           |
| _max_act        | 3.2545      |
| _max_adv        | 4.42        |
| _max_discrew    | 0.0619      |
| _max_obs        | 1.45        |
| _mean_act       | 0.0462906   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.185      |
| _mean_obs       | 0.033       |
| _min_adv        | -6.99       |
| _min_discrew    | -0.379      |
| _min_obs        | -1.36       |
| _std_act        | 0.420041    |
| _std_adv        | 1           |
| _std_discrew    | 0.00823     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.4        |
| ExplainedVarOld | 0.35       |
| KL              | 0.00291362 |
| Phi_loss        | 17.7454    |
| PolicyEntropy   | 5.40606    |
| PolicyLoss      | 0.00460095 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00504    |
| _MeanReward     | -151       |
| _lr_multiplier  | 1          |
| _max_act        | 3.07675    |
| _max_adv        | 4.34       |
| _max_discrew    | 0.137      |
| _max_obs        | 1.54       |
| _mean_act       | 0.0553795  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | -0.126     |
| _mean_obs       | 0.0341     |
| _min_adv        | -4.38      |
| _min_discrew    | -0.39      |
| _min_obs        | -1.25      |
| _std_act        | 0.412071   |
| _std_adv        | 1          |
| _std_discrew    | 0.00687    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.245      |
| ExplainedVarOld | 0.208      |
| KL              | 0.00279352 |
| Phi_loss        | 20.3964    |
| PolicyEntropy   | 5.37887    |
| PolicyLoss      | 0.00647245 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00586    |
| _MeanReward     | -159       |
| _lr_multiplier  | 1          |
| _max_act        | 2.46991    |
| _max_adv        | 4.55       |
| _max_discrew    | 0.0987     |
| _max_obs        | 1.4        |
| _mean_act       | 0.0517531  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.137     |
| _mean_obs       | 0.0393     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.312     |
| _min_obs        | -1.2       |
| _std_act        | 0.413163   |
| _std_adv        | 1          |
| _std_discrew    | 0.00489    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.461      |
| ExplainedVarOld | 0.418      |
| KL              | 0.00282993 |
| Phi_loss        | 19.2317    |
| PolicyEntropy   | 5.34989    |
| PolicyLoss      | 0.00925553 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00269    |
| _MeanReward     | -141       |
| _lr_multiplier  | 1          |
| _max_act        | 2.82084    |
| _max_adv        | 3.79       |
| _max_discrew    | 0.0445     |
| _max_obs        | 1.36       |
| _mean_act       | 0.0514288  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | -0.124     |
| _mean_obs       | 0.0413     |
| _min_adv        | -4.59      |
| _min_discrew    | -0.284     |
| _min_obs        | -1.24      |
| _std_act        | 0.406263   |
| _std_adv        | 1          |
| _std_discrew    | 0.00366    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.288      |
| ExplainedVarOld | 0.225      |
| KL              | 0.00338001 |
| Phi_loss        | 19.3165    |
| PolicyEntropy   | 5.32043    |
| PolicyLoss      | 0.00817361 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00261    |
| _MeanReward     | -151       |
| _lr_multiplier  | 1          |
| _max_act        | 3.03235    |
| _max_adv        | 3.89       |
| _max_discrew    | 0.116      |
| _max_obs        | 1.39       |
| _mean_act       | 0.0512461  |
| _mean_adv       | -4.12e-17  |
| _mean_discrew   | -0.13      |
| _mean_obs       | 0.0329     |
| _min_adv        | -4.23      |
| _min_discrew    | -0.341     |
| _min_obs        | -1.26      |
| _std_act        | 0.399597   |
| _std_adv        | 1          |
| _std_discrew    | 0.00693    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.631      |
| ExplainedVarOld | 0.607      |
| KL              | 0.00408117 |
| Phi_loss        | 18.85      |
| PolicyEntropy   | 5.29796    |
| PolicyLoss      | 0.00556653 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00261    |
| _MeanReward     | -137       |
| _lr_multiplier  | 1          |
| _max_act        | 2.68984    |
| _max_adv        | 4.61       |
| _max_discrew    | 0.111      |
| _max_obs        | 1.41       |
| _mean_act       | 0.0485647  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.116     |
| _mean_obs       | 0.0336     |
| _min_adv        | -4.25      |
| _min_discrew    | -0.312     |
| _min_obs        | -1.21      |
| _std_act        | 0.399612   |
| _std_adv        | 1          |
| _std_discrew    | 0.00466    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.325      |
| ExplainedVarOld | 0.32       |
| KL              | 0.00350824 |
| Phi_loss        | 19.912     |
| PolicyEntropy   | 5.29669    |
| PolicyLoss      | 0.00120142 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00315    |
| _MeanReward     | -125       |
| _lr_multiplier  | 1          |
| _max_act        | 2.63225    |
| _max_adv        | 4.2        |
| _max_discrew    | 0.147      |
| _max_obs        | 1.33       |
| _mean_act       | 0.0449867  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | -0.0967    |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.23      |
| _min_discrew    | -0.28      |
| _min_obs        | -1.29      |
| _std_act        | 0.404014   |
| _std_adv        | 1          |
| _std_discrew    | 0.00438    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.356      |
| ExplainedVarOld | 0.31       |
| KL              | 0.00311078 |
| Phi_loss        | 18.9109    |
| PolicyEntropy   | 5.27658    |
| PolicyLoss      | 0.00560119 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00294    |
| _MeanReward     | -111       |
| _lr_multiplier  | 1          |
| _max_act        | 2.61781    |
| _max_adv        | 4          |
| _max_discrew    | 0.093      |
| _max_obs        | 1.4        |
| _mean_act       | 0.0505808  |
| _mean_adv       | -5.12e-17  |
| _mean_discrew   | -0.0917    |
| _mean_obs       | 0.0362     |
| _min_adv        | -3.53      |
| _min_discrew    | -0.336     |
| _min_obs        | -1.24      |
| _std_act        | 0.394562   |
| _std_adv        | 1          |
| _std_discrew    | 0.0063     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.284      |
| ExplainedVarOld | 0.273      |
| KL              | 0.00375704 |
| Phi_loss        | 20.2568    |
| PolicyEntropy   | 5.26626    |
| PolicyLoss      | 0.00151811 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00451    |
| _MeanReward     | -124       |
| _lr_multiplier  | 1          |
| _max_act        | 2.65705    |
| _max_adv        | 5.14       |
| _max_discrew    | 0.0638     |
| _max_obs        | 1.43       |
| _mean_act       | 0.042738   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.109     |
| _mean_obs       | 0.0381     |
| _min_adv        | -5.34      |
| _min_discrew    | -0.361     |
| _min_obs        | -1.21      |
| _std_act        | 0.399784   |
| _std_adv        | 1          |
| _std_discrew    | 0.0065     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.527      |
| ExplainedVarOld | 0.468      |
| KL              | 0.00384917 |
| Phi_loss        | 20.0255    |
| PolicyEntropy   | 5.25682    |
| PolicyLoss      | 0.00258598 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00308    |
| _MeanReward     | -112       |
| _lr_multiplier  | 1          |
| _max_act        | 2.96776    |
| _max_adv        | 4.17       |
| _max_discrew    | 0.131      |
| _max_obs        | 1.34       |
| _mean_act       | 0.0422808  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.0941    |
| _mean_obs       | 0.0345     |
| _min_adv        | -5.7       |
| _min_discrew    | -0.421     |
| _min_obs        | -1.29      |
| _std_act        | 0.401397   |
| _std_adv        | 1          |
| _std_discrew    | 0.00649    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.175       |
| ExplainedVarOld | 0.122       |
| KL              | 0.00386116  |
| Phi_loss        | 19.7766     |
| PolicyEntropy   | 5.25036     |
| PolicyLoss      | -0.00353999 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00538     |
| _MeanReward     | -68.8       |
| _lr_multiplier  | 1           |
| _max_act        | 2.85925     |
| _max_adv        | 5.94        |
| _max_discrew    | 0.204       |
| _max_obs        | 1.39        |
| _mean_act       | 0.0408734   |
| _mean_adv       | -3.84e-17   |
| _mean_discrew   | -0.0631     |
| _mean_obs       | 0.0384      |
| _min_adv        | -4.13       |
| _min_discrew    | -0.27       |
| _min_obs        | -1.28       |
| _std_act        | 0.396651    |
| _std_adv        | 1           |
| _std_discrew    | 0.00394     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.404       |
| ExplainedVarOld | 0.312       |
| KL              | 0.00366812  |
| Phi_loss        | 20.2959     |
| PolicyEntropy   | 5.27385     |
| PolicyLoss      | -0.00790558 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00251     |
| _MeanReward     | -78.8       |
| _lr_multiplier  | 1           |
| _max_act        | 2.65826     |
| _max_adv        | 5           |
| _max_discrew    | 0.173       |
| _max_obs        | 1.37        |
| _mean_act       | 0.0412448   |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | -0.0723     |
| _mean_obs       | 0.0436      |
| _min_adv        | -6.94       |
| _min_discrew    | -0.416      |
| _min_obs        | -1.27       |
| _std_act        | 0.402847    |
| _std_adv        | 1           |
| _std_discrew    | 0.00428     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.223      |
| ExplainedVarOld | 0.197      |
| KL              | 0.00487719 |
| Phi_loss        | 18.8329    |
| PolicyEntropy   | 5.24704    |
| PolicyLoss      | 0.0065931  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00333    |
| _MeanReward     | -78.1      |
| _lr_multiplier  | 1          |
| _max_act        | 3.04121    |
| _max_adv        | 4.55       |
| _max_discrew    | 0.168      |
| _max_obs        | 1.46       |
| _mean_act       | 0.0459799  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.0591    |
| _mean_obs       | 0.0406     |
| _min_adv        | -4.49      |
| _min_discrew    | -0.235     |
| _min_obs        | -1.2       |
| _std_act        | 0.403202   |
| _std_adv        | 1          |
| _std_discrew    | 0.00383    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.198      |
| ExplainedVarOld | 0.118      |
| KL              | 0.00521249 |
| Phi_loss        | 20.202     |
| PolicyEntropy   | 5.21548    |
| PolicyLoss      | 0.009305   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00313    |
| _MeanReward     | -59.5      |
| _lr_multiplier  | 1          |
| _max_act        | 2.76148    |
| _max_adv        | 4.01       |
| _max_discrew    | 0.18       |
| _max_obs        | 1.48       |
| _mean_act       | 0.0395877  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | -0.0556    |
| _mean_obs       | 0.0392     |
| _min_adv        | -4.62      |
| _min_discrew    | -0.223     |
| _min_obs        | -1.36      |
| _std_act        | 0.40391    |
| _std_adv        | 1          |
| _std_discrew    | 0.00304    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.26       |
| ExplainedVarOld | 0.223      |
| KL              | 0.00575421 |
| Phi_loss        | 21.9725    |
| PolicyEntropy   | 5.18927    |
| PolicyLoss      | 0.00463228 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00227    |
| _MeanReward     | -34.8      |
| _lr_multiplier  | 1          |
| _max_act        | 2.83016    |
| _max_adv        | 4.17       |
| _max_discrew    | 0.144      |
| _max_obs        | 1.47       |
| _mean_act       | 0.0390727  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.031     |
| _mean_obs       | 0.0399     |
| _min_adv        | -4.84      |
| _min_discrew    | -0.17      |
| _min_obs        | -1.32      |
| _std_act        | 0.394465   |
| _std_adv        | 1          |
| _std_discrew    | 0.00207    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.252      |
| ExplainedVarOld | 0.196      |
| KL              | 0.00262608 |
| Phi_loss        | 22.4154    |
| PolicyEntropy   | 5.17845    |
| PolicyLoss      | 0.00237415 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00169    |
| _MeanReward     | -38.2      |
| _lr_multiplier  | 1          |
| _max_act        | 3.14766    |
| _max_adv        | 4.81       |
| _max_discrew    | 0.212      |
| _max_obs        | 1.44       |
| _mean_act       | 0.0259746  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | -0.0372    |
| _mean_obs       | 0.033      |
| _min_adv        | -4.96      |
| _min_discrew    | -0.336     |
| _min_obs        | -1.28      |
| _std_act        | 0.405599   |
| _std_adv        | 1          |
| _std_discrew    | 0.00666    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.467      |
| ExplainedVarOld | 0.443      |
| KL              | 0.00382486 |
| Phi_loss        | 23.9162    |
| PolicyEntropy   | 5.15536    |
| PolicyLoss      | 0.00269881 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00355    |
| _MeanReward     | -5.52      |
| _lr_multiplier  | 1          |
| _max_act        | 2.81151    |
| _max_adv        | 6.05       |
| _max_discrew    | 0.258      |
| _max_obs        | 1.57       |
| _mean_act       | 0.0374964  |
| _mean_adv       | -3.55e-18  |
| _mean_discrew   | -0.0115    |
| _mean_obs       | 0.0331     |
| _min_adv        | -4.55      |
| _min_discrew    | -0.276     |
| _min_obs        | -1.31      |
| _std_act        | 0.398235   |
| _std_adv        | 1          |
| _std_discrew    | 0.00521    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.312      |
| ExplainedVarOld | 0.238      |
| KL              | 0.00313488 |
| Phi_loss        | 21.1343    |
| PolicyEntropy   | 5.13105    |
| PolicyLoss      | 0.00275757 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00362    |
| _MeanReward     | -7.72      |
| _lr_multiplier  | 1          |
| _max_act        | 3.19475    |
| _max_adv        | 5.93       |
| _max_discrew    | 0.216      |
| _max_obs        | 1.4        |
| _mean_act       | 0.0346456  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | -0.00559   |
| _mean_obs       | 0.0348     |
| _min_adv        | -5.32      |
| _min_discrew    | -0.194     |
| _min_obs        | -1.31      |
| _std_act        | 0.395525   |
| _std_adv        | 1          |
| _std_discrew    | 0.00332    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.189      |
| ExplainedVarOld | 0.0924     |
| KL              | 0.00321077 |
| Phi_loss        | 21.661     |
| PolicyEntropy   | 5.0959     |
| PolicyLoss      | 0.00949206 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00274    |
| _MeanReward     | 8.59       |
| _lr_multiplier  | 1          |
| _max_act        | 3.18227    |
| _max_adv        | 4.85       |
| _max_discrew    | 0.248      |
| _max_obs        | 1.47       |
| _mean_act       | 0.0227631  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 0.00328    |
| _mean_obs       | 0.0346     |
| _min_adv        | -4.14      |
| _min_discrew    | -0.242     |
| _min_obs        | -1.4       |
| _std_act        | 0.392707   |
| _std_adv        | 1          |
| _std_discrew    | 0.00508    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.318      |
| ExplainedVarOld | 0.28       |
| KL              | 0.00315053 |
| Phi_loss        | 24.609     |
| PolicyEntropy   | 5.06342    |
| PolicyLoss      | 0.00702863 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00356    |
| _MeanReward     | 23.1       |
| _lr_multiplier  | 1          |
| _max_act        | 2.54957    |
| _max_adv        | 4.16       |
| _max_discrew    | 0.208      |
| _max_obs        | 1.7        |
| _mean_act       | 0.0265823  |
| _mean_adv       | -6.25e-17  |
| _mean_discrew   | 0.0147     |
| _mean_obs       | 0.0371     |
| _min_adv        | -5.26      |
| _min_discrew    | -0.168     |
| _min_obs        | -1.34      |
| _std_act        | 0.390331   |
| _std_adv        | 1          |
| _std_discrew    | 0.00366    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.143       |
| ExplainedVarOld | 0.116       |
| KL              | 0.00310232  |
| Phi_loss        | 22.9856     |
| PolicyEntropy   | 5.05577     |
| PolicyLoss      | 0.000711018 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00319     |
| _MeanReward     | 6.16        |
| _lr_multiplier  | 1           |
| _max_act        | 3.21024     |
| _max_adv        | 4.64        |
| _max_discrew    | 0.209       |
| _max_obs        | 1.59        |
| _mean_act       | 0.0121604   |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | -0.000358   |
| _mean_obs       | 0.0288      |
| _min_adv        | -4.77       |
| _min_discrew    | -0.357      |
| _min_obs        | -1.26       |
| _std_act        | 0.393836    |
| _std_adv        | 1           |
| _std_discrew    | 0.00788     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.509      |
| ExplainedVarOld | 0.385      |
| KL              | 0.00296243 |
| Phi_loss        | 21.6056    |
| PolicyEntropy   | 5.03358    |
| PolicyLoss      | 0.00147685 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00387    |
| _MeanReward     | 19         |
| _lr_multiplier  | 1          |
| _max_act        | 2.68872    |
| _max_adv        | 5.71       |
| _max_discrew    | 0.285      |
| _max_obs        | 1.54       |
| _mean_act       | 0.0209633  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.0173     |
| _mean_obs       | 0.0347     |
| _min_adv        | -4.66      |
| _min_discrew    | -0.216     |
| _min_obs        | -1.26      |
| _std_act        | 0.387248   |
| _std_adv        | 1          |
| _std_discrew    | 0.00432    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.148      |
| ExplainedVarOld | 0.137      |
| KL              | 0.00315453 |
| Phi_loss        | 24.0092    |
| PolicyEntropy   | 5.01368    |
| PolicyLoss      | 0.00319333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00368    |
| _MeanReward     | 48.2       |
| _lr_multiplier  | 1          |
| _max_act        | 3.06523    |
| _max_adv        | 6.13       |
| _max_discrew    | 0.354      |
| _max_obs        | 1.62       |
| _mean_act       | 0.00906073 |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 0.0362     |
| _mean_obs       | 0.0307     |
| _min_adv        | -5.95      |
| _min_discrew    | -0.369     |
| _min_obs        | -1.4       |
| _std_act        | 0.398448   |
| _std_adv        | 1          |
| _std_discrew    | 0.0139     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.602      |
| ExplainedVarOld | 0.485      |
| KL              | 0.00311884 |
| Phi_loss        | 20.762     |
| PolicyEntropy   | 5.00581    |
| PolicyLoss      | 0.00193585 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00558    |
| _MeanReward     | 50.8       |
| _lr_multiplier  | 1          |
| _max_act        | 2.90905    |
| _max_adv        | 4.76       |
| _max_discrew    | 0.252      |
| _max_obs        | 1.54       |
| _mean_act       | 0.0178079  |
| _mean_adv       | -6.39e-18  |
| _mean_discrew   | 0.043      |
| _mean_obs       | 0.0338     |
| _min_adv        | -4.4       |
| _min_discrew    | -0.12      |
| _min_obs        | -1.25      |
| _std_act        | 0.388419   |
| _std_adv        | 1          |
| _std_discrew    | 0.0032     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.209      |
| ExplainedVarOld | 0.211      |
| KL              | 0.00438449 |
| Phi_loss        | 24.6196    |
| PolicyEntropy   | 5.01234    |
| PolicyLoss      | 0.00303907 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00253    |
| _MeanReward     | 76.7       |
| _lr_multiplier  | 1          |
| _max_act        | 2.97026    |
| _max_adv        | 4.87       |
| _max_discrew    | 0.345      |
| _max_obs        | 1.6        |
| _mean_act       | 0.0148008  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.0593     |
| _mean_obs       | 0.0283     |
| _min_adv        | -4.8       |
| _min_discrew    | -0.101     |
| _min_obs        | -1.34      |
| _std_act        | 0.387725   |
| _std_adv        | 1          |
| _std_discrew    | 0.00519    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.258       |
| ExplainedVarOld | 0.219       |
| KL              | 0.00332128  |
| Phi_loss        | 25.7198     |
| PolicyEntropy   | 4.99846     |
| PolicyLoss      | 0.000676815 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00385     |
| _MeanReward     | 84          |
| _lr_multiplier  | 1           |
| _max_act        | 2.58402     |
| _max_adv        | 4.87        |
| _max_discrew    | 0.351       |
| _max_obs        | 1.39        |
| _mean_act       | 0.0184932   |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 0.0624      |
| _mean_obs       | 0.0314      |
| _min_adv        | -4.67       |
| _min_discrew    | -0.124      |
| _min_obs        | -1.38       |
| _std_act        | 0.39051     |
| _std_adv        | 1           |
| _std_discrew    | 0.00561     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.317      |
| ExplainedVarOld | 0.299      |
| KL              | 0.00310786 |
| Phi_loss        | 28.05      |
| PolicyEntropy   | 4.97521    |
| PolicyLoss      | 0.00357113 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00385    |
| _MeanReward     | 104        |
| _lr_multiplier  | 1          |
| _max_act        | 2.98862    |
| _max_adv        | 5.74       |
| _max_discrew    | 0.369      |
| _max_obs        | 1.56       |
| _mean_act       | 0.018428   |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.0832     |
| _mean_obs       | 0.0375     |
| _min_adv        | -5.3       |
| _min_discrew    | -0.191     |
| _min_obs        | -1.26      |
| _std_act        | 0.381116   |
| _std_adv        | 1          |
| _std_discrew    | 0.00544    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.337       |
| ExplainedVarOld | 0.31        |
| KL              | 0.00366574  |
| Phi_loss        | 23.8072     |
| PolicyEntropy   | 4.97534     |
| PolicyLoss      | 0.000310329 |
| Steps           | 10000       |
| VarFuncLoss     | 0.004       |
| _MeanReward     | 85.6        |
| _lr_multiplier  | 1           |
| _max_act        | 2.82738     |
| _max_adv        | 3.92        |
| _max_discrew    | 0.355       |
| _max_obs        | 1.53        |
| _mean_act       | 0.0138938   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.0714      |
| _mean_obs       | 0.0342      |
| _min_adv        | -4.91       |
| _min_discrew    | -0.232      |
| _min_obs        | -1.31       |
| _std_act        | 0.387271    |
| _std_adv        | 1           |
| _std_discrew    | 0.00517     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.125      |
| ExplainedVarOld | 0.0395     |
| KL              | 0.00348183 |
| Phi_loss        | 23.0594    |
| PolicyEntropy   | 4.9717     |
| PolicyLoss      | 0.00261698 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00454    |
| _MeanReward     | 111        |
| _lr_multiplier  | 1          |
| _max_act        | 2.992      |
| _max_adv        | 4.3        |
| _max_discrew    | 0.375      |
| _max_obs        | 1.52       |
| _mean_act       | 0.0165255  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.0844     |
| _mean_obs       | 0.0267     |
| _min_adv        | -3.88      |
| _min_discrew    | -0.0962    |
| _min_obs        | -1.27      |
| _std_act        | 0.39688    |
| _std_adv        | 1          |
| _std_discrew    | 0.00528    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.272      |
| ExplainedVarOld | 0.228      |
| KL              | 0.00403551 |
| Phi_loss        | 30.0189    |
| PolicyEntropy   | 4.94352    |
| PolicyLoss      | 0.0025452  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00385    |
| _MeanReward     | 115        |
| _lr_multiplier  | 1          |
| _max_act        | 2.80317    |
| _max_adv        | 4.14       |
| _max_discrew    | 0.408      |
| _max_obs        | 1.51       |
| _mean_act       | 0.0132605  |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 0.0931     |
| _mean_obs       | 0.0321     |
| _min_adv        | -5.65      |
| _min_discrew    | -0.0997    |
| _min_obs        | -1.27      |
| _std_act        | 0.388447   |
| _std_adv        | 1          |
| _std_discrew    | 0.0063     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.274      |
| ExplainedVarOld | 0.202      |
| KL              | 0.00387867 |
| Phi_loss        | 26.1463    |
| PolicyEntropy   | 4.92767    |
| PolicyLoss      | 0.00310194 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00464    |
| _MeanReward     | 122        |
| _lr_multiplier  | 1          |
| _max_act        | 2.64027    |
| _max_adv        | 4.65       |
| _max_discrew    | 0.405      |
| _max_obs        | 1.48       |
| _mean_act       | 0.0140095  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.0916     |
| _mean_obs       | 0.0305     |
| _min_adv        | -4.32      |
| _min_discrew    | -0.108     |
| _min_obs        | -1.4       |
| _std_act        | 0.389423   |
| _std_adv        | 1          |
| _std_discrew    | 0.00642    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.292      |
| ExplainedVarOld | 0.276      |
| KL              | 0.00271473 |
| Phi_loss        | 28.3307    |
| PolicyEntropy   | 4.90678    |
| PolicyLoss      | 0.00358053 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00455    |
| _MeanReward     | 145        |
| _lr_multiplier  | 1          |
| _max_act        | 2.69538    |
| _max_adv        | 4.73       |
| _max_discrew    | 0.35       |
| _max_obs        | 1.6        |
| _mean_act       | 0.0155167  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 0.114      |
| _mean_obs       | 0.0326     |
| _min_adv        | -4.82      |
| _min_discrew    | -0.0568    |
| _min_obs        | -1.31      |
| _std_act        | 0.389294   |
| _std_adv        | 1          |
| _std_discrew    | 0.00529    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.296       |
| ExplainedVarOld | 0.283       |
| KL              | 0.00438581  |
| Phi_loss        | 29.2859     |
| PolicyEntropy   | 4.89894     |
| PolicyLoss      | -0.00197078 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00385     |
| _MeanReward     | 146         |
| _lr_multiplier  | 1           |
| _max_act        | 2.62456     |
| _max_adv        | 3.94        |
| _max_discrew    | 0.384       |
| _max_obs        | 1.59        |
| _mean_act       | 0.0145841   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.115       |
| _mean_obs       | 0.0293      |
| _min_adv        | -4.81       |
| _min_discrew    | -0.072      |
| _min_obs        | -2.03       |
| _std_act        | 0.392322    |
| _std_adv        | 1           |
| _std_discrew    | 0.00571     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.359       |
| ExplainedVarOld | 0.324       |
| KL              | 0.00375751  |
| Phi_loss        | 29.4357     |
| PolicyEntropy   | 4.89358     |
| PolicyLoss      | 0.00121545  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00366     |
| _MeanReward     | 115         |
| _lr_multiplier  | 1           |
| _max_act        | 2.72073     |
| _max_adv        | 5.79        |
| _max_discrew    | 0.589       |
| _max_obs        | 1.6         |
| _mean_act       | -0.00559924 |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.0842      |
| _mean_obs       | 0.0314      |
| _min_adv        | -7.98       |
| _min_discrew    | -0.504      |
| _min_obs        | -1.73       |
| _std_act        | 0.39917     |
| _std_adv        | 1           |
| _std_discrew    | 0.029       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.693        |
| ExplainedVarOld | 0.656        |
| KL              | 0.00329915   |
| Phi_loss        | 25.9636      |
| PolicyEntropy   | 4.87821      |
| PolicyLoss      | -0.000575395 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0089       |
| _MeanReward     | 132          |
| _lr_multiplier  | 1            |
| _max_act        | 2.78828      |
| _max_adv        | 3.98         |
| _max_discrew    | 0.42         |
| _max_obs        | 1.72         |
| _mean_act       | 0.0137233    |
| _mean_adv       | -5.68e-18    |
| _mean_discrew   | 0.114        |
| _mean_obs       | 0.0321       |
| _min_adv        | -4.62        |
| _min_discrew    | -0.139       |
| _min_obs        | -1.28        |
| _std_act        | 0.390345     |
| _std_adv        | 1            |
| _std_discrew    | 0.00865      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.192       |
| ExplainedVarOld | 0.154       |
| KL              | 0.002865    |
| Phi_loss        | 29.3739     |
| PolicyEntropy   | 4.87157     |
| PolicyLoss      | -0.00205321 |
| Steps           | 10000       |
| VarFuncLoss     | 0.007       |
| _MeanReward     | 169         |
| _lr_multiplier  | 1           |
| _max_act        | 2.72742     |
| _max_adv        | 4.72        |
| _max_discrew    | 0.492       |
| _max_obs        | 1.67        |
| _mean_act       | 0.0138233   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.13        |
| _mean_obs       | 0.0348      |
| _min_adv        | -4.6        |
| _min_discrew    | -0.0943     |
| _min_obs        | -1.35       |
| _std_act        | 0.39043     |
| _std_adv        | 1           |
| _std_discrew    | 0.00805     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.439      |
| ExplainedVarOld | 0.376      |
| KL              | 0.00369186 |
| Phi_loss        | 28.0481    |
| PolicyEntropy   | 4.85957    |
| PolicyLoss      | 0.00181537 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00453    |
| _MeanReward     | 158        |
| _lr_multiplier  | 1          |
| _max_act        | 3.42349    |
| _max_adv        | 5.61       |
| _max_discrew    | 0.509      |
| _max_obs        | 1.82       |
| _mean_act       | 0.00906635 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.127      |
| _mean_obs       | 0.0355     |
| _min_adv        | -4.63      |
| _min_discrew    | -0.0762    |
| _min_obs        | -1.27      |
| _std_act        | 0.392589   |
| _std_adv        | 1          |
| _std_discrew    | 0.00918    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.299       |
| ExplainedVarOld | 0.26        |
| KL              | 0.00377067  |
| Phi_loss        | 29.5109     |
| PolicyEntropy   | 4.84156     |
| PolicyLoss      | -0.00253044 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00644     |
| _MeanReward     | 218         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90128     |
| _max_adv        | 5.89        |
| _max_discrew    | 0.588       |
| _max_obs        | 1.65        |
| _mean_act       | 0.00636862  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.172       |
| _mean_obs       | 0.0306      |
| _min_adv        | -4.77       |
| _min_discrew    | -0.0373     |
| _min_obs        | -1.36       |
| _std_act        | 0.404032    |
| _std_adv        | 1           |
| _std_discrew    | 0.009       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.473       |
| ExplainedVarOld | 0.455       |
| KL              | 0.00308237  |
| Phi_loss        | 29.5513     |
| PolicyEntropy   | 4.85058     |
| PolicyLoss      | -0.00264538 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00504     |
| _MeanReward     | 188         |
| _lr_multiplier  | 1           |
| _max_act        | 2.92341     |
| _max_adv        | 4.53        |
| _max_discrew    | 0.584       |
| _max_obs        | 1.51        |
| _mean_act       | 0.00954172  |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.159       |
| _mean_obs       | 0.0324      |
| _min_adv        | -5.72       |
| _min_discrew    | -0.144      |
| _min_obs        | -1.28       |
| _std_act        | 0.402319    |
| _std_adv        | 1           |
| _std_discrew    | 0.0099      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.368      |
| ExplainedVarOld | 0.348      |
| KL              | 0.00286612 |
| Phi_loss        | 27.9833    |
| PolicyEntropy   | 4.84053    |
| PolicyLoss      | 0.00431405 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00627    |
| _MeanReward     | 208        |
| _lr_multiplier  | 1          |
| _max_act        | 3.05663    |
| _max_adv        | 4.36       |
| _max_discrew    | 0.485      |
| _max_obs        | 1.62       |
| _mean_act       | 0.0112233  |
| _mean_adv       | -4.97e-18  |
| _mean_discrew   | 0.159      |
| _mean_obs       | 0.0327     |
| _min_adv        | -4.81      |
| _min_discrew    | -0.151     |
| _min_obs        | -1.39      |
| _std_act        | 0.400693   |
| _std_adv        | 1          |
| _std_discrew    | 0.0104     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.432       |
| ExplainedVarOld | 0.412       |
| KL              | 0.00310912  |
| Phi_loss        | 30.0921     |
| PolicyEntropy   | 4.82849     |
| PolicyLoss      | -0.00482588 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00588     |
| _MeanReward     | 186         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03389     |
| _max_adv        | 3.42        |
| _max_discrew    | 0.433       |
| _max_obs        | 1.56        |
| _mean_act       | -0.0040515  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.149       |
| _mean_obs       | 0.0268      |
| _min_adv        | -8.23       |
| _min_discrew    | -0.49       |
| _min_obs        | -1.33       |
| _std_act        | 0.41878     |
| _std_adv        | 1           |
| _std_discrew    | 0.0233      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.604       |
| ExplainedVarOld | 0.541       |
| KL              | 0.00623664  |
| Phi_loss        | 32.2301     |
| PolicyEntropy   | 4.81014     |
| PolicyLoss      | 0.000386753 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00922     |
| _MeanReward     | 180         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18163     |
| _max_adv        | 4.56        |
| _max_discrew    | 0.454       |
| _max_obs        | 1.73        |
| _mean_act       | 0.00226623  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.137       |
| _mean_obs       | 0.0333      |
| _min_adv        | -4.67       |
| _min_discrew    | -0.188      |
| _min_obs        | -1.41       |
| _std_act        | 0.399861    |
| _std_adv        | 1           |
| _std_discrew    | 0.00979     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.405      |
| ExplainedVarOld | 0.393      |
| KL              | 0.00173338 |
| Phi_loss        | 33.4584    |
| PolicyEntropy   | 4.7854     |
| PolicyLoss      | 0.00297237 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00612    |
| _MeanReward     | 224        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0705     |
| _max_adv        | 5.09       |
| _max_discrew    | 0.574      |
| _max_obs        | 1.51       |
| _mean_act       | 0.00243543 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.175      |
| _mean_obs       | 0.0309     |
| _min_adv        | -3.57      |
| _min_discrew    | -0.126     |
| _min_obs        | -1.42      |
| _std_act        | 0.406487   |
| _std_adv        | 1          |
| _std_discrew    | 0.0166     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.414       |
| ExplainedVarOld | 0.379       |
| KL              | 0.00186924  |
| Phi_loss        | 33.2605     |
| PolicyEntropy   | 4.78178     |
| PolicyLoss      | -0.00703014 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0101      |
| _MeanReward     | 164         |
| _lr_multiplier  | 1           |
| _max_act        | 3.20511     |
| _max_adv        | 3.92        |
| _max_discrew    | 0.491       |
| _max_obs        | 1.56        |
| _mean_act       | -0.00872738 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.131       |
| _mean_obs       | 0.0272      |
| _min_adv        | -9.21       |
| _min_discrew    | -0.511      |
| _min_obs        | -1.38       |
| _std_act        | 0.413607    |
| _std_adv        | 1           |
| _std_discrew    | 0.031       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.594       |
| ExplainedVarOld | 0.571       |
| KL              | 0.00169818  |
| Phi_loss        | 38.1454     |
| PolicyEntropy   | 4.75918     |
| PolicyLoss      | 0.0080641   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0126      |
| _MeanReward     | 195         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0462      |
| _max_adv        | 3.46        |
| _max_discrew    | 0.546       |
| _max_obs        | 1.58        |
| _mean_act       | -0.00676647 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.15        |
| _mean_obs       | 0.0261      |
| _min_adv        | -10         |
| _min_discrew    | -0.539      |
| _min_obs        | -1.26       |
| _std_act        | 0.418853    |
| _std_adv        | 1           |
| _std_discrew    | 0.0298      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.696        |
| ExplainedVarOld | 0.68         |
| KL              | 0.00123769   |
| Phi_loss        | 36.4598      |
| PolicyEntropy   | 4.75452      |
| PolicyLoss      | -0.000226662 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00911      |
| _MeanReward     | 215          |
| _lr_multiplier  | 1            |
| _max_act        | 2.96267      |
| _max_adv        | 4.65         |
| _max_discrew    | 0.472        |
| _max_obs        | 1.47         |
| _mean_act       | 0.0104695    |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 0.172        |
| _mean_obs       | 0.0292       |
| _min_adv        | -4.2         |
| _min_discrew    | -0.0601      |
| _min_obs        | -1.41        |
| _std_act        | 0.402244     |
| _std_adv        | 1            |
| _std_discrew    | 0.011        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.413      |
| ExplainedVarOld | 0.396      |
| KL              | 0.00250668 |
| Phi_loss        | 35.3083    |
| PolicyEntropy   | 4.73825    |
| PolicyLoss      | -0.0023881 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00648    |
| _MeanReward     | 235        |
| _lr_multiplier  | 1          |
| _max_act        | 2.80144    |
| _max_adv        | 4.4        |
| _max_discrew    | 0.584      |
| _max_obs        | 1.52       |
| _mean_act       | 0.00585996 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.187      |
| _mean_obs       | 0.0327     |
| _min_adv        | -5.61      |
| _min_discrew    | -0.0599    |
| _min_obs        | -1.49      |
| _std_act        | 0.405394   |
| _std_adv        | 1          |
| _std_discrew    | 0.011      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.403      |
| ExplainedVarOld | 0.382      |
| KL              | 0.00195019 |
| Phi_loss        | 36.0507    |
| PolicyEntropy   | 4.71452    |
| PolicyLoss      | 0.00215795 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00662    |
| _MeanReward     | 234        |
| _lr_multiplier  | 1          |
| _max_act        | 2.99538    |
| _max_adv        | 5.65       |
| _max_discrew    | 0.62       |
| _max_obs        | 1.55       |
| _mean_act       | 0.00558557 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 0.191      |
| _mean_obs       | 0.0345     |
| _min_adv        | -5.45      |
| _min_discrew    | -0.0487    |
| _min_obs        | -1.28      |
| _std_act        | 0.398688   |
| _std_adv        | 1          |
| _std_discrew    | 0.00934    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.543       |
| ExplainedVarOld | 0.531       |
| KL              | 0.00366551  |
| Phi_loss        | 36.4923     |
| PolicyEntropy   | 4.6998      |
| PolicyLoss      | -0.00707848 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00427     |
| _MeanReward     | 280         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01863     |
| _max_adv        | 4.21        |
| _max_discrew    | 0.656       |
| _max_obs        | 1.69        |
| _mean_act       | 0.00700516  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.214       |
| _mean_obs       | 0.0351      |
| _min_adv        | -4.31       |
| _min_discrew    | -0.0104     |
| _min_obs        | -1.39       |
| _std_act        | 0.395358    |
| _std_adv        | 1           |
| _std_discrew    | 0.0157      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.583        |
| ExplainedVarOld | 0.532        |
| KL              | 0.00260787   |
| Phi_loss        | 35.7906      |
| PolicyEntropy   | 4.68178      |
| PolicyLoss      | -0.000391254 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00662      |
| _MeanReward     | 248          |
| _lr_multiplier  | 1            |
| _max_act        | 3.01033      |
| _max_adv        | 3.96         |
| _max_discrew    | 0.542        |
| _max_obs        | 1.47         |
| _mean_act       | 0.00411931   |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 0.188        |
| _mean_obs       | 0.0319       |
| _min_adv        | -5.26        |
| _min_discrew    | -0.0612      |
| _min_obs        | -1.42        |
| _std_act        | 0.40554      |
| _std_adv        | 1            |
| _std_discrew    | 0.0108       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.429      |
| ExplainedVarOld | 0.394      |
| KL              | 0.00330937 |
| Phi_loss        | 37.2444    |
| PolicyEntropy   | 4.66937    |
| PolicyLoss      | 0.00222751 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00648    |
| _MeanReward     | 297        |
| _lr_multiplier  | 1          |
| _max_act        | 3.4484     |
| _max_adv        | 4.4        |
| _max_discrew    | 0.623      |
| _max_obs        | 1.65       |
| _mean_act       | 0.00835963 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.241      |
| _mean_obs       | 0.0299     |
| _min_adv        | -5.47      |
| _min_discrew    | -0.0312    |
| _min_obs        | -1.39      |
| _std_act        | 0.411236   |
| _std_adv        | 1          |
| _std_discrew    | 0.0153     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.551        |
| ExplainedVarOld | 0.519        |
| KL              | 0.00300013   |
| Phi_loss        | 36.5935      |
| PolicyEntropy   | 4.64949      |
| PolicyLoss      | -0.000362738 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00736      |
| _MeanReward     | 274          |
| _lr_multiplier  | 1            |
| _max_act        | 2.86736      |
| _max_adv        | 4.63         |
| _max_discrew    | 0.545        |
| _max_obs        | 1.84         |
| _mean_act       | 0.00861202   |
| _mean_adv       | 1.71e-17     |
| _mean_discrew   | 0.219        |
| _mean_obs       | 0.027        |
| _min_adv        | -3.99        |
| _min_discrew    | -0.0809      |
| _min_obs        | -1.36        |
| _std_act        | 0.416268     |
| _std_adv        | 1            |
| _std_discrew    | 0.0123       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.328       |
| ExplainedVarOld | 0.26        |
| KL              | 0.00266343  |
| Phi_loss        | 36.6387     |
| PolicyEntropy   | 4.6407      |
| PolicyLoss      | -0.00329718 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00842     |
| _MeanReward     | 274         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24991     |
| _max_adv        | 4.95        |
| _max_discrew    | 0.646       |
| _max_obs        | 1.51        |
| _mean_act       | 0.00262647  |
| _mean_adv       | -3.69e-17   |
| _mean_discrew   | 0.223       |
| _mean_obs       | 0.0318      |
| _min_adv        | -5.04       |
| _min_discrew    | -0.0579     |
| _min_obs        | -1.33       |
| _std_act        | 0.411786    |
| _std_adv        | 1           |
| _std_discrew    | 0.0125      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.571      |
| ExplainedVarOld | 0.543      |
| KL              | 0.00309649 |
| Phi_loss        | 36.9369    |
| PolicyEntropy   | 4.62797    |
| PolicyLoss      | 0.00208714 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00539    |
| _MeanReward     | 309        |
| _lr_multiplier  | 1          |
| _max_act        | 3.19758    |
| _max_adv        | 3.38       |
| _max_discrew    | 0.616      |
| _max_obs        | 1.65       |
| _mean_act       | 0.00648192 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.252      |
| _mean_obs       | 0.0205     |
| _min_adv        | -3.85      |
| _min_discrew    | -0.0673    |
| _min_obs        | -1.32      |
| _std_act        | 0.431543   |
| _std_adv        | 1          |
| _std_discrew    | 0.0154     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.606      |
| ExplainedVarOld | 0.55       |
| KL              | 0.00301564 |
| Phi_loss        | 38.4707    |
| PolicyEntropy   | 4.61715    |
| PolicyLoss      | 0.00417972 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00607    |
| _MeanReward     | 297        |
| _lr_multiplier  | 1          |
| _max_act        | 2.94892    |
| _max_adv        | 4.26       |
| _max_discrew    | 0.733      |
| _max_obs        | 1.5        |
| _mean_act       | 0.00343056 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.236      |
| _mean_obs       | 0.0274     |
| _min_adv        | -4.11      |
| _min_discrew    | -0.0238    |
| _min_obs        | -1.26      |
| _std_act        | 0.406244   |
| _std_adv        | 1          |
| _std_discrew    | 0.0155     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.573       |
| ExplainedVarOld | 0.533       |
| KL              | 0.00302772  |
| Phi_loss        | 39.4122     |
| PolicyEntropy   | 4.61088     |
| PolicyLoss      | -0.00886538 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00661     |
| _MeanReward     | 286         |
| _lr_multiplier  | 1           |
| _max_act        | 3.44703     |
| _max_adv        | 4.94        |
| _max_discrew    | 0.67        |
| _max_obs        | 1.51        |
| _mean_act       | 0.00236804  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.219       |
| _mean_obs       | 0.0342      |
| _min_adv        | -4.78       |
| _min_discrew    | -0.00541    |
| _min_obs        | -1.33       |
| _std_act        | 0.405347    |
| _std_adv        | 1           |
| _std_discrew    | 0.0149      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.541       |
| ExplainedVarOld | 0.505       |
| KL              | 0.00321617  |
| Phi_loss        | 38.3361     |
| PolicyEntropy   | 4.60058     |
| PolicyLoss      | -0.00196349 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00684     |
| _MeanReward     | 327         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95986     |
| _max_adv        | 4.38        |
| _max_discrew    | 0.622       |
| _max_obs        | 1.54        |
| _mean_act       | 0.00571931  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.255       |
| _mean_obs       | 0.0312      |
| _min_adv        | -4.26       |
| _min_discrew    | -0.00572    |
| _min_obs        | -1.3        |
| _std_act        | 0.41455     |
| _std_adv        | 1           |
| _std_discrew    | 0.0122      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.406      |
| ExplainedVarOld | 0.293      |
| KL              | 0.00347601 |
| Phi_loss        | 38.4982    |
| PolicyEntropy   | 4.59677    |
| PolicyLoss      | -0.0106019 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00758    |
| _MeanReward     | 312        |
| _lr_multiplier  | 1          |
| _max_act        | 3.33536    |
| _max_adv        | 3.91       |
| _max_discrew    | 0.671      |
| _max_obs        | 1.78       |
| _mean_act       | 0.00220358 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.246      |
| _mean_obs       | 0.0308     |
| _min_adv        | -4.11      |
| _min_discrew    | -0.0229    |
| _min_obs        | -1.37      |
| _std_act        | 0.425821   |
| _std_adv        | 1          |
| _std_discrew    | 0.0159     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.54        |
| ExplainedVarOld | 0.526       |
| KL              | 0.00365652  |
| Phi_loss        | 39.0971     |
| PolicyEntropy   | 4.59689     |
| PolicyLoss      | -0.00621429 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00731     |
| _MeanReward     | 309         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1824      |
| _max_adv        | 3.72        |
| _max_discrew    | 0.542       |
| _max_obs        | 1.63        |
| _mean_act       | 0.0031952   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.254       |
| _mean_obs       | 0.0262      |
| _min_adv        | -4.3        |
| _min_discrew    | -0.0305     |
| _min_obs        | -1.34       |
| _std_act        | 0.441134    |
| _std_adv        | 1           |
| _std_discrew    | 0.015       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.524       |
| ExplainedVarOld | 0.487       |
| KL              | 0.00235053  |
| Phi_loss        | 42.9217     |
| PolicyEntropy   | 4.58838     |
| PolicyLoss      | -0.00460472 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00716     |
| _MeanReward     | 334         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04284     |
| _max_adv        | 4.29        |
| _max_discrew    | 0.567       |
| _max_obs        | 1.62        |
| _mean_act       | 0.0024203   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.265       |
| _mean_obs       | 0.0303      |
| _min_adv        | -4.37       |
| _min_discrew    | -0.0299     |
| _min_obs        | -1.41       |
| _std_act        | 0.425395    |
| _std_adv        | 1           |
| _std_discrew    | 0.0164      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.624       |
| ExplainedVarOld | 0.608       |
| KL              | 0.00268549  |
| Phi_loss        | 40.7479     |
| PolicyEntropy   | 4.56781     |
| PolicyLoss      | 0.000563439 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00618     |
| _MeanReward     | 367         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03998     |
| _max_adv        | 4.14        |
| _max_discrew    | 0.678       |
| _max_obs        | 1.73        |
| _mean_act       | -0.003573   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.293       |
| _mean_obs       | 0.0322      |
| _min_adv        | -3.82       |
| _min_discrew    | -0.0924     |
| _min_obs        | -1.31       |
| _std_act        | 0.425075    |
| _std_adv        | 1           |
| _std_discrew    | 0.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.636       |
| ExplainedVarOld | 0.604       |
| KL              | 0.00339424  |
| Phi_loss        | 45.0172     |
| PolicyEntropy   | 4.54202     |
| PolicyLoss      | -0.00516874 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00759     |
| _MeanReward     | 396         |
| _lr_multiplier  | 1           |
| _max_act        | 3.10622     |
| _max_adv        | 4.21        |
| _max_discrew    | 0.652       |
| _max_obs        | 1.44        |
| _mean_act       | 0.0048278   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.321       |
| _mean_obs       | 0.0298      |
| _min_adv        | -4.05       |
| _min_discrew    | -0.0193     |
| _min_obs        | -1.43       |
| _std_act        | 0.438407    |
| _std_adv        | 1           |
| _std_discrew    | 0.0196      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.605       |
| ExplainedVarOld | 0.577       |
| KL              | 0.00317241  |
| Phi_loss        | 39.9364     |
| PolicyEntropy   | 4.54588     |
| PolicyLoss      | -0.00899826 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0078      |
| _MeanReward     | 338         |
| _lr_multiplier  | 1           |
| _max_act        | 2.89145     |
| _max_adv        | 3.61        |
| _max_discrew    | 0.683       |
| _max_obs        | 1.58        |
| _mean_act       | 0.000789482 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.272       |
| _mean_obs       | 0.0292      |
| _min_adv        | -4.52       |
| _min_discrew    | -0.0101     |
| _min_obs        | -1.28       |
| _std_act        | 0.44042     |
| _std_adv        | 1           |
| _std_discrew    | 0.0147      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.57        |
| ExplainedVarOld | 0.53        |
| KL              | 0.00253797  |
| Phi_loss        | 43.538      |
| PolicyEntropy   | 4.52426     |
| PolicyLoss      | 0.000560872 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00694     |
| _MeanReward     | 289         |
| _lr_multiplier  | 1           |
| _max_act        | 3.45859     |
| _max_adv        | 4.93        |
| _max_discrew    | 0.875       |
| _max_obs        | 1.63        |
| _mean_act       | -0.0437921  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.216       |
| _mean_obs       | 0.0265      |
| _min_adv        | -7.9        |
| _min_discrew    | -0.739      |
| _min_obs        | -1.36       |
| _std_act        | 0.46567     |
| _std_adv        | 1           |
| _std_discrew    | 0.0783      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.681      |
| ExplainedVarOld | 0.612      |
| KL              | 0.00341288 |
| Phi_loss        | 36.8918    |
| PolicyEntropy   | 4.49188    |
| PolicyLoss      | 0.00338413 |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 378        |
| _lr_multiplier  | 1          |
| _max_act        | 3.32354    |
| _max_adv        | 4.91       |
| _max_discrew    | 0.748      |
| _max_obs        | 1.81       |
| _mean_act       | -0.0115371 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 0.304      |
| _mean_obs       | 0.033      |
| _min_adv        | -4.43      |
| _min_discrew    | -0.0175    |
| _min_obs        | -1.3       |
| _std_act        | 0.423538   |
| _std_adv        | 1          |
| _std_discrew    | 0.0169     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.515       |
| ExplainedVarOld | 0.482       |
| KL              | 0.00258979  |
| Phi_loss        | 42.367      |
| PolicyEntropy   | 4.48289     |
| PolicyLoss      | 0.00059307  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00828     |
| _MeanReward     | 404         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83148     |
| _max_adv        | 4.04        |
| _max_discrew    | 0.724       |
| _max_obs        | 1.62        |
| _mean_act       | -0.00198337 |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 0.329       |
| _mean_obs       | 0.0272      |
| _min_adv        | -4.88       |
| _min_discrew    | -0.0378     |
| _min_obs        | -1.28       |
| _std_act        | 0.434959    |
| _std_adv        | 1           |
| _std_discrew    | 0.0187      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.622       |
| ExplainedVarOld | 0.569       |
| KL              | 0.00320604  |
| Phi_loss        | 41.8654     |
| PolicyEntropy   | 4.459       |
| PolicyLoss      | -0.00269291 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00709     |
| _MeanReward     | 367         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13976     |
| _max_adv        | 4.49        |
| _max_discrew    | 0.825       |
| _max_obs        | 1.6         |
| _mean_act       | -0.00451471 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.295       |
| _mean_obs       | 0.0271      |
| _min_adv        | -4.7        |
| _min_discrew    | -0.116      |
| _min_obs        | -1.31       |
| _std_act        | 0.427549    |
| _std_adv        | 1           |
| _std_discrew    | 0.0223      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.563       |
| ExplainedVarOld | 0.535       |
| KL              | 0.00362289  |
| Phi_loss        | 47.5243     |
| PolicyEntropy   | 4.42517     |
| PolicyLoss      | 0.00824131  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00999     |
| _MeanReward     | 351         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1231      |
| _max_adv        | 4.61        |
| _max_discrew    | 0.67        |
| _max_obs        | 1.5         |
| _mean_act       | -0.00625001 |
| _mean_adv       | 2.7e-17     |
| _mean_discrew   | 0.285       |
| _mean_obs       | 0.0281      |
| _min_adv        | -5.03       |
| _min_discrew    | -0.0712     |
| _min_obs        | -1.36       |
| _std_act        | 0.428252    |
| _std_adv        | 1           |
| _std_discrew    | 0.0196      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.435      |
| ExplainedVarOld | 0.401      |
| KL              | 0.00339089 |
| Phi_loss        | 51.002     |
| PolicyEntropy   | 4.39785    |
| PolicyLoss      | 0.0112059  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0111     |
| _MeanReward     | 416        |
| _lr_multiplier  | 1          |
| _max_act        | 4.10484    |
| _max_adv        | 4.79       |
| _max_discrew    | 0.755      |
| _max_obs        | 1.65       |
| _mean_act       | -0.0079119 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.327      |
| _mean_obs       | 0.0309     |
| _min_adv        | -4.23      |
| _min_discrew    | -0.0297    |
| _min_obs        | -1.33      |
| _std_act        | 0.425929   |
| _std_adv        | 1          |
| _std_discrew    | 0.0198     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.725       |
| ExplainedVarOld | 0.697       |
| KL              | 0.00329716  |
| Phi_loss        | 46.3211     |
| PolicyEntropy   | 4.37807     |
| PolicyLoss      | 0.00189928  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00596     |
| _MeanReward     | 421         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19297     |
| _max_adv        | 3.73        |
| _max_discrew    | 0.787       |
| _max_obs        | 1.5         |
| _mean_act       | -0.00536045 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.332       |
| _mean_obs       | 0.0311      |
| _min_adv        | -4.47       |
| _min_discrew    | -0.0568     |
| _min_obs        | -1.27       |
| _std_act        | 0.424751    |
| _std_adv        | 1           |
| _std_discrew    | 0.0214      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.661       |
| ExplainedVarOld | 0.631       |
| KL              | 0.00242926  |
| Phi_loss        | 48.6273     |
| PolicyEntropy   | 4.38248     |
| PolicyLoss      | -0.00177251 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00728     |
| _MeanReward     | 410         |
| _lr_multiplier  | 1           |
| _max_act        | 3.60259     |
| _max_adv        | 5.68        |
| _max_discrew    | 0.787       |
| _max_obs        | 1.68        |
| _mean_act       | -0.00960646 |
| _mean_adv       | -9.95e-18   |
| _mean_discrew   | 0.328       |
| _mean_obs       | 0.0295      |
| _min_adv        | -4.54       |
| _min_discrew    | -0.00764    |
| _min_obs        | -1.56       |
| _std_act        | 0.426582    |
| _std_adv        | 1           |
| _std_discrew    | 0.0186      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.67        |
| ExplainedVarOld | 0.645       |
| KL              | 0.00288005  |
| Phi_loss        | 48.3773     |
| PolicyEntropy   | 4.36742     |
| PolicyLoss      | 0.00343364  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00614     |
| _MeanReward     | 421         |
| _lr_multiplier  | 1           |
| _max_act        | 2.94235     |
| _max_adv        | 4.31        |
| _max_discrew    | 0.779       |
| _max_obs        | 1.51        |
| _mean_act       | -0.00145099 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.335       |
| _mean_obs       | 0.0279      |
| _min_adv        | -4.25       |
| _min_discrew    | -0.0273     |
| _min_obs        | -1.37       |
| _std_act        | 0.437723    |
| _std_adv        | 1           |
| _std_discrew    | 0.0246      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.612      |
| ExplainedVarOld | 0.605      |
| KL              | 0.00306867 |
| Phi_loss        | 52.0226    |
| PolicyEntropy   | 4.32288    |
| PolicyLoss      | 0.00909257 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00955    |
| _MeanReward     | 349        |
| _lr_multiplier  | 1          |
| _max_act        | 3.11121    |
| _max_adv        | 3.74       |
| _max_discrew    | 0.683      |
| _max_obs        | 1.94       |
| _mean_act       | -0.0382118 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.267      |
| _mean_obs       | 0.0261     |
| _min_adv        | -11.8      |
| _min_discrew    | -0.762     |
| _min_obs        | -1.4       |
| _std_act        | 0.455403   |
| _std_adv        | 1          |
| _std_discrew    | 0.0662     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.807       |
| ExplainedVarOld | 0.779       |
| KL              | 0.00328683  |
| Phi_loss        | 39.5897     |
| PolicyEntropy   | 4.29326     |
| PolicyLoss      | 0.000417857 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0129      |
| _MeanReward     | 446         |
| _lr_multiplier  | 1           |
| _max_act        | 2.98567     |
| _max_adv        | 4.56        |
| _max_discrew    | 0.993       |
| _max_obs        | 1.42        |
| _mean_act       | -0.00504185 |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 0.362       |
| _mean_obs       | 0.0302      |
| _min_adv        | -5.75       |
| _min_discrew    | -0.028      |
| _min_obs        | -1.37       |
| _std_act        | 0.432796    |
| _std_adv        | 1           |
| _std_discrew    | 0.0303      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.578       |
| ExplainedVarOld | 0.54        |
| KL              | 0.00315398  |
| Phi_loss        | 46.8353     |
| PolicyEntropy   | 4.273       |
| PolicyLoss      | 0.000406343 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0133      |
| _MeanReward     | 490         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13546     |
| _max_adv        | 6.93        |
| _max_discrew    | 0.807       |
| _max_obs        | 1.66        |
| _mean_act       | -0.00273397 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.384       |
| _mean_obs       | 0.0255      |
| _min_adv        | -3.14       |
| _min_discrew    | -0.0168     |
| _min_obs        | -1.34       |
| _std_act        | 0.435181    |
| _std_adv        | 1           |
| _std_discrew    | 0.0267      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.656       |
| ExplainedVarOld | 0.631       |
| KL              | 0.00251288  |
| Phi_loss        | 51.7517     |
| PolicyEntropy   | 4.26084     |
| PolicyLoss      | -0.0108958  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00922     |
| _MeanReward     | 437         |
| _lr_multiplier  | 1           |
| _max_act        | 3.30438     |
| _max_adv        | 4.81        |
| _max_discrew    | 0.806       |
| _max_obs        | 1.47        |
| _mean_act       | -0.00560368 |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | 0.355       |
| _mean_obs       | 0.0303      |
| _min_adv        | -3.73       |
| _min_discrew    | -0.0167     |
| _min_obs        | -1.31       |
| _std_act        | 0.429339    |
| _std_adv        | 1           |
| _std_discrew    | 0.0181      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.701       |
| ExplainedVarOld | 0.681       |
| KL              | 0.00270775  |
| Phi_loss        | 52.5841     |
| PolicyEntropy   | 4.24474     |
| PolicyLoss      | 0.00223421  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00543     |
| _MeanReward     | 399         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02649     |
| _max_adv        | 3.45        |
| _max_discrew    | 0.712       |
| _max_obs        | 1.79        |
| _mean_act       | -0.00751241 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.324       |
| _mean_obs       | 0.0296      |
| _min_adv        | -3.56       |
| _min_discrew    | -0.0928     |
| _min_obs        | -1.34       |
| _std_act        | 0.431691    |
| _std_adv        | 1           |
| _std_discrew    | 0.0223      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.688        |
| ExplainedVarOld | 0.664        |
| KL              | 0.00258046   |
| Phi_loss        | 53.003       |
| PolicyEntropy   | 4.22741      |
| PolicyLoss      | -0.000570135 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0072       |
| _MeanReward     | 408          |
| _lr_multiplier  | 1            |
| _max_act        | 3.10866      |
| _max_adv        | 3.08         |
| _max_discrew    | 0.766        |
| _max_obs        | 1.47         |
| _mean_act       | -0.0392498   |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | 0.319        |
| _mean_obs       | 0.0243       |
| _min_adv        | -11.5        |
| _min_discrew    | -0.823       |
| _min_obs        | -1.62        |
| _std_act        | 0.474515     |
| _std_adv        | 1            |
| _std_discrew    | 0.0998       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.835       |
| ExplainedVarOld | 0.793       |
| KL              | 0.00366303  |
| Phi_loss        | 44.0682     |
| PolicyEntropy   | 4.23557     |
| PolicyLoss      | 0.00487646  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0174      |
| _MeanReward     | 506         |
| _lr_multiplier  | 1           |
| _max_act        | 3.42249     |
| _max_adv        | 3.59        |
| _max_discrew    | 0.814       |
| _max_obs        | 1.41        |
| _mean_act       | 0.000212306 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.4         |
| _mean_obs       | 0.0286      |
| _min_adv        | -3.74       |
| _min_discrew    | -0.00457    |
| _min_obs        | -1.29       |
| _std_act        | 0.435104    |
| _std_adv        | 1           |
| _std_discrew    | 0.0272      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.672       |
| ExplainedVarOld | 0.646       |
| KL              | 0.00159992  |
| Phi_loss        | 52.1972     |
| PolicyEntropy   | 4.21769     |
| PolicyLoss      | 0.000989612 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00893     |
| _MeanReward     | 545         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16606     |
| _max_adv        | 5.08        |
| _max_discrew    | 0.797       |
| _max_obs        | 1.58        |
| _mean_act       | 0.00129833  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.441       |
| _mean_obs       | 0.0248      |
| _min_adv        | -3.33       |
| _min_discrew    | -0.0188     |
| _min_obs        | -1.3        |
| _std_act        | 0.445499    |
| _std_adv        | 1           |
| _std_discrew    | 0.0281      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.728       |
| ExplainedVarOld | 0.704       |
| KL              | 0.00316014  |
| Phi_loss        | 57.8616     |
| PolicyEntropy   | 4.18822     |
| PolicyLoss      | -0.003181   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00779     |
| _MeanReward     | 538         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03396     |
| _max_adv        | 4           |
| _max_discrew    | 0.899       |
| _max_obs        | 1.6         |
| _mean_act       | -0.00488845 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 0.432       |
| _mean_obs       | 0.0266      |
| _min_adv        | -5.66       |
| _min_discrew    | -0.0523     |
| _min_obs        | -1.7        |
| _std_act        | 0.439239    |
| _std_adv        | 1           |
| _std_discrew    | 0.0361      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.727       |
| ExplainedVarOld | 0.697       |
| KL              | 0.00262436  |
| Phi_loss        | 55.6975     |
| PolicyEntropy   | 4.18712     |
| PolicyLoss      | -0.00454301 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00986     |
| _MeanReward     | 579         |
| _lr_multiplier  | 1           |
| _max_act        | 3.15551     |
| _max_adv        | 3.05        |
| _max_discrew    | 0.898       |
| _max_obs        | 1.5         |
| _mean_act       | -0.00524471 |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.476       |
| _mean_obs       | 0.0191      |
| _min_adv        | -3.65       |
| _min_discrew    | -0.00349    |
| _min_obs        | -1.37       |
| _std_act        | 0.452262    |
| _std_adv        | 1           |
| _std_discrew    | 0.0403      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.559       |
| ExplainedVarOld | 0.543       |
| KL              | 0.00322721  |
| Phi_loss        | 60.8506     |
| PolicyEntropy   | 4.15668     |
| PolicyLoss      | -0.00599755 |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 582         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19329     |
| _max_adv        | 3.87        |
| _max_discrew    | 0.963       |
| _max_obs        | 1.7         |
| _mean_act       | -0.00385712 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.469       |
| _mean_obs       | 0.0255      |
| _min_adv        | -3.28       |
| _min_discrew    | -0.0062     |
| _min_obs        | -1.32       |
| _std_act        | 0.441972    |
| _std_adv        | 1           |
| _std_discrew    | 0.0323      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.618       |
| ExplainedVarOld | 0.597       |
| KL              | 0.00289047  |
| Phi_loss        | 59.6238     |
| PolicyEntropy   | 4.15193     |
| PolicyLoss      | -0.011146   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0123      |
| _MeanReward     | 567         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14917     |
| _max_adv        | 4.83        |
| _max_discrew    | 1.08        |
| _max_obs        | 1.77        |
| _mean_act       | -0.00725284 |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 0.439       |
| _mean_obs       | 0.0302      |
| _min_adv        | -3.07       |
| _min_discrew    | -0.0398     |
| _min_obs        | -1.3        |
| _std_act        | 0.436592    |
| _std_adv        | 1           |
| _std_discrew    | 0.0454      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.779        |
| ExplainedVarOld | 0.737        |
| KL              | 0.0034589    |
| Phi_loss        | 54.257       |
| PolicyEntropy   | 4.13294      |
| PolicyLoss      | -0.000484014 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0102       |
| _MeanReward     | 583          |
| _lr_multiplier  | 1            |
| _max_act        | 3.3051       |
| _max_adv        | 3.9          |
| _max_discrew    | 0.853        |
| _max_obs        | 1.69         |
| _mean_act       | 0.00050827   |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 0.468        |
| _mean_obs       | 0.0246       |
| _min_adv        | -3.64        |
| _min_discrew    | -0.0506      |
| _min_obs        | -1.32        |
| _std_act        | 0.444818     |
| _std_adv        | 1            |
| _std_discrew    | 0.0299       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.657       |
| ExplainedVarOld | 0.633       |
| KL              | 0.00382047  |
| Phi_loss        | 59.3073     |
| PolicyEntropy   | 4.12317     |
| PolicyLoss      | 0.000700892 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0103      |
| _MeanReward     | 578         |
| _lr_multiplier  | 1           |
| _max_act        | 3.40532     |
| _max_adv        | 3.37        |
| _max_discrew    | 0.953       |
| _max_obs        | 1.88        |
| _mean_act       | -0.00780317 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.465       |
| _mean_obs       | 0.0295      |
| _min_adv        | -4.93       |
| _min_discrew    | -0.0162     |
| _min_obs        | -1.23       |
| _std_act        | 0.436448    |
| _std_adv        | 1           |
| _std_discrew    | 0.0371      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.751       |
| ExplainedVarOld | 0.726       |
| KL              | 0.00287093  |
| Phi_loss        | 57.4553     |
| PolicyEntropy   | 4.10675     |
| PolicyLoss      | -0.00152047 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00924     |
| _MeanReward     | 581         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93818     |
| _max_adv        | 3.64        |
| _max_discrew    | 0.976       |
| _max_obs        | 1.56        |
| _mean_act       | -0.0030463  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 0.469       |
| _mean_obs       | 0.0258      |
| _min_adv        | -3.49       |
| _min_discrew    | -0.00969    |
| _min_obs        | -1.33       |
| _std_act        | 0.44616     |
| _std_adv        | 1           |
| _std_discrew    | 0.0375      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.698       |
| ExplainedVarOld | 0.689       |
| KL              | 0.00195209  |
| Phi_loss        | 63.1665     |
| PolicyEntropy   | 4.08792     |
| PolicyLoss      | -0.00175071 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0113      |
| _MeanReward     | 638         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19237     |
| _max_adv        | 3.71        |
| _max_discrew    | 1.09        |
| _max_obs        | 1.64        |
| _mean_act       | 0.00307243  |
| _mean_adv       | -3.55e-17   |
| _mean_discrew   | 0.509       |
| _mean_obs       | 0.0248      |
| _min_adv        | -3.81       |
| _min_discrew    | -0.00199    |
| _min_obs        | -1.29       |
| _std_act        | 0.455965    |
| _std_adv        | 1           |
| _std_discrew    | 0.0407      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.716       |
| ExplainedVarOld | 0.7         |
| KL              | 0.00223544  |
| Phi_loss        | 66.0522     |
| PolicyEntropy   | 4.06781     |
| PolicyLoss      | -0.00222509 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0117      |
| _MeanReward     | 658         |
| _lr_multiplier  | 1           |
| _max_act        | 3.17267     |
| _max_adv        | 3.58        |
| _max_discrew    | 1.02        |
| _max_obs        | 1.99        |
| _mean_act       | 0.00111436  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.539       |
| _mean_obs       | 0.0225      |
| _min_adv        | -3.16       |
| _min_discrew    | -0.0294     |
| _min_obs        | -1.32       |
| _std_act        | 0.446773    |
| _std_adv        | 1           |
| _std_discrew    | 0.053       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.699      |
| ExplainedVarOld | 0.674      |
| KL              | 0.00330437 |
| Phi_loss        | 64.7633    |
| PolicyEntropy   | 4.04915    |
| PolicyLoss      | -0.0119391 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0161     |
| _MeanReward     | 656        |
| _lr_multiplier  | 1          |
| _max_act        | 3.3536     |
| _max_adv        | 3.37       |
| _max_discrew    | 1.08       |
| _max_obs        | 1.54       |
| _mean_act       | 0.00125339 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.529      |
| _mean_obs       | 0.0271     |
| _min_adv        | -4.21      |
| _min_discrew    | -0.00763   |
| _min_obs        | -1.33      |
| _std_act        | 0.451627   |
| _std_adv        | 1          |
| _std_discrew    | 0.0521     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.716       |
| ExplainedVarOld | 0.708       |
| KL              | 0.00259243  |
| Phi_loss        | 64.1874     |
| PolicyEntropy   | 4.04869     |
| PolicyLoss      | 0.000697925 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0148      |
| _MeanReward     | 683         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06575     |
| _max_adv        | 3.45        |
| _max_discrew    | 0.964       |
| _max_obs        | 1.5         |
| _mean_act       | 0.00748527  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.548       |
| _mean_obs       | 0.0267      |
| _min_adv        | -3.87       |
| _min_discrew    | -0.0466     |
| _min_obs        | -1.32       |
| _std_act        | 0.453346    |
| _std_adv        | 1           |
| _std_discrew    | 0.0459      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.698       |
| ExplainedVarOld | 0.673       |
| KL              | 0.00380511  |
| Phi_loss        | 63.022      |
| PolicyEntropy   | 4.03889     |
| PolicyLoss      | -0.0033646  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0139      |
| _MeanReward     | 683         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04188     |
| _max_adv        | 3.47        |
| _max_discrew    | 0.969       |
| _max_obs        | 1.5         |
| _mean_act       | 0.000267978 |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 0.56        |
| _mean_obs       | 0.0282      |
| _min_adv        | -4.61       |
| _min_discrew    | -0.00696    |
| _min_obs        | -1.29       |
| _std_act        | 0.450582    |
| _std_adv        | 1           |
| _std_discrew    | 0.0422      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.778       |
| ExplainedVarOld | 0.752       |
| KL              | 0.00292524  |
| Phi_loss        | 63.1687     |
| PolicyEntropy   | 4.04733     |
| PolicyLoss      | -0.00990464 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00936     |
| _MeanReward     | 685         |
| _lr_multiplier  | 1           |
| _max_act        | 3.00051     |
| _max_adv        | 3.52        |
| _max_discrew    | 1.01        |
| _max_obs        | 1.69        |
| _mean_act       | 0.00326099  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 0.557       |
| _mean_obs       | 0.0287      |
| _min_adv        | -4.22       |
| _min_discrew    | -0.0334     |
| _min_obs        | -1.34       |
| _std_act        | 0.457759    |
| _std_adv        | 1           |
| _std_discrew    | 0.0436      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.74        |
| ExplainedVarOld | 0.741       |
| KL              | 0.00319741  |
| Phi_loss        | 69.4233     |
| PolicyEntropy   | 4.03823     |
| PolicyLoss      | -0.00740813 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0113      |
| _MeanReward     | 732         |
| _lr_multiplier  | 1           |
| _max_act        | 3.31015     |
| _max_adv        | 3.26        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.66        |
| _mean_act       | 0.00468878  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.598       |
| _mean_obs       | 0.0236      |
| _min_adv        | -5.21       |
| _min_discrew    | -0.00918    |
| _min_obs        | -1.26       |
| _std_act        | 0.459968    |
| _std_adv        | 1           |
| _std_discrew    | 0.0599      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.717        |
| ExplainedVarOld | 0.703        |
| KL              | 0.00309587   |
| Phi_loss        | 67.0861      |
| PolicyEntropy   | 3.9983       |
| PolicyLoss      | -0.000181975 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0174       |
| _MeanReward     | 771          |
| _lr_multiplier  | 1            |
| _max_act        | 2.99886      |
| _max_adv        | 3.99         |
| _max_discrew    | 1.08         |
| _max_obs        | 1.41         |
| _mean_act       | 0.00151797   |
| _mean_adv       | -4.69e-17    |
| _mean_discrew   | 0.625        |
| _mean_obs       | 0.0268       |
| _min_adv        | -3.43        |
| _min_discrew    | -0.0013      |
| _min_obs        | -1.29        |
| _std_act        | 0.461702     |
| _std_adv        | 1            |
| _std_discrew    | 0.0519       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.79       |
| ExplainedVarOld | 0.78       |
| KL              | 0.00266059 |
| Phi_loss        | 69.479     |
| PolicyEntropy   | 3.99608    |
| PolicyLoss      | -0.008492  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 570        |
| _lr_multiplier  | 1          |
| _max_act        | 3.1396     |
| _max_adv        | 2.42       |
| _max_discrew    | 1.09       |
| _max_obs        | 1.61       |
| _mean_act       | -0.0578138 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 0.462      |
| _mean_obs       | 0.0202     |
| _min_adv        | -9.91      |
| _min_discrew    | -0.965     |
| _min_obs        | -1.24      |
| _std_act        | 0.534786   |
| _std_adv        | 1          |
| _std_discrew    | 0.203      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.766       |
| KL              | 0.0049256   |
| Phi_loss        | 41.9774     |
| PolicyEntropy   | 3.986       |
| PolicyLoss      | -0.00216056 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0244      |
| _MeanReward     | 811         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03169     |
| _max_adv        | 3.88        |
| _max_discrew    | 1.23        |
| _max_obs        | 1.66        |
| _mean_act       | 0.00416086  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.664       |
| _mean_obs       | 0.0269      |
| _min_adv        | -3.16       |
| _min_discrew    | -0.00653    |
| _min_obs        | -1.23       |
| _std_act        | 0.463573    |
| _std_adv        | 1           |
| _std_discrew    | 0.066       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.733       |
| ExplainedVarOld | 0.723       |
| KL              | 0.00266731  |
| Phi_loss        | 64.8399     |
| PolicyEntropy   | 3.98188     |
| PolicyLoss      | -0.00760102 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0189      |
| _MeanReward     | 802         |
| _lr_multiplier  | 1           |
| _max_act        | 3.22936     |
| _max_adv        | 4.72        |
| _max_discrew    | 1.08        |
| _max_obs        | 1.42        |
| _mean_act       | 0.00687272  |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.642       |
| _mean_obs       | 0.0273      |
| _min_adv        | -4.07       |
| _min_discrew    | -0.00252    |
| _min_obs        | -1.34       |
| _std_act        | 0.467433    |
| _std_adv        | 1           |
| _std_discrew    | 0.0486      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.774      |
| ExplainedVarOld | 0.74       |
| KL              | 0.00303937 |
| Phi_loss        | 62.9911    |
| PolicyEntropy   | 3.94313    |
| PolicyLoss      | 0.00152222 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0112     |
| _MeanReward     | 843        |
| _lr_multiplier  | 1          |
| _max_act        | 2.96509    |
| _max_adv        | 3.46       |
| _max_discrew    | 1.23       |
| _max_obs        | 1.65       |
| _mean_act       | 0.00725229 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.693      |
| _mean_obs       | 0.027      |
| _min_adv        | -4.04      |
| _min_discrew    | -0.0111    |
| _min_obs        | -1.26      |
| _std_act        | 0.46706    |
| _std_adv        | 1          |
| _std_discrew    | 0.067      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.764       |
| ExplainedVarOld | 0.757       |
| KL              | 0.00355908  |
| Phi_loss        | 74.6057     |
| PolicyEntropy   | 3.92536     |
| PolicyLoss      | -0.00481183 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0161      |
| _MeanReward     | 800         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01976     |
| _max_adv        | 2.88        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.6         |
| _mean_act       | -0.00201385 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.653       |
| _mean_obs       | 0.0278      |
| _min_adv        | -8.56       |
| _min_discrew    | -0.551      |
| _min_obs        | -1.25       |
| _std_act        | 0.492368    |
| _std_adv        | 1           |
| _std_discrew    | 0.0774      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.741      |
| ExplainedVarOld | 0.704      |
| KL              | 0.00391858 |
| Phi_loss        | 65.3317    |
| PolicyEntropy   | 3.91156    |
| PolicyLoss      | -0.0106354 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0202     |
| _MeanReward     | 858        |
| _lr_multiplier  | 1          |
| _max_act        | 3.11073    |
| _max_adv        | 4.08       |
| _max_discrew    | 1.42       |
| _max_obs        | 1.48       |
| _mean_act       | 0.0108021  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.706      |
| _mean_obs       | 0.0279     |
| _min_adv        | -3.45      |
| _min_discrew    | -0.00228   |
| _min_obs        | -1.33      |
| _std_act        | 0.475895   |
| _std_adv        | 1          |
| _std_discrew    | 0.0779     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.673       |
| ExplainedVarOld | 0.664       |
| KL              | 0.00333411  |
| Phi_loss        | 71.6059     |
| PolicyEntropy   | 3.88533     |
| PolicyLoss      | -0.00170653 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0256      |
| _MeanReward     | 943         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0247      |
| _max_adv        | 3.17        |
| _max_discrew    | 1.29        |
| _max_obs        | 1.62        |
| _mean_act       | 0.0136203   |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 0.771       |
| _mean_obs       | 0.0294      |
| _min_adv        | -3.31       |
| _min_discrew    | -0.000472   |
| _min_obs        | -1.26       |
| _std_act        | 0.479225    |
| _std_adv        | 1           |
| _std_discrew    | 0.0832      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.826      |
| ExplainedVarOld | 0.781      |
| KL              | 0.00313909 |
| Phi_loss        | 73.5067    |
| PolicyEntropy   | 3.8577     |
| PolicyLoss      | 0.00227389 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0149     |
| _MeanReward     | 903        |
| _lr_multiplier  | 1          |
| _max_act        | 3.33693    |
| _max_adv        | 3.34       |
| _max_discrew    | 1.19       |
| _max_obs        | 1.6        |
| _mean_act       | 0.0113963  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.741      |
| _mean_obs       | 0.0279     |
| _min_adv        | -3.49      |
| _min_discrew    | 0.00206    |
| _min_obs        | -1.34      |
| _std_act        | 0.473301   |
| _std_adv        | 1          |
| _std_discrew    | 0.0641     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.755        |
| ExplainedVarOld | 0.746        |
| KL              | 0.00305252   |
| Phi_loss        | 74.5373      |
| PolicyEntropy   | 3.8372       |
| PolicyLoss      | -0.000773234 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0158       |
| _MeanReward     | 950          |
| _lr_multiplier  | 1            |
| _max_act        | 3.26501      |
| _max_adv        | 4.19         |
| _max_discrew    | 1.3          |
| _max_obs        | 1.52         |
| _mean_act       | 0.0146763    |
| _mean_adv       | -2.84e-18    |
| _mean_discrew   | 0.781        |
| _mean_obs       | 0.0283       |
| _min_adv        | -4.36        |
| _min_discrew    | 0.000515     |
| _min_obs        | -1.39        |
| _std_act        | 0.469301     |
| _std_adv        | 1            |
| _std_discrew    | 0.0759       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.816       |
| ExplainedVarOld | 0.809       |
| KL              | 0.00371208  |
| Phi_loss        | 77.5911     |
| PolicyEntropy   | 3.83083     |
| PolicyLoss      | -0.00887988 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 979         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90825     |
| _max_adv        | 3.57        |
| _max_discrew    | 1.5         |
| _max_obs        | 1.54        |
| _mean_act       | 0.0181859   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.796       |
| _mean_obs       | 0.0307      |
| _min_adv        | -3.5        |
| _min_discrew    | -0.00156    |
| _min_obs        | -1.29       |
| _std_act        | 0.47996     |
| _std_adv        | 1           |
| _std_discrew    | 0.0881      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.821       |
| ExplainedVarOld | 0.788       |
| KL              | 0.00368215  |
| Phi_loss        | 74.7648     |
| PolicyEntropy   | 3.79155     |
| PolicyLoss      | -0.00256843 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0158      |
| _MeanReward     | 963         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14384     |
| _max_adv        | 3.12        |
| _max_discrew    | 1.36        |
| _max_obs        | 1.65        |
| _mean_act       | 0.0118023   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.795       |
| _mean_obs       | 0.0327      |
| _min_adv        | -3.51       |
| _min_discrew    | -0.00631    |
| _min_obs        | -1.35       |
| _std_act        | 0.483617    |
| _std_adv        | 1           |
| _std_discrew    | 0.0798      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.803      |
| ExplainedVarOld | 0.794      |
| KL              | 0.00358928 |
| Phi_loss        | 75.8363    |
| PolicyEntropy   | 3.77214    |
| PolicyLoss      | -0.0096079 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0158     |
| _MeanReward     | 1e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 3.48072    |
| _max_adv        | 3.34       |
| _max_discrew    | 1.3        |
| _max_obs        | 1.59       |
| _mean_act       | 0.0128847  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.822      |
| _mean_obs       | 0.0325     |
| _min_adv        | -3.42      |
| _min_discrew    | -0.00948   |
| _min_obs        | -1.22      |
| _std_act        | 0.487111   |
| _std_adv        | 1          |
| _std_discrew    | 0.0813     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.834        |
| ExplainedVarOld | 0.812        |
| KL              | 0.0032299    |
| Phi_loss        | 75.5071      |
| PolicyEntropy   | 3.74115      |
| PolicyLoss      | -0.000646862 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0135       |
| _MeanReward     | 1.02e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.02867      |
| _max_adv        | 3.81         |
| _max_discrew    | 1.47         |
| _max_obs        | 1.66         |
| _mean_act       | 0.0124751    |
| _mean_adv       | -1.71e-17    |
| _mean_discrew   | 0.846        |
| _mean_obs       | 0.028        |
| _min_adv        | -4.17        |
| _min_discrew    | 0.000961     |
| _min_obs        | -1.29        |
| _std_act        | 0.476527     |
| _std_adv        | 1            |
| _std_discrew    | 0.0804       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.815       |
| ExplainedVarOld | 0.804       |
| KL              | 0.00463073  |
| Phi_loss        | 80.1834     |
| PolicyEntropy   | 3.70556     |
| PolicyLoss      | -0.00611482 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0149      |
| _MeanReward     | 1.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12001     |
| _max_adv        | 3.89        |
| _max_discrew    | 1.44        |
| _max_obs        | 1.67        |
| _mean_act       | 0.0190842   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.917       |
| _mean_obs       | 0.0309      |
| _min_adv        | -3.5        |
| _min_discrew    | 0.00169     |
| _min_obs        | -1.32       |
| _std_act        | 0.486829    |
| _std_adv        | 1           |
| _std_discrew    | 0.0795      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.824        |
| ExplainedVarOld | 0.815        |
| KL              | 0.00344052   |
| Phi_loss        | 78.2896      |
| PolicyEntropy   | 3.66903      |
| PolicyLoss      | -0.000160926 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0148       |
| _MeanReward     | 1.05e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.07291      |
| _max_adv        | 3.58         |
| _max_discrew    | 1.57         |
| _max_obs        | 1.48         |
| _mean_act       | 0.0178174    |
| _mean_adv       | 3.69e-17     |
| _mean_discrew   | 0.859        |
| _mean_obs       | 0.0289       |
| _min_adv        | -3.87        |
| _min_discrew    | -0.0012      |
| _min_obs        | -1.2         |
| _std_act        | 0.486138     |
| _std_adv        | 1            |
| _std_discrew    | 0.092        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.769       |
| ExplainedVarOld | 0.759       |
| KL              | 0.00283043  |
| Phi_loss        | 84.8451     |
| PolicyEntropy   | 3.65134     |
| PolicyLoss      | -0.00505582 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0219      |
| _MeanReward     | 1.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12825     |
| _max_adv        | 3.74        |
| _max_discrew    | 1.44        |
| _max_obs        | 1.55        |
| _mean_act       | 0.0216942   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.92        |
| _mean_obs       | 0.0322      |
| _min_adv        | -3.71       |
| _min_discrew    | 0.004       |
| _min_obs        | -1.26       |
| _std_act        | 0.489721    |
| _std_adv        | 1           |
| _std_discrew    | 0.106       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.809       |
| ExplainedVarOld | 0.793       |
| KL              | 0.00318199  |
| Phi_loss        | 80.0625     |
| PolicyEntropy   | 3.59928     |
| PolicyLoss      | -0.00300364 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0212      |
| _MeanReward     | 1.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.5947      |
| _max_adv        | 3.2         |
| _max_discrew    | 1.51        |
| _max_obs        | 1.57        |
| _mean_act       | 0.0184904   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.889       |
| _mean_obs       | 0.0316      |
| _min_adv        | -3.53       |
| _min_discrew    | -0.00458    |
| _min_obs        | -1.27       |
| _std_act        | 0.489929    |
| _std_adv        | 1           |
| _std_discrew    | 0.112       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.844      |
| ExplainedVarOld | 0.828      |
| KL              | 0.00319786 |
| Phi_loss        | 85.1172    |
| PolicyEntropy   | 3.58042    |
| PolicyLoss      | -0.0147064 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0175     |
| _MeanReward     | 1.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.39183    |
| _max_adv        | 3.84       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.48       |
| _mean_act       | 0.0259524  |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 0.983      |
| _mean_obs       | 0.0302     |
| _min_adv        | -3.58      |
| _min_discrew    | -0.00765   |
| _min_obs        | -1.53      |
| _std_act        | 0.495924   |
| _std_adv        | 1          |
| _std_discrew    | 0.0995     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.874       |
| ExplainedVarOld | 0.86        |
| KL              | 0.00283076  |
| Phi_loss        | 84.649      |
| PolicyEntropy   | 3.55503     |
| PolicyLoss      | -0.00730429 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0136      |
| _MeanReward     | 1.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.26339     |
| _max_adv        | 4.31        |
| _max_discrew    | 1.7         |
| _max_obs        | 1.5         |
| _mean_act       | 0.0255305   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.94        |
| _mean_obs       | 0.0328      |
| _min_adv        | -4.26       |
| _min_discrew    | 0.00299     |
| _min_obs        | -1.25       |
| _std_act        | 0.499509    |
| _std_adv        | 1           |
| _std_discrew    | 0.116       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.785      |
| ExplainedVarOld | 0.779      |
| KL              | 0.00284999 |
| Phi_loss        | 90.0243    |
| PolicyEntropy   | 3.52683    |
| PolicyLoss      | -0.011471  |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 1.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.09313    |
| _max_adv        | 3.3        |
| _max_discrew    | 1.56       |
| _max_obs        | 1.49       |
| _mean_act       | 0.0236073  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.976      |
| _mean_obs       | 0.0347     |
| _min_adv        | -3.61      |
| _min_discrew    | 0.000957   |
| _min_obs        | -1.3       |
| _std_act        | 0.499968   |
| _std_adv        | 1          |
| _std_discrew    | 0.114      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.857      |
| ExplainedVarOld | 0.853      |
| KL              | 0.00307908 |
| Phi_loss        | 84.7349    |
| PolicyEntropy   | 3.51574    |
| PolicyLoss      | -0.0129675 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0165     |
| _MeanReward     | 1.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08107    |
| _max_adv        | 3.15       |
| _max_discrew    | 1.54       |
| _max_obs        | 1.81       |
| _mean_act       | 0.023018   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.999      |
| _mean_obs       | 0.0336     |
| _min_adv        | -3.79      |
| _min_discrew    | -0.0068    |
| _min_obs        | -1.24      |
| _std_act        | 0.505829   |
| _std_adv        | 1          |
| _std_discrew    | 0.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.851      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00309814 |
| Phi_loss        | 93.4733    |
| PolicyEntropy   | 3.50182    |
| PolicyLoss      | -0.0209518 |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 1.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.50284    |
| _max_adv        | 3.35       |
| _max_discrew    | 1.62       |
| _max_obs        | 1.64       |
| _mean_act       | 0.0267771  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0361     |
| _min_adv        | -3.85      |
| _min_discrew    | -0.0017    |
| _min_obs        | -1.43      |
| _std_act        | 0.50999    |
| _std_adv        | 1          |
| _std_discrew    | 0.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.81       |
| ExplainedVarOld | 0.789      |
| KL              | 0.00334564 |
| Phi_loss        | 85.7167    |
| PolicyEntropy   | 3.48433    |
| PolicyLoss      | 0.00133709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 1.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.82749    |
| _max_adv        | 3.13       |
| _max_discrew    | 1.64       |
| _max_obs        | 1.58       |
| _mean_act       | 0.0259168  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 0.997      |
| _mean_obs       | 0.0341     |
| _min_adv        | -4.1       |
| _min_discrew    | -0.00122   |
| _min_obs        | -1.37      |
| _std_act        | 0.502345   |
| _std_adv        | 1          |
| _std_discrew    | 0.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.842       |
| ExplainedVarOld | 0.824       |
| KL              | 0.004593    |
| Phi_loss        | 91.8125     |
| PolicyEntropy   | 3.44702     |
| PolicyLoss      | -0.00506197 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0225      |
| _MeanReward     | 1.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09197     |
| _max_adv        | 3.51        |
| _max_discrew    | 1.76        |
| _max_obs        | 1.56        |
| _mean_act       | 0.0328452   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 1.12        |
| _mean_obs       | 0.0354      |
| _min_adv        | -4.37       |
| _min_discrew    | 0.00168     |
| _min_obs        | -1.47       |
| _std_act        | 0.507455    |
| _std_adv        | 1           |
| _std_discrew    | 0.152       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.865       |
| ExplainedVarOld | 0.854       |
| KL              | 0.00298548  |
| Phi_loss        | 99.5017     |
| PolicyEntropy   | 3.41941     |
| PolicyLoss      | -0.00684318 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 1.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88463     |
| _max_adv        | 3           |
| _max_discrew    | 1.65        |
| _max_obs        | 1.47        |
| _mean_act       | 0.0322749   |
| _mean_adv       | 4.12e-17    |
| _mean_discrew   | 1.13        |
| _mean_obs       | 0.034       |
| _min_adv        | -3.88       |
| _min_discrew    | -0.00637    |
| _min_obs        | -1.34       |
| _std_act        | 0.503825    |
| _std_adv        | 1           |
| _std_discrew    | 0.149       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.857       |
| ExplainedVarOld | 0.837       |
| KL              | 0.0044156   |
| Phi_loss        | 88.3505     |
| PolicyEntropy   | 3.40788     |
| PolicyLoss      | -0.00853057 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0214      |
| _MeanReward     | 1.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.97825     |
| _max_adv        | 3.18        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.61        |
| _mean_act       | 0.0295623   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.13        |
| _mean_obs       | 0.0356      |
| _min_adv        | -3.61       |
| _min_discrew    | -0.00241    |
| _min_obs        | -1.29       |
| _std_act        | 0.509573    |
| _std_adv        | 1           |
| _std_discrew    | 0.164       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.842      |
| ExplainedVarOld | 0.838      |
| KL              | 0.00354366 |
| Phi_loss        | 100.043    |
| PolicyEntropy   | 3.39611    |
| PolicyLoss      | -0.0121176 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0258     |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17       |
| _max_adv        | 3.97       |
| _max_discrew    | 1.73       |
| _max_obs        | 1.67       |
| _mean_act       | 0.0301571  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0362     |
| _min_adv        | -3.66      |
| _min_discrew    | 6.65e-05   |
| _min_obs        | -1.25      |
| _std_act        | 0.521592   |
| _std_adv        | 1          |
| _std_discrew    | 0.152      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00269998 |
| Phi_loss        | 97.5437    |
| PolicyEntropy   | 3.37788    |
| PolicyLoss      | 0.00391279 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0174     |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.12481    |
| _max_adv        | 3.19       |
| _max_discrew    | 1.92       |
| _max_obs        | 1.51       |
| _mean_act       | 0.0302305  |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0364     |
| _min_adv        | -3.79      |
| _min_discrew    | -0.00684   |
| _min_obs        | -1.24      |
| _std_act        | 0.522781   |
| _std_adv        | 1          |
| _std_discrew    | 0.173      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.85        |
| ExplainedVarOld | 0.845       |
| KL              | 0.00332479  |
| Phi_loss        | 101.155     |
| PolicyEntropy   | 3.35426     |
| PolicyLoss      | -0.00580721 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0261      |
| _MeanReward     | 1.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93402     |
| _max_adv        | 3.03        |
| _max_discrew    | 1.89        |
| _max_obs        | 1.36        |
| _mean_act       | 0.0313195   |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 1.17        |
| _mean_obs       | 0.0355      |
| _min_adv        | -3.77       |
| _min_discrew    | -0.00093    |
| _min_obs        | -1.3        |
| _std_act        | 0.516327    |
| _std_adv        | 1           |
| _std_discrew    | 0.166       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.863      |
| ExplainedVarOld | 0.858      |
| KL              | 0.00345615 |
| Phi_loss        | 100.509    |
| PolicyEntropy   | 3.33876    |
| PolicyLoss      | -0.0145311 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0228     |
| _MeanReward     | 1.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9165     |
| _max_adv        | 3.1        |
| _max_discrew    | 1.86       |
| _max_obs        | 1.42       |
| _mean_act       | 0.0338762  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.18       |
| _mean_obs       | 0.0356     |
| _min_adv        | -3.25      |
| _min_discrew    | -0.00183   |
| _min_obs        | -1.41      |
| _std_act        | 0.512737   |
| _std_adv        | 1          |
| _std_discrew    | 0.149      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.87       |
| ExplainedVarOld | 0.86       |
| KL              | 0.00333357 |
| Phi_loss        | 102.85     |
| PolicyEntropy   | 3.31033    |
| PolicyLoss      | -0.0153698 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 1.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.64247    |
| _max_adv        | 2.98       |
| _max_discrew    | 1.85       |
| _max_obs        | 1.56       |
| _mean_act       | 0.0333985  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.000242  |
| _min_obs        | -1.41      |
| _std_act        | 0.527357   |
| _std_adv        | 1          |
| _std_discrew    | 0.189      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.852        |
| ExplainedVarOld | 0.842        |
| KL              | 0.00397924   |
| Phi_loss        | 99.4376      |
| PolicyEntropy   | 3.29525      |
| PolicyLoss      | -0.000195952 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0279       |
| _MeanReward     | 1.44e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.88409      |
| _max_adv        | 2.87         |
| _max_discrew    | 2            |
| _max_obs        | 1.43         |
| _mean_act       | 0.0201046    |
| _mean_adv       | -3.98e-17    |
| _mean_discrew   | 1.18         |
| _mean_obs       | 0.0365       |
| _min_adv        | -8.41        |
| _min_discrew    | -0.582       |
| _min_obs        | -1.42        |
| _std_act        | 0.5415       |
| _std_adv        | 1            |
| _std_discrew    | 0.237        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.823      |
| ExplainedVarOld | 0.807      |
| KL              | 0.00528711 |
| Phi_loss        | 92.4035    |
| PolicyEntropy   | 3.28849    |
| PolicyLoss      | -0.0290604 |
| Steps           | 10000      |
| VarFuncLoss     | 0.042      |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.43099    |
| _max_adv        | 3.76       |
| _max_discrew    | 1.82       |
| _max_obs        | 1.61       |
| _mean_act       | 0.031853   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.0368     |
| _min_adv        | -3.89      |
| _min_discrew    | 0.00245    |
| _min_obs        | -1.29      |
| _std_act        | 0.533695   |
| _std_adv        | 1          |
| _std_discrew    | 0.166      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.829      |
| ExplainedVarOld | 0.818      |
| KL              | 0.00396527 |
| Phi_loss        | 106.401    |
| PolicyEntropy   | 3.26719    |
| PolicyLoss      | 0.00433878 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.29634    |
| _max_adv        | 3.73       |
| _max_discrew    | 1.97       |
| _max_obs        | 1.47       |
| _mean_act       | 0.0369018  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0369     |
| _min_adv        | -4.74      |
| _min_discrew    | 0.00119    |
| _min_obs        | -1.43      |
| _std_act        | 0.528281   |
| _std_adv        | 1          |
| _std_discrew    | 0.182      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.892       |
| ExplainedVarOld | 0.876       |
| KL              | 0.00364381  |
| Phi_loss        | 96.9209     |
| PolicyEntropy   | 3.23431     |
| PolicyLoss      | -0.00482683 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0215      |
| _MeanReward     | 1.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9451      |
| _max_adv        | 3.25        |
| _max_discrew    | 2.02        |
| _max_obs        | 1.58        |
| _mean_act       | 0.0393597   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.3         |
| _mean_obs       | 0.0376      |
| _min_adv        | -4.73       |
| _min_discrew    | -0.00124    |
| _min_obs        | -1.26       |
| _std_act        | 0.531535    |
| _std_adv        | 1           |
| _std_discrew    | 0.191       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.878       |
| ExplainedVarOld | 0.873       |
| KL              | 0.00356475  |
| Phi_loss        | 114.815     |
| PolicyEntropy   | 3.21704     |
| PolicyLoss      | -0.00901551 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0232      |
| _MeanReward     | 1.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01914     |
| _max_adv        | 3.12        |
| _max_discrew    | 2.09        |
| _max_obs        | 1.51        |
| _mean_act       | 0.0399788   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.3         |
| _mean_obs       | 0.0387      |
| _min_adv        | -4.88       |
| _min_discrew    | 0.00445     |
| _min_obs        | -1.38       |
| _std_act        | 0.528876    |
| _std_adv        | 1           |
| _std_discrew    | 0.203       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.862      |
| ExplainedVarOld | 0.852      |
| KL              | 0.00341183 |
| Phi_loss        | 108.137    |
| PolicyEntropy   | 3.20225    |
| PolicyLoss      | -0.0171967 |
| Steps           | 10000      |
| VarFuncLoss     | 0.028      |
| _MeanReward     | 1.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.33779    |
| _max_adv        | 3.21       |
| _max_discrew    | 2.13       |
| _max_obs        | 1.45       |
| _mean_act       | 0.0403681  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0384     |
| _min_adv        | -3.97      |
| _min_discrew    | 0.00465    |
| _min_obs        | -1.25      |
| _std_act        | 0.537777   |
| _std_adv        | 1          |
| _std_discrew    | 0.202      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.838      |
| ExplainedVarOld | 0.833      |
| KL              | 0.00391654 |
| Phi_loss        | 112.469    |
| PolicyEntropy   | 3.18106    |
| PolicyLoss      | -0.0126372 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0332     |
| _MeanReward     | 1.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.18886    |
| _max_adv        | 2.51       |
| _max_discrew    | 1.94       |
| _max_obs        | 1.6        |
| _mean_act       | -0.0105722 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.0339     |
| _min_adv        | -10.6      |
| _min_discrew    | -0.941     |
| _min_obs        | -1.39      |
| _std_act        | 0.611302   |
| _std_adv        | 1          |
| _std_discrew    | 0.432      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.788       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00346688  |
| Phi_loss        | 83.2771     |
| PolicyEntropy   | 3.18152     |
| PolicyLoss      | -0.00298088 |
| Steps           | 10000       |
| VarFuncLoss     | 0.093       |
| _MeanReward     | 1.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.48897     |
| _max_adv        | 4.04        |
| _max_discrew    | 2.17        |
| _max_obs        | 1.44        |
| _mean_act       | 0.0371331   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 1.4         |
| _mean_obs       | 0.0395      |
| _min_adv        | -4.1        |
| _min_discrew    | 0.00223     |
| _min_obs        | -1.35       |
| _std_act        | 0.531225    |
| _std_adv        | 1           |
| _std_discrew    | 0.255       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.875        |
| ExplainedVarOld | 0.869        |
| KL              | 0.00396436   |
| Phi_loss        | 108.161      |
| PolicyEntropy   | 3.14315      |
| PolicyLoss      | -0.000440564 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0353       |
| _MeanReward     | 1.71e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.20002      |
| _max_adv        | 7.23         |
| _max_discrew    | 2.03         |
| _max_obs        | 1.49         |
| _mean_act       | 0.0490739    |
| _mean_adv       | -2.56e-17    |
| _mean_discrew   | 1.4          |
| _mean_obs       | 0.0402       |
| _min_adv        | -4.74        |
| _min_discrew    | 0.00498      |
| _min_obs        | -1.23        |
| _std_act        | 0.542368     |
| _std_adv        | 1            |
| _std_discrew    | 0.221        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.897       |
| ExplainedVarOld | 0.881       |
| KL              | 0.00303404  |
| Phi_loss        | 110.444     |
| PolicyEntropy   | 3.12861     |
| PolicyLoss      | -0.00316305 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0228      |
| _MeanReward     | 1.74e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01837     |
| _max_adv        | 2.96        |
| _max_discrew    | 2.32        |
| _max_obs        | 1.38        |
| _mean_act       | 0.0400488   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 1.44        |
| _mean_obs       | 0.0399      |
| _min_adv        | -4.16       |
| _min_discrew    | -0.00279    |
| _min_obs        | -1.36       |
| _std_act        | 0.540878    |
| _std_adv        | 1           |
| _std_discrew    | 0.236       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.873      |
| KL              | 0.0034286  |
| Phi_loss        | 115.024    |
| PolicyEntropy   | 3.10567    |
| PolicyLoss      | -0.0108704 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 1.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.12603    |
| _max_adv        | 3.57       |
| _max_discrew    | 2.14       |
| _max_obs        | 1.64       |
| _mean_act       | 0.0496525  |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 1.5        |
| _mean_obs       | 0.0401     |
| _min_adv        | -4.01      |
| _min_discrew    | -0.00233   |
| _min_obs        | -1.29      |
| _std_act        | 0.533041   |
| _std_adv        | 1          |
| _std_discrew    | 0.232      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.895      |
| ExplainedVarOld | 0.887      |
| KL              | 0.00260386 |
| Phi_loss        | 116.105    |
| PolicyEntropy   | 3.08965    |
| PolicyLoss      | 0.0017157  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 1.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14935    |
| _max_adv        | 3.37       |
| _max_discrew    | 2.3        |
| _max_obs        | 1.47       |
| _mean_act       | 0.0420734  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 1.45       |
| _mean_obs       | 0.0388     |
| _min_adv        | -4.36      |
| _min_discrew    | -0.00399   |
| _min_obs        | -1.23      |
| _std_act        | 0.54152    |
| _std_adv        | 1          |
| _std_discrew    | 0.204      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00396727 |
| Phi_loss        | 112.727    |
| PolicyEntropy   | 3.03752    |
| PolicyLoss      | 0.00311604 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0213     |
| _MeanReward     | 1.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.16616    |
| _max_adv        | 3.14       |
| _max_discrew    | 2.12       |
| _max_obs        | 1.72       |
| _mean_act       | 0.045224   |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.5        |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.72      |
| _min_discrew    | 0.00525    |
| _min_obs        | -1.26      |
| _std_act        | 0.543286   |
| _std_adv        | 1          |
| _std_discrew    | 0.245      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.894      |
| ExplainedVarOld | 0.89       |
| KL              | 0.00374145 |
| Phi_loss        | 123.5      |
| PolicyEntropy   | 3.00032    |
| PolicyLoss      | -0.0094748 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0264     |
| _MeanReward     | 1.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91252    |
| _max_adv        | 3.28       |
| _max_discrew    | 2.24       |
| _max_obs        | 1.41       |
| _mean_act       | 0.0466353  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.59       |
| _mean_obs       | 0.0407     |
| _min_adv        | -4.42      |
| _min_discrew    | 0.000293   |
| _min_obs        | -1.31      |
| _std_act        | 0.539695   |
| _std_adv        | 1          |
| _std_discrew    | 0.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.919      |
| KL              | 0.00321126 |
| Phi_loss        | 127.366    |
| PolicyEntropy   | 2.97634    |
| PolicyLoss      | 0.0109131  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 1.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97775    |
| _max_adv        | 2.59       |
| _max_discrew    | 2.34       |
| _max_obs        | 1.51       |
| _mean_act       | 0.0504617  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.57       |
| _mean_obs       | 0.0407     |
| _min_adv        | -4.5       |
| _min_discrew    | 0.00306    |
| _min_obs        | -1.25      |
| _std_act        | 0.535866   |
| _std_adv        | 1          |
| _std_discrew    | 0.259      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.9        |
| KL              | 0.00338572 |
| Phi_loss        | 119.045    |
| PolicyEntropy   | 2.95054    |
| PolicyLoss      | -0.0136336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 2e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 3.18374    |
| _max_adv        | 3.46       |
| _max_discrew    | 2.39       |
| _max_obs        | 1.41       |
| _mean_act       | 0.0485402  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.64       |
| _mean_obs       | 0.0427     |
| _min_adv        | -4.39      |
| _min_discrew    | 0.002      |
| _min_obs        | -1.31      |
| _std_act        | 0.542275   |
| _std_adv        | 1          |
| _std_discrew    | 0.268      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.924      |
| KL              | 0.00370609 |
| Phi_loss        | 139.371    |
| PolicyEntropy   | 2.89411    |
| PolicyLoss      | 0.010145   |
| Steps           | 10000      |
| VarFuncLoss     | 0.021      |
| _MeanReward     | 1.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.20926    |
| _max_adv        | 2.84       |
| _max_discrew    | 2.37       |
| _max_obs        | 1.35       |
| _mean_act       | 0.0479908  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.63       |
| _mean_obs       | 0.0406     |
| _min_adv        | -4.71      |
| _min_discrew    | 0.00363    |
| _min_obs        | -1.31      |
| _std_act        | 0.537872   |
| _std_adv        | 1          |
| _std_discrew    | 0.262      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.917      |
| ExplainedVarOld | 0.908      |
| KL              | 0.00405485 |
| Phi_loss        | 130.763    |
| PolicyEntropy   | 2.85424    |
| PolicyLoss      | -0.0170985 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0219     |
| _MeanReward     | 1.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.12485    |
| _max_adv        | 2.39       |
| _max_discrew    | 2.45       |
| _max_obs        | 1.4        |
| _mean_act       | 0.0491449  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.62       |
| _mean_obs       | 0.041      |
| _min_adv        | -4.68      |
| _min_discrew    | 0.00419    |
| _min_obs        | -1.34      |
| _std_act        | 0.544026   |
| _std_adv        | 1          |
| _std_discrew    | 0.297      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.879       |
| KL              | 0.0031891   |
| Phi_loss        | 132.591     |
| PolicyEntropy   | 2.83627     |
| PolicyLoss      | 0.0091158   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0345      |
| _MeanReward     | 1.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92886     |
| _max_adv        | 2.03        |
| _max_discrew    | 2.29        |
| _max_obs        | 1.48        |
| _mean_act       | -0.00685068 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.46        |
| _mean_obs       | 0.0356      |
| _min_adv        | -13.4       |
| _min_discrew    | -0.993      |
| _min_obs        | -1.47       |
| _std_act        | 0.624035    |
| _std_adv        | 1           |
| _std_discrew    | 0.697       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.881       |
| ExplainedVarOld | 0.854       |
| KL              | 0.0046399   |
| Phi_loss        | 94.1171     |
| PolicyEntropy   | 2.83387     |
| PolicyLoss      | -0.00263651 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0831      |
| _MeanReward     | 2.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.0878      |
| _max_adv        | 3.65        |
| _max_discrew    | 2.5         |
| _max_obs        | 1.48        |
| _mean_act       | 0.0541781   |
| _mean_adv       | 7.96e-17    |
| _mean_discrew   | 1.72        |
| _mean_obs       | 0.0407      |
| _min_adv        | -4.84       |
| _min_discrew    | 0.00279     |
| _min_obs        | -1.47       |
| _std_act        | 0.540946    |
| _std_adv        | 1           |
| _std_discrew    | 0.303       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.882       |
| KL              | 0.00442274  |
| Phi_loss        | 120.208     |
| PolicyEntropy   | 2.79833     |
| PolicyLoss      | -0.00481451 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0294      |
| _MeanReward     | 2.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.1486      |
| _max_adv        | 12.9        |
| _max_discrew    | 2.4         |
| _max_obs        | 1.49        |
| _mean_act       | 0.0516729   |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 1.71        |
| _mean_obs       | 0.0404      |
| _min_adv        | -4.63       |
| _min_discrew    | 0.00471     |
| _min_obs        | -1.52       |
| _std_act        | 0.536942    |
| _std_adv        | 1           |
| _std_discrew    | 0.316       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.925      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00615288 |
| Phi_loss        | 143.087    |
| PolicyEntropy   | 2.7674     |
| PolicyLoss      | -0.014826  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0237     |
| _MeanReward     | 2.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.32508    |
| _max_adv        | 3.55       |
| _max_discrew    | 2.58       |
| _max_obs        | 1.5        |
| _mean_act       | 0.0535539  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.72       |
| _mean_obs       | 0.0413     |
| _min_adv        | -4.07      |
| _min_discrew    | 0.00217    |
| _min_obs        | -1.4       |
| _std_act        | 0.539533   |
| _std_adv        | 1          |
| _std_discrew    | 0.312      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.921      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00227912 |
| Phi_loss        | 149.759    |
| PolicyEntropy   | 2.75823    |
| PolicyLoss      | -0.0313394 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0246     |
| _MeanReward     | 2.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00922    |
| _max_adv        | 3.39       |
| _max_discrew    | 2.47       |
| _max_obs        | 1.46       |
| _mean_act       | 0.0258496  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.65       |
| _mean_obs       | 0.0395     |
| _min_adv        | -13        |
| _min_discrew    | -0.826     |
| _min_obs        | -1.37      |
| _std_act        | 0.603621   |
| _std_adv        | 1          |
| _std_discrew    | 0.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.833       |
| KL              | 0.00200645  |
| Phi_loss        | 109.322     |
| PolicyEntropy   | 2.73936     |
| PolicyLoss      | -0.00301706 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0806      |
| _MeanReward     | 2.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.01425     |
| _max_adv        | 13.1        |
| _max_discrew    | 2.6         |
| _max_obs        | 1.46        |
| _mean_act       | 0.0552057   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.82        |
| _mean_obs       | 0.0424      |
| _min_adv        | -4.86       |
| _min_discrew    | 0.00801     |
| _min_obs        | -1.29       |
| _std_act        | 0.555226    |
| _std_adv        | 1           |
| _std_discrew    | 0.342       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.875      |
| ExplainedVarOld | 0.871      |
| KL              | 0.00218227 |
| Phi_loss        | 143.663    |
| PolicyEntropy   | 2.71219    |
| PolicyLoss      | 0.00245691 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0448     |
| _MeanReward     | 2.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.11002    |
| _max_adv        | 5.78       |
| _max_discrew    | 2.43       |
| _max_obs        | 1.51       |
| _mean_act       | 0.0506959  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.73       |
| _mean_obs       | 0.0412     |
| _min_adv        | -4.09      |
| _min_discrew    | 0.0035     |
| _min_obs        | -1.52      |
| _std_act        | 0.549164   |
| _std_adv        | 1          |
| _std_discrew    | 0.298      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.905       |
| KL              | 0.00204764  |
| Phi_loss        | 160.556     |
| PolicyEntropy   | 2.681       |
| PolicyLoss      | -0.00530708 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0287      |
| _MeanReward     | 2.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.92878     |
| _max_adv        | 3.01        |
| _max_discrew    | 2.48        |
| _max_obs        | 1.43        |
| _mean_act       | 0.0511214   |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | 1.82        |
| _mean_obs       | 0.0423      |
| _min_adv        | -5.28       |
| _min_discrew    | 0.00137     |
| _min_obs        | -1.32       |
| _std_act        | 0.547624    |
| _std_adv        | 1           |
| _std_discrew    | 0.316       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00201541 |
| Phi_loss        | 148.335    |
| PolicyEntropy   | 2.65749    |
| PolicyLoss      | 0.0020998  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0279     |
| _MeanReward     | 2.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09909    |
| _max_adv        | 3.36       |
| _max_discrew    | 2.64       |
| _max_obs        | 1.33       |
| _mean_act       | 0.0532022  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.87       |
| _mean_obs       | 0.0418     |
| _min_adv        | -5.44      |
| _min_discrew    | 0.0067     |
| _min_obs        | -1.27      |
| _std_act        | 0.554738   |
| _std_adv        | 1          |
| _std_discrew    | 0.335      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.899      |
| KL              | 0.00208288 |
| Phi_loss        | 152.578    |
| PolicyEntropy   | 2.63924    |
| PolicyLoss      | 0.00346009 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0335     |
| _MeanReward     | 2.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.11538    |
| _max_adv        | 3.41       |
| _max_discrew    | 2.62       |
| _max_obs        | 1.34       |
| _mean_act       | 0.0507923  |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | 1.84       |
| _mean_obs       | 0.0418     |
| _min_adv        | -4.53      |
| _min_discrew    | 0.000471   |
| _min_obs        | -1.39      |
| _std_act        | 0.547518   |
| _std_adv        | 1          |
| _std_discrew    | 0.329      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00323303 |
| Phi_loss        | 158.145    |
| PolicyEntropy   | 2.62246    |
| PolicyLoss      | -0.0197034 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0266     |
| _MeanReward     | 2.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1001     |
| _max_adv        | 3.2        |
| _max_discrew    | 2.61       |
| _max_obs        | 1.24       |
| _mean_act       | 0.0502632  |
| _mean_adv       | 3.2e-17    |
| _mean_discrew   | 1.86       |
| _mean_obs       | 0.0426     |
| _min_adv        | -4.62      |
| _min_discrew    | 0.00486    |
| _min_obs        | -1.4       |
| _std_act        | 0.554201   |
| _std_adv        | 1          |
| _std_discrew    | 0.342      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.908      |
| KL              | 0.00192737 |
| Phi_loss        | 158.146    |
| PolicyEntropy   | 2.6145     |
| PolicyLoss      | -0.0117414 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0304     |
| _MeanReward     | 2.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.32017    |
| _max_adv        | 2.92       |
| _max_discrew    | 2.69       |
| _max_obs        | 1.4        |
| _mean_act       | 0.0485822  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.9        |
| _mean_obs       | 0.0413     |
| _min_adv        | -5.1       |
| _min_discrew    | 0.00787    |
| _min_obs        | -1.33      |
| _std_act        | 0.552167   |
| _std_adv        | 1          |
| _std_discrew    | 0.361      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.904      |
| KL              | 0.00222895 |
| Phi_loss        | 152.904    |
| PolicyEntropy   | 2.6074     |
| PolicyLoss      | -0.0181548 |
| Steps           | 10000      |
| VarFuncLoss     | 0.033      |
| _MeanReward     | 2.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.3103     |
| _max_adv        | 3.46       |
| _max_discrew    | 2.58       |
| _max_obs        | 1.36       |
| _mean_act       | 0.0516821  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.9        |
| _mean_obs       | 0.0419     |
| _min_adv        | -5.38      |
| _min_discrew    | 0.00447    |
| _min_obs        | -1.15      |
| _std_act        | 0.555743   |
| _std_adv        | 1          |
| _std_discrew    | 0.341      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.925      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00237889 |
| Phi_loss        | 150.801    |
| PolicyEntropy   | 2.5773     |
| PolicyLoss      | 0.00523276 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0256     |
| _MeanReward     | 2.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.43422    |
| _max_adv        | 2.9        |
| _max_discrew    | 2.79       |
| _max_obs        | 1.35       |
| _mean_act       | 0.046635   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.95       |
| _mean_obs       | 0.041      |
| _min_adv        | -7.37      |
| _min_discrew    | -0.184     |
| _min_obs        | -1.31      |
| _std_act        | 0.558583   |
| _std_adv        | 1          |
| _std_discrew    | 0.435      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.93       |
| KL              | 0.00368869 |
| Phi_loss        | 135.976    |
| PolicyEntropy   | 2.55922    |
| PolicyLoss      | -0.0177108 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0223     |
| _MeanReward     | 2.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89164    |
| _max_adv        | 3.37       |
| _max_discrew    | 2.68       |
| _max_obs        | 1.29       |
| _mean_act       | 0.0502728  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2          |
| _mean_obs       | 0.0421     |
| _min_adv        | -5.1       |
| _min_discrew    | 0.004      |
| _min_obs        | -1.24      |
| _std_act        | 0.563393   |
| _std_adv        | 1          |
| _std_discrew    | 0.373      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.933      |
| KL              | 0.00246919 |
| Phi_loss        | 165.689    |
| PolicyEntropy   | 2.54197    |
| PolicyLoss      | 0.00259779 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 2.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13923    |
| _max_adv        | 2.84       |
| _max_discrew    | 2.76       |
| _max_obs        | 1.4        |
| _mean_act       | 0.0504859  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.95       |
| _mean_obs       | 0.0415     |
| _min_adv        | -5.49      |
| _min_discrew    | 0.00748    |
| _min_obs        | -1.42      |
| _std_act        | 0.557057   |
| _std_adv        | 1          |
| _std_discrew    | 0.365      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.936       |
| ExplainedVarOld | 0.934       |
| KL              | 0.00194342  |
| Phi_loss        | 179.389     |
| PolicyEntropy   | 2.51469     |
| PolicyLoss      | -0.00699614 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0237      |
| _MeanReward     | 2.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.46415     |
| _max_adv        | 3           |
| _max_discrew    | 2.85        |
| _max_obs        | 1.3         |
| _mean_act       | 0.0488452   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 1.96        |
| _mean_obs       | 0.0424      |
| _min_adv        | -5.3        |
| _min_discrew    | -0.000721   |
| _min_obs        | -1.25       |
| _std_act        | 0.563117    |
| _std_adv        | 1           |
| _std_discrew    | 0.387       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.934        |
| ExplainedVarOld | 0.931        |
| KL              | 0.00208517   |
| Phi_loss        | 182.08       |
| PolicyEntropy   | 2.50568      |
| PolicyLoss      | -0.000546511 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0254       |
| _MeanReward     | 2.23e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.15706      |
| _max_adv        | 4.89         |
| _max_discrew    | 2.81         |
| _max_obs        | 1.45         |
| _mean_act       | 0.00318199   |
| _mean_adv       | 0            |
| _mean_discrew   | 1.82         |
| _mean_obs       | 0.0368       |
| _min_adv        | -15.2        |
| _min_discrew    | -0.894       |
| _min_obs        | -1.27        |
| _std_act        | 0.621374     |
| _std_adv        | 1            |
| _std_discrew    | 0.822        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.848      |
| ExplainedVarOld | 0.837      |
| KL              | 0.00702379 |
| Phi_loss        | 143.108    |
| PolicyEntropy   | 2.48798    |
| PolicyLoss      | 0.0299976  |
| Steps           | 10000      |
| VarFuncLoss     | 0.125      |
| _MeanReward     | 2.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01813    |
| _max_adv        | 4.13       |
| _max_discrew    | 2.93       |
| _max_obs        | 1.3        |
| _mean_act       | 0.0498608  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2          |
| _mean_obs       | 0.0426     |
| _min_adv        | -7.02      |
| _min_discrew    | 0.00276    |
| _min_obs        | -1.42      |
| _std_act        | 0.564241   |
| _std_adv        | 1          |
| _std_discrew    | 0.384      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00120266 |
| Phi_loss        | 170.961    |
| PolicyEntropy   | 2.48225    |
| PolicyLoss      | -0.0136262 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0329     |
| _MeanReward     | 2.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97492    |
| _max_adv        | 4.22       |
| _max_discrew    | 2.87       |
| _max_obs        | 1.33       |
| _mean_act       | 0.0494034  |
| _mean_adv       | 7.11e-17   |
| _mean_discrew   | 2.05       |
| _mean_obs       | 0.0418     |
| _min_adv        | -5.95      |
| _min_discrew    | 0.00472    |
| _min_obs        | -1.4       |
| _std_act        | 0.563605   |
| _std_adv        | 1          |
| _std_discrew    | 0.426      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.941       |
| ExplainedVarOld | 0.926       |
| KL              | 0.00243758  |
| Phi_loss        | 176.879     |
| PolicyEntropy   | 2.45889     |
| PolicyLoss      | -0.00221975 |
| Steps           | 10000       |
| VarFuncLoss     | 0.026       |
| _MeanReward     | 2.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07778     |
| _max_adv        | 9.63        |
| _max_discrew    | 3.22        |
| _max_obs        | 1.45        |
| _mean_act       | 0.0492818   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.07        |
| _mean_obs       | 0.0427      |
| _min_adv        | -6.71       |
| _min_discrew    | 0.00515     |
| _min_obs        | -1.23       |
| _std_act        | 0.56398     |
| _std_adv        | 1           |
| _std_discrew    | 0.426       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.902      |
| KL              | 0.00261744 |
| Phi_loss        | 162.204    |
| PolicyEntropy   | 2.4401     |
| PolicyLoss      | -0.0124411 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0404     |
| _MeanReward     | 2.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.21753    |
| _max_adv        | 3.75       |
| _max_discrew    | 2.94       |
| _max_obs        | 1.35       |
| _mean_act       | 0.0496658  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.13       |
| _mean_obs       | 0.0421     |
| _min_adv        | -5.8       |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.22      |
| _std_act        | 0.57056    |
| _std_adv        | 1          |
| _std_discrew    | 0.455      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.941      |
| KL              | 0.00243008 |
| Phi_loss        | 194.582    |
| PolicyEntropy   | 2.40571    |
| PolicyLoss      | -0.0153034 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0276     |
| _MeanReward     | 2.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08626    |
| _max_adv        | 3.62       |
| _max_discrew    | 2.92       |
| _max_obs        | 1.53       |
| _mean_act       | 0.0465931  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.11       |
| _mean_obs       | 0.0413     |
| _min_adv        | -7.18      |
| _min_discrew    | 0.00734    |
| _min_obs        | -1.23      |
| _std_act        | 0.567941   |
| _std_adv        | 1          |
| _std_discrew    | 0.427      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.957       |
| KL              | 0.00216885  |
| Phi_loss        | 181.328     |
| PolicyEntropy   | 2.3924      |
| PolicyLoss      | -0.00461854 |
| Steps           | 10000       |
| VarFuncLoss     | 0.017       |
| _MeanReward     | 2.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09413     |
| _max_adv        | 3.09        |
| _max_discrew    | 2.96        |
| _max_obs        | 1.28        |
| _mean_act       | 0.0481447   |
| _mean_adv       | -1.21e-17   |
| _mean_discrew   | 2.13        |
| _mean_obs       | 0.0414      |
| _min_adv        | -6          |
| _min_discrew    | -0.00121    |
| _min_obs        | -1.27       |
| _std_act        | 0.567617    |
| _std_adv        | 1           |
| _std_discrew    | 0.452       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00245731 |
| Phi_loss        | 190.899    |
| PolicyEntropy   | 2.37124    |
| PolicyLoss      | -0.013808  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0332     |
| _MeanReward     | 2.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95176    |
| _max_adv        | 3.4        |
| _max_discrew    | 3.02       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0513158  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.2        |
| _mean_obs       | 0.0424     |
| _min_adv        | -5.54      |
| _min_discrew    | 0.0095     |
| _min_obs        | -1.33      |
| _std_act        | 0.569713   |
| _std_adv        | 1          |
| _std_discrew    | 0.451      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.962      |
| KL              | 0.0022808  |
| Phi_loss        | 199.904    |
| PolicyEntropy   | 2.34651    |
| PolicyLoss      | -0.0219794 |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 2.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85731    |
| _max_adv        | 4.91       |
| _max_discrew    | 3.04       |
| _max_obs        | 1.42       |
| _mean_act       | 0.0527413  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.17       |
| _mean_obs       | 0.0421     |
| _min_adv        | -7.71      |
| _min_discrew    | 0.00663    |
| _min_obs        | -1.41      |
| _std_act        | 0.574241   |
| _std_adv        | 1          |
| _std_discrew    | 0.481      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.95        |
| ExplainedVarOld | 0.945       |
| KL              | 0.00261369  |
| Phi_loss        | 180.753     |
| PolicyEntropy   | 2.33768     |
| PolicyLoss      | -0.00426015 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0242      |
| _MeanReward     | 2.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.17339     |
| _max_adv        | 4.21        |
| _max_discrew    | 3.01        |
| _max_obs        | 1.29        |
| _mean_act       | 0.0495016   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.25        |
| _mean_obs       | 0.043       |
| _min_adv        | -8.65       |
| _min_discrew    | 0.00933     |
| _min_obs        | -1.21       |
| _std_act        | 0.575238    |
| _std_adv        | 1           |
| _std_discrew    | 0.462       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.944      |
| KL              | 0.00246149 |
| Phi_loss        | 190.196    |
| PolicyEntropy   | 2.31703    |
| PolicyLoss      | -0.0136484 |
| Steps           | 10000      |
| VarFuncLoss     | 0.026      |
| _MeanReward     | 2.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19592    |
| _max_adv        | 3.18       |
| _max_discrew    | 3.07       |
| _max_obs        | 1.25       |
| _mean_act       | 0.0519994  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.24       |
| _mean_obs       | 0.0428     |
| _min_adv        | -6.29      |
| _min_discrew    | 0.00676    |
| _min_obs        | -1.43      |
| _std_act        | 0.578631   |
| _std_adv        | 1          |
| _std_discrew    | 0.453      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.943      |
| ExplainedVarOld | 0.94       |
| KL              | 0.00243668 |
| Phi_loss        | 192.477    |
| PolicyEntropy   | 2.29996    |
| PolicyLoss      | -0.0199999 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0257     |
| _MeanReward     | 2.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05657    |
| _max_adv        | 3.92       |
| _max_discrew    | 3.11       |
| _max_obs        | 1.3        |
| _mean_act       | 0.0518474  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.28       |
| _mean_obs       | 0.0429     |
| _min_adv        | -5.55      |
| _min_discrew    | 0.000184   |
| _min_obs        | -1.24      |
| _std_act        | 0.58264    |
| _std_adv        | 1          |
| _std_discrew    | 0.513      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00210573 |
| Phi_loss        | 202.085    |
| PolicyEntropy   | 2.27951    |
| PolicyLoss      | -0.0104983 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0192     |
| _MeanReward     | 2.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09016    |
| _max_adv        | 4.17       |
| _max_discrew    | 3.06       |
| _max_obs        | 1.29       |
| _mean_act       | 0.0561468  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.31       |
| _mean_obs       | 0.0444     |
| _min_adv        | -6.84      |
| _min_discrew    | 0.00664    |
| _min_obs        | -1.25      |
| _std_act        | 0.594474   |
| _std_adv        | 1          |
| _std_discrew    | 0.517      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00225406 |
| Phi_loss        | 207.982    |
| PolicyEntropy   | 2.26254    |
| PolicyLoss      | -0.0118784 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0208     |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15136    |
| _max_adv        | 2.81       |
| _max_discrew    | 3.09       |
| _max_obs        | 1.31       |
| _mean_act       | 0.0514779  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.0427     |
| _min_adv        | -5.15      |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.26      |
| _std_act        | 0.586414   |
| _std_adv        | 1          |
| _std_discrew    | 0.483      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.93        |
| ExplainedVarOld | 0.922       |
| KL              | 0.00188393  |
| Phi_loss        | 190.553     |
| PolicyEntropy   | 2.25611     |
| PolicyLoss      | -0.00268525 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0344      |
| _MeanReward     | 2.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.22102     |
| _max_adv        | 3.63        |
| _max_discrew    | 3.1         |
| _max_obs        | 1.24        |
| _mean_act       | 0.0500608   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.33        |
| _mean_obs       | 0.0434      |
| _min_adv        | -6.53       |
| _min_discrew    | 0.00538     |
| _min_obs        | -1.3        |
| _std_act        | 0.590815    |
| _std_adv        | 1           |
| _std_discrew    | 0.522       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00231652 |
| Phi_loss        | 208.838    |
| PolicyEntropy   | 2.24175    |
| PolicyLoss      | -0.0091968 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0198     |
| _MeanReward     | 2.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88181    |
| _max_adv        | 3.16       |
| _max_discrew    | 3.33       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0543402  |
| _mean_adv       | 4.12e-17   |
| _mean_discrew   | 2.36       |
| _mean_obs       | 0.0437     |
| _min_adv        | -6.24      |
| _min_discrew    | 0.0105     |
| _min_obs        | -1.31      |
| _std_act        | 0.586736   |
| _std_adv        | 1          |
| _std_discrew    | 0.534      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00239445 |
| Phi_loss        | 214.945    |
| PolicyEntropy   | 2.23204    |
| PolicyLoss      | -0.025337  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0194     |
| _MeanReward     | 2.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.91372    |
| _max_adv        | 3.3        |
| _max_discrew    | 3.28       |
| _max_obs        | 1.31       |
| _mean_act       | 0.0505484  |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 2.31       |
| _mean_obs       | 0.0423     |
| _min_adv        | -5.83      |
| _min_discrew    | 0.00613    |
| _min_obs        | -1.37      |
| _std_act        | 0.590267   |
| _std_adv        | 1          |
| _std_discrew    | 0.515      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.944       |
| KL              | 0.00229943  |
| Phi_loss        | 202.491     |
| PolicyEntropy   | 2.20972     |
| PolicyLoss      | -0.00438512 |
| Steps           | 10000       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 2.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92386     |
| _max_adv        | 2.72        |
| _max_discrew    | 3.23        |
| _max_obs        | 1.36        |
| _mean_act       | 0.0358512   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.25        |
| _mean_obs       | 0.0415      |
| _min_adv        | -12.7       |
| _min_discrew    | -0.623      |
| _min_obs        | -1.38       |
| _std_act        | 0.615785    |
| _std_adv        | 1           |
| _std_discrew    | 0.788       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.862      |
| ExplainedVarOld | 0.839      |
| KL              | 0.00241716 |
| Phi_loss        | 144.089    |
| PolicyEntropy   | 2.20928    |
| PolicyLoss      | 0.0186851  |
| Steps           | 10000      |
| VarFuncLoss     | 0.109      |
| _MeanReward     | 2.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.99458    |
| _max_adv        | 9.77       |
| _max_discrew    | 3.21       |
| _max_obs        | 1.35       |
| _mean_act       | 0.0446439  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.3        |
| _mean_obs       | 0.0421     |
| _min_adv        | -10.3      |
| _min_discrew    | -0.269     |
| _min_obs        | -1.42      |
| _std_act        | 0.593395   |
| _std_adv        | 1          |
| _std_discrew    | 0.575      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.922     |
| ExplainedVarOld | 0.917     |
| KL              | 0.0134234 |
| Phi_loss        | 230.744   |
| PolicyEntropy   | 2.2137    |
| PolicyLoss      | 0.01032   |
| Steps           | 10000     |
| VarFuncLoss     | 0.045     |
| _MeanReward     | 2.9e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.26127   |
| _max_adv        | 3.21      |
| _max_discrew    | 3.29      |
| _max_obs        | 1.23      |
| _mean_act       | 0.0515468 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 2.38      |
| _mean_obs       | 0.0423    |
| _min_adv        | -4.25     |
| _min_discrew    | 0.0114    |
| _min_obs        | -1.23     |
| _std_act        | 0.589486  |
| _std_adv        | 1         |
| _std_discrew    | 0.531     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00187853 |
| Phi_loss        | 244.678    |
| PolicyEntropy   | 2.20057    |
| PolicyLoss      | 0.00253148 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0188     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08983    |
| _max_adv        | 11         |
| _max_discrew    | 3.29       |
| _max_obs        | 1.33       |
| _mean_act       | 0.0524551  |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 2.45       |
| _mean_obs       | 0.0442     |
| _min_adv        | -6.66      |
| _min_discrew    | 0.00636    |
| _min_obs        | -1.39      |
| _std_act        | 0.591367   |
| _std_adv        | 1          |
| _std_discrew    | 0.605      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00115419  |
| Phi_loss        | 224.84      |
| PolicyEntropy   | 2.18364     |
| PolicyLoss      | -0.00200109 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0185      |
| _MeanReward     | 2.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.10406     |
| _max_adv        | 5.41        |
| _max_discrew    | 3.31        |
| _max_obs        | 1.21        |
| _mean_act       | 0.0513368   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.41        |
| _mean_obs       | 0.043       |
| _min_adv        | -6.07       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.32       |
| _std_act        | 0.588413    |
| _std_adv        | 1           |
| _std_discrew    | 0.567       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00205918 |
| Phi_loss        | 263.961    |
| PolicyEntropy   | 2.1561     |
| PolicyLoss      | -0.0101858 |
| Steps           | 10000      |
| VarFuncLoss     | 0.019      |
| _MeanReward     | 2.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.12998    |
| _max_adv        | 3.9        |
| _max_discrew    | 3.27       |
| _max_obs        | 1.38       |
| _mean_act       | 0.0506415  |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 2.37       |
| _mean_obs       | 0.0419     |
| _min_adv        | -7.49      |
| _min_discrew    | 0.00783    |
| _min_obs        | -1.36      |
| _std_act        | 0.587459   |
| _std_adv        | 1          |
| _std_discrew    | 0.557      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.965       |
| KL              | 0.00210749  |
| Phi_loss        | 232.14      |
| PolicyEntropy   | 2.14507     |
| PolicyLoss      | -0.00928712 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0188      |
| _MeanReward     | 2.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09987     |
| _max_adv        | 3.14        |
| _max_discrew    | 3.39        |
| _max_obs        | 1.3         |
| _mean_act       | 0.0535882   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.46        |
| _mean_obs       | 0.043       |
| _min_adv        | -6.17       |
| _min_discrew    | 0.00904     |
| _min_obs        | -1.42       |
| _std_act        | 0.593705    |
| _std_adv        | 1           |
| _std_discrew    | 0.604       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.959       |
| KL              | 0.00225647  |
| Phi_loss        | 229.788     |
| PolicyEntropy   | 2.11423     |
| PolicyLoss      | -0.00150262 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0249      |
| _MeanReward     | 2.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96705     |
| _max_adv        | 4.73        |
| _max_discrew    | 3.24        |
| _max_obs        | 1.31        |
| _mean_act       | 0.0525269   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.46        |
| _mean_obs       | 0.0426      |
| _min_adv        | -7.29       |
| _min_discrew    | 0.00911     |
| _min_obs        | -1.2        |
| _std_act        | 0.59656     |
| _std_adv        | 1           |
| _std_discrew    | 0.526       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.96        |
| KL              | 0.00241514  |
| Phi_loss        | 239.675     |
| PolicyEntropy   | 2.07997     |
| PolicyLoss      | 0.000970995 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0193      |
| _MeanReward     | 3.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12758     |
| _max_adv        | 4           |
| _max_discrew    | 3.25        |
| _max_obs        | 1.23        |
| _mean_act       | 0.0501988   |
| _mean_adv       | -9.95e-18   |
| _mean_discrew   | 2.5         |
| _mean_obs       | 0.0424      |
| _min_adv        | -4.05       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.39       |
| _std_act        | 0.593205    |
| _std_adv        | 1           |
| _std_discrew    | 0.546       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00204047 |
| Phi_loss        | 245.518    |
| PolicyEntropy   | 2.06676    |
| PolicyLoss      | -0.0329452 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0158     |
| _MeanReward     | 3.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.31061    |
| _max_adv        | 4.26       |
| _max_discrew    | 3.42       |
| _max_obs        | 1.24       |
| _mean_act       | 0.0557188  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 2.51       |
| _mean_obs       | 0.0434     |
| _min_adv        | -4.93      |
| _min_discrew    | 0.00905    |
| _min_obs        | -1.32      |
| _std_act        | 0.594604   |
| _std_adv        | 1          |
| _std_discrew    | 0.628      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.962      |
| KL              | 0.00251537 |
| Phi_loss        | 241.305    |
| PolicyEntropy   | 2.02746    |
| PolicyLoss      | -0.0127519 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0191     |
| _MeanReward     | 3.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1476     |
| _max_adv        | 2.76       |
| _max_discrew    | 3.46       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0529499  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 2.53       |
| _mean_obs       | 0.0436     |
| _min_adv        | -7.13      |
| _min_discrew    | 0.00539    |
| _min_obs        | -1.29      |
| _std_act        | 0.602139   |
| _std_adv        | 1          |
| _std_discrew    | 0.575      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00281921 |
| Phi_loss        | 242.54     |
| PolicyEntropy   | 1.99072    |
| PolicyLoss      | -0.0121913 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 3.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83754    |
| _max_adv        | 3.01       |
| _max_discrew    | 3.46       |
| _max_obs        | 1.26       |
| _mean_act       | 0.0519371  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.6        |
| _mean_obs       | 0.0441     |
| _min_adv        | -8.33      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.27      |
| _std_act        | 0.608804   |
| _std_adv        | 1          |
| _std_discrew    | 0.638      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00201783 |
| Phi_loss        | 247.345    |
| PolicyEntropy   | 1.96791    |
| PolicyLoss      | -0.0275041 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0219     |
| _MeanReward     | 3.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93623    |
| _max_adv        | 3.52       |
| _max_discrew    | 3.38       |
| _max_obs        | 1.39       |
| _mean_act       | 0.0496413  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 2.57       |
| _mean_obs       | 0.0433     |
| _min_adv        | -6.39      |
| _min_discrew    | -0.0633    |
| _min_obs        | -1.31      |
| _std_act        | 0.608575   |
| _std_adv        | 1          |
| _std_discrew    | 0.672      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00255139 |
| Phi_loss        | 244.649    |
| PolicyEntropy   | 1.93246    |
| PolicyLoss      | 0.00576142 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 3.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.2387     |
| _max_adv        | 5.25       |
| _max_discrew    | 3.47       |
| _max_obs        | 1.23       |
| _mean_act       | 0.0528458  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.62       |
| _mean_obs       | 0.0436     |
| _min_adv        | -7.56      |
| _min_discrew    | 0.00905    |
| _min_obs        | -1.2       |
| _std_act        | 0.610145   |
| _std_adv        | 1          |
| _std_discrew    | 0.671      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00280955 |
| Phi_loss        | 271.719    |
| PolicyEntropy   | 1.90484    |
| PolicyLoss      | 0.0052874  |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 3.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09082    |
| _max_adv        | 4.74       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.27       |
| _mean_act       | 0.0555224  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.62       |
| _mean_obs       | 0.0436     |
| _min_adv        | -8.69      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.25      |
| _std_act        | 0.602426   |
| _std_adv        | 1          |
| _std_discrew    | 0.679      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00315732  |
| Phi_loss        | 242.571     |
| PolicyEntropy   | 1.86505     |
| PolicyLoss      | -0.00352442 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0171      |
| _MeanReward     | 3.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.04479     |
| _max_adv        | 3.13        |
| _max_discrew    | 3.51        |
| _max_obs        | 1.25        |
| _mean_act       | 0.0522886   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.69        |
| _mean_obs       | 0.044       |
| _min_adv        | -6.67       |
| _min_discrew    | 0.0142      |
| _min_obs        | -1.24       |
| _std_act        | 0.6149      |
| _std_adv        | 1           |
| _std_discrew    | 0.688       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.981       |
| KL              | 0.0023325   |
| Phi_loss        | 266.178     |
| PolicyEntropy   | 1.83121     |
| PolicyLoss      | -0.00797398 |
| Steps           | 10000       |
| VarFuncLoss     | 0.013       |
| _MeanReward     | 3.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.25184     |
| _max_adv        | 4.85        |
| _max_discrew    | 3.47        |
| _max_obs        | 1.18        |
| _mean_act       | 0.0542719   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.64        |
| _mean_obs       | 0.0439      |
| _min_adv        | -4.66       |
| _min_discrew    | 0.00457     |
| _min_obs        | -1.25       |
| _std_act        | 0.600419    |
| _std_adv        | 1           |
| _std_discrew    | 0.693       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00276652 |
| Phi_loss        | 272.39     |
| PolicyEntropy   | 1.80097    |
| PolicyLoss      | -0.0346884 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 3.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.28847    |
| _max_adv        | 2.99       |
| _max_discrew    | 3.5        |
| _max_obs        | 1.18       |
| _mean_act       | 0.0520151  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.62       |
| _mean_obs       | 0.0424     |
| _min_adv        | -9.21      |
| _min_discrew    | 0.0104     |
| _min_obs        | -1.44      |
| _std_act        | 0.604038   |
| _std_adv        | 1          |
| _std_discrew    | 0.627      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.966      |
| KL              | 0.00230955 |
| Phi_loss        | 289.752    |
| PolicyEntropy   | 1.77744    |
| PolicyLoss      | 0.0221888  |
| Steps           | 10000      |
| VarFuncLoss     | 0.019      |
| _MeanReward     | 3.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96353    |
| _max_adv        | 1.66       |
| _max_discrew    | 3.62       |
| _max_obs        | 1.4        |
| _mean_act       | 0.0263727  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.54       |
| _mean_obs       | 0.041      |
| _min_adv        | -15.4      |
| _min_discrew    | -0.706     |
| _min_obs        | -1.3       |
| _std_act        | 0.647346   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.861       |
| KL              | 0.00361482  |
| Phi_loss        | 190.698     |
| PolicyEntropy   | 1.75694     |
| PolicyLoss      | -0.00820354 |
| Steps           | 10000       |
| VarFuncLoss     | 0.13        |
| _MeanReward     | 3.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09262     |
| _max_adv        | 7.92        |
| _max_discrew    | 3.61        |
| _max_obs        | 1.17        |
| _mean_act       | 0.050341    |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.66        |
| _mean_obs       | 0.0439      |
| _min_adv        | -7.93       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.14       |
| _std_act        | 0.621993    |
| _std_adv        | 1           |
| _std_discrew    | 0.671       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.947      |
| KL              | 0.00266641 |
| Phi_loss        | 243.442    |
| PolicyEntropy   | 1.74012    |
| PolicyLoss      | -0.0107086 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0333     |
| _MeanReward     | 3.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24828    |
| _max_adv        | 3.88       |
| _max_discrew    | 3.74       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0537192  |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 2.74       |
| _mean_obs       | 0.0439     |
| _min_adv        | -4.58      |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.17      |
| _std_act        | 0.61391    |
| _std_adv        | 1          |
| _std_discrew    | 0.733      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00176014 |
| Phi_loss        | 268.198    |
| PolicyEntropy   | 1.71535    |
| PolicyLoss      | -0.0205759 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0169     |
| _MeanReward     | 3.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9116     |
| _max_adv        | 4.12       |
| _max_discrew    | 3.65       |
| _max_obs        | 1.25       |
| _mean_act       | 0.0510433  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.75       |
| _mean_obs       | 0.0434     |
| _min_adv        | -5.39      |
| _min_discrew    | 0.0131     |
| _min_obs        | -1.3       |
| _std_act        | 0.612728   |
| _std_adv        | 1          |
| _std_discrew    | 0.731      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00231726 |
| Phi_loss        | 297.071    |
| PolicyEntropy   | 1.682      |
| PolicyLoss      | -0.0303526 |
| Steps           | 10000      |
| VarFuncLoss     | 0.012      |
| _MeanReward     | 3.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1869     |
| _max_adv        | 9.44       |
| _max_discrew    | 3.66       |
| _max_obs        | 1.29       |
| _mean_act       | 0.049907   |
| _mean_adv       | -3.2e-17   |
| _mean_discrew   | 2.75       |
| _mean_obs       | 0.043      |
| _min_adv        | -5.72      |
| _min_discrew    | 0.00893    |
| _min_obs        | -1.19      |
| _std_act        | 0.620294   |
| _std_adv        | 1          |
| _std_discrew    | 0.716      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00246803 |
| Phi_loss        | 315.034    |
| PolicyEntropy   | 1.65053    |
| PolicyLoss      | -0.0198274 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0168     |
| _MeanReward     | 3.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00664    |
| _max_adv        | 3.55       |
| _max_discrew    | 3.7        |
| _max_obs        | 1.2        |
| _mean_act       | 0.0518132  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.76       |
| _mean_obs       | 0.0438     |
| _min_adv        | -4.96      |
| _min_discrew    | 0.0103     |
| _min_obs        | -1.42      |
| _std_act        | 0.619369   |
| _std_adv        | 1          |
| _std_discrew    | 0.74       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00207249 |
| Phi_loss        | 364.841    |
| PolicyEntropy   | 1.62552    |
| PolicyLoss      | -0.0105955 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 3.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1105     |
| _max_adv        | 3.22       |
| _max_discrew    | 3.75       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0497279  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 2.82       |
| _mean_obs       | 0.0445     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.33      |
| _std_act        | 0.625765   |
| _std_adv        | 1          |
| _std_discrew    | 0.753      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.00276937 |
| Phi_loss        | 309.082    |
| PolicyEntropy   | 1.59438    |
| PolicyLoss      | -0.0119361 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0241     |
| _MeanReward     | 3.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13801    |
| _max_adv        | 3.75       |
| _max_discrew    | 3.78       |
| _max_obs        | 1.25       |
| _mean_act       | 0.0483886  |
| _mean_adv       | 2.98e-17   |
| _mean_discrew   | 2.86       |
| _mean_obs       | 0.0446     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.19      |
| _std_act        | 0.638858   |
| _std_adv        | 1          |
| _std_discrew    | 0.807      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.967      |
| KL              | 0.00287088 |
| Phi_loss        | 317.387    |
| PolicyEntropy   | 1.56403    |
| PolicyLoss      | -0.0210682 |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 3.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88226    |
| _max_adv        | 8.76       |
| _max_discrew    | 3.85       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0504074  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 2.85       |
| _mean_obs       | 0.0445     |
| _min_adv        | -8.92      |
| _min_discrew    | 0.00848    |
| _min_obs        | -1.21      |
| _std_act        | 0.634969   |
| _std_adv        | 1          |
| _std_discrew    | 0.783      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00558919 |
| Phi_loss        | 358.433    |
| PolicyEntropy   | 1.56652    |
| PolicyLoss      | -0.0313865 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0202     |
| _MeanReward     | 3.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.07861    |
| _max_adv        | 4.62       |
| _max_discrew    | 3.81       |
| _max_obs        | 1.17       |
| _mean_act       | 0.0497027  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.87       |
| _mean_obs       | 0.0441     |
| _min_adv        | -8.98      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.2       |
| _std_act        | 0.640941   |
| _std_adv        | 1          |
| _std_discrew    | 0.765      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00292016  |
| Phi_loss        | 367.514     |
| PolicyEntropy   | 1.52422     |
| PolicyLoss      | -0.00575031 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0145      |
| _MeanReward     | 3.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02256     |
| _max_adv        | 4.18        |
| _max_discrew    | 3.75        |
| _max_obs        | 1.18        |
| _mean_act       | 0.0513643   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 2.88        |
| _mean_obs       | 0.0444      |
| _min_adv        | -6.04       |
| _min_discrew    | 0.0102      |
| _min_obs        | -1.3        |
| _std_act        | 0.636299    |
| _std_adv        | 1           |
| _std_discrew    | 0.803       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00246045 |
| Phi_loss        | 363.734    |
| PolicyEntropy   | 1.51356    |
| PolicyLoss      | -0.0166634 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17751    |
| _max_adv        | 4.88       |
| _max_discrew    | 3.89       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0505147  |
| _mean_adv       | -5.12e-17  |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.045      |
| _min_adv        | -3.68      |
| _min_discrew    | 0.012      |
| _min_obs        | -1.18      |
| _std_act        | 0.652466   |
| _std_adv        | 1          |
| _std_discrew    | 0.844      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.983       |
| KL              | 0.0020092   |
| Phi_loss        | 374.159     |
| PolicyEntropy   | 1.49439     |
| PolicyLoss      | -0.00554948 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0128      |
| _MeanReward     | 3.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92386     |
| _max_adv        | 2.99        |
| _max_discrew    | 3.88        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0130978  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.55        |
| _mean_obs       | 0.0371      |
| _min_adv        | -15.6       |
| _min_discrew    | -0.94       |
| _min_obs        | -1.19       |
| _std_act        | 0.705001    |
| _std_adv        | 1           |
| _std_discrew    | 1.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00934264 |
| Phi_loss        | 226.032    |
| PolicyEntropy   | 1.48011    |
| PolicyLoss      | -0.10429   |
| Steps           | 10000      |
| VarFuncLoss     | 0.128      |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.07768    |
| _max_adv        | 15.6       |
| _max_discrew    | 3.85       |
| _max_obs        | 1.17       |
| _mean_act       | 0.047079   |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.81       |
| _mean_obs       | 0.0432     |
| _min_adv        | -10.5      |
| _min_discrew    | 0.00931    |
| _min_obs        | -1.17      |
| _std_act        | 0.64091    |
| _std_adv        | 1          |
| _std_discrew    | 0.802      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.913      |
| KL              | 0.00212645 |
| Phi_loss        | 384.242    |
| PolicyEntropy   | 1.46525    |
| PolicyLoss      | -0.0190039 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0647     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.5087     |
| _max_adv        | 4.95       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0491415  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.92       |
| _mean_obs       | 0.044      |
| _min_adv        | -8.71      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.15      |
| _std_act        | 0.642274   |
| _std_adv        | 1          |
| _std_discrew    | 0.822      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.978       |
| KL              | 0.00103578  |
| Phi_loss        | 332.379     |
| PolicyEntropy   | 1.45469     |
| PolicyLoss      | -0.00427708 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0159      |
| _MeanReward     | 3.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12833     |
| _max_adv        | 10.1        |
| _max_discrew    | 3.86        |
| _max_obs        | 1.13        |
| _mean_act       | 0.0514019   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.89        |
| _mean_obs       | 0.0437      |
| _min_adv        | -13.1       |
| _min_discrew    | 0.00617     |
| _min_obs        | -1.31       |
| _std_act        | 0.640169    |
| _std_adv        | 1           |
| _std_discrew    | 0.865       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00280947  |
| Phi_loss        | 287.287     |
| PolicyEntropy   | 1.43428     |
| PolicyLoss      | -0.00385344 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0182      |
| _MeanReward     | 3.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0165      |
| _max_adv        | 3.88        |
| _max_discrew    | 3.84        |
| _max_obs        | 1.14        |
| _mean_act       | 0.0486526   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.94        |
| _mean_obs       | 0.043       |
| _min_adv        | -5.51       |
| _min_discrew    | 0.00742     |
| _min_obs        | -1.3        |
| _std_act        | 0.642588    |
| _std_adv        | 1           |
| _std_discrew    | 0.814       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0024225  |
| Phi_loss        | 410.344    |
| PolicyEntropy   | 1.40113    |
| PolicyLoss      | -0.0155936 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0102     |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.99765    |
| _max_adv        | 3.81       |
| _max_discrew    | 3.93       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0506151  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.0438     |
| _min_adv        | -10        |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.26      |
| _std_act        | 0.646524   |
| _std_adv        | 1          |
| _std_discrew    | 0.809      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00256738 |
| Phi_loss        | 396.315    |
| PolicyEntropy   | 1.36687    |
| PolicyLoss      | 0.00311798 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 3.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.02079    |
| _max_adv        | 3.89       |
| _max_discrew    | 3.9        |
| _max_obs        | 1.18       |
| _mean_act       | 0.049564   |
| _mean_adv       | 0          |
| _mean_discrew   | 2.97       |
| _mean_obs       | 0.0431     |
| _min_adv        | -5.44      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.27      |
| _std_act        | 0.647857   |
| _std_adv        | 1          |
| _std_discrew    | 0.84       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00229591 |
| Phi_loss        | 399.719    |
| PolicyEntropy   | 1.3461     |
| PolicyLoss      | -0.0215029 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00892    |
| _MeanReward     | 3.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97162    |
| _max_adv        | 3.55       |
| _max_discrew    | 3.9        |
| _max_obs        | 1.15       |
| _mean_act       | 0.0507156  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.98       |
| _mean_obs       | 0.0429     |
| _min_adv        | -4.06      |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.21      |
| _std_act        | 0.643328   |
| _std_adv        | 1          |
| _std_discrew    | 0.836      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00214609 |
| Phi_loss        | 451.108    |
| PolicyEntropy   | 1.32375    |
| PolicyLoss      | -0.0190167 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00982    |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03241    |
| _max_adv        | 3.72       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.22       |
| _mean_act       | 0.0492277  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.98       |
| _mean_obs       | 0.0429     |
| _min_adv        | -5.19      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.16      |
| _std_act        | 0.649015   |
| _std_adv        | 1          |
| _std_discrew    | 0.867      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0023915  |
| Phi_loss        | 439.215    |
| PolicyEntropy   | 1.29363    |
| PolicyLoss      | -0.0185062 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0124     |
| _MeanReward     | 3.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13029    |
| _max_adv        | 3.74       |
| _max_discrew    | 4.07       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0499649  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.05       |
| _mean_obs       | 0.0441     |
| _min_adv        | -5.41      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.26      |
| _std_act        | 0.65705    |
| _std_adv        | 1          |
| _std_discrew    | 0.906      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00233203 |
| Phi_loss        | 434.467    |
| PolicyEntropy   | 1.25739    |
| PolicyLoss      | -0.0119673 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0117     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94463    |
| _max_adv        | 3.81       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0489363  |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 3.03       |
| _mean_obs       | 0.0431     |
| _min_adv        | -5.07      |
| _min_discrew    | 0.0111     |
| _min_obs        | -1.39      |
| _std_act        | 0.656958   |
| _std_adv        | 1          |
| _std_discrew    | 0.869      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.99        |
| KL              | 0.00275358  |
| Phi_loss        | 467.076     |
| PolicyEntropy   | 1.24335     |
| PolicyLoss      | -0.00588996 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00863     |
| _MeanReward     | 3.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08625     |
| _max_adv        | 3.06        |
| _max_discrew    | 4.03        |
| _max_obs        | 1.16        |
| _mean_act       | 0.0502276   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.03        |
| _mean_obs       | 0.0437      |
| _min_adv        | -6.52       |
| _min_discrew    | 0.0105      |
| _min_obs        | -1.2        |
| _std_act        | 0.660877    |
| _std_adv        | 1           |
| _std_discrew    | 0.901       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00211428  |
| Phi_loss        | 452.491     |
| PolicyEntropy   | 1.22534     |
| PolicyLoss      | -0.00912728 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0165      |
| _MeanReward     | 3.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07557     |
| _max_adv        | 2.72        |
| _max_discrew    | 4.03        |
| _max_obs        | 1.14        |
| _mean_act       | 0.0478622   |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 3.03        |
| _mean_obs       | 0.0433      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0105      |
| _min_obs        | -1.25       |
| _std_act        | 0.656824    |
| _std_adv        | 1           |
| _std_discrew    | 0.865       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00209069 |
| Phi_loss        | 406.073    |
| PolicyEntropy   | 1.20784    |
| PolicyLoss      | -0.0128199 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 3.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.12493    |
| _max_adv        | 3.83       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.22       |
| _mean_act       | 0.0471428  |
| _mean_adv       | 2.98e-17   |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0429     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.23      |
| _std_act        | 0.659667   |
| _std_adv        | 1          |
| _std_discrew    | 0.884      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00227514 |
| Phi_loss        | 407.109    |
| PolicyEntropy   | 1.20068    |
| PolicyLoss      | -0.0195047 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0295     |
| _MeanReward     | 3.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05043    |
| _max_adv        | 3.71       |
| _max_discrew    | 4.05       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0503703  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.03       |
| _mean_obs       | 0.0433     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.00713    |
| _min_obs        | -1.38      |
| _std_act        | 0.665124   |
| _std_adv        | 1          |
| _std_discrew    | 0.908      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00245384 |
| Phi_loss        | 429.507    |
| PolicyEntropy   | 1.1793     |
| PolicyLoss      | -0.0199613 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.92048    |
| _max_adv        | 10.8       |
| _max_discrew    | 4.05       |
| _max_obs        | 1.23       |
| _mean_act       | 0.0463688  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0437     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.21      |
| _std_act        | 0.667965   |
| _std_adv        | 1          |
| _std_discrew    | 0.945      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00250216 |
| Phi_loss        | 353.844    |
| PolicyEntropy   | 1.17114    |
| PolicyLoss      | -0.0177383 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 3.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90581    |
| _max_adv        | 5.4        |
| _max_discrew    | 4.05       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0469686  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.06       |
| _mean_obs       | 0.0428     |
| _min_adv        | -9.45      |
| _min_discrew    | 0.0103     |
| _min_obs        | -1.24      |
| _std_act        | 0.666681   |
| _std_adv        | 1          |
| _std_discrew    | 0.916      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00243449 |
| Phi_loss        | 428.697    |
| PolicyEntropy   | 1.14275    |
| PolicyLoss      | 0.00536074 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0137     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10496    |
| _max_adv        | 3.25       |
| _max_discrew    | 4.07       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0478381  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.0434     |
| _min_adv        | -6.15      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.29      |
| _std_act        | 0.663683   |
| _std_adv        | 1          |
| _std_discrew    | 0.923      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00233989 |
| Phi_loss        | 476.925    |
| PolicyEntropy   | 1.12469    |
| PolicyLoss      | -0.0173263 |
| Steps           | 10000      |
| VarFuncLoss     | 0.012      |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.16515    |
| _max_adv        | 2.95       |
| _max_discrew    | 4.04       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0448277  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.043      |
| _min_adv        | -10.4      |
| _min_discrew    | 0.00981    |
| _min_obs        | -1.23      |
| _std_act        | 0.670552   |
| _std_adv        | 1          |
| _std_discrew    | 0.926      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.98         |
| ExplainedVarOld | 0.979        |
| KL              | 0.00276324   |
| Phi_loss        | 414.468      |
| PolicyEntropy   | 1.10471      |
| PolicyLoss      | -0.000932393 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0185       |
| _MeanReward     | 3.79e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.95513      |
| _max_adv        | 3.52         |
| _max_discrew    | 4.03         |
| _max_obs        | 1.13         |
| _mean_act       | 0.0478787    |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 3.13         |
| _mean_obs       | 0.0433       |
| _min_adv        | -7.69        |
| _min_discrew    | 0.0125       |
| _min_obs        | -1.52        |
| _std_act        | 0.673508     |
| _std_adv        | 1            |
| _std_discrew    | 0.925        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00237687  |
| Phi_loss        | 469.943     |
| PolicyEntropy   | 1.08375     |
| PolicyLoss      | -0.0179769  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00776     |
| _MeanReward     | 3.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94466     |
| _max_adv        | 2.69        |
| _max_discrew    | 4.11        |
| _max_obs        | 1.47        |
| _mean_act       | -0.00621595 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.77        |
| _mean_obs       | 0.0368      |
| _min_adv        | -17.7       |
| _min_discrew    | -0.851      |
| _min_obs        | -1.2        |
| _std_act        | 0.71489     |
| _std_adv        | 1           |
| _std_discrew    | 1.84        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.888      |
| KL              | 0.00647933 |
| Phi_loss        | 392.872    |
| PolicyEntropy   | 1.08359    |
| PolicyLoss      | -0.0937086 |
| Steps           | 10000      |
| VarFuncLoss     | 0.187      |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.9603     |
| _max_adv        | 4.12       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0479576  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.0427     |
| _min_adv        | -7.86      |
| _min_discrew    | -0.0114    |
| _min_obs        | -1.22      |
| _std_act        | 0.672987   |
| _std_adv        | 1          |
| _std_discrew    | 0.985      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00138001 |
| Phi_loss        | 404.081    |
| PolicyEntropy   | 1.06942    |
| PolicyLoss      | -0.0205159 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 3.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91574    |
| _max_adv        | 23.6       |
| _max_discrew    | 4.1        |
| _max_obs        | 1.28       |
| _mean_act       | 0.0433491  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0429     |
| _min_adv        | -12.2      |
| _min_discrew    | 0.0166     |
| _min_obs        | -1.27      |
| _std_act        | 0.673777   |
| _std_adv        | 1          |
| _std_discrew    | 0.974      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.976     |
| ExplainedVarOld | 0.965     |
| KL              | 0.0151095 |
| Phi_loss        | 482.528   |
| PolicyEntropy   | 1.07797   |
| PolicyLoss      | 0.209774  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0232    |
| _MeanReward     | 3.8e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.48157   |
| _max_adv        | 3.79      |
| _max_discrew    | 4.16      |
| _max_obs        | 1.12      |
| _mean_act       | 0.0438767 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.12      |
| _mean_obs       | 0.0418    |
| _min_adv        | -4.93     |
| _min_discrew    | 0.0144    |
| _min_obs        | -1.19     |
| _std_act        | 0.671975  |
| _std_adv        | 1         |
| _std_discrew    | 0.953     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00196037 |
| Phi_loss        | 551.029    |
| PolicyEntropy   | 1.06464    |
| PolicyLoss      | -0.0287241 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.27213    |
| _max_adv        | 21.3       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0464382  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.043      |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0128     |
| _min_obs        | -1.12      |
| _std_act        | 0.676184   |
| _std_adv        | 1          |
| _std_discrew    | 0.954      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00121977 |
| Phi_loss        | 393.037    |
| PolicyEntropy   | 1.05666    |
| PolicyLoss      | -0.0265122 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0188     |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8714     |
| _max_adv        | 6.58       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0432352  |
| _mean_adv       | -2.13e-18  |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.0423     |
| _min_adv        | -14.5      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.26      |
| _std_act        | 0.679745   |
| _std_adv        | 1          |
| _std_discrew    | 0.984      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0042483  |
| Phi_loss        | 518.935    |
| PolicyEntropy   | 1.05237    |
| PolicyLoss      | -0.0162564 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94533    |
| _max_adv        | 5.91       |
| _max_discrew    | 4.12       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0456445  |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0423     |
| _min_adv        | -8.61      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.25      |
| _std_act        | 0.682901   |
| _std_adv        | 1          |
| _std_discrew    | 0.951      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00172998 |
| Phi_loss        | 557.854    |
| PolicyEntropy   | 1.03195    |
| PolicyLoss      | -0.0103404 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.02084    |
| _max_adv        | 1.18       |
| _max_discrew    | 4.2        |
| _max_obs        | 1.49       |
| _mean_act       | -0.0272377 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 2.79       |
| _mean_obs       | 0.0352     |
| _min_adv        | -14.9      |
| _min_discrew    | -0.997     |
| _min_obs        | -1.19      |
| _std_act        | 0.737868   |
| _std_adv        | 1          |
| _std_discrew    | 2.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.861      |
| KL              | 0.00302084 |
| Phi_loss        | 150.594    |
| PolicyEntropy   | 1.02653    |
| PolicyLoss      | -0.019139  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0698     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.26555    |
| _max_adv        | 13.7       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.72       |
| _mean_act       | 0.0355451  |
| _mean_adv       | -2.06e-17  |
| _mean_discrew   | 3.11       |
| _mean_obs       | 0.0418     |
| _min_adv        | -13.4      |
| _min_discrew    | -0.417     |
| _min_obs        | -1.18      |
| _std_act        | 0.691348   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.944      |
| ExplainedVarOld | 0.939      |
| KL              | 0.00365045 |
| Phi_loss        | 434.762    |
| PolicyEntropy   | 0.998741   |
| PolicyLoss      | 0.00995668 |
| Steps           | 10000      |
| VarFuncLoss     | 0.064      |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93115    |
| _max_adv        | 14.6       |
| _max_discrew    | 4.28       |
| _max_obs        | 1.17       |
| _mean_act       | 0.0442056  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0418     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.21      |
| _std_act        | 0.676882   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00296047 |
| Phi_loss        | 441.422    |
| PolicyEntropy   | 0.976072   |
| PolicyLoss      | -0.0288423 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 3.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78636    |
| _max_adv        | 12.5       |
| _max_discrew    | 4.24       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0427941  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0418     |
| _min_adv        | -8.99      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.38      |
| _std_act        | 0.68048    |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.00278253  |
| Phi_loss        | 477.899     |
| PolicyEntropy   | 0.953352    |
| PolicyLoss      | -0.00722949 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0103      |
| _MeanReward     | 3.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00726     |
| _max_adv        | 7.83        |
| _max_discrew    | 4.23        |
| _max_obs        | 1.15        |
| _mean_act       | 0.0464196   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.23        |
| _mean_obs       | 0.0423      |
| _min_adv        | -3.71       |
| _min_discrew    | 0.0125      |
| _min_obs        | -1.21       |
| _std_act        | 0.680487    |
| _std_adv        | 1           |
| _std_discrew    | 0.998       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00207356 |
| Phi_loss        | 572.155    |
| PolicyEntropy   | 0.92307    |
| PolicyLoss      | -0.0110867 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00747    |
| _MeanReward     | 3.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03749    |
| _max_adv        | 3.77       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0438862  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.042      |
| _min_adv        | -6.46      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.33      |
| _std_act        | 0.679808   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.993       |
| KL              | 0.001908    |
| Phi_loss        | 574.571     |
| PolicyEntropy   | 0.885095    |
| PolicyLoss      | -0.00265761 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00618     |
| _MeanReward     | 3.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.23815     |
| _max_adv        | 2.97        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.13        |
| _mean_act       | 0.041999    |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 3.23        |
| _mean_obs       | 0.0415      |
| _min_adv        | -5.25       |
| _min_discrew    | 0.0113      |
| _min_obs        | -1.2        |
| _std_act        | 0.683666    |
| _std_adv        | 1           |
| _std_discrew    | 0.997       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00237708 |
| Phi_loss        | 623.146    |
| PolicyEntropy   | 0.850979   |
| PolicyLoss      | -0.0139423 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0115     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97287    |
| _max_adv        | 6.21       |
| _max_discrew    | 4.25       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0430644  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.0422     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0074     |
| _min_obs        | -1.29      |
| _std_act        | 0.684146   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00381712  |
| Phi_loss        | 545.132     |
| PolicyEntropy   | 0.829102    |
| PolicyLoss      | -0.00829025 |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02533     |
| _max_adv        | 3.57        |
| _max_discrew    | 4.26        |
| _max_obs        | 1.13        |
| _mean_act       | 0.0450721   |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 3.26        |
| _mean_obs       | 0.0419      |
| _min_adv        | -4.84       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.17       |
| _std_act        | 0.678735    |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00179469  |
| Phi_loss        | 605.28      |
| PolicyEntropy   | 0.814973    |
| PolicyLoss      | 0.000971884 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00586     |
| _MeanReward     | 3.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.10533     |
| _max_adv        | 3.56        |
| _max_discrew    | 4.27        |
| _max_obs        | 1.14        |
| _mean_act       | 0.0451077   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 3.27        |
| _mean_obs       | 0.0416      |
| _min_adv        | -5.91       |
| _min_discrew    | 0.0152      |
| _min_obs        | -1.58       |
| _std_act        | 0.688259    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00170376  |
| Phi_loss        | 619.125     |
| PolicyEntropy   | 0.797174    |
| PolicyLoss      | -0.00481938 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00731     |
| _MeanReward     | 4e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 2.95783     |
| _max_adv        | 5.3         |
| _max_discrew    | 4.25        |
| _max_obs        | 1.13        |
| _mean_act       | 0.0430102   |
| _mean_adv       | -4.26e-17   |
| _mean_discrew   | 3.28        |
| _mean_obs       | 0.0416      |
| _min_adv        | -4.32       |
| _min_discrew    | 0.0138      |
| _min_obs        | -1.29       |
| _std_act        | 0.690718    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00196405 |
| Phi_loss        | 618.257    |
| PolicyEntropy   | 0.768135   |
| PolicyLoss      | -0.0153707 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00669    |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9914     |
| _max_adv        | 4.73       |
| _max_discrew    | 4.29       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0413355  |
| _mean_adv       | 5.97e-17   |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.0422     |
| _min_adv        | -4.98      |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.2       |
| _std_act        | 0.692398   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00245807 |
| Phi_loss        | 656.302    |
| PolicyEntropy   | 0.742173   |
| PolicyLoss      | 0.0118751  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00884    |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10337    |
| _max_adv        | 3.55       |
| _max_discrew    | 4.32       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0411146  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.0422     |
| _min_adv        | -4.98      |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.14      |
| _std_act        | 0.690458   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00217312 |
| Phi_loss        | 599.535    |
| PolicyEntropy   | 0.716377   |
| PolicyLoss      | -0.0247981 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00446    |
| _MeanReward     | 4.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00305    |
| _max_adv        | 12.7       |
| _max_discrew    | 4.26       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0391679  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0417     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.23      |
| _std_act        | 0.687104   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00316272 |
| Phi_loss        | 609.867    |
| PolicyEntropy   | 0.687741   |
| PolicyLoss      | -0.0105849 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0153     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06609    |
| _max_adv        | 3.43       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0413571  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0415     |
| _min_adv        | -5.63      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.31      |
| _std_act        | 0.692957   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00206955  |
| Phi_loss        | 683.3       |
| PolicyEntropy   | 0.664571    |
| PolicyLoss      | -0.00023706 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00606     |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.35692     |
| _max_adv        | 4.62        |
| _max_discrew    | 4.35        |
| _max_obs        | 1.17        |
| _mean_act       | 0.0401621   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0414      |
| _min_adv        | -5.18       |
| _min_discrew    | 0.0139      |
| _min_obs        | -1.24       |
| _std_act        | 0.695766    |
| _std_adv        | 1           |
| _std_discrew    | 1.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00252559 |
| Phi_loss        | 658.89     |
| PolicyEntropy   | 0.661375   |
| PolicyLoss      | -0.0107601 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00811    |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.29384    |
| _max_adv        | 5.4        |
| _max_discrew    | 4.29       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0420086  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0417     |
| _min_adv        | -12.5      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.22      |
| _std_act        | 0.695078   |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00254748 |
| Phi_loss        | 644.388    |
| PolicyEntropy   | 0.638822   |
| PolicyLoss      | -0.0162283 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0111     |
| _MeanReward     | 4.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96141    |
| _max_adv        | 4.47       |
| _max_discrew    | 4.35       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0440246  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0421     |
| _min_adv        | -4.63      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.13      |
| _std_act        | 0.694713   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00215245 |
| Phi_loss        | 687.513    |
| PolicyEntropy   | 0.616613   |
| PolicyLoss      | 0.0320572  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00661    |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.05616    |
| _max_adv        | 3.36       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0432724  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0418     |
| _min_adv        | -5.5       |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.2       |
| _std_act        | 0.691589   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00192153  |
| Phi_loss        | 692.681     |
| PolicyEntropy   | 0.600368    |
| PolicyLoss      | -0.00304907 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00694     |
| _MeanReward     | 4.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92297     |
| _max_adv        | 3.86        |
| _max_discrew    | 4.34        |
| _max_obs        | 1.12        |
| _mean_act       | 0.0421097   |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 3.4         |
| _mean_obs       | 0.0417      |
| _min_adv        | -5.26       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.19       |
| _std_act        | 0.69259     |
| _std_adv        | 1           |
| _std_discrew    | 1.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.992       |
| KL              | 0.00289039  |
| Phi_loss        | 705.466     |
| PolicyEntropy   | 0.557011    |
| PolicyLoss      | -0.00717244 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00838     |
| _MeanReward     | 4.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02435     |
| _max_adv        | 6.37        |
| _max_discrew    | 4.41        |
| _max_obs        | 1.12        |
| _mean_act       | 0.0401816   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.44        |
| _mean_obs       | 0.0424      |
| _min_adv        | -4.84       |
| _min_discrew    | 0.0177      |
| _min_obs        | -1.17       |
| _std_act        | 0.696278    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00218935 |
| Phi_loss        | 709.03     |
| PolicyEntropy   | 0.522376   |
| PolicyLoss      | -0.021173  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00525    |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86669    |
| _max_adv        | 4.36       |
| _max_discrew    | 4.36       |
| _max_obs        | 1.06       |
| _mean_act       | 0.0416622  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.41       |
| _mean_obs       | 0.0424     |
| _min_adv        | -4.67      |
| _min_discrew    | 0.00911    |
| _min_obs        | -1.22      |
| _std_act        | 0.693347   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0024916 |
| Phi_loss        | 709.515   |
| PolicyEntropy   | 0.502213  |
| PolicyLoss      | 0.0119497 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00633   |
| _MeanReward     | 4.14e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.63433   |
| _max_adv        | 3.73      |
| _max_discrew    | 4.41      |
| _max_obs        | 1.18      |
| _mean_act       | 0.041782  |
| _mean_adv       | 5.12e-17  |
| _mean_discrew   | 3.41      |
| _mean_obs       | 0.0418    |
| _min_adv        | -4.28     |
| _min_discrew    | 0.0163    |
| _min_obs        | -1.38     |
| _std_act        | 0.688443  |
| _std_adv        | 1         |
| _std_discrew    | 1.1       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00197149 |
| Phi_loss        | 740.98     |
| PolicyEntropy   | 0.487023   |
| PolicyLoss      | 0.0179015  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00654    |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96189    |
| _max_adv        | 3.75       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0399785  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.042      |
| _min_adv        | -6.57      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.22      |
| _std_act        | 0.694625   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.0024125   |
| Phi_loss        | 791.407     |
| PolicyEntropy   | 0.461349    |
| PolicyLoss      | -0.00458171 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00591     |
| _MeanReward     | 4.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96209     |
| _max_adv        | 3.08        |
| _max_discrew    | 4.4         |
| _max_obs        | 1.08        |
| _mean_act       | 0.0420928   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.43        |
| _mean_obs       | 0.0419      |
| _min_adv        | -7.93       |
| _min_discrew    | 0.0141      |
| _min_obs        | -1.35       |
| _std_act        | 0.696204    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00198325 |
| Phi_loss        | 839.744    |
| PolicyEntropy   | 0.438216   |
| PolicyLoss      | -0.0240118 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0063     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.2414     |
| _max_adv        | 3.81       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0401903  |
| _mean_adv       | -5.12e-17  |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0419     |
| _min_adv        | -4.46      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.12      |
| _std_act        | 0.700638   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.994     |
| KL              | 0.001894  |
| Phi_loss        | 775.664   |
| PolicyEntropy   | 0.413199  |
| PolicyLoss      | -0.021113 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00678   |
| _MeanReward     | 4.2e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.86272   |
| _max_adv        | 6.68      |
| _max_discrew    | 4.42      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0422427 |
| _mean_adv       | 2.84e-18  |
| _mean_discrew   | 3.45      |
| _mean_obs       | 0.0418    |
| _min_adv        | -7.36     |
| _min_discrew    | 0.017     |
| _min_obs        | -1.26     |
| _std_act        | 0.696595  |
| _std_adv        | 1         |
| _std_discrew    | 1.13      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00301652 |
| Phi_loss        | 755.376    |
| PolicyEntropy   | 0.399396   |
| PolicyLoss      | -0.0100494 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00572    |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9435     |
| _max_adv        | 10.4       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.08       |
| _mean_act       | 0.0401659  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0416     |
| _min_adv        | -8.02      |
| _min_discrew    | 0.019      |
| _min_obs        | -1.21      |
| _std_act        | 0.695428   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00260469 |
| Phi_loss        | 792.664    |
| PolicyEntropy   | 0.369922   |
| PolicyLoss      | 0.00196578 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00702    |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88948    |
| _max_adv        | 0.668      |
| _max_discrew    | 4.43       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0493056 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.93       |
| _mean_obs       | 0.0342     |
| _min_adv        | -14.9      |
| _min_discrew    | -1.18      |
| _min_obs        | -1.21      |
| _std_act        | 0.785741   |
| _std_adv        | 1          |
| _std_discrew    | 2.87       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.873     |
| ExplainedVarOld | 0.861     |
| KL              | 0.0201695 |
| Phi_loss        | 737.357   |
| PolicyEntropy   | 0.367716  |
| PolicyLoss      | 0.058212  |
| Steps           | 10000     |
| VarFuncLoss     | 0.368     |
| _MeanReward     | 4.2e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.00378   |
| _max_adv        | 12.3      |
| _max_discrew    | 4.41      |
| _max_obs        | 1.17      |
| _mean_act       | 0.0423809 |
| _mean_adv       | 4.55e-17  |
| _mean_discrew   | 3.45      |
| _mean_obs       | 0.0411    |
| _min_adv        | -4.85     |
| _min_discrew    | 0.017     |
| _min_obs        | -1.24     |
| _std_act        | 0.694445  |
| _std_adv        | 1         |
| _std_discrew    | 1.14      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00987709 |
| Phi_loss        | 740.609    |
| PolicyEntropy   | 0.355306   |
| PolicyLoss      | 0.0687809  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0123     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79395    |
| _max_adv        | 6.67       |
| _max_discrew    | 4.44       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0432927  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0414     |
| _min_adv        | -4.72      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.07      |
| _std_act        | 0.695367   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
---------------------------------
| Beta            | 1.5         |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.993       |
| KL              | 0.0140094   |
| Phi_loss        | 795.273     |
| PolicyEntropy   | 0.350153    |
| PolicyLoss      | -0.00101142 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00589     |
| _MeanReward     | 4.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.69721     |
| _max_adv        | 3.92        |
| _max_discrew    | 4.39        |
| _max_obs        | 1.11        |
| _mean_act       | 0.0355248   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.45        |
| _mean_obs       | 0.0406      |
| _min_adv        | -4.53       |
| _min_discrew    | 0.0148      |
| _min_obs        | -1.15       |
| _std_act        | 0.693044    |
| _std_adv        | 1           |
| _std_discrew    | 1.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
-------------------------------
| Beta            | 2.25      |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0180924 |
| Phi_loss        | 938.138   |
| PolicyEntropy   | 0.348496  |
| PolicyLoss      | 0.0162357 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0059    |
| _MeanReward     | 4.2e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.98809   |
| _max_adv        | 7.22      |
| _max_discrew    | 4.43      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0283079 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.46      |
| _mean_obs       | 0.0397    |
| _min_adv        | -6.92     |
| _min_discrew    | 0.0143    |
| _min_obs        | -1.26     |
| _std_act        | 0.687155  |
| _std_adv        | 1         |
| _std_discrew    | 1.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
-------------------------------
| Beta            | 3.38      |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.995     |
| KL              | 0.0131766 |
| Phi_loss        | 938.871   |
| PolicyEntropy   | 0.346177  |
| PolicyLoss      | 0.0228612 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00557   |
| _MeanReward     | 4.18e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.80614   |
| _max_adv        | 29.3      |
| _max_discrew    | 4.38      |
| _max_obs        | 1.11      |
| _mean_act       | 0.0158238 |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 3.44      |
| _mean_obs       | 0.0385    |
| _min_adv        | -15.4     |
| _min_discrew    | 0.0164    |
| _min_obs        | -1.14     |
| _std_act        | 0.685565  |
| _std_adv        | 1         |
| _std_discrew    | 1.08      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
-------------------------------
| Beta            | 5.06      |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.985     |
| KL              | 0.100685  |
| Phi_loss        | 735.721   |
| PolicyEntropy   | 0.343539  |
| PolicyLoss      | 0.791853  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0131    |
| _MeanReward     | 4.25e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.93395   |
| _max_adv        | 6.68      |
| _max_discrew    | 4.47      |
| _max_obs        | 1.11      |
| _mean_act       | 0.0349146 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.49      |
| _mean_obs       | 0.0408    |
| _min_adv        | -7.11     |
| _min_discrew    | 0.0128    |
| _min_obs        | -1.22     |
| _std_act        | 0.688576  |
| _std_adv        | 1         |
| _std_discrew    | 1.15      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
-------------------------------
| Beta            | 7.59      |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.995     |
| KL              | 0.140598  |
| Phi_loss        | 1028.72   |
| PolicyEntropy   | 0.343169  |
| PolicyLoss      | 1.61445   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00625   |
| _MeanReward     | 4.08e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.75419   |
| _max_adv        | 4.74      |
| _max_discrew    | 4.47      |
| _max_obs        | 1.07      |
| _mean_act       | 0.0415693 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 3.38      |
| _mean_obs       | 0.0405    |
| _min_adv        | -12       |
| _min_discrew    | 0.0169    |
| _min_obs        | -1.09     |
| _std_act        | 0.705864  |
| _std_adv        | 1         |
| _std_discrew    | 1.27      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
-------------------------------
| Beta            | 11.4      |
| ExplainedVarNew | 0.983     |
| ExplainedVarOld | 0.921     |
| KL              | 0.110452  |
| Phi_loss        | 291.293   |
| PolicyEntropy   | 0.343017  |
| PolicyLoss      | 1.34253   |
| Steps           | 10000     |
| VarFuncLoss     | 0.022     |
| _MeanReward     | 4.13e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.84779   |
| _max_adv        | 12.7      |
| _max_discrew    | 4.4       |
| _max_obs        | 1.07      |
| _mean_act       | 0.0760308 |
| _mean_adv       | -1.42e-17 |
| _mean_discrew   | 3.38      |
| _mean_obs       | 0.0426    |
| _min_adv        | -5.27     |
| _min_discrew    | 0.0139    |
| _min_obs        | -1.2      |
| _std_act        | 0.707064  |
| _std_adv        | 1         |
| _std_discrew    | 1.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
---------------------------------
| Beta            | 17.1        |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.993       |
| KL              | 0.0894483   |
| Phi_loss        | 731.177     |
| PolicyEntropy   | 0.342574    |
| PolicyLoss      | 1.38161     |
| Steps           | 10000       |
| VarFuncLoss     | 0.00828     |
| _MeanReward     | 3.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01492     |
| _max_adv        | 2.6         |
| _max_discrew    | 4.28        |
| _max_obs        | 1.54        |
| _mean_act       | -0.00617266 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.85        |
| _mean_obs       | 0.0345      |
| _min_adv        | -22.4       |
| _min_discrew    | -1.24       |
| _min_obs        | -1.24       |
| _std_act        | 0.815144    |
| _std_adv        | 1           |
| _std_discrew    | 2.54        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
-------------------------------
| Beta            | 25.6      |
| ExplainedVarNew | 0.975     |
| ExplainedVarOld | 0.971     |
| KL              | 0.0634327 |
| Phi_loss        | 950.705   |
| PolicyEntropy   | 0.341915  |
| PolicyLoss      | 1.2511    |
| Steps           | 10000     |
| VarFuncLoss     | 0.066     |
| _MeanReward     | 3.36e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.73359   |
| _max_adv        | 3.75      |
| _max_discrew    | 4.19      |
| _max_obs        | 1.53      |
| _mean_act       | 0.0130693 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 2.72      |
| _mean_obs       | 0.0348    |
| _min_adv        | -19.5     |
| _min_discrew    | -1.23     |
| _min_obs        | -1.28     |
| _std_act        | 0.809004  |
| _std_adv        | 1         |
| _std_discrew    | 2.33      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.95      |
| ExplainedVarOld | 0.945     |
| KL              | 0.0478335 |
| Phi_loss        | 929.176   |
| PolicyEntropy   | 0.341188  |
| PolicyLoss      | 1.29706   |
| Steps           | 10000     |
| VarFuncLoss     | 0.119     |
| _MeanReward     | 3.32e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.76505   |
| _max_adv        | 4.09      |
| _max_discrew    | 4.1       |
| _max_obs        | 1.53      |
| _mean_act       | 0.0373293 |
| _mean_adv       | 4.97e-18  |
| _mean_discrew   | 2.66      |
| _mean_obs       | 0.0355    |
| _min_adv        | -19.8     |
| _min_discrew    | -1.16     |
| _min_obs        | -1.23     |
| _std_act        | 0.800027  |
| _std_adv        | 1         |
| _std_discrew    | 2.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.917     |
| ExplainedVarOld | 0.911     |
| KL              | 0.0375804 |
| Phi_loss        | 747.117   |
| PolicyEntropy   | 0.340453  |
| PolicyLoss      | 1.37735   |
| Steps           | 10000     |
| VarFuncLoss     | 0.178     |
| _MeanReward     | 3.59e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.89813   |
| _max_adv        | 9.05      |
| _max_discrew    | 3.98      |
| _max_obs        | 1.14      |
| _mean_act       | 0.12826   |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 2.91      |
| _mean_obs       | 0.0412    |
| _min_adv        | -3.45     |
| _min_discrew    | 0.00624   |
| _min_obs        | -1.13     |
| _std_act        | 0.689781  |
| _std_adv        | 1         |
| _std_discrew    | 0.959     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.99      |
| ExplainedVarOld | 0.985     |
| KL              | 0.0309321 |
| Phi_loss        | 506.152   |
| PolicyEntropy   | 0.33949   |
| PolicyLoss      | 1.08238   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00988   |
| _MeanReward     | 3.47e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.90533   |
| _max_adv        | 18.9      |
| _max_discrew    | 3.95      |
| _max_obs        | 1.16      |
| _mean_act       | 0.136504  |
| _mean_adv       | 5.4e-17   |
| _mean_discrew   | 2.82      |
| _mean_obs       | 0.0405    |
| _min_adv        | -7.21     |
| _min_discrew    | 0.00778   |
| _min_obs        | -1.2      |
| _std_act        | 0.684566  |
| _std_adv        | 1         |
| _std_discrew    | 0.945     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.985     |
| KL              | 0.0233551 |
| Phi_loss        | 595.953   |
| PolicyEntropy   | 0.338364  |
| PolicyLoss      | 0.792887  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0101    |
| _MeanReward     | 3.39e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.13029   |
| _max_adv        | 33.4      |
| _max_discrew    | 3.83      |
| _max_obs        | 1.11      |
| _mean_act       | 0.14553   |
| _mean_adv       | 4.26e-17  |
| _mean_discrew   | 2.73      |
| _mean_obs       | 0.0407    |
| _min_adv        | -5.52     |
| _min_discrew    | 0.0114    |
| _min_obs        | -1.25     |
| _std_act        | 0.685022  |
| _std_adv        | 1         |
| _std_discrew    | 0.939     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.992     |
| KL              | 0.0168353 |
| Phi_loss        | 694.781   |
| PolicyEntropy   | 0.337048  |
| PolicyLoss      | 0.604004  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00673   |
| _MeanReward     | 3.33e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.08512   |
| _max_adv        | 5.47      |
| _max_discrew    | 3.83      |
| _max_obs        | 1.08      |
| _mean_act       | 0.148529  |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 2.67      |
| _mean_obs       | 0.0399    |
| _min_adv        | -4.98     |
| _min_discrew    | 0.00962   |
| _min_obs        | -1.12     |
| _std_act        | 0.690934  |
| _std_adv        | 1         |
| _std_discrew    | 0.927     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.991     |
| KL              | 0.0120337 |
| Phi_loss        | 725.665   |
| PolicyEntropy   | 0.335418  |
| PolicyLoss      | 0.416957  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00688   |
| _MeanReward     | 2.87e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.00256   |
| _max_adv        | 2.35      |
| _max_discrew    | 3.8       |
| _max_obs        | 1.56      |
| _mean_act       | 0.0532656 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 2.3       |
| _mean_obs       | 0.0322    |
| _min_adv        | -23.6     |
| _min_discrew    | -1.27     |
| _min_obs        | -1.18     |
| _std_act        | 0.84167   |
| _std_adv        | 1         |
| _std_discrew    | 1.99      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.97      |
| ExplainedVarOld | 0.965     |
| KL              | 0.112143  |
| Phi_loss        | 647.17    |
| PolicyEntropy   | 0.339338  |
| PolicyLoss      | 4.49461   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0598    |
| _MeanReward     | 3.5e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.97909   |
| _max_adv        | 8.03      |
| _max_discrew    | 3.95      |
| _max_obs        | 1.16      |
| _mean_act       | 0.138722  |
| _mean_adv       | -6.54e-17 |
| _mean_discrew   | 2.83      |
| _mean_obs       | 0.0408    |
| _min_adv        | -4.34     |
| _min_discrew    | 0.00565   |
| _min_obs        | -1.11     |
| _std_act        | 0.695927  |
| _std_adv        | 1         |
| _std_discrew    | 0.971     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
------------------------------
| Beta            | 35       |
| ExplainedVarNew | 0.992    |
| ExplainedVarOld | 0.989    |
| KL              | 0.158157 |
| Phi_loss        | 761.089  |
| PolicyEntropy   | 0.343583 |
| PolicyLoss      | 6.65623  |
| Steps           | 10000    |
| VarFuncLoss     | 0.0155   |
| _MeanReward     | 3.7e+03  |
| _lr_multiplier  | 1        |
| _max_act        | 2.89564  |
| _max_adv        | 23       |
| _max_discrew    | 4.07     |
| _max_obs        | 1.11     |
| _mean_act       | 0.122559 |
| _mean_adv       | 5.97e-17 |
| _mean_discrew   | 3.01     |
| _mean_obs       | 0.0419   |
| _min_adv        | -4.83    |
| _min_discrew    | 0.00625  |
| _min_obs        | -1.23    |
| _std_act        | 0.700766 |
| _std_adv        | 1        |
| _std_discrew    | 1.02     |
------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.989     |
| KL              | 0.126822  |
| Phi_loss        | 779.606   |
| PolicyEntropy   | 0.34708   |
| PolicyLoss      | 5.15571   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0121    |
| _MeanReward     | 3.87e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.84399   |
| _max_adv        | 2.95      |
| _max_discrew    | 4.19      |
| _max_obs        | 1.17      |
| _mean_act       | 0.104348  |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 3.17      |
| _mean_obs       | 0.0421    |
| _min_adv        | -4.77     |
| _min_discrew    | 0.0107    |
| _min_obs        | -1.13     |
| _std_act        | 0.703607  |
| _std_adv        | 1         |
| _std_discrew    | 1.04      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.989     |
| KL              | 0.102052  |
| Phi_loss        | 822.997   |
| PolicyEntropy   | 0.35008   |
| PolicyLoss      | 4.0019    |
| Steps           | 10000     |
| VarFuncLoss     | 0.012     |
| _MeanReward     | 3.95e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.87288   |
| _max_adv        | 4.08      |
| _max_discrew    | 4.32      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0897245 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.24      |
| _mean_obs       | 0.0418    |
| _min_adv        | -4.12     |
| _min_discrew    | 0.012     |
| _min_obs        | -1.12     |
| _std_act        | 0.699034  |
| _std_adv        | 1         |
| _std_discrew    | 1.05      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.99      |
| KL              | 0.08224   |
| Phi_loss        | 794.424   |
| PolicyEntropy   | 0.352611  |
| PolicyLoss      | 3.14086   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00827   |
| _MeanReward     | 4.08e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.91177   |
| _max_adv        | 3.54      |
| _max_discrew    | 4.35      |
| _max_obs        | 1.07      |
| _mean_act       | 0.0773051 |
| _mean_adv       | 2.84e-17  |
| _mean_discrew   | 3.35      |
| _mean_obs       | 0.0417    |
| _min_adv        | -4.22     |
| _min_discrew    | 0.0115    |
| _min_obs        | -1.15     |
| _std_act        | 0.699879  |
| _std_adv        | 1         |
| _std_discrew    | 1.07      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0658683 |
| Phi_loss        | 830.568   |
| PolicyEntropy   | 0.354555  |
| PolicyLoss      | 2.44844   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0074    |
| _MeanReward     | 4.1e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.08958   |
| _max_adv        | 3.48      |
| _max_discrew    | 4.41      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0682509 |
| _mean_adv       | 4.55e-17  |
| _mean_discrew   | 3.37      |
| _mean_obs       | 0.0412    |
| _min_adv        | -5.11     |
| _min_discrew    | 0.00989   |
| _min_obs        | -1.23     |
| _std_act        | 0.694227  |
| _std_adv        | 1         |
| _std_discrew    | 1.09      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.992     |
| ExplainedVarOld | 0.991     |
| KL              | 0.0529022 |
| Phi_loss        | 922.161   |
| PolicyEntropy   | 0.356013  |
| PolicyLoss      | 1.93846   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00887   |
| _MeanReward     | 4.15e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.82172   |
| _max_adv        | 4.86      |
| _max_discrew    | 4.36      |
| _max_obs        | 1.06      |
| _mean_act       | 0.0532898 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 3.42      |
| _mean_obs       | 0.0401    |
| _min_adv        | -6.35     |
| _min_discrew    | 0.0129    |
| _min_obs        | -1.1      |
| _std_act        | 0.692011  |
| _std_adv        | 1         |
| _std_discrew    | 1.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.995     |
| KL              | 0.0421618 |
| Phi_loss        | 892.621   |
| PolicyEntropy   | 0.357097  |
| PolicyLoss      | 1.49346   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00567   |
| _MeanReward     | 4.15e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.9458    |
| _max_adv        | 23.6      |
| _max_discrew    | 4.42      |
| _max_obs        | 1.19      |
| _mean_act       | 0.04635   |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 3.42      |
| _mean_obs       | 0.0395    |
| _min_adv        | -13.3     |
| _min_discrew    | 0.0173    |
| _min_obs        | -1.2      |
| _std_act        | 0.685022  |
| _std_adv        | 1         |
| _std_discrew    | 1.11      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0335636 |
| Phi_loss        | 676.293   |
| PolicyEntropy   | 0.35797   |
| PolicyLoss      | 1.1996    |
| Steps           | 10000     |
| VarFuncLoss     | 0.00545   |
| _MeanReward     | 4.16e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.91463   |
| _max_adv        | 4.77      |
| _max_discrew    | 4.39      |
| _max_obs        | 1.16      |
| _mean_act       | 0.0348188 |
| _mean_adv       | -1.42e-17 |
| _mean_discrew   | 3.43      |
| _mean_obs       | 0.0385    |
| _min_adv        | -5.04     |
| _min_discrew    | 0.0137    |
| _min_obs        | -1.25     |
| _std_act        | 0.682632  |
| _std_adv        | 1         |
| _std_discrew    | 1.07      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0268048 |
| Phi_loss        | 870.315   |
| PolicyEntropy   | 0.358558  |
| PolicyLoss      | 0.936589  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00661   |
| _MeanReward     | 4.18e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.83295   |
| _max_adv        | 4.24      |
| _max_discrew    | 4.4       |
| _max_obs        | 1.04      |
| _mean_act       | 0.0314363 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 3.43      |
| _mean_obs       | 0.0377    |
| _min_adv        | -5.78     |
| _min_discrew    | 0.0164    |
| _min_obs        | -1.18     |
| _std_act        | 0.675033  |
| _std_adv        | 1         |
| _std_discrew    | 1.11      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0213402 |
| Phi_loss        | 828.536   |
| PolicyEntropy   | 0.359035  |
| PolicyLoss      | 0.75747   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00641   |
| _MeanReward     | 4.11e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.76219   |
| _max_adv        | 3.76      |
| _max_discrew    | 4.38      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0217695 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 3.39      |
| _mean_obs       | 0.0355    |
| _min_adv        | -4.82     |
| _min_discrew    | 0.015     |
| _min_obs        | -1.23     |
| _std_act        | 0.664306  |
| _std_adv        | 1         |
| _std_discrew    | 1.09      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0168853 |
| Phi_loss        | 795.82    |
| PolicyEntropy   | 0.359267  |
| PolicyLoss      | 0.568974  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00795   |
| _MeanReward     | 4.05e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.78653   |
| _max_adv        | 3.89      |
| _max_discrew    | 4.3       |
| _max_obs        | 1.07      |
| _mean_act       | 0.0153805 |
| _mean_adv       | 4.55e-17  |
| _mean_discrew   | 3.34      |
| _mean_obs       | 0.0343    |
| _min_adv        | -5.11     |
| _min_discrew    | 0.0147    |
| _min_obs        | -1.32     |
| _std_act        | 0.660695  |
| _std_adv        | 1         |
| _std_discrew    | 1.03      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0133822 |
| Phi_loss        | 826.776   |
| PolicyEntropy   | 0.359163  |
| PolicyLoss      | 0.440492  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00711   |
| _MeanReward     | 4.03e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.96449   |
| _max_adv        | 3.63      |
| _max_discrew    | 4.31      |
| _max_obs        | 1.11      |
| _mean_act       | 0.0127454 |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 3.32      |
| _mean_obs       | 0.0343    |
| _min_adv        | -5.97     |
| _min_discrew    | 0.0137    |
| _min_obs        | -1.19     |
| _std_act        | 0.663483  |
| _std_adv        | 1         |
| _std_discrew    | 1.03      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.99      |
| KL              | 0.0373248 |
| Phi_loss        | 921.886   |
| PolicyEntropy   | 0.363753  |
| PolicyLoss      | 1.34398   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00958   |
| _MeanReward     | 4.04e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.66808   |
| _max_adv        | 3.09      |
| _max_discrew    | 4.39      |
| _max_obs        | 1.07      |
| _mean_act       | 0.0191087 |
| _mean_adv       | -2.42e-17 |
| _mean_discrew   | 3.33      |
| _mean_obs       | 0.0345    |
| _min_adv        | -4.39     |
| _min_discrew    | 0.0164    |
| _min_obs        | -1.06     |
| _std_act        | 0.660819  |
| _std_adv        | 1         |
| _std_discrew    | 1.03      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.991     |
| KL              | 0.0681302 |
| Phi_loss        | 937.536   |
| PolicyEntropy   | 0.367739  |
| PolicyLoss      | 2.56363   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00901   |
| _MeanReward     | 4.13e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.76686   |
| _max_adv        | 3.73      |
| _max_discrew    | 4.36      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0309054 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.4       |
| _mean_obs       | 0.0368    |
| _min_adv        | -4.94     |
| _min_discrew    | 0.0132    |
| _min_obs        | -1.36     |
| _std_act        | 0.673786  |
| _std_adv        | 1         |
| _std_discrew    | 1.08      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0542091 |
| Phi_loss        | 907.056   |
| PolicyEntropy   | 0.371146  |
| PolicyLoss      | 2.00896   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00734   |
| _MeanReward     | 4.04e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.7623    |
| _max_adv        | 13.9      |
| _max_discrew    | 4.33      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0332163 |
| _mean_adv       | -7.11e-18 |
| _mean_discrew   | 3.35      |
| _mean_obs       | 0.0373    |
| _min_adv        | -20.7     |
| _min_discrew    | 0.0109    |
| _min_obs        | -1.21     |
| _std_act        | 0.673235  |
| _std_adv        | 1         |
| _std_discrew    | 1.11      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.979     |
| KL              | 0.0423352 |
| Phi_loss        | 348.905   |
| PolicyEntropy   | 0.373867  |
| PolicyLoss      | 1.5792    |
| Steps           | 10000     |
| VarFuncLoss     | 0.0133    |
| _MeanReward     | 4.12e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.069     |
| _max_adv        | 5.38      |
| _max_discrew    | 4.42      |
| _max_obs        | 1.12      |
| _mean_act       | 0.0486523 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 3.39      |
| _mean_obs       | 0.0389    |
| _min_adv        | -6.93     |
| _min_discrew    | 0.0124    |
| _min_obs        | -1.25     |
| _std_act        | 0.684938  |
| _std_adv        | 1         |
| _std_discrew    | 1.09      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.99      |
| KL              | 0.0337527 |
| Phi_loss        | 868.451   |
| PolicyEntropy   | 0.375911  |
| PolicyLoss      | 1.20621   |
| Steps           | 10000     |
| VarFuncLoss     | 0.01      |
| _MeanReward     | 4.02e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.88356   |
| _max_adv        | 7.49      |
| _max_discrew    | 4.21      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0570311 |
| _mean_adv       | -7.96e-17 |
| _mean_discrew   | 3.31      |
| _mean_obs       | 0.0386    |
| _min_adv        | -5.12     |
| _min_discrew    | 0.0141    |
| _min_obs        | -1.07     |
| _std_act        | 0.673612  |
| _std_adv        | 1         |
| _std_discrew    | 1.01      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.992     |
| ExplainedVarOld | 0.991     |
| KL              | 0.0261593 |
| Phi_loss        | 792.737   |
| PolicyEntropy   | 0.377413  |
| PolicyLoss      | 0.914129  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00893   |
| _MeanReward     | 3.96e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.73139   |
| _max_adv        | 3.1       |
| _max_discrew    | 4.17      |
| _max_obs        | 1.14      |
| _mean_act       | 0.0607378 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.25      |
| _mean_obs       | 0.0389    |
| _min_adv        | -12.8     |
| _min_discrew    | 0.0108    |
| _min_obs        | -1.21     |
| _std_act        | 0.678054  |
| _std_adv        | 1         |
| _std_discrew    | 1.02      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.979     |
| ExplainedVarOld | 0.977     |
| KL              | 0.0205645 |
| Phi_loss        | 705.969   |
| PolicyEntropy   | 0.378704  |
| PolicyLoss      | 0.704173  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0225    |
| _MeanReward     | 3.88e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.90626   |
| _max_adv        | 12.5      |
| _max_discrew    | 4.19      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0653292 |
| _mean_adv       | -4.12e-17 |
| _mean_discrew   | 3.2       |
| _mean_obs       | 0.0385    |
| _min_adv        | -17.3     |
| _min_discrew    | 0.0143    |
| _min_obs        | -1.1      |
| _std_act        | 0.676462  |
| _std_adv        | 1         |
| _std_discrew    | 0.999     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.989     |
| ExplainedVarOld | 0.971     |
| KL              | 0.0160307 |
| Phi_loss        | 641.54    |
| PolicyEntropy   | 0.379785  |
| PolicyLoss      | 0.543864  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0115    |
| _MeanReward     | 3.83e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.75727   |
| _max_adv        | 4.13      |
| _max_discrew    | 4.12      |
| _max_obs        | 1.19      |
| _mean_act       | 0.0692558 |
| _mean_adv       | 3.41e-17  |
| _mean_discrew   | 3.17      |
| _mean_obs       | 0.0383    |
| _min_adv        | -17.9     |
| _min_discrew    | 0.0115    |
| _min_obs        | -1.19     |
| _std_act        | 0.683501  |
| _std_adv        | 1         |
| _std_discrew    | 0.95      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0127266  |
| Phi_loss        | 625.309    |
| PolicyEntropy   | 0.380655   |
| PolicyLoss      | 0.415327   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0129     |
| _MeanReward     | 3.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89864    |
| _max_adv        | 2.22       |
| _max_discrew    | 4.12       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0154635 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.73       |
| _mean_obs       | 0.0309     |
| _min_adv        | -14.9      |
| _min_discrew    | -1.03      |
| _min_obs        | -1.27      |
| _std_act        | 0.763465   |
| _std_adv        | 1          |
| _std_discrew    | 2.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
--------------------------------
| Beta            | 23.3       |
| ExplainedVarNew | 0.952      |
| ExplainedVarOld | 0.841      |
| KL              | 0.00111297 |
| Phi_loss        | 557.52     |
| PolicyEntropy   | 0.380953   |
| PolicyLoss      | 0.0561851  |
| Steps           | 10000      |
| VarFuncLoss     | 0.11       |
| _MeanReward     | 3.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89021    |
| _max_adv        | 9.02       |
| _max_discrew    | 4.04       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0783277  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0385     |
| _min_adv        | -3.75      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.17      |
| _std_act        | 0.675868   |
| _std_adv        | 1          |
| _std_discrew    | 0.947      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
---------------------------------
| Beta            | 15.6        |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.993       |
| KL              | 6.04771e-05 |
| Phi_loss        | 675.718     |
| PolicyEntropy   | 0.380454    |
| PolicyLoss      | -0.00183753 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00657     |
| _MeanReward     | 3.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64667     |
| _max_adv        | 1.86        |
| _max_discrew    | 4.07        |
| _max_obs        | 1.57        |
| _mean_act       | 0.00772308  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 2.79        |
| _mean_obs       | 0.0327      |
| _min_adv        | -18.7       |
| _min_discrew    | -0.967      |
| _min_obs        | -1.19       |
| _std_act        | 0.743514    |
| _std_adv        | 1           |
| _std_discrew    | 2           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.903       |
| KL              | 1.297e-05   |
| Phi_loss        | 791.962     |
| PolicyEntropy   | 0.379998    |
| PolicyLoss      | 3.51801e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.182       |
| _MeanReward     | 3.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90213     |
| _max_adv        | 1.93        |
| _max_discrew    | 4.07        |
| _max_obs        | 1.57        |
| _mean_act       | -0.0129513  |
| _mean_adv       | -2.88e-17   |
| _mean_discrew   | 2.76        |
| _mean_obs       | 0.0307      |
| _min_adv        | -22.3       |
| _min_discrew    | -1.04       |
| _min_obs        | -1.24       |
| _std_act        | 0.757686    |
| _std_adv        | 1           |
| _std_discrew    | 2.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
---------------------------------
| Beta            | 6.91        |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.971       |
| KL              | 6.64885e-06 |
| Phi_loss        | 653.654     |
| PolicyEntropy   | 0.379615    |
| PolicyLoss      | 0.00257178  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0622      |
| _MeanReward     | 3.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84336     |
| _max_adv        | 12.7        |
| _max_discrew    | 4.04        |
| _max_obs        | 1.22        |
| _mean_act       | 0.0762501   |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0385      |
| _min_adv        | -3.94       |
| _min_discrew    | 0.0107      |
| _min_obs        | -1.08       |
| _std_act        | 0.679005    |
| _std_adv        | 1           |
| _std_discrew    | 0.969       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.989       |
| KL              | 9.26113e-06 |
| Phi_loss        | 606.192     |
| PolicyEntropy   | 0.378594    |
| PolicyLoss      | -0.00453192 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00647     |
| _MeanReward     | 3.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80168     |
| _max_adv        | 8.35        |
| _max_discrew    | 4.14        |
| _max_obs        | 1.6         |
| _mean_act       | 0.0606499   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.06        |
| _mean_obs       | 0.0375      |
| _min_adv        | -19         |
| _min_discrew    | -0.5        |
| _min_obs        | -1.21       |
| _std_act        | 0.692655    |
| _std_adv        | 1           |
| _std_discrew    | 1.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.94        |
| ExplainedVarOld | 0.934       |
| KL              | 1.10097e-05 |
| Phi_loss        | 774.629     |
| PolicyEntropy   | 0.378465    |
| PolicyLoss      | 0.00555994  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0736      |
| _MeanReward     | 3.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01455     |
| _max_adv        | 12.2        |
| _max_discrew    | 4.11        |
| _max_obs        | 1.12        |
| _mean_act       | 0.0754837   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0385      |
| _min_adv        | -6.19       |
| _min_discrew    | 0.00956     |
| _min_obs        | -1.22       |
| _std_act        | 0.682258    |
| _std_adv        | 1           |
| _std_discrew    | 0.995       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
--------------------------------
| Beta            | 2.05       |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.994      |
| KL              | 2.982e-05  |
| Phi_loss        | 850.608    |
| PolicyEntropy   | 0.376035   |
| PolicyLoss      | -0.0275594 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00814    |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81662    |
| _max_adv        | 19.9       |
| _max_discrew    | 4.19       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0758278  |
| _mean_adv       | -3.27e-17  |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.0383     |
| _min_adv        | -4.22      |
| _min_discrew    | 0.0094     |
| _min_obs        | -1.14      |
| _std_act        | 0.676647   |
| _std_adv        | 1          |
| _std_discrew    | 0.998      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.992       |
| KL              | 5.19043e-05 |
| Phi_loss        | 663.623     |
| PolicyEntropy   | 0.370307    |
| PolicyLoss      | -0.0151408  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00676     |
| _MeanReward     | 3.82e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92963     |
| _max_adv        | 15.8        |
| _max_discrew    | 4.1         |
| _max_obs        | 1.09        |
| _mean_act       | 0.0748131   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.14        |
| _mean_obs       | 0.0376      |
| _min_adv        | -4.58       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.38       |
| _std_act        | 0.671293    |
| _std_adv        | 1           |
| _std_discrew    | 0.949       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.99        |
| KL              | 0.000105718 |
| Phi_loss        | 841.203     |
| PolicyEntropy   | 0.364177    |
| PolicyLoss      | -0.0191779  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00938     |
| _MeanReward     | 3.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03296     |
| _max_adv        | 5.88        |
| _max_discrew    | 4.14        |
| _max_obs        | 1.1         |
| _mean_act       | 0.0728044   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.16        |
| _mean_obs       | 0.0377      |
| _min_adv        | -4.08       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.18       |
| _std_act        | 0.679737    |
| _std_adv        | 1           |
| _std_discrew    | 0.986       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.000385881 |
| Phi_loss        | 840.431     |
| PolicyEntropy   | 0.348812    |
| PolicyLoss      | -0.00738628 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00576     |
| _MeanReward     | 3.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.70042     |
| _max_adv        | 4.45        |
| _max_discrew    | 4.17        |
| _max_obs        | 1.14        |
| _mean_act       | 0.0717763   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.17        |
| _mean_obs       | 0.0381      |
| _min_adv        | -4.79       |
| _min_discrew    | 0.0116      |
| _min_obs        | -1.21       |
| _std_act        | 0.680439    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
---------------------------------
| Beta            | 0.405       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.000489797 |
| Phi_loss        | 864.674     |
| PolicyEntropy   | 0.342134    |
| PolicyLoss      | -0.0179942  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00945     |
| _MeanReward     | 3.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8854      |
| _max_adv        | 17.8        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.1         |
| _mean_act       | 0.0686325   |
| _mean_adv       | -3.55e-19   |
| _mean_discrew   | 3.17        |
| _mean_obs       | 0.0382      |
| _min_adv        | -13.7       |
| _min_discrew    | 0.0117      |
| _min_obs        | -1.26       |
| _std_act        | 0.680907    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.97        |
| KL              | 0.000701583 |
| Phi_loss        | 631.927     |
| PolicyEntropy   | 0.335073    |
| PolicyLoss      | -0.00870106 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0276      |
| _MeanReward     | 3.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86068     |
| _max_adv        | 3.25        |
| _max_discrew    | 4.15        |
| _max_obs        | 1.09        |
| _mean_act       | 0.0721611   |
| _mean_adv       | -4.26e-17   |
| _mean_discrew   | 3.22        |
| _mean_obs       | 0.0386      |
| _min_adv        | -3.65       |
| _min_discrew    | 0.0113      |
| _min_obs        | -1.15       |
| _std_act        | 0.68457     |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00179426 |
| Phi_loss        | 869.059    |
| PolicyEntropy   | 0.311086   |
| PolicyLoss      | -0.018224  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00815    |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.774      |
| _max_adv        | 13.7       |
| _max_discrew    | 4.18       |
| _max_obs        | 1.58       |
| _mean_act       | 0.0559498  |
| _mean_adv       | 1.81e-17   |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.0377     |
| _min_adv        | -16.6      |
| _min_discrew    | -0.333     |
| _min_obs        | -1.17      |
| _std_act        | 0.695818   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.948       |
| KL              | 0.000632582 |
| Phi_loss        | 544.869     |
| PolicyEntropy   | 0.309973    |
| PolicyLoss      | 0.0124741   |
| Steps           | 10000       |
| VarFuncLoss     | 0.052       |
| _MeanReward     | 3.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72474     |
| _max_adv        | 22.8        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.13        |
| _mean_act       | 0.0677358   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0385      |
| _min_adv        | -16.4       |
| _min_discrew    | 0.0129      |
| _min_obs        | -1.18       |
| _std_act        | 0.690049    |
| _std_adv        | 1           |
| _std_discrew    | 0.995       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00152671  |
| Phi_loss        | 873.394     |
| PolicyEntropy   | 0.301919    |
| PolicyLoss      | -0.00197083 |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 4.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7638      |
| _max_adv        | 6.69        |
| _max_discrew    | 4.27        |
| _max_obs        | 1.11        |
| _mean_act       | 0.0698556   |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 3.3         |
| _mean_obs       | 0.0387      |
| _min_adv        | -4.43       |
| _min_discrew    | 0.0152      |
| _min_obs        | -1.28       |
| _std_act        | 0.69477     |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00255233 |
| Phi_loss        | 763.079    |
| PolicyEntropy   | 0.294707   |
| PolicyLoss      | -0.0225984 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00587    |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87257    |
| _max_adv        | 5.43       |
| _max_discrew    | 4.21       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0709877  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0391     |
| _min_adv        | -4.45      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.22      |
| _std_act        | 0.700493   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00200539 |
| Phi_loss        | 847.827    |
| PolicyEntropy   | 0.283676   |
| PolicyLoss      | -0.0096132 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00432    |
| _MeanReward     | 4.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05838    |
| _max_adv        | 9.47       |
| _max_discrew    | 4.32       |
| _max_obs        | 1.06       |
| _mean_act       | 0.0648181  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0386     |
| _min_adv        | -21.7      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.22      |
| _std_act        | 0.700817   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.985       |
| KL              | 0.000524479 |
| Phi_loss        | 584.148     |
| PolicyEntropy   | 0.281544    |
| PolicyLoss      | -0.00552885 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0133      |
| _MeanReward     | 4e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 2.94967     |
| _max_adv        | 4.9         |
| _max_discrew    | 4.32        |
| _max_obs        | 1.05        |
| _mean_act       | 0.0581762   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0385      |
| _min_adv        | -17         |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.23       |
| _std_act        | 0.703574    |
| _std_adv        | 1           |
| _std_discrew    | 1.09        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.000717372 |
| Phi_loss        | 769.756     |
| PolicyEntropy   | 0.263125    |
| PolicyLoss      | -0.00564405 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0176      |
| _MeanReward     | 4.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02095     |
| _max_adv        | 5.52        |
| _max_discrew    | 4.39        |
| _max_obs        | 1.04        |
| _mean_act       | 0.0674438   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 3.38        |
| _mean_obs       | 0.0396      |
| _min_adv        | -3.93       |
| _min_discrew    | 0.0139      |
| _min_obs        | -1.15       |
| _std_act        | 0.70314     |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00186631 |
| Phi_loss        | 856.093    |
| PolicyEntropy   | 0.237353   |
| PolicyLoss      | -0.0235772 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00665    |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92139    |
| _max_adv        | 1.88       |
| _max_discrew    | 4.36       |
| _max_obs        | 1.62       |
| _mean_act       | 0.0283555  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0361     |
| _min_adv        | -17.6      |
| _min_discrew    | -0.837     |
| _min_obs        | -1.24      |
| _std_act        | 0.741977   |
| _std_adv        | 1          |
| _std_discrew    | 1.8        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
-------------------------------
| Beta            | 0.0799    |
| ExplainedVarNew | 0.905     |
| ExplainedVarOld | 0.882     |
| KL              | 0.0023782 |
| Phi_loss        | 720.198   |
| PolicyEntropy   | 0.228477  |
| PolicyLoss      | 0.0149354 |
| Steps           | 10000     |
| VarFuncLoss     | 0.174     |
| _MeanReward     | 4.12e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.84555   |
| _max_adv        | 6.75      |
| _max_discrew    | 4.41      |
| _max_obs        | 1.06      |
| _mean_act       | 0.0659127 |
| _mean_adv       | 8.53e-18  |
| _mean_discrew   | 3.38      |
| _mean_obs       | 0.0393    |
| _min_adv        | -4.57     |
| _min_discrew    | 0.0186    |
| _min_obs        | -1.18     |
| _std_act        | 0.713238  |
| _std_adv        | 1         |
| _std_discrew    | 1.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00222561 |
| Phi_loss        | 885.103    |
| PolicyEntropy   | 0.21196    |
| PolicyLoss      | -0.0051925 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00963    |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74658    |
| _max_adv        | 11.1       |
| _max_discrew    | 4.46       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0569401  |
| _mean_adv       | -9.24e-18  |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0391     |
| _min_adv        | -20.1      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.14      |
| _std_act        | 0.71136    |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
----------------------------------
| Beta            | 0.0799       |
| ExplainedVarNew | 0.984        |
| ExplainedVarOld | 0.978        |
| KL              | 0.00157355   |
| Phi_loss        | 581.958      |
| PolicyEntropy   | 0.197592     |
| PolicyLoss      | -0.000581744 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0179       |
| _MeanReward     | 4.16e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.81955      |
| _max_adv        | 5.51         |
| _max_discrew    | 4.42         |
| _max_obs        | 1.05         |
| _mean_act       | 0.0648836    |
| _mean_adv       | 3.69e-17     |
| _mean_discrew   | 3.43         |
| _mean_obs       | 0.0397       |
| _min_adv        | -4.41        |
| _min_discrew    | 0.0119       |
| _min_obs        | -1.07        |
| _std_act        | 0.708259     |
| _std_adv        | 1            |
| _std_discrew    | 1.14         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00342809 |
| Phi_loss        | 923.918    |
| PolicyEntropy   | 0.181836   |
| PolicyLoss      | -0.0275295 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00693    |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.99159    |
| _max_adv        | 8.2        |
| _max_discrew    | 4.51       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0627003  |
| _mean_adv       | -5.68e-17  |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0397     |
| _min_adv        | -5.49      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.19      |
| _std_act        | 0.718141   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
-------------------------------
| Beta            | 0.0799    |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.995     |
| KL              | 0.0030442 |
| Phi_loss        | 864.767   |
| PolicyEntropy   | 0.154113  |
| PolicyLoss      | 0.0247859 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00543   |
| _MeanReward     | 4.22e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.78982   |
| _max_adv        | 8.26      |
| _max_discrew    | 4.45      |
| _max_obs        | 1.06      |
| _mean_act       | 0.0590095 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.47      |
| _mean_obs       | 0.0394    |
| _min_adv        | -5.18     |
| _min_discrew    | 0.016     |
| _min_obs        | -1.17     |
| _std_act        | 0.71272   |
| _std_adv        | 1         |
| _std_discrew    | 1.14      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00282073 |
| Phi_loss        | 941.958    |
| PolicyEntropy   | 0.122895   |
| PolicyLoss      | -0.0187366 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00503    |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82034    |
| _max_adv        | 28.6       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0607991  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0396     |
| _min_adv        | -11.5      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.1       |
| _std_act        | 0.717529   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00236153 |
| Phi_loss        | 628.703    |
| PolicyEntropy   | 0.102301   |
| PolicyLoss      | -0.0301244 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00616    |
| _MeanReward     | 3.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83473    |
| _max_adv        | 4.03       |
| _max_discrew    | 4.53       |
| _max_obs        | 1.63       |
| _mean_act       | -0.0267687 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.06       |
| _mean_obs       | 0.0321     |
| _min_adv        | -21.1      |
| _min_discrew    | -1.04      |
| _min_obs        | -1.21      |
| _std_act        | 0.78815    |
| _std_adv        | 1          |
| _std_discrew    | 2.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.958      |
| KL              | 0.0140299  |
| Phi_loss        | 977.07     |
| PolicyEntropy   | 0.0786715  |
| PolicyLoss      | -0.0815256 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0956     |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74645    |
| _max_adv        | 11.5       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0601443  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.51       |
| _mean_obs       | 0.0399     |
| _min_adv        | -4.16      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.07      |
| _std_act        | 0.723192   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00318291 |
| Phi_loss        | 606.717    |
| PolicyEntropy   | 0.0468092  |
| PolicyLoss      | 0.00437332 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0103     |
| _MeanReward     | 4.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79679    |
| _max_adv        | 9.15       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0595686  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.52       |
| _mean_obs       | 0.0398     |
| _min_adv        | -5.97      |
| _min_discrew    | 0.0124     |
| _min_obs        | -1.16      |
| _std_act        | 0.713933   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00128573 |
| Phi_loss        | 848.994    |
| PolicyEntropy   | 0.0305576  |
| PolicyLoss      | 0.00223829 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00668    |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84725    |
| _max_adv        | 5.96       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0608776  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0402     |
| _min_adv        | -4.6       |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.26      |
| _std_act        | 0.715271   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00193007  |
| Phi_loss        | 954.55      |
| PolicyEntropy   | 0.00679493  |
| PolicyLoss      | -0.0206283  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00575     |
| _MeanReward     | 3.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.83275     |
| _max_adv        | 1.14        |
| _max_discrew    | 4.52        |
| _max_obs        | 1.66        |
| _mean_act       | -0.00880252 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.16        |
| _mean_obs       | 0.034       |
| _min_adv        | -18.8       |
| _min_discrew    | -0.989      |
| _min_obs        | -1.11       |
| _std_act        | 0.781692    |
| _std_adv        | 1           |
| _std_discrew    | 2.48        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.906       |
| KL              | 0.00549736  |
| Phi_loss        | 756.366     |
| PolicyEntropy   | -0.00374985 |
| PolicyLoss      | 0.0083071   |
| Steps           | 10000       |
| VarFuncLoss     | 0.215       |
| _MeanReward     | 4.21e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76424     |
| _max_adv        | 12.9        |
| _max_discrew    | 4.51        |
| _max_obs        | 1.01        |
| _mean_act       | 0.0550903   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.5         |
| _mean_obs       | 0.0394      |
| _min_adv        | -17.8       |
| _min_discrew    | 0.0109      |
| _min_obs        | -1.12       |
| _std_act        | 0.724793    |
| _std_adv        | 1           |
| _std_discrew    | 1.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.955       |
| KL              | 0.00144743  |
| Phi_loss        | 417.968     |
| PolicyEntropy   | -0.00561905 |
| PolicyLoss      | -0.0115874  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0297      |
| _MeanReward     | 4.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79821     |
| _max_adv        | 30.6        |
| _max_discrew    | 4.53        |
| _max_obs        | 1.02        |
| _mean_act       | 0.058746    |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.49        |
| _mean_obs       | 0.0398      |
| _min_adv        | -13.3       |
| _min_discrew    | 0.0118      |
| _min_obs        | -1.28       |
| _std_act        | 0.720198    |
| _std_adv        | 1           |
| _std_discrew    | 1.18        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.976      |
| KL              | 0.00201788 |
| Phi_loss        | 825.467    |
| PolicyEntropy   | -0.018424  |
| PolicyLoss      | 0.00360704 |
| Steps           | 10000      |
| VarFuncLoss     | 0.024      |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75482    |
| _max_adv        | 8.72       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0640805  |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0403     |
| _min_adv        | -4.5       |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.13      |
| _std_act        | 0.726959   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
----------------------------------
| Beta            | 0.0533       |
| ExplainedVarNew | 0.996        |
| ExplainedVarOld | 0.994        |
| KL              | 0.00363478   |
| Phi_loss        | 958.968      |
| PolicyEntropy   | -0.049283    |
| PolicyLoss      | -0.000705153 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00588      |
| _MeanReward     | 4.28e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.88059      |
| _max_adv        | 25.5         |
| _max_discrew    | 4.54         |
| _max_obs        | 1.06         |
| _mean_act       | 0.0612561    |
| _mean_adv       | 0            |
| _mean_discrew   | 3.53         |
| _mean_obs       | 0.0397       |
| _min_adv        | -9.08        |
| _min_discrew    | 0.0133       |
| _min_obs        | -1.16        |
| _std_act        | 0.716763     |
| _std_adv        | 1            |
| _std_discrew    | 1.18         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00175373 |
| Phi_loss        | 903.522    |
| PolicyEntropy   | -0.0768251 |
| PolicyLoss      | 0.0242596  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00605    |
| _MeanReward     | 4.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72624    |
| _max_adv        | 1.01       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.59       |
| _mean_act       | 0.00869162 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.036      |
| _min_adv        | -14.3      |
| _min_discrew    | -0.899     |
| _min_obs        | -1.11      |
| _std_act        | 0.766935   |
| _std_adv        | 1          |
| _std_discrew    | 2.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00317312 |
| Phi_loss        | 447.697    |
| PolicyEntropy   | -0.0607347 |
| PolicyLoss      | 0.0121036  |
| Steps           | 10000      |
| VarFuncLoss     | 0.207      |
| _MeanReward     | 4.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.7248     |
| _max_adv        | 11.8       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0597076  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0396     |
| _min_adv        | -4.32      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.15      |
| _std_act        | 0.718278   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00283583  |
| Phi_loss        | 866.952     |
| PolicyEntropy   | -0.0631723  |
| PolicyLoss      | -0.00882915 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00744     |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7835      |
| _max_adv        | 9.84        |
| _max_discrew    | 4.59        |
| _max_obs        | 0.999       |
| _mean_act       | 0.061594    |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0399      |
| _min_adv        | -7.24       |
| _min_discrew    | 0.0109      |
| _min_obs        | -1.25       |
| _std_act        | 0.717586    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00332125  |
| Phi_loss        | 931.397     |
| PolicyEntropy   | -0.0799971  |
| PolicyLoss      | -0.00226479 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00883     |
| _MeanReward     | 4.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8432      |
| _max_adv        | 11.8        |
| _max_discrew    | 4.65        |
| _max_obs        | 1.01        |
| _mean_act       | 0.0572059   |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.04        |
| _min_adv        | -6.02       |
| _min_discrew    | 0.0192      |
| _min_obs        | -1.07       |
| _std_act        | 0.722996    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.0039214  |
| Phi_loss        | 1046.1     |
| PolicyEntropy   | -0.0975771 |
| PolicyLoss      | 0.0113337  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00859    |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64011    |
| _max_adv        | 16.6       |
| _max_discrew    | 4.53       |
| _max_obs        | 1.67       |
| _mean_act       | 0.0440417  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0383     |
| _min_adv        | -14.2      |
| _min_discrew    | -0.309     |
| _min_obs        | -1.09      |
| _std_act        | 0.731426   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.935      |
| KL              | 0.00368724 |
| Phi_loss        | 604.479    |
| PolicyEntropy   | -0.119128  |
| PolicyLoss      | -0.010161  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0427     |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85754    |
| _max_adv        | 5.98       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0582832  |
| _mean_adv       | -3.06e-17  |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0401     |
| _min_adv        | -5.23      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.21      |
| _std_act        | 0.728803   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00260279  |
| Phi_loss        | 1003.51     |
| PolicyEntropy   | -0.142885   |
| PolicyLoss      | -0.00777806 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00645     |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79679     |
| _max_adv        | 9.2         |
| _max_discrew    | 4.59        |
| _max_obs        | 1.1         |
| _mean_act       | 0.0568817   |
| _mean_adv       | -1.85e-17   |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0403      |
| _min_adv        | -9.24       |
| _min_discrew    | 0.0153      |
| _min_obs        | -1.32       |
| _std_act        | 0.731654    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00303974  |
| Phi_loss        | 929.915     |
| PolicyEntropy   | -0.159955   |
| PolicyLoss      | -0.00755009 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00543     |
| _MeanReward     | 3.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78418     |
| _max_adv        | 3.64        |
| _max_discrew    | 4.67        |
| _max_obs        | 1.61        |
| _mean_act       | -0.0299785  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0324      |
| _min_adv        | -23.3       |
| _min_discrew    | -1.08       |
| _min_obs        | -1.11       |
| _std_act        | 0.79441     |
| _std_adv        | 1           |
| _std_discrew    | 2.8         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.972      |
| KL              | 0.00913332 |
| Phi_loss        | 811.916    |
| PolicyEntropy   | -0.141227  |
| PolicyLoss      | -0.0399572 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0577     |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09693    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.61       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0574255  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.04       |
| _min_adv        | -3.72      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.29      |
| _std_act        | 0.72183    |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00290646 |
| Phi_loss        | 951.789    |
| PolicyEntropy   | -0.174453  |
| PolicyLoss      | -0.017778  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00636    |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90227    |
| _max_adv        | 10.8       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0578497  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0406     |
| _min_adv        | -4.08      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.18      |
| _std_act        | 0.718795   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00250857 |
| Phi_loss        | 903.157    |
| PolicyEntropy   | -0.21272   |
| PolicyLoss      | 0.00782779 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00646    |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92235    |
| _max_adv        | 24.9       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0533155  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0397     |
| _min_adv        | -6.24      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.12      |
| _std_act        | 0.720286   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00219023  |
| Phi_loss        | 1171.45     |
| PolicyEntropy   | -0.240921   |
| PolicyLoss      | -0.00242427 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00633     |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81278     |
| _max_adv        | 6.66        |
| _max_discrew    | 4.62        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0538356   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.62        |
| _mean_obs       | 0.0402      |
| _min_adv        | -11.3       |
| _min_discrew    | 0.0129      |
| _min_obs        | -1.08       |
| _std_act        | 0.722552    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00213847 |
| Phi_loss        | 1150.1     |
| PolicyEntropy   | -0.27595   |
| PolicyLoss      | 0.00529523 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00503    |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.79813    |
| _max_adv        | 5.49       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0537104  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0401     |
| _min_adv        | -3.9       |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.03      |
| _std_act        | 0.724276   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00223792 |
| Phi_loss        | 1192.34    |
| PolicyEntropy   | -0.292423  |
| PolicyLoss      | 0.00487775 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00508    |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.99072    |
| _max_adv        | 6.24       |
| _max_discrew    | 4.67       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0529206  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0397     |
| _min_adv        | -5.27      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.08      |
| _std_act        | 0.713815   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.0055118   |
| Phi_loss        | 1186.21     |
| PolicyEntropy   | -0.313592   |
| PolicyLoss      | -0.00799318 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00701     |
| _MeanReward     | 4.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66809     |
| _max_adv        | 11.7        |
| _max_discrew    | 4.57        |
| _max_obs        | 1.01        |
| _mean_act       | 0.0469797   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.0391      |
| _min_adv        | -12.7       |
| _min_discrew    | 0.016       |
| _min_obs        | -1.18       |
| _std_act        | 0.712004    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00337202 |
| Phi_loss        | 739.715    |
| PolicyEntropy   | -0.352609  |
| PolicyLoss      | -0.0172627 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0475     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63915    |
| _max_adv        | 6.72       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0539537  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.0399     |
| _min_adv        | -5.39      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.12      |
| _std_act        | 0.714446   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00348898 |
| Phi_loss        | 1129.83    |
| PolicyEntropy   | -0.380657  |
| PolicyLoss      | -0.0058856 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00878    |
| _MeanReward     | 4.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60244    |
| _max_adv        | 11.1       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0555521  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0404     |
| _min_adv        | -7.03      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.18      |
| _std_act        | 0.722821   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00234419 |
| Phi_loss        | 1201.44    |
| PolicyEntropy   | -0.383369  |
| PolicyLoss      | -0.0302888 |
| Steps           | 10000      |
| VarFuncLoss     | 0.01       |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88975    |
| _max_adv        | 15.4       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.1        |
| _mean_act       | 0.0513499  |
| _mean_adv       | -1.07e-17  |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.04       |
| _min_adv        | -18.4      |
| _min_discrew    | 0.0184     |
| _min_obs        | -1.16      |
| _std_act        | 0.724894   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00253379 |
| Phi_loss        | 1278.57    |
| PolicyEntropy   | -0.391349  |
| PolicyLoss      | -0.0217545 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0369     |
| _MeanReward     | 3.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75208    |
| _max_adv        | 5.16       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.68       |
| _mean_act       | -0.0158637 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0338     |
| _min_adv        | -16.3      |
| _min_discrew    | -0.999     |
| _min_obs        | -1.1       |
| _std_act        | 0.784245   |
| _std_adv        | 1          |
| _std_discrew    | 2.52       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.889      |
| KL              | 0.0127005  |
| Phi_loss        | 1098.72    |
| PolicyEntropy   | -0.40979   |
| PolicyLoss      | 0.0449275  |
| Steps           | 10000      |
| VarFuncLoss     | 0.265      |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73399    |
| _max_adv        | 4.66       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.62       |
| _mean_act       | 0.00968314 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0361     |
| _min_adv        | -17.7      |
| _min_discrew    | -0.914     |
| _min_obs        | -1.13      |
| _std_act        | 0.764175   |
| _std_adv        | 1          |
| _std_discrew    | 2.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.893      |
| KL              | 0.00187029 |
| Phi_loss        | 1174.65    |
| PolicyEntropy   | -0.424056  |
| PolicyLoss      | 0.00771934 |
| Steps           | 10000      |
| VarFuncLoss     | 0.223      |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67803    |
| _max_adv        | 13.9       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0591076  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0403     |
| _min_adv        | -4.93      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.09      |
| _std_act        | 0.719322   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00154392  |
| Phi_loss        | 1080.46     |
| PolicyEntropy   | -0.4468     |
| PolicyLoss      | -0.00267801 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0104      |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69084     |
| _max_adv        | 6.16        |
| _max_discrew    | 4.67        |
| _max_obs        | 1.05        |
| _mean_act       | 0.0568903   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0401      |
| _min_adv        | -7.07       |
| _min_discrew    | 0.015       |
| _min_obs        | -1.1        |
| _std_act        | 0.723736    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00458965 |
| Phi_loss        | 1406.5     |
| PolicyEntropy   | -0.468928  |
| PolicyLoss      | 0.0180801  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00678    |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.72474    |
| _max_adv        | 11.9       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.07       |
| _mean_act       | 0.0520532  |
| _mean_adv       | -7.11e-18  |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0399     |
| _min_adv        | -19.5      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.31      |
| _std_act        | 0.720309   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.973      |
| KL              | 0.0039534  |
| Phi_loss        | 740.636    |
| PolicyEntropy   | -0.469367  |
| PolicyLoss      | -0.0178431 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 3.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70157    |
| _max_adv        | 11.6       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.64       |
| _mean_act       | -0.0200288 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.0333     |
| _min_adv        | -17.7      |
| _min_discrew    | -1.02      |
| _min_obs        | -1.13      |
| _std_act        | 0.778787   |
| _std_adv        | 1          |
| _std_discrew    | 2.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
-------------------------------
| Beta            | 0.18      |
| ExplainedVarNew | 0.908     |
| ExplainedVarOld | 0.892     |
| KL              | 0.0127043 |
| Phi_loss        | 1308.18   |
| PolicyEntropy   | -0.473469 |
| PolicyLoss      | -0.164632 |
| Steps           | 10000     |
| VarFuncLoss     | 0.245     |
| _MeanReward     | 4.35e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.882     |
| _max_adv        | 3.93      |
| _max_discrew    | 4.71      |
| _max_obs        | 1.73      |
| _mean_act       | 0.0473982 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.57      |
| _mean_obs       | 0.0393    |
| _min_adv        | -18.6     |
| _min_discrew    | -0.413    |
| _min_obs        | -1.12     |
| _std_act        | 0.726187  |
| _std_adv        | 1         |
| _std_discrew    | 1.46      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.949      |
| KL              | 0.00278569 |
| Phi_loss        | 1234.0     |
| PolicyEntropy   | -0.47861   |
| PolicyLoss      | 0.00635935 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0687     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79266    |
| _max_adv        | 8.25       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.69       |
| _mean_act       | 0.0215556  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.0364     |
| _min_adv        | -16.6      |
| _min_discrew    | -0.844     |
| _min_obs        | -1.26      |
| _std_act        | 0.749686   |
| _std_adv        | 1          |
| _std_discrew    | 1.94       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.883      |
| KL              | 0.00110775 |
| Phi_loss        | 1078.96    |
| PolicyEntropy   | -0.485682  |
| PolicyLoss      | -0.0232334 |
| Steps           | 10000      |
| VarFuncLoss     | 0.201      |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65012    |
| _max_adv        | 17.2       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0568147  |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0397     |
| _min_adv        | -19.9      |
| _min_discrew    | 0.0189     |
| _min_obs        | -1.1       |
| _std_act        | 0.711356   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00223146  |
| Phi_loss        | 636.743     |
| PolicyEntropy   | -0.495437   |
| PolicyLoss      | -0.00251488 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0169      |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96597     |
| _max_adv        | 10.3        |
| _max_discrew    | 4.67        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0599175   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0405      |
| _min_adv        | -11.2       |
| _min_discrew    | 0.0143      |
| _min_obs        | -1.22       |
| _std_act        | 0.718688    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00309378  |
| Phi_loss        | 1131.22     |
| PolicyEntropy   | -0.494776   |
| PolicyLoss      | -0.00174728 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71853     |
| _max_adv        | 16.3        |
| _max_discrew    | 4.69        |
| _max_obs        | 1           |
| _mean_act       | 0.0527201   |
| _mean_adv       | -2.13e-18   |
| _mean_discrew   | 3.6         |
| _mean_obs       | 0.0392      |
| _min_adv        | -15.6       |
| _min_discrew    | 0.0149      |
| _min_obs        | -1.16       |
| _std_act        | 0.714908    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.967      |
| KL              | 0.0023661  |
| Phi_loss        | 1078.19    |
| PolicyEntropy   | -0.495861  |
| PolicyLoss      | -0.0057577 |
| Steps           | 10000      |
| VarFuncLoss     | 0.037      |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66569    |
| _max_adv        | 3.49       |
| _max_discrew    | 4.75       |
| _max_obs        | 1.63       |
| _mean_act       | 0.00503544 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0355     |
| _min_adv        | -19        |
| _min_discrew    | -0.988     |
| _min_obs        | -1.24      |
| _std_act        | 0.757964   |
| _std_adv        | 1          |
| _std_discrew    | 2.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.887      |
| ExplainedVarOld | 0.881      |
| KL              | 0.00783364 |
| Phi_loss        | 1708.74    |
| PolicyEntropy   | -0.500676  |
| PolicyLoss      | -0.0398472 |
| Steps           | 10000      |
| VarFuncLoss     | 0.257      |
| _MeanReward     | 4.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78562    |
| _max_adv        | 9.54       |
| _max_discrew    | 4.72       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0592679  |
| _mean_adv       | -3.69e-17  |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0398     |
| _min_adv        | -7.23      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.09      |
| _std_act        | 0.714092   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00168221  |
| Phi_loss        | 1374.79     |
| PolicyEntropy   | -0.504086   |
| PolicyLoss      | -0.00439671 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0113      |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76388     |
| _max_adv        | 6.04        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.01        |
| _mean_act       | 0.0614331   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0401      |
| _min_adv        | -5.16       |
| _min_discrew    | 0.0195      |
| _min_obs        | -1.15       |
| _std_act        | 0.714081    |
| _std_adv        | 1           |
| _std_discrew    | 1.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00226956 |
| Phi_loss        | 1328.16    |
| PolicyEntropy   | -0.515365  |
| PolicyLoss      | 0.0342321  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00726    |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83584    |
| _max_adv        | 5.02       |
| _max_discrew    | 4.62       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0589671  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0394     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.13      |
| _std_act        | 0.703151   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00257276 |
| Phi_loss        | 1391.68    |
| PolicyEntropy   | -0.533716  |
| PolicyLoss      | -0.0114519 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00627    |
| _MeanReward     | 4.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72307    |
| _max_adv        | 28.8       |
| _max_discrew    | 4.8        |
| _max_obs        | 0.999      |
| _mean_act       | 0.059247   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0397     |
| _min_adv        | -14.5      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.11      |
| _std_act        | 0.713807   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00202934 |
| Phi_loss        | 955.525    |
| PolicyEntropy   | -0.552568  |
| PolicyLoss      | -0.012673  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67957    |
| _max_adv        | 9.08       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0623921  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0405     |
| _min_adv        | -6.34      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.08      |
| _std_act        | 0.708553   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00200247 |
| Phi_loss        | 1315.64    |
| PolicyEntropy   | -0.572242  |
| PolicyLoss      | 0.0202629  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00602    |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.61193    |
| _max_adv        | 4.98       |
| _max_discrew    | 4.76       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0609246  |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.72      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.29      |
| _std_act        | 0.714805   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00260128 |
| Phi_loss        | 1497.63    |
| PolicyEntropy   | -0.596192  |
| PolicyLoss      | 0.0253963  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00625    |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71109    |
| _max_adv        | 7.99       |
| _max_discrew    | 4.79       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0563878  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0398     |
| _min_adv        | -19.9      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.15      |
| _std_act        | 0.712562   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00209327  |
| Phi_loss        | 675.72      |
| PolicyEntropy   | -0.60073    |
| PolicyLoss      | -0.00363686 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0147      |
| _MeanReward     | 4.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.53505     |
| _max_adv        | 8.4         |
| _max_discrew    | 4.7         |
| _max_obs        | 1.05        |
| _mean_act       | 0.0615178   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.69        |
| _mean_obs       | 0.04        |
| _min_adv        | -8.3        |
| _min_discrew    | 0.0129      |
| _min_obs        | -1.1        |
| _std_act        | 0.71387     |
| _std_adv        | 1           |
| _std_discrew    | 1.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00163498  |
| Phi_loss        | 1354.72     |
| PolicyEntropy   | -0.624104   |
| PolicyLoss      | -0.00817854 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00629     |
| _MeanReward     | 4.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.63433     |
| _max_adv        | 8.53        |
| _max_discrew    | 4.78        |
| _max_obs        | 1.04        |
| _mean_act       | 0.0610783   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.7         |
| _mean_obs       | 0.0404      |
| _min_adv        | -5.64       |
| _min_discrew    | 0.0156      |
| _min_obs        | -1.07       |
| _std_act        | 0.714978    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00181522 |
| Phi_loss        | 1376.56    |
| PolicyEntropy   | -0.635155  |
| PolicyLoss      | -0.0240969 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00559    |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70927    |
| _max_adv        | 6.43       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.07       |
| _mean_act       | 0.061894   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.04       |
| _min_adv        | -4.68      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.09      |
| _std_act        | 0.712176   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00197939 |
| Phi_loss        | 1619.51    |
| PolicyEntropy   | -0.642043  |
| PolicyLoss      | -0.0175729 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00825    |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60301    |
| _max_adv        | 8.51       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.06       |
| _mean_act       | 0.0637292  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0407     |
| _min_adv        | -5.07      |
| _min_discrew    | 0.0132     |
| _min_obs        | -1.32      |
| _std_act        | 0.718454   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00182391 |
| Phi_loss        | 1500.13    |
| PolicyEntropy   | -0.657245  |
| PolicyLoss      | -0.0088212 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00654    |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91796    |
| _max_adv        | 4.47       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.03       |
| _mean_act       | 0.05995    |
| _mean_adv       | 1.85e-17   |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0402     |
| _min_adv        | -6.48      |
| _min_discrew    | 0.0201     |
| _min_obs        | -1.13      |
| _std_act        | 0.718406   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00200034 |
| Phi_loss        | 1403.11    |
| PolicyEntropy   | -0.683793  |
| PolicyLoss      | -0.0262892 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00699    |
| _MeanReward     | 4.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59731    |
| _max_adv        | 6.21       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0603557  |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0407     |
| _min_adv        | -15.6      |
| _min_discrew    | 0.0139     |
| _min_obs        | -1.06      |
| _std_act        | 0.722282   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00225316 |
| Phi_loss        | 1717.09    |
| PolicyEntropy   | -0.706094  |
| PolicyLoss      | 0.00385375 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0201     |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66518    |
| _max_adv        | 0.964      |
| _max_discrew    | 4.77       |
| _max_obs        | 1.65       |
| _mean_act       | 0.0165231  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0369     |
| _min_adv        | -17.9      |
| _min_discrew    | -0.954     |
| _min_obs        | -1.24      |
| _std_act        | 0.763837   |
| _std_adv        | 1          |
| _std_discrew    | 2.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.89        |
| ExplainedVarOld | 0.875       |
| KL              | 0.00198783  |
| Phi_loss        | 978.269     |
| PolicyEntropy   | -0.70698    |
| PolicyLoss      | -0.00657501 |
| Steps           | 10000       |
| VarFuncLoss     | 0.25        |
| _MeanReward     | 4.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59497     |
| _max_adv        | 14.5        |
| _max_discrew    | 4.76        |
| _max_obs        | 1.1         |
| _mean_act       | 0.054967    |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.68        |
| _mean_obs       | 0.0399      |
| _min_adv        | -17.4       |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.04       |
| _std_act        | 0.713963    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
-------------------------------
| Beta            | 0.18      |
| ExplainedVarNew | 0.958     |
| ExplainedVarOld | 0.952     |
| KL              | 0.0026545 |
| Phi_loss        | 1027.27   |
| PolicyEntropy   | -0.730211 |
| PolicyLoss      | 0.001638  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0564    |
| _MeanReward     | 4.48e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.89859   |
| _max_adv        | 23.9      |
| _max_discrew    | 4.85      |
| _max_obs        | 1.15      |
| _mean_act       | 0.061644  |
| _mean_adv       | -7.11e-18 |
| _mean_discrew   | 3.69      |
| _mean_obs       | 0.0399    |
| _min_adv        | -12.7     |
| _min_discrew    | 0.0145    |
| _min_obs        | -1.13     |
| _std_act        | 0.709723  |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.975       |
| KL              | 0.000964785 |
| Phi_loss        | 982.506     |
| PolicyEntropy   | -0.740211   |
| PolicyLoss      | -0.0255089  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0249      |
| _MeanReward     | 4.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68652     |
| _max_adv        | 8.58        |
| _max_discrew    | 4.72        |
| _max_obs        | 1           |
| _mean_act       | 0.0628071   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.69        |
| _mean_obs       | 0.04        |
| _min_adv        | -5.89       |
| _min_discrew    | 0.0151      |
| _min_obs        | -1.16       |
| _std_act        | 0.716373    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00356458 |
| Phi_loss        | 1572.92    |
| PolicyEntropy   | -0.765367  |
| PolicyLoss      | -0.0311589 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00782    |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76028    |
| _max_adv        | 10.7       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0641271  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0402     |
| _min_adv        | -4.67      |
| _min_discrew    | 0.013      |
| _min_obs        | -1.1       |
| _std_act        | 0.71977    |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00418158 |
| Phi_loss        | 1524.99    |
| PolicyEntropy   | -0.792697  |
| PolicyLoss      | -0.0233775 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00522    |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62082    |
| _max_adv        | 5.01       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.65       |
| _mean_act       | 0.0124154  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0361     |
| _min_adv        | -18.9      |
| _min_discrew    | -0.949     |
| _min_obs        | -1.11      |
| _std_act        | 0.771498   |
| _std_adv        | 1          |
| _std_discrew    | 2.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.893      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00842691 |
| Phi_loss        | 1361.05    |
| PolicyEntropy   | -0.788407  |
| PolicyLoss      | -0.100315  |
| Steps           | 10000      |
| VarFuncLoss     | 0.238      |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57837    |
| _max_adv        | 9.76       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.06       |
| _mean_act       | 0.0599535  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0402     |
| _min_adv        | -4.95      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.1       |
| _std_act        | 0.71975    |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00192173 |
| Phi_loss        | 1605.6     |
| PolicyEntropy   | -0.804046  |
| PolicyLoss      | 0.0124293  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0127     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.66004    |
| _max_adv        | 37.6       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0579822  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0399     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.11      |
| _std_act        | 0.720418   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00241314 |
| Phi_loss        | 1119.13    |
| PolicyEntropy   | -0.810975  |
| PolicyLoss      | 0.0213342  |
| Steps           | 10000      |
| VarFuncLoss     | 0.019      |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76618    |
| _max_adv        | 1.34       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.65       |
| _mean_act       | -0.0394561 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0317     |
| _min_adv        | -15.6      |
| _min_discrew    | -1.2       |
| _min_obs        | -1.23      |
| _std_act        | 0.800969   |
| _std_adv        | 1          |
| _std_discrew    | 3.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.933       |
| ExplainedVarOld | 0.905       |
| KL              | 0.00379011  |
| Phi_loss        | 995.004     |
| PolicyEntropy   | -0.815298   |
| PolicyLoss      | -0.00791953 |
| Steps           | 10000       |
| VarFuncLoss     | 0.202       |
| _MeanReward     | 4.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.63472     |
| _max_adv        | 13.5        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.64        |
| _mean_act       | 0.0468555   |
| _mean_adv       | 8.88e-18    |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.039       |
| _min_adv        | -14.5       |
| _min_discrew    | -0.327      |
| _min_obs        | -1.15       |
| _std_act        | 0.726941    |
| _std_adv        | 1           |
| _std_discrew    | 1.45        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.938       |
| KL              | 0.00233881  |
| Phi_loss        | 1052.88     |
| PolicyEntropy   | -0.820916   |
| PolicyLoss      | -0.00124386 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0762      |
| _MeanReward     | 4.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54981     |
| _max_adv        | 7.8         |
| _max_discrew    | 4.74        |
| _max_obs        | 0.999       |
| _mean_act       | 0.0428411   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.62        |
| _mean_obs       | 0.0379      |
| _min_adv        | -13.8       |
| _min_discrew    | 0.0149      |
| _min_obs        | -1.11       |
| _std_act        | 0.728132    |
| _std_adv        | 1           |
| _std_discrew    | 1.39        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00159095 |
| Phi_loss        | 1251.22    |
| PolicyEntropy   | -0.816737  |
| PolicyLoss      | 0.012599   |
| Steps           | 10000      |
| VarFuncLoss     | 0.069      |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65365    |
| _max_adv        | 3.34       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.66       |
| _mean_act       | 0.0248301  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0376     |
| _min_adv        | -18.2      |
| _min_discrew    | -0.883     |
| _min_obs        | -1.04      |
| _std_act        | 0.757007   |
| _std_adv        | 1          |
| _std_discrew    | 2.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.889      |
| KL              | 0.00800099 |
| Phi_loss        | 1060.75    |
| PolicyEntropy   | -0.817233  |
| PolicyLoss      | 0.00960528 |
| Steps           | 10000      |
| VarFuncLoss     | 0.204      |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47639    |
| _max_adv        | 6.3        |
| _max_discrew    | 4.78       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0613101  |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0403     |
| _min_adv        | -4.46      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.13      |
| _std_act        | 0.728756   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00132345 |
| Phi_loss        | 1216.56    |
| PolicyEntropy   | -0.822937  |
| PolicyLoss      | 0.0224372  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00906    |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64109    |
| _max_adv        | 2.19       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.66       |
| _mean_act       | 0.00306552 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0348     |
| _min_adv        | -20.4      |
| _min_discrew    | -1.1       |
| _min_obs        | -1.14      |
| _std_act        | 0.777708   |
| _std_adv        | 1          |
| _std_discrew    | 2.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.894      |
| ExplainedVarOld | 0.891      |
| KL              | 0.00508867 |
| Phi_loss        | 1597.92    |
| PolicyEntropy   | -0.836027  |
| PolicyLoss      | 0.0111548  |
| Steps           | 10000      |
| VarFuncLoss     | 0.258      |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57174    |
| _max_adv        | 2.24       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.64       |
| _mean_act       | -0.0256159 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.31       |
| _mean_obs       | 0.0335     |
| _min_adv        | -19.9      |
| _min_discrew    | -1.21      |
| _min_obs        | -1.14      |
| _std_act        | 0.801822   |
| _std_adv        | 1          |
| _std_discrew    | 2.99       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.918      |
| KL              | 0.00278309 |
| Phi_loss        | 1394.97    |
| PolicyEntropy   | -0.834659  |
| PolicyLoss      | -0.0235753 |
| Steps           | 10000      |
| VarFuncLoss     | 0.231      |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58539    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0462983  |
| _mean_adv       | 8.88e-18   |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0383     |
| _min_adv        | -17.5      |
| _min_discrew    | 0.0166     |
| _min_obs        | -1.1       |
| _std_act        | 0.721177   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00223638 |
| Phi_loss        | 1214.51    |
| PolicyEntropy   | -0.836679  |
| PolicyLoss      | -0.0232778 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0375     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56476    |
| _max_adv        | 21.2       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.05       |
| _mean_act       | 0.057632   |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0396     |
| _min_adv        | -3.73      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.09      |
| _std_act        | 0.718678   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00300471 |
| Phi_loss        | 1192.34    |
| PolicyEntropy   | -0.847069  |
| PolicyLoss      | 0.017778   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00648    |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44634    |
| _max_adv        | 12.1       |
| _max_discrew    | 4.8        |
| _max_obs        | 0.999      |
| _mean_act       | 0.058236   |
| _mean_adv       | 0          |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0396     |
| _min_adv        | -5.22      |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.1       |
| _std_act        | 0.717937   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.992       |
| KL              | 0.0021415   |
| Phi_loss        | 1161.26     |
| PolicyEntropy   | -0.866907   |
| PolicyLoss      | -0.00593648 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00769     |
| _MeanReward     | 4.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.5877      |
| _max_adv        | 13.3        |
| _max_discrew    | 4.81        |
| _max_obs        | 1.68        |
| _mean_act       | 0.00313006  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.42        |
| _mean_obs       | 0.035       |
| _min_adv        | -18.7       |
| _min_discrew    | -1.07       |
| _min_obs        | -1.12       |
| _std_act        | 0.768872    |
| _std_adv        | 1           |
| _std_discrew    | 2.32        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
-------------------------------
| Beta            | 0.27      |
| ExplainedVarNew | 0.893     |
| ExplainedVarOld | 0.884     |
| KL              | 0.012157  |
| Phi_loss        | 2085.44   |
| PolicyEntropy   | -0.87667  |
| PolicyLoss      | 0.155823  |
| Steps           | 10000     |
| VarFuncLoss     | 0.251     |
| _MeanReward     | 4.55e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.66115   |
| _max_adv        | 6.58      |
| _max_discrew    | 4.85      |
| _max_obs        | 0.999     |
| _mean_act       | 0.0579365 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.75      |
| _mean_obs       | 0.0393    |
| _min_adv        | -5.06     |
| _min_discrew    | 0.0124    |
| _min_obs        | -1.08     |
| _std_act        | 0.715883  |
| _std_adv        | 1         |
| _std_discrew    | 1.33      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.992       |
| KL              | 0.00196242  |
| Phi_loss        | 1494.87     |
| PolicyEntropy   | -0.902272   |
| PolicyLoss      | -0.00224304 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0145      |
| _MeanReward     | 4.55e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.44655     |
| _max_adv        | 10.8        |
| _max_discrew    | 4.8         |
| _max_obs        | 1.06        |
| _mean_act       | 0.0582947   |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0396      |
| _min_adv        | -7.39       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.08       |
| _std_act        | 0.716074    |
| _std_adv        | 1           |
| _std_discrew    | 1.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.991       |
| KL              | 0.000857597 |
| Phi_loss        | 1320.64     |
| PolicyEntropy   | -0.924354   |
| PolicyLoss      | 0.0134259   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00597     |
| _MeanReward     | 4.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56983     |
| _max_adv        | 8.84        |
| _max_discrew    | 4.87        |
| _max_obs        | 1.05        |
| _mean_act       | 0.0570981   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0395      |
| _min_adv        | -7.04       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.02       |
| _std_act        | 0.711592    |
| _std_adv        | 1           |
| _std_discrew    | 1.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00281812 |
| Phi_loss        | 1705.51    |
| PolicyEntropy   | -0.94164   |
| PolicyLoss      | 0.0177525  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00627    |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55332    |
| _max_adv        | 18.6       |
| _max_discrew    | 4.86       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0538061  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0393     |
| _min_adv        | -14.3      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.24      |
| _std_act        | 0.711161   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00199879 |
| Phi_loss        | 1483.43    |
| PolicyEntropy   | -0.964408  |
| PolicyLoss      | -0.0296368 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0221     |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43013    |
| _max_adv        | 7.16       |
| _max_discrew    | 4.8        |
| _max_obs        | 0.999      |
| _mean_act       | 0.0466502  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0379     |
| _min_adv        | -18.8      |
| _min_discrew    | 0.0172     |
| _min_obs        | -1.25      |
| _std_act        | 0.708642   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00546077 |
| Phi_loss        | 917.839    |
| PolicyEntropy   | -1.00482   |
| PolicyLoss      | 0.0568711  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5246     |
| _max_adv        | 17.1       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0543525  |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0394     |
| _min_adv        | -13.4      |
| _min_discrew    | 0.0201     |
| _min_obs        | -1.1       |
| _std_act        | 0.714412   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00213569 |
| Phi_loss        | 1595.2     |
| PolicyEntropy   | -1.02855   |
| PolicyLoss      | -0.0100869 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00799    |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.56887    |
| _max_adv        | 6.83       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0559459  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0393     |
| _min_adv        | -6.07      |
| _min_discrew    | 0.0212     |
| _min_obs        | -1.09      |
| _std_act        | 0.719288   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00311187 |
| Phi_loss        | 1663.92    |
| PolicyEntropy   | -1.05497   |
| PolicyLoss      | -0.0129192 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00671    |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.50561    |
| _max_adv        | 5.32       |
| _max_discrew    | 4.96       |
| _max_obs        | 0.999      |
| _mean_act       | 0.056072   |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0393     |
| _min_adv        | -4.97      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.09      |
| _std_act        | 0.714642   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00245587 |
| Phi_loss        | 1695.83    |
| PolicyEntropy   | -1.08007   |
| PolicyLoss      | -0.0183921 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00532    |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64113    |
| _max_adv        | 15.3       |
| _max_discrew    | 4.91       |
| _max_obs        | 0.999      |
| _mean_act       | 0.056639   |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0396     |
| _min_adv        | -11.6      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.12      |
| _std_act        | 0.713419   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.0024517  |
| Phi_loss        | 1706.78    |
| PolicyEntropy   | -1.09095   |
| PolicyLoss      | 0.00990702 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 4.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70018    |
| _max_adv        | 1.83       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.7        |
| _mean_act       | -0.0248064 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.0326     |
| _min_adv        | -19.8      |
| _min_discrew    | -1.11      |
| _min_obs        | -1.16      |
| _std_act        | 0.786623   |
| _std_adv        | 1          |
| _std_discrew    | 2.94       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.92       |
| KL              | 0.0067995  |
| Phi_loss        | 1702.14    |
| PolicyEntropy   | -1.1187    |
| PolicyLoss      | -0.0471678 |
| Steps           | 10000      |
| VarFuncLoss     | 0.213      |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.6253     |
| _max_adv        | 7.3        |
| _max_discrew    | 4.8        |
| _max_obs        | 1.02       |
| _mean_act       | 0.055163   |
| _mean_adv       | -4.83e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0392     |
| _min_adv        | -5.91      |
| _min_discrew    | 0.0124     |
| _min_obs        | -1.03      |
| _std_act        | 0.71376    |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00174268 |
| Phi_loss        | 1696.19    |
| PolicyEntropy   | -1.14275   |
| PolicyLoss      | 0.00464658 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0106     |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49394    |
| _max_adv        | 1.31       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.67       |
| _mean_act       | -0.0257432 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.35       |
| _mean_obs       | 0.0326     |
| _min_adv        | -21.8      |
| _min_discrew    | -1.12      |
| _min_obs        | -1.13      |
| _std_act        | 0.789278   |
| _std_adv        | 1          |
| _std_discrew    | 3.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.93       |
| ExplainedVarOld | 0.93       |
| KL              | 0.00191233 |
| Phi_loss        | 3103.63    |
| PolicyEntropy   | -1.16432   |
| PolicyLoss      | 0.0418014  |
| Steps           | 10000      |
| VarFuncLoss     | 0.213      |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49778    |
| _max_adv        | 17.1       |
| _max_discrew    | 4.93       |
| _max_obs        | 1          |
| _mean_act       | 0.0497931  |
| _mean_adv       | 3.06e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0387     |
| _min_adv        | -12.8      |
| _min_discrew    | 0.0192     |
| _min_obs        | -1.07      |
| _std_act        | 0.71263    |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.957       |
| KL              | 0.00137492  |
| Phi_loss        | 1374.11     |
| PolicyEntropy   | -1.17516    |
| PolicyLoss      | -0.00993472 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0384      |
| _MeanReward     | 4.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51526     |
| _max_adv        | 6.48        |
| _max_discrew    | 4.9         |
| _max_obs        | 0.999       |
| _mean_act       | 0.0527882   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.77        |
| _mean_obs       | 0.0389      |
| _min_adv        | -4.95       |
| _min_discrew    | 0.0153      |
| _min_obs        | -1.12       |
| _std_act        | 0.709527    |
| _std_adv        | 1           |
| _std_discrew    | 1.35        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00253153  |
| Phi_loss        | 1345.38     |
| PolicyEntropy   | -1.19623    |
| PolicyLoss      | -0.00844527 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00725     |
| _MeanReward     | 4.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.63478     |
| _max_adv        | 4.75        |
| _max_discrew    | 4.84        |
| _max_obs        | 0.999       |
| _mean_act       | 0.0538513   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0389      |
| _min_adv        | -8.75       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.13       |
| _std_act        | 0.712584    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00417446 |
| Phi_loss        | 1996.32    |
| PolicyEntropy   | -1.22136   |
| PolicyLoss      | -0.0143584 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00539    |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59466    |
| _max_adv        | 12.5       |
| _max_discrew    | 4.86       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0535779  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.039      |
| _min_adv        | -7.45      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.14      |
| _std_act        | 0.711074   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00215531 |
| Phi_loss        | 2087.74    |
| PolicyEntropy   | -1.24716   |
| PolicyLoss      | 0.00252911 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00588    |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43141    |
| _max_adv        | 14.2       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0437044  |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0383     |
| _min_adv        | -21.1      |
| _min_discrew    | 0.0185     |
| _min_obs        | -1.07      |
| _std_act        | 0.72188    |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00263333 |
| Phi_loss        | 1080.04    |
| PolicyEntropy   | -1.25628   |
| PolicyLoss      | 0.0066973  |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47701    |
| _max_adv        | 11.2       |
| _max_discrew    | 4.87       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0502307  |
| _mean_adv       | 9.24e-18   |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0387     |
| _min_adv        | -20.5      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.06      |
| _std_act        | 0.72529    |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00210658 |
| Phi_loss        | 1106.08    |
| PolicyEntropy   | -1.2602    |
| PolicyLoss      | 0.0261444  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0127     |
| _MeanReward     | 4.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52659    |
| _max_adv        | 3.72       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.7        |
| _mean_act       | -0.0296928 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0317     |
| _min_adv        | -18.7      |
| _min_discrew    | -1.08      |
| _min_obs        | -1.13      |
| _std_act        | 0.785355   |
| _std_adv        | 1          |
| _std_discrew    | 3.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
-------------------------------
| Beta            | 0.27      |
| ExplainedVarNew | 0.935     |
| ExplainedVarOld | 0.916     |
| KL              | 0.015483  |
| Phi_loss        | 1900.63   |
| PolicyEntropy   | -1.28586  |
| PolicyLoss      | -0.300687 |
| Steps           | 10000     |
| VarFuncLoss     | 0.195     |
| _MeanReward     | 4.64e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.39434   |
| _max_adv        | 9.54      |
| _max_discrew    | 4.92      |
| _max_obs        | 1.01      |
| _mean_act       | 0.0509218 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.82      |
| _mean_obs       | 0.0389    |
| _min_adv        | -7.98     |
| _min_discrew    | 0.0144    |
| _min_obs        | -1.07     |
| _std_act        | 0.719349  |
| _std_adv        | 1         |
| _std_discrew    | 1.38      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00166299  |
| Phi_loss        | 1811.26     |
| PolicyEntropy   | -1.31605    |
| PolicyLoss      | -0.0326088  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0123      |
| _MeanReward     | 4.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.41904     |
| _max_adv        | 4.25        |
| _max_discrew    | 4.81        |
| _max_obs        | 1.66        |
| _mean_act       | -0.00541663 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.46        |
| _mean_obs       | 0.0343      |
| _min_adv        | -17.2       |
| _min_discrew    | -1.07       |
| _min_obs        | -1.09       |
| _std_act        | 0.782638    |
| _std_adv        | 1           |
| _std_discrew    | 2.53        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.885      |
| KL              | 0.0014962  |
| Phi_loss        | 1193.12    |
| PolicyEntropy   | -1.31166   |
| PolicyLoss      | -0.0501708 |
| Steps           | 10000      |
| VarFuncLoss     | 0.261      |
| _MeanReward     | 4.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46289    |
| _max_adv        | 42.6       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0486552  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0389     |
| _min_adv        | -6.29      |
| _min_discrew    | 0.0208     |
| _min_obs        | -1.2       |
| _std_act        | 0.715398   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00645885 |
| Phi_loss        | 2874.83    |
| PolicyEntropy   | -1.29904   |
| PolicyLoss      | 0.00623271 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0204     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62366    |
| _max_adv        | 11.2       |
| _max_discrew    | 4.91       |
| _max_obs        | 1          |
| _mean_act       | 0.0516476  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0392     |
| _min_adv        | -8.74      |
| _min_discrew    | 0.0196     |
| _min_obs        | -1.05      |
| _std_act        | 0.717304   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00344269 |
| Phi_loss        | 1755.69    |
| PolicyEntropy   | -1.30974   |
| PolicyLoss      | -0.0213348 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00845    |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43927    |
| _max_adv        | 4.3        |
| _max_discrew    | 4.91       |
| _max_obs        | 1.66       |
| _mean_act       | -0.0157935 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0341     |
| _min_adv        | -20.8      |
| _min_discrew    | -1.08      |
| _min_obs        | -1.17      |
| _std_act        | 0.780665   |
| _std_adv        | 1          |
| _std_discrew    | 2.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.903      |
| ExplainedVarOld | 0.898      |
| KL              | 0.00242992 |
| Phi_loss        | 2195.62    |
| PolicyEntropy   | -1.3342    |
| PolicyLoss      | 0.0134076  |
| Steps           | 10000      |
| VarFuncLoss     | 0.261      |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4467     |
| _max_adv        | 16.9       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0412592  |
| _mean_adv       | 4.97e-18   |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0377     |
| _min_adv        | -21        |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.08      |
| _std_act        | 0.717971   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00386202 |
| Phi_loss        | 1649.99    |
| PolicyEntropy   | -1.34275   |
| PolicyLoss      | -0.0313251 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0234     |
| _MeanReward     | 4.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3316     |
| _max_adv        | 4.05       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.69       |
| _mean_act       | -0.0444505 |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0312     |
| _min_adv        | -18.4      |
| _min_discrew    | -1.17      |
| _min_obs        | -1.19      |
| _std_act        | 0.79868    |
| _std_adv        | 1          |
| _std_discrew    | 3.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 0.405      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.923      |
| KL              | 0.00650964 |
| Phi_loss        | 2639.76    |
| PolicyEntropy   | -1.35594   |
| PolicyLoss      | 0.0219723  |
| Steps           | 10000      |
| VarFuncLoss     | 0.215      |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51506    |
| _max_adv        | 24.6       |
| _max_discrew    | 4.83       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0507326  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.039      |
| _min_adv        | -3.48      |
| _min_discrew    | 0.0192     |
| _min_obs        | -1.16      |
| _std_act        | 0.719208   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00115896 |
| Phi_loss        | 1261.23    |
| PolicyEntropy   | -1.35299   |
| PolicyLoss      | -0.0131244 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44108    |
| _max_adv        | 15.5       |
| _max_discrew    | 4.96       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0507661  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0388     |
| _min_adv        | -3.66      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.12      |
| _std_act        | 0.719393   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.988       |
| KL              | 0.000953162 |
| Phi_loss        | 1435.68     |
| PolicyEntropy   | -1.3513     |
| PolicyLoss      | -0.012289   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00649     |
| _MeanReward     | 4.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.37168     |
| _max_adv        | 1.4         |
| _max_discrew    | 4.89        |
| _max_obs        | 1.67        |
| _mean_act       | -0.0203418  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 3.42        |
| _mean_obs       | 0.0334      |
| _min_adv        | -20.4       |
| _min_discrew    | -1.12       |
| _min_obs        | -1.07       |
| _std_act        | 0.789199    |
| _std_adv        | 1           |
| _std_discrew    | 2.82        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.901      |
| KL              | 0.00305337 |
| Phi_loss        | 1960.46    |
| PolicyEntropy   | -1.3563    |
| PolicyLoss      | -0.0100096 |
| Steps           | 10000      |
| VarFuncLoss     | 0.26       |
| _MeanReward     | 4.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.38014    |
| _max_adv        | 2.2        |
| _max_discrew    | 4.87       |
| _max_obs        | 1.66       |
| _mean_act       | -0.0396085 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0318     |
| _min_adv        | -15.4      |
| _min_discrew    | -1.03      |
| _min_obs        | -1.2       |
| _std_act        | 0.806252   |
| _std_adv        | 1          |
| _std_discrew    | 3.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.859      |
| ExplainedVarOld | 0.852      |
| KL              | 0.00360054 |
| Phi_loss        | 2311.72    |
| PolicyEntropy   | -1.35533   |
| PolicyLoss      | -0.0040473 |
| Steps           | 10000      |
| VarFuncLoss     | 0.433      |
| _MeanReward     | 3.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82936    |
| _max_adv        | 6.23       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.66       |
| _mean_act       | -0.0723096 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0293     |
| _min_adv        | -14.6      |
| _min_discrew    | -1.11      |
| _min_obs        | -1.12      |
| _std_act        | 0.824748   |
| _std_adv        | 1          |
| _std_discrew    | 3.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.865      |
| ExplainedVarOld | 0.862      |
| KL              | 0.00302266 |
| Phi_loss        | 2647.98    |
| PolicyEntropy   | -1.36974   |
| PolicyLoss      | 0.0420482  |
| Steps           | 10000      |
| VarFuncLoss     | 0.495      |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47708    |
| _max_adv        | 6.01       |
| _max_discrew    | 4.94       |
| _max_obs        | 1.65       |
| _mean_act       | -0.0320504 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0324     |
| _min_adv        | -18.1      |
| _min_discrew    | -1.16      |
| _min_obs        | -1.09      |
| _std_act        | 0.79029    |
| _std_adv        | 1          |
| _std_discrew    | 3.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.917      |
| ExplainedVarOld | 0.908      |
| KL              | 0.00219853 |
| Phi_loss        | 2400.99    |
| PolicyEntropy   | -1.38105   |
| PolicyLoss      | 0.0213062  |
| Steps           | 10000      |
| VarFuncLoss     | 0.254      |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50808    |
| _max_adv        | 10.4       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0477932  |
| _mean_adv       | -5.54e-17  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0387     |
| _min_adv        | -4.89      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.04      |
| _std_act        | 0.710748   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00290189 |
| Phi_loss        | 1396.51    |
| PolicyEntropy   | -1.39701   |
| PolicyLoss      | 0.00392171 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0135     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4489     |
| _max_adv        | 23.6       |
| _max_discrew    | 4.86       |
| _max_obs        | 0.999      |
| _mean_act       | 0.047186   |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0384     |
| _min_adv        | -4.87      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.12      |
| _std_act        | 0.713187   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00287505 |
| Phi_loss        | 1204.68    |
| PolicyEntropy   | -1.40984   |
| PolicyLoss      | 0.0378328  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00527    |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44761    |
| _max_adv        | 35.8       |
| _max_discrew    | 4.87       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0457957  |
| _mean_adv       | -6.39e-18  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0386     |
| _min_adv        | -6.92      |
| _min_discrew    | 0.0176     |
| _min_obs        | -1.02      |
| _std_act        | 0.711427   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
-------------------------------
| Beta            | 0.12      |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0014798 |
| Phi_loss        | 1214.17   |
| PolicyEntropy   | -1.44085  |
| PolicyLoss      | 0.0122852 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00514   |
| _MeanReward     | 4.44e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.32777   |
| _max_adv        | 14.8      |
| _max_discrew    | 4.86      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0245997 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.69      |
| _mean_obs       | 0.0364    |
| _min_adv        | -20.8     |
| _min_discrew    | 0.014     |
| _min_obs        | -1.13     |
| _std_act        | 0.71273   |
| _std_adv        | 1         |
| _std_discrew    | 1.6       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.949       |
| KL              | 0.00789281  |
| Phi_loss        | 959.187     |
| PolicyEntropy   | -1.45898    |
| PolicyLoss      | -0.00258754 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0251      |
| _MeanReward     | 4.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.38915     |
| _max_adv        | 13.5        |
| _max_discrew    | 4.87        |
| _max_obs        | 0.999       |
| _mean_act       | 0.043276    |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.83        |
| _mean_obs       | 0.0376      |
| _min_adv        | -6.28       |
| _min_discrew    | 0.0165      |
| _min_obs        | -1.06       |
| _std_act        | 0.705242    |
| _std_adv        | 1           |
| _std_discrew    | 1.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00219165 |
| Phi_loss        | 2240.49    |
| PolicyEntropy   | -1.46338   |
| PolicyLoss      | -0.0322462 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00717    |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57404    |
| _max_adv        | 10.2       |
| _max_discrew    | 4.91       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0447476  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0384     |
| _min_adv        | -3.94      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.06      |
| _std_act        | 0.713608   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00210876 |
| Phi_loss        | 1994.63    |
| PolicyEntropy   | -1.47402   |
| PolicyLoss      | -0.0176415 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00561    |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44851    |
| _max_adv        | 10.6       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.03       |
| _mean_act       | 0.04664    |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0383     |
| _min_adv        | -4.22      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.15      |
| _std_act        | 0.716997   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00223636  |
| Phi_loss        | 2102.93     |
| PolicyEntropy   | -1.48649    |
| PolicyLoss      | -0.00901599 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00643     |
| _MeanReward     | 4.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.42798     |
| _max_adv        | 4.27        |
| _max_discrew    | 4.9         |
| _max_obs        | 1.66        |
| _mean_act       | 0.0156698   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.68        |
| _mean_obs       | 0.0359      |
| _min_adv        | -19.2       |
| _min_discrew    | -0.804      |
| _min_obs        | -1.09       |
| _std_act        | 0.739925    |
| _std_adv        | 1           |
| _std_discrew    | 1.95        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.901      |
| KL              | 0.00347084 |
| Phi_loss        | 1652.76    |
| PolicyEntropy   | -1.4906    |
| PolicyLoss      | -0.0210476 |
| Steps           | 10000      |
| VarFuncLoss     | 0.178      |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.33812    |
| _max_adv        | 8.15       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.03       |
| _mean_act       | 0.044678   |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0383     |
| _min_adv        | -7.38      |
| _min_discrew    | 0.0172     |
| _min_obs        | -1.1       |
| _std_act        | 0.716838   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.0032618  |
| Phi_loss        | 2069.42    |
| PolicyEntropy   | -1.49829   |
| PolicyLoss      | -0.0346541 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0106     |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71583    |
| _max_adv        | 10.8       |
| _max_discrew    | 5.02       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0305344  |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0366     |
| _min_adv        | -18.3      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.06      |
| _std_act        | 0.716678   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.954      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00370195 |
| Phi_loss        | 1789.63    |
| PolicyEntropy   | -1.50695   |
| PolicyLoss      | -0.0241426 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0722     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.38177    |
| _max_adv        | 14.4       |
| _max_discrew    | 4.89       |
| _max_obs        | 0.999      |
| _mean_act       | 0.042776   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.47      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.16      |
| _std_act        | 0.71329    |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
-------------------------------
| Beta            | 0.18      |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.996     |
| KL              | 0.0022555 |
| Phi_loss        | 2025.83   |
| PolicyEntropy   | -1.53649  |
| PolicyLoss      | 0.0194624 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00572   |
| _MeanReward     | 4.62e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.57606   |
| _max_adv        | 33        |
| _max_discrew    | 4.87      |
| _max_obs        | 0.999     |
| _mean_act       | 0.0430407 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.83      |
| _mean_obs       | 0.0374    |
| _min_adv        | -7.57     |
| _min_discrew    | 0.0167    |
| _min_obs        | -1.11     |
| _std_act        | 0.715782  |
| _std_adv        | 1         |
| _std_discrew    | 1.38      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00296839 |
| Phi_loss        | 1920.69    |
| PolicyEntropy   | -1.55796   |
| PolicyLoss      | 0.0075598  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00544    |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50897    |
| _max_adv        | 7.55       |
| _max_discrew    | 4.94       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0333862  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0371     |
| _min_adv        | -15.6      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.06      |
| _std_act        | 0.717423   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00839062 |
| Phi_loss        | 2501.45    |
| PolicyEntropy   | -1.59184   |
| PolicyLoss      | 0.102036   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0835     |
| _MeanReward     | 4.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39169    |
| _max_adv        | 7.72       |
| _max_discrew    | 4.91       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0318478  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0362     |
| _min_adv        | -17.1      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.06      |
| _std_act        | 0.715428   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.937      |
| KL              | 0.00418214 |
| Phi_loss        | 1912.08    |
| PolicyEntropy   | -1.58598   |
| PolicyLoss      | -0.0135993 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0798     |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46814    |
| _max_adv        | 5.1        |
| _max_discrew    | 4.94       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0427841  |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.038      |
| _min_adv        | -5.33      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.11      |
| _std_act        | 0.710868   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00119168  |
| Phi_loss        | 2134.76     |
| PolicyEntropy   | -1.59775    |
| PolicyLoss      | -0.00546099 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00687     |
| _MeanReward     | 4.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71032     |
| _max_adv        | 5.07        |
| _max_discrew    | 4.93        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0332578   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.77        |
| _mean_obs       | 0.0366      |
| _min_adv        | -19.7       |
| _min_discrew    | 0.0146      |
| _min_obs        | -1.28       |
| _std_act        | 0.714775    |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.952      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00302624 |
| Phi_loss        | 1874.43    |
| PolicyEntropy   | -1.58819   |
| PolicyLoss      | 0.0174822  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0683     |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52885    |
| _max_adv        | 13.1       |
| _max_discrew    | 4.93       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0436701  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.038      |
| _min_adv        | -4.82      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.11      |
| _std_act        | 0.714204   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00332478  |
| Phi_loss        | 1974.37     |
| PolicyEntropy   | -1.58744    |
| PolicyLoss      | -0.0251559  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00739     |
| _MeanReward     | 4.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.50057     |
| _max_adv        | 1.92        |
| _max_discrew    | 4.91        |
| _max_obs        | 1.67        |
| _mean_act       | -0.00988375 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.52        |
| _mean_obs       | 0.0335      |
| _min_adv        | -17.3       |
| _min_discrew    | -1.05       |
| _min_obs        | -1.11       |
| _std_act        | 0.771414    |
| _std_adv        | 1           |
| _std_discrew    | 2.54        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.882      |
| KL              | 0.00638818 |
| Phi_loss        | 1483.63    |
| PolicyEntropy   | -1.57998   |
| PolicyLoss      | 0.0406026  |
| Steps           | 10000      |
| VarFuncLoss     | 0.262      |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42994    |
| _max_adv        | 30.1       |
| _max_discrew    | 4.91       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0423169  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.44      |
| _min_discrew    | 0.0208     |
| _min_obs        | -1.06      |
| _std_act        | 0.71753    |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00105549 |
| Phi_loss        | 1979.46    |
| PolicyEntropy   | -1.58997   |
| PolicyLoss      | -0.0138783 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0118     |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31007    |
| _max_adv        | 14.9       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0436057  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0378     |
| _min_adv        | -5.21      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.13      |
| _std_act        | 0.716868   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00122091  |
| Phi_loss        | 1932.36     |
| PolicyEntropy   | -1.60615    |
| PolicyLoss      | -0.00719949 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00447     |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.43232     |
| _max_adv        | 1.77        |
| _max_discrew    | 4.96        |
| _max_obs        | 1.71        |
| _mean_act       | -0.0787191  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0284      |
| _min_adv        | -15.7       |
| _min_discrew    | -1.13       |
| _min_obs        | -1.19       |
| _std_act        | 0.818255    |
| _std_adv        | 1           |
| _std_discrew    | 3.79        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.882      |
| ExplainedVarOld | 0.877      |
| KL              | 0.00781864 |
| Phi_loss        | 3179.47    |
| PolicyEntropy   | -1.60007   |
| PolicyLoss      | -0.0793889 |
| Steps           | 10000      |
| VarFuncLoss     | 0.451      |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3887     |
| _max_adv        | 5.13       |
| _max_discrew    | 5.02       |
| _max_obs        | 1.67       |
| _mean_act       | 0.0155927  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0354     |
| _min_adv        | -19.9      |
| _min_discrew    | -0.797     |
| _min_obs        | -1.05      |
| _std_act        | 0.73774    |
| _std_adv        | 1          |
| _std_discrew    | 1.99       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.899      |
| KL              | 0.00261258 |
| Phi_loss        | 3131.23    |
| PolicyEntropy   | -1.61337   |
| PolicyLoss      | 0.0113991  |
| Steps           | 10000      |
| VarFuncLoss     | 0.195      |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.31916    |
| _max_adv        | 12.8       |
| _max_discrew    | 5.01       |
| _max_obs        | 0.999      |
| _mean_act       | 0.031663   |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0367     |
| _min_adv        | -19.4      |
| _min_discrew    | 0.0191     |
| _min_obs        | -1.09      |
| _std_act        | 0.714135   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.943      |
| KL              | 0.00383975 |
| Phi_loss        | 1327.65    |
| PolicyEntropy   | -1.60996   |
| PolicyLoss      | -0.0482465 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48744    |
| _max_adv        | 9.05       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0424443  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0379     |
| _min_adv        | -3.43      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.08      |
| _std_act        | 0.715312   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00283651 |
| Phi_loss        | 2218.84    |
| PolicyEntropy   | -1.61804   |
| PolicyLoss      | -0.0225678 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00487    |
| _MeanReward     | 4.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62478    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.88       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0403724  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0373     |
| _min_adv        | -16.2      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.15      |
| _std_act        | 0.709058   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00280554 |
| Phi_loss        | 2144.42    |
| PolicyEntropy   | -1.617     |
| PolicyLoss      | -0.018618  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0222     |
| _MeanReward     | 4.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46445    |
| _max_adv        | 10.3       |
| _max_discrew    | 4.93       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0408238  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0372     |
| _min_adv        | -7.48      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.01      |
| _std_act        | 0.713946   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00249184 |
| Phi_loss        | 2452.73    |
| PolicyEntropy   | -1.6305    |
| PolicyLoss      | -0.0172158 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00538    |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58828    |
| _max_adv        | 4.17       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0295666  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0362     |
| _min_adv        | -16.8      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.12      |
| _std_act        | 0.717141   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.946       |
| KL              | 0.00651901  |
| Phi_loss        | 1160.72     |
| PolicyEntropy   | -1.63723    |
| PolicyLoss      | 0.000217837 |
| Steps           | 10000       |
| VarFuncLoss     | 0.032       |
| _MeanReward     | 4.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.41139     |
| _max_adv        | 11.8        |
| _max_discrew    | 4.85        |
| _max_obs        | 0.999       |
| _mean_act       | 0.0409245   |
| _mean_adv       | 1.28e-17    |
| _mean_discrew   | 3.86        |
| _mean_obs       | 0.0372      |
| _min_adv        | -4.32       |
| _min_discrew    | 0.0131      |
| _min_obs        | -1.14       |
| _std_act        | 0.7123      |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00188013 |
| Phi_loss        | 2149.36    |
| PolicyEntropy   | -1.64188   |
| PolicyLoss      | 0.0115455  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00481    |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.50828    |
| _max_adv        | 18.5       |
| _max_discrew    | 4.94       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0412647  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.36      |
| _min_discrew    | 0.0212     |
| _min_obs        | -1.04      |
| _std_act        | 0.716333   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00111602 |
| Phi_loss        | 2014.01    |
| PolicyEntropy   | -1.64484   |
| PolicyLoss      | -0.01116   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00538    |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.58943    |
| _max_adv        | 13.6       |
| _max_discrew    | 4.92       |
| _max_obs        | 1          |
| _mean_act       | 0.0405803  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.87       |
| _mean_obs       | 0.0375     |
| _min_adv        | -8.73      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.07      |
| _std_act        | 0.717416   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00331681  |
| Phi_loss        | 2713.89     |
| PolicyEntropy   | -1.66343    |
| PolicyLoss      | -0.00389123 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00581     |
| _MeanReward     | 4.72e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.38934     |
| _max_adv        | 7.09        |
| _max_discrew    | 4.89        |
| _max_obs        | 1.02        |
| _mean_act       | 0.0420384   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.89        |
| _mean_obs       | 0.0379      |
| _min_adv        | -4.82       |
| _min_discrew    | 0.0172      |
| _min_obs        | -1.04       |
| _std_act        | 0.716708    |
| _std_adv        | 1           |
| _std_discrew    | 1.4         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00203742 |
| Phi_loss        | 2802.0     |
| PolicyEntropy   | -1.68387   |
| PolicyLoss      | -0.0140444 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00378    |
| _MeanReward     | 4.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24615    |
| _max_adv        | 27.8       |
| _max_discrew    | 4.96       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0426265  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0382     |
| _min_adv        | -8.31      |
| _min_discrew    | 0.0139     |
| _min_obs        | -1.15      |
| _std_act        | 0.717725   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00262527  |
| Phi_loss        | 2636.57     |
| PolicyEntropy   | -1.70614    |
| PolicyLoss      | -0.00890999 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00428     |
| _MeanReward     | 4.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.39596     |
| _max_adv        | 5.65        |
| _max_discrew    | 4.99        |
| _max_obs        | 1.01        |
| _mean_act       | 0.042622    |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.9         |
| _mean_obs       | 0.0381      |
| _min_adv        | -6.68       |
| _min_discrew    | 0.0192      |
| _min_obs        | -1.05       |
| _std_act        | 0.71241     |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.0023406   |
| Phi_loss        | 3347.16     |
| PolicyEntropy   | -1.72768    |
| PolicyLoss      | -0.00474453 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00521     |
| _MeanReward     | 4.74e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72812     |
| _max_adv        | 4.63        |
| _max_discrew    | 4.97        |
| _max_obs        | 0.999       |
| _mean_act       | 0.0423436   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 3.9         |
| _mean_obs       | 0.038       |
| _min_adv        | -4.8        |
| _min_discrew    | 0.0166      |
| _min_obs        | -1.11       |
| _std_act        | 0.71324     |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00280205 |
| Phi_loss        | 3003.92    |
| PolicyEntropy   | -1.76104   |
| PolicyLoss      | 0.00665106 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00452    |
| _MeanReward     | 4.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.33104    |
| _max_adv        | 15.4       |
| _max_discrew    | 4.98       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0434986  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.038      |
| _min_adv        | -5.06      |
| _min_discrew    | 0.0202     |
| _min_obs        | -1.09      |
| _std_act        | 0.712293   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00258462  |
| Phi_loss        | 2949.64     |
| PolicyEntropy   | -1.79728    |
| PolicyLoss      | -0.00336179 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00655     |
| _MeanReward     | 4.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.30479     |
| _max_adv        | 8.64        |
| _max_discrew    | 5.03        |
| _max_obs        | 1           |
| _mean_act       | 0.0427597   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.92        |
| _mean_obs       | 0.0385      |
| _min_adv        | -5.03       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.03       |
| _std_act        | 0.71371     |
| _std_adv        | 1           |
| _std_discrew    | 1.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00296017 |
| Phi_loss        | 3213.27    |
| PolicyEntropy   | -1.84229   |
| PolicyLoss      | 0.00877469 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00552    |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55127    |
| _max_adv        | 12.2       |
| _max_discrew    | 5.02       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0416978  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0379     |
| _min_adv        | -9.46      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.13      |
| _std_act        | 0.711012   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00429896 |
| Phi_loss        | 2902.22    |
| PolicyEntropy   | -1.87563   |
| PolicyLoss      | -0.0291589 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00704    |
| _MeanReward     | 4.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42065    |
| _max_adv        | 7.21       |
| _max_discrew    | 4.98       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0444065  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.98      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.07      |
| _std_act        | 0.714308   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 477
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00346581 |
| Phi_loss        | 3022.18    |
| PolicyEntropy   | -1.90051   |
| PolicyLoss      | -0.0378894 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0044     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32614    |
| _max_adv        | 2.47       |
| _max_discrew    | 5.06       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0256168  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0364     |
| _min_adv        | -22.6      |
| _min_discrew    | 0.0178     |
| _min_obs        | -1.07      |
| _std_act        | 0.715837   |
| _std_adv        | 1          |
| _std_discrew    | 1.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 478
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.941      |
| KL              | 0.00650974 |
| Phi_loss        | 1513.33    |
| PolicyEntropy   | -1.88913   |
| PolicyLoss      | -0.0706333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 4.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3348     |
| _max_adv        | 13.1       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0448952  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.93       |
| _mean_obs       | 0.0389     |
| _min_adv        | -8.06      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.08      |
| _std_act        | 0.717175   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 479
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00181878 |
| Phi_loss        | 2844.84    |
| PolicyEntropy   | -1.90189   |
| PolicyLoss      | -0.0193608 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00712    |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.40818    |
| _max_adv        | 2.94       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.7        |
| _mean_act       | 0.0139156  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0364     |
| _min_adv        | -20.7      |
| _min_discrew    | -0.84      |
| _min_obs        | -1.1       |
| _std_act        | 0.747901   |
| _std_adv        | 1          |
| _std_discrew    | 2.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 480
Draw Samples..
-------------------------------
| Beta            | 0.405     |
| ExplainedVarNew | 0.908     |
| ExplainedVarOld | 0.901     |
| KL              | 0.0125849 |
| Phi_loss        | 3411.76   |
| PolicyEntropy   | -1.89897  |
| PolicyLoss      | 0.144843  |
| Steps           | 10000     |
| VarFuncLoss     | 0.196     |
| _MeanReward     | 4.78e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.45341   |
| _max_adv        | 8.15      |
| _max_discrew    | 5.07      |
| _max_obs        | 1.03      |
| _mean_act       | 0.0437273 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.93      |
| _mean_obs       | 0.0383    |
| _min_adv        | -6.59     |
| _min_discrew    | 0.0173    |
| _min_obs        | -1.11     |
| _std_act        | 0.723606  |
| _std_adv        | 1         |
| _std_discrew    | 1.45      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 481
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00120691 |
| Phi_loss        | 2807.86    |
| PolicyEntropy   | -1.89912   |
| PolicyLoss      | -0.0457532 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00982    |
| _MeanReward     | 4.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31179    |
| _max_adv        | 8.49       |
| _max_discrew    | 4.97       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0442565  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.0381     |
| _min_adv        | -6.35      |
| _min_discrew    | 0.0201     |
| _min_obs        | -1.1       |
| _std_act        | 0.71833    |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 482
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00137081 |
| Phi_loss        | 2718.37    |
| PolicyEntropy   | -1.92107   |
| PolicyLoss      | 0.00362099 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00753    |
| _MeanReward     | 4.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.52733    |
| _max_adv        | 5.59       |
| _max_discrew    | 5.04       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0444128  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.95       |
| _mean_obs       | 0.0387     |
| _min_adv        | -6.68      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.02      |
| _std_act        | 0.723145   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 483
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00344254 |
| Phi_loss        | 3574.8     |
| PolicyEntropy   | -1.93898   |
| PolicyLoss      | -0.0619456 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00456    |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.30964    |
| _max_adv        | 10         |
| _max_discrew    | 5.03       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0351764  |
| _mean_adv       | 1.78e-17   |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.0375     |
| _min_adv        | -19.4      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.15      |
| _std_act        | 0.724666   |
| _std_adv        | 1          |
| _std_discrew    | 1.53       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 484
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00302107 |
| Phi_loss        | 2062.59    |
| PolicyEntropy   | -1.95428   |
| PolicyLoss      | 0.00336063 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0342     |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5816     |
| _max_adv        | 8.41       |
| _max_discrew    | 5.03       |
| _max_obs        | 1.23       |
| _mean_act       | 0.0294125  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0367     |
| _min_adv        | -15.8      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.09      |
| _std_act        | 0.725275   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 485
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00701981 |
| Phi_loss        | 2031.99    |
| PolicyEntropy   | -1.93981   |
| PolicyLoss      | -0.0493484 |
| Steps           | 10000      |
| VarFuncLoss     | 0.112      |
| _MeanReward     | 4.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35174    |
| _max_adv        | 8.11       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0425657  |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.038      |
| _min_adv        | -3.51      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.2       |
| _std_act        | 0.728605   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 486
Draw Samples..
--------------------------------
| Beta            | 0.18       |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00140622 |
| Phi_loss        | 2741.88    |
| PolicyEntropy   | -1.9566    |
| PolicyLoss      | 0.0362853  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00731    |
| _MeanReward     | 4.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4936     |
| _max_adv        | 8.42       |
| _max_discrew    | 5.08       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0424412  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.0384     |
| _min_adv        | -6.59      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.09      |
| _std_act        | 0.724462   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
