Logging to halfcheetah_unbiased_121
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
-----------------------------
| Steps         | 10000     |
| _MeanReward   | -308      |
| _max_act      | 3.06042   |
| _max_adv      | 4.21      |
| _max_discrew  | 0.0942    |
| _max_obs      | 2.57      |
| _mean_act     | 0.0318721 |
| _mean_adv     | 1.07e-17  |
| _mean_discrew | -0.253    |
| _mean_obs     | 0.0398    |
| _min_adv      | -3.39     |
| _min_discrew  | -0.669    |
| _min_obs      | -1.27     |
| _std_act      | 0.422566  |
| _std_adv      | 1         |
| _std_discrew  | 0.0148    |
-----------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.231       |
| ExplainedVarOld | -3.42       |
| KL              | 0.000204248 |
| Phi_loss        | 2.94904     |
| PolicyEntropy   | 5.51473     |
| PolicyLoss      | -0.00144994 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0114      |
| _MeanReward     | -337        |
| _lr_multiplier  | 1           |
| _max_act        | 2.84532     |
| _max_adv        | 5.37        |
| _max_discrew    | 0.108       |
| _max_obs        | 1.41        |
| _mean_act       | 0.0162229   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | -0.274      |
| _mean_obs       | 0.0264      |
| _min_adv        | -3.74       |
| _min_discrew    | -0.607      |
| _min_obs        | -1.21       |
| _std_act        | 0.424661    |
| _std_adv        | 1           |
| _std_discrew    | 0.0237      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.317       |
| ExplainedVarOld | 0.214       |
| KL              | 0.000944738 |
| Phi_loss        | 22.3123     |
| PolicyEntropy   | 5.51208     |
| PolicyLoss      | 0.00071178  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | -329        |
| _lr_multiplier  | 1           |
| _max_act        | 3.05337     |
| _max_adv        | 3.57        |
| _max_discrew    | 0.0202      |
| _max_obs        | 1.51        |
| _mean_act       | 0.0142308   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | -0.262      |
| _mean_obs       | 0.0257      |
| _min_adv        | -3.43       |
| _min_discrew    | -0.617      |
| _min_obs        | -1.25       |
| _std_act        | 0.422607    |
| _std_adv        | 1           |
| _std_discrew    | 0.0143      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.291      |
| ExplainedVarOld | 0.252      |
| KL              | 0.00145427 |
| Phi_loss        | 21.3843    |
| PolicyEntropy   | 5.48845    |
| PolicyLoss      | 0.00873072 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0102     |
| _MeanReward     | -266       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75678    |
| _max_adv        | 3.79       |
| _max_discrew    | 0.0574     |
| _max_obs        | 1.38       |
| _mean_act       | 0.0160019  |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | -0.213     |
| _mean_obs       | 0.0345     |
| _min_adv        | -4.86      |
| _min_discrew    | -0.485     |
| _min_obs        | -1.28      |
| _std_act        | 0.421366   |
| _std_adv        | 1          |
| _std_discrew    | 0.0122     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.451       |
| ExplainedVarOld | 0.383       |
| KL              | 0.00273486  |
| Phi_loss        | 17.9015     |
| PolicyEntropy   | 5.49258     |
| PolicyLoss      | 0.000483093 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0074      |
| _MeanReward     | -298        |
| _lr_multiplier  | 1           |
| _max_act        | 2.84454     |
| _max_adv        | 3.42        |
| _max_discrew    | 0.0401      |
| _max_obs        | 1.36        |
| _mean_act       | 0.0159118   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | -0.244      |
| _mean_obs       | 0.0265      |
| _min_adv        | -4.4        |
| _min_discrew    | -0.678      |
| _min_obs        | -1.39       |
| _std_act        | 0.42089     |
| _std_adv        | 1           |
| _std_discrew    | 0.0173      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.35        |
| ExplainedVarOld | 0.331       |
| KL              | 0.00366141  |
| Phi_loss        | 18.7303     |
| PolicyEntropy   | 5.49319     |
| PolicyLoss      | 0.000991619 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0114      |
| _MeanReward     | -214        |
| _lr_multiplier  | 1           |
| _max_act        | 3.00324     |
| _max_adv        | 3.81        |
| _max_discrew    | 0.0683      |
| _max_obs        | 1.34        |
| _mean_act       | 0.0207846   |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | -0.179      |
| _mean_obs       | 0.0386      |
| _min_adv        | -3.96       |
| _min_discrew    | -0.533      |
| _min_obs        | -1.46       |
| _std_act        | 0.423608    |
| _std_adv        | 1           |
| _std_discrew    | 0.0132      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.268       |
| ExplainedVarOld | 0.192       |
| KL              | 0.00257673  |
| Phi_loss        | 17.4458     |
| PolicyEntropy   | 5.49996     |
| PolicyLoss      | -0.00266197 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0104      |
| _MeanReward     | -201        |
| _lr_multiplier  | 1           |
| _max_act        | 2.82018     |
| _max_adv        | 3.8         |
| _max_discrew    | 0.0752      |
| _max_obs        | 1.35        |
| _mean_act       | 0.0164259   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.161      |
| _mean_obs       | 0.0305      |
| _min_adv        | -4.34       |
| _min_discrew    | -0.452      |
| _min_obs        | -1.21       |
| _std_act        | 0.42336     |
| _std_adv        | 1           |
| _std_discrew    | 0.00839     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.3        |
| ExplainedVarOld | 0.0735     |
| KL              | 0.00294573 |
| Phi_loss        | 17.7391    |
| PolicyEntropy   | 5.47757    |
| PolicyLoss      | 0.00527089 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00589    |
| _MeanReward     | -165       |
| _lr_multiplier  | 1          |
| _max_act        | 2.65078    |
| _max_adv        | 4.37       |
| _max_discrew    | 0.198      |
| _max_obs        | 1.27       |
| _mean_act       | 0.0151509  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.139     |
| _mean_obs       | 0.034      |
| _min_adv        | -3.65      |
| _min_discrew    | -0.409     |
| _min_obs        | -1.29      |
| _std_act        | 0.409055   |
| _std_adv        | 1          |
| _std_discrew    | 0.00953    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.201      |
| ExplainedVarOld | 0.116      |
| KL              | 0.00262664 |
| Phi_loss        | 18.6455    |
| PolicyEntropy   | 5.46594    |
| PolicyLoss      | 0.00200672 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00792    |
| _MeanReward     | -198       |
| _lr_multiplier  | 1          |
| _max_act        | 2.88852    |
| _max_adv        | 4.4        |
| _max_discrew    | 0.198      |
| _max_obs        | 1.64       |
| _mean_act       | 0.0101785  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | -0.171     |
| _mean_obs       | 0.0311     |
| _min_adv        | -3.49      |
| _min_discrew    | -0.455     |
| _min_obs        | -1.31      |
| _std_act        | 0.417749   |
| _std_adv        | 1          |
| _std_discrew    | 0.0125     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.27       |
| ExplainedVarOld | 0.25       |
| KL              | 0.00278985 |
| Phi_loss        | 18.6498    |
| PolicyEntropy   | 5.46348    |
| PolicyLoss      | 0.0028544  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00917    |
| _MeanReward     | -171       |
| _lr_multiplier  | 1          |
| _max_act        | 3.01716    |
| _max_adv        | 4          |
| _max_discrew    | 0.117      |
| _max_obs        | 1.25       |
| _mean_act       | 0.00973556 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.149     |
| _mean_obs       | 0.0387     |
| _min_adv        | -3.87      |
| _min_discrew    | -0.457     |
| _min_obs        | -1.41      |
| _std_act        | 0.414713   |
| _std_adv        | 1          |
| _std_discrew    | 0.00831    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.242      |
| ExplainedVarOld | 0.156      |
| KL              | 0.00228314 |
| Phi_loss        | 16.9724    |
| PolicyEntropy   | 5.40881    |
| PolicyLoss      | 0.0154665  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00641    |
| _MeanReward     | -144       |
| _lr_multiplier  | 1          |
| _max_act        | 2.67938    |
| _max_adv        | 3.28       |
| _max_discrew    | 0.178      |
| _max_obs        | 1.32       |
| _mean_act       | 0.0121061  |
| _mean_adv       | 6.82e-17   |
| _mean_discrew   | -0.118     |
| _mean_obs       | 0.0335     |
| _min_adv        | -4.29      |
| _min_discrew    | -0.488     |
| _min_obs        | -1.23      |
| _std_act        | 0.40992    |
| _std_adv        | 1          |
| _std_discrew    | 0.0136     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.15       |
| ExplainedVarOld | 0.125      |
| KL              | 0.00355199 |
| Phi_loss        | 18.1701    |
| PolicyEntropy   | 5.39077    |
| PolicyLoss      | 0.00319416 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0118     |
| _MeanReward     | -141       |
| _lr_multiplier  | 1          |
| _max_act        | 2.74074    |
| _max_adv        | 3.81       |
| _max_discrew    | 0.195      |
| _max_obs        | 1.38       |
| _mean_act       | 0.0113429  |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | -0.117     |
| _mean_obs       | 0.0388     |
| _min_adv        | -4.37      |
| _min_discrew    | -0.371     |
| _min_obs        | -1.2       |
| _std_act        | 0.405368   |
| _std_adv        | 1          |
| _std_discrew    | 0.00951    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.346      |
| ExplainedVarOld | 0.293      |
| KL              | 0.00284913 |
| Phi_loss        | 17.1387    |
| PolicyEntropy   | 5.37439    |
| PolicyLoss      | 0.00385186 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00623    |
| _MeanReward     | -115       |
| _lr_multiplier  | 1          |
| _max_act        | 2.51254    |
| _max_adv        | 3.41       |
| _max_discrew    | 0.144      |
| _max_obs        | 1.68       |
| _mean_act       | 0.00736477 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | -0.0984    |
| _mean_obs       | 0.0307     |
| _min_adv        | -3.82      |
| _min_discrew    | -0.453     |
| _min_obs        | -1.33      |
| _std_act        | 0.407784   |
| _std_adv        | 1          |
| _std_discrew    | 0.0101     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.277      |
| ExplainedVarOld | 0.229      |
| KL              | 0.00331327 |
| Phi_loss        | 19.182     |
| PolicyEntropy   | 5.35565    |
| PolicyLoss      | 0.00146087 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00732    |
| _MeanReward     | -112       |
| _lr_multiplier  | 1          |
| _max_act        | 2.94114    |
| _max_adv        | 4.77       |
| _max_discrew    | 0.223      |
| _max_obs        | 1.41       |
| _mean_act       | 0.00306064 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.0989    |
| _mean_obs       | 0.0358     |
| _min_adv        | -3.84      |
| _min_discrew    | -0.367     |
| _min_obs        | -1.19      |
| _std_act        | 0.410319   |
| _std_adv        | 1          |
| _std_discrew    | 0.00921    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.521      |
| ExplainedVarOld | 0.463      |
| KL              | 0.00305648 |
| Phi_loss        | 17.6051    |
| PolicyEntropy   | 5.34396    |
| PolicyLoss      | 0.0041726  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00458    |
| _MeanReward     | -140       |
| _lr_multiplier  | 1          |
| _max_act        | 2.86869    |
| _max_adv        | 3.78       |
| _max_discrew    | 0.0907     |
| _max_obs        | 1.27       |
| _mean_act       | 0.00342643 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.119     |
| _mean_obs       | 0.0381     |
| _min_adv        | -4.36      |
| _min_discrew    | -0.371     |
| _min_obs        | -1.29      |
| _std_act        | 0.40985    |
| _std_adv        | 1          |
| _std_discrew    | 0.00921    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.398      |
| ExplainedVarOld | 0.273      |
| KL              | 0.00276923 |
| Phi_loss        | 16.2834    |
| PolicyEntropy   | 5.31237    |
| PolicyLoss      | 0.00204558 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00555    |
| _MeanReward     | -124       |
| _lr_multiplier  | 1          |
| _max_act        | 2.6        |
| _max_adv        | 3.74       |
| _max_discrew    | 0.24       |
| _max_obs        | 1.48       |
| _mean_act       | 0.00446406 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.11      |
| _mean_obs       | 0.0367     |
| _min_adv        | -3.88      |
| _min_discrew    | -0.348     |
| _min_obs        | -1.28      |
| _std_act        | 0.410717   |
| _std_adv        | 1          |
| _std_discrew    | 0.015      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.388      |
| ExplainedVarOld | 0.279      |
| KL              | 0.00331402 |
| Phi_loss        | 15.9166    |
| PolicyEntropy   | 5.299      |
| PolicyLoss      | 0.00181617 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00917    |
| _MeanReward     | -103       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75473    |
| _max_adv        | 3.94       |
| _max_discrew    | 0.208      |
| _max_obs        | 1.41       |
| _mean_act       | 0.0013698  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.0921    |
| _mean_obs       | 0.0387     |
| _min_adv        | -4.05      |
| _min_discrew    | -0.315     |
| _min_obs        | -1.39      |
| _std_act        | 0.410776   |
| _std_adv        | 1          |
| _std_discrew    | 0.0112     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.42        |
| ExplainedVarOld | 0.425       |
| KL              | 0.0037729   |
| Phi_loss        | 19.1608     |
| PolicyEntropy   | 5.30204     |
| PolicyLoss      | -0.00110406 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00662     |
| _MeanReward     | -77.8       |
| _lr_multiplier  | 1           |
| _max_act        | 2.6993      |
| _max_adv        | 4           |
| _max_discrew    | 0.179       |
| _max_obs        | 1.34        |
| _mean_act       | 0.00182461  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | -0.0658     |
| _mean_obs       | 0.0307      |
| _min_adv        | -4.63       |
| _min_discrew    | -0.319      |
| _min_obs        | -1.19       |
| _std_act        | 0.413107    |
| _std_adv        | 1           |
| _std_discrew    | 0.0103      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.326      |
| ExplainedVarOld | 0.288      |
| KL              | 0.00365062 |
| Phi_loss        | 20.8883    |
| PolicyEntropy   | 5.27593    |
| PolicyLoss      | 0.00754378 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00698    |
| _MeanReward     | -50.6      |
| _lr_multiplier  | 1          |
| _max_act        | 2.65117    |
| _max_adv        | 3.47       |
| _max_discrew    | 0.246      |
| _max_obs        | 1.44       |
| _mean_act       | 0.00769915 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | -0.0439    |
| _mean_obs       | 0.0283     |
| _min_adv        | -3.97      |
| _min_discrew    | -0.309     |
| _min_obs        | -1.44      |
| _std_act        | 0.409733   |
| _std_adv        | 1          |
| _std_discrew    | 0.0145     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.373       |
| ExplainedVarOld | 0.344       |
| KL              | 0.00434536  |
| Phi_loss        | 22.4767     |
| PolicyEntropy   | 5.25682     |
| PolicyLoss      | 0.000272315 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00908     |
| _MeanReward     | -31.8       |
| _lr_multiplier  | 1           |
| _max_act        | 2.67298     |
| _max_adv        | 3.87        |
| _max_discrew    | 0.193       |
| _max_obs        | 1.22        |
| _mean_act       | 0.00578109  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.0233     |
| _mean_obs       | 0.0345      |
| _min_adv        | -4.8        |
| _min_discrew    | -0.239      |
| _min_obs        | -1.33       |
| _std_act        | 0.408895    |
| _std_adv        | 1           |
| _std_discrew    | 0.00825     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.369      |
| ExplainedVarOld | 0.238      |
| KL              | 0.00211513 |
| Phi_loss        | 19.7508    |
| PolicyEntropy   | 5.24061    |
| PolicyLoss      | 0.00305724 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00563    |
| _MeanReward     | -60.4      |
| _lr_multiplier  | 1          |
| _max_act        | 2.45233    |
| _max_adv        | 3.79       |
| _max_discrew    | 0.22       |
| _max_obs        | 1.3        |
| _mean_act       | 0.00307804 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | -0.056     |
| _mean_obs       | 0.0374     |
| _min_adv        | -3.88      |
| _min_discrew    | -0.282     |
| _min_obs        | -1.34      |
| _std_act        | 0.402762   |
| _std_adv        | 1          |
| _std_discrew    | 0.00992    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.355      |
| ExplainedVarOld | 0.347      |
| KL              | 0.00371703 |
| Phi_loss        | 18.9337    |
| PolicyEntropy   | 5.19491    |
| PolicyLoss      | 0.0155997  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00645    |
| _MeanReward     | -67.7      |
| _lr_multiplier  | 1          |
| _max_act        | 2.67011    |
| _max_adv        | 4.19       |
| _max_discrew    | 0.276      |
| _max_obs        | 1.27       |
| _mean_act       | 0.00888395 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.064     |
| _mean_obs       | 0.0347     |
| _min_adv        | -5.68      |
| _min_discrew    | -0.285     |
| _min_obs        | -1.16      |
| _std_act        | 0.399356   |
| _std_adv        | 1          |
| _std_discrew    | 0.0109     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.511      |
| ExplainedVarOld | 0.485      |
| KL              | 0.00299523 |
| Phi_loss        | 19.6465    |
| PolicyEntropy   | 5.18281    |
| PolicyLoss      | 0.00208253 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00536    |
| _MeanReward     | -18.8      |
| _lr_multiplier  | 1          |
| _max_act        | 2.70704    |
| _max_adv        | 4.11       |
| _max_discrew    | 0.249      |
| _max_obs        | 1.42       |
| _mean_act       | 0.008009   |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | -0.0278    |
| _mean_obs       | 0.0315     |
| _min_adv        | -4.33      |
| _min_discrew    | -0.295     |
| _min_obs        | -1.49      |
| _std_act        | 0.395074   |
| _std_adv        | 1          |
| _std_discrew    | 0.0105     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.52       |
| ExplainedVarOld | 0.468      |
| KL              | 0.00307261 |
| Phi_loss        | 21.8864    |
| PolicyEntropy   | 5.16473    |
| PolicyLoss      | 0.00308025 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00508    |
| _MeanReward     | -15.5      |
| _lr_multiplier  | 1          |
| _max_act        | 2.88066    |
| _max_adv        | 3.76       |
| _max_discrew    | 0.332      |
| _max_obs        | 1.65       |
| _mean_act       | 0.00666296 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | -0.0181    |
| _mean_obs       | 0.0327     |
| _min_adv        | -4.07      |
| _min_discrew    | -0.255     |
| _min_obs        | -1.24      |
| _std_act        | 0.396252   |
| _std_adv        | 1          |
| _std_discrew    | 0.0102     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.312      |
| ExplainedVarOld | 0.275      |
| KL              | 0.00256707 |
| Phi_loss        | 21.6008    |
| PolicyEntropy   | 5.15581    |
| PolicyLoss      | 0.00264101 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00707    |
| _MeanReward     | -11.7      |
| _lr_multiplier  | 1          |
| _max_act        | 2.60834    |
| _max_adv        | 3.49       |
| _max_discrew    | 0.317      |
| _max_obs        | 1.31       |
| _mean_act       | 0.00343091 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.0167    |
| _mean_obs       | 0.0357     |
| _min_adv        | -4.17      |
| _min_discrew    | -0.305     |
| _min_obs        | -1.39      |
| _std_act        | 0.399869   |
| _std_adv        | 1          |
| _std_discrew    | 0.0137     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.358       |
| ExplainedVarOld | 0.29        |
| KL              | 0.0027557   |
| Phi_loss        | 19.2321     |
| PolicyEntropy   | 5.1457      |
| PolicyLoss      | -0.00415975 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00881     |
| _MeanReward     | 2.05        |
| _lr_multiplier  | 1           |
| _max_act        | 2.7362      |
| _max_adv        | 3.71        |
| _max_discrew    | 0.43        |
| _max_obs        | 1.36        |
| _mean_act       | 0.00764984  |
| _mean_adv       | -4.26e-17   |
| _mean_discrew   | -0.0105     |
| _mean_obs       | 0.0242      |
| _min_adv        | -4.34       |
| _min_discrew    | -0.411      |
| _min_obs        | -1.27       |
| _std_act        | 0.405337    |
| _std_adv        | 1           |
| _std_discrew    | 0.0291      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.578      |
| ExplainedVarOld | 0.191      |
| KL              | 0.0141722  |
| Phi_loss        | 22.9142    |
| PolicyEntropy   | 5.15132    |
| PolicyLoss      | 0.00702879 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0123     |
| _MeanReward     | -54.9      |
| _lr_multiplier  | 1          |
| _max_act        | 2.72906    |
| _max_adv        | 3.53       |
| _max_discrew    | 0.3        |
| _max_obs        | 1.57       |
| _mean_act       | 0.0137041  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | -0.0527    |
| _mean_obs       | 0.0355     |
| _min_adv        | -5.81      |
| _min_discrew    | -0.304     |
| _min_obs        | -1.21      |
| _std_act        | 0.394367   |
| _std_adv        | 1          |
| _std_discrew    | 0.0121     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.475      |
| ExplainedVarOld | 0.434      |
| KL              | 0.0024575  |
| Phi_loss        | 27.1058    |
| PolicyEntropy   | 5.13697    |
| PolicyLoss      | 0.00451533 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00671    |
| _MeanReward     | 18.6       |
| _lr_multiplier  | 1          |
| _max_act        | 2.63911    |
| _max_adv        | 4.23       |
| _max_discrew    | 0.291      |
| _max_obs        | 1.39       |
| _mean_act       | 0.0177044  |
| _mean_adv       | 2.49e-17   |
| _mean_discrew   | 0.0112     |
| _mean_obs       | 0.0308     |
| _min_adv        | -4.26      |
| _min_discrew    | -0.231     |
| _min_obs        | -1.27      |
| _std_act        | 0.397781   |
| _std_adv        | 1          |
| _std_discrew    | 0.0077     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.459      |
| ExplainedVarOld | 0.409      |
| KL              | 0.00145421 |
| Phi_loss        | 28.7379    |
| PolicyEntropy   | 5.1234     |
| PolicyLoss      | 0.00307123 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00432    |
| _MeanReward     | 0.0705     |
| _lr_multiplier  | 1          |
| _max_act        | 2.66915    |
| _max_adv        | 4.6        |
| _max_discrew    | 0.353      |
| _max_obs        | 1.34       |
| _mean_act       | 0.00908775 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | -0.00604   |
| _mean_obs       | 0.0363     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.295     |
| _min_obs        | -1.18      |
| _std_act        | 0.394764   |
| _std_adv        | 1          |
| _std_discrew    | 0.0141     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.41       |
| ExplainedVarOld | 0.381      |
| KL              | 0.00292879 |
| Phi_loss        | 29.6952    |
| PolicyEntropy   | 5.11409    |
| PolicyLoss      | 0.00196904 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00829    |
| _MeanReward     | 3.71       |
| _lr_multiplier  | 1          |
| _max_act        | 2.84216    |
| _max_adv        | 3.33       |
| _max_discrew    | 0.286      |
| _max_obs        | 1.43       |
| _mean_act       | 0.0137482  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.00382   |
| _mean_obs       | 0.0341     |
| _min_adv        | -4.21      |
| _min_discrew    | -0.272     |
| _min_obs        | -1.23      |
| _std_act        | 0.395741   |
| _std_adv        | 1          |
| _std_discrew    | 0.0126     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.526       |
| ExplainedVarOld | 0.505       |
| KL              | 0.00273635  |
| Phi_loss        | 28.4087     |
| PolicyEntropy   | 5.09413     |
| PolicyLoss      | 0.000592257 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00598     |
| _MeanReward     | 6.55        |
| _lr_multiplier  | 1           |
| _max_act        | 2.92723     |
| _max_adv        | 3.98        |
| _max_discrew    | 0.336       |
| _max_obs        | 1.37        |
| _mean_act       | 0.0134214   |
| _mean_adv       | 0           |
| _mean_discrew   | -0.00788    |
| _mean_obs       | 0.0354      |
| _min_adv        | -4.09       |
| _min_discrew    | -0.251      |
| _min_obs        | -1.24       |
| _std_act        | 0.394371    |
| _std_adv        | 1           |
| _std_discrew    | 0.0123      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.481        |
| ExplainedVarOld | 0.458        |
| KL              | 0.00243577   |
| Phi_loss        | 28.3025      |
| PolicyEntropy   | 5.06447      |
| PolicyLoss      | 0.0120779    |
| Steps           | 10000        |
| VarFuncLoss     | 0.00636      |
| _MeanReward     | 2.88         |
| _lr_multiplier  | 1            |
| _max_act        | 2.53027      |
| _max_adv        | 3.37         |
| _max_discrew    | 0.313        |
| _max_obs        | 1.57         |
| _mean_act       | -0.000333554 |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | -0.0133      |
| _mean_obs       | 0.0358       |
| _min_adv        | -3.8         |
| _min_discrew    | -0.269       |
| _min_obs        | -1.26        |
| _std_act        | 0.392022     |
| _std_adv        | 1            |
| _std_discrew    | 0.0142       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.478      |
| ExplainedVarOld | 0.444      |
| KL              | 0.00216408 |
| Phi_loss        | 28.2697    |
| PolicyEntropy   | 5.03425    |
| PolicyLoss      | 0.0064504  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00743    |
| _MeanReward     | 74.3       |
| _lr_multiplier  | 1          |
| _max_act        | 2.62953    |
| _max_adv        | 3.56       |
| _max_discrew    | 0.361      |
| _max_obs        | 1.56       |
| _mean_act       | 0.00561346 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 0.0611     |
| _mean_obs       | 0.0275     |
| _min_adv        | -5.04      |
| _min_discrew    | -0.195     |
| _min_obs        | -1.13      |
| _std_act        | 0.386172   |
| _std_adv        | 1          |
| _std_discrew    | 0.0105     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.326      |
| ExplainedVarOld | 0.289      |
| KL              | 0.0026612  |
| Phi_loss        | 27.5252    |
| PolicyEntropy   | 5.00447    |
| PolicyLoss      | 0.00686467 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00723    |
| _MeanReward     | 72.1       |
| _lr_multiplier  | 1          |
| _max_act        | 2.48059    |
| _max_adv        | 4.49       |
| _max_discrew    | 0.519      |
| _max_obs        | 1.77       |
| _mean_act       | 0.00317721 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 0.0595     |
| _mean_obs       | 0.0315     |
| _min_adv        | -3.99      |
| _min_discrew    | -0.193     |
| _min_obs        | -1.16      |
| _std_act        | 0.383683   |
| _std_adv        | 1          |
| _std_discrew    | 0.0147     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.35       |
| ExplainedVarOld | 0.315      |
| KL              | 0.00262262 |
| Phi_loss        | 28.9756    |
| PolicyEntropy   | 4.97998    |
| PolicyLoss      | 0.00463048 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00957    |
| _MeanReward     | 94.4       |
| _lr_multiplier  | 1          |
| _max_act        | 3.0205     |
| _max_adv        | 4.39       |
| _max_discrew    | 0.393      |
| _max_obs        | 1.55       |
| _mean_act       | 0.0129561  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 0.0754     |
| _mean_obs       | 0.0317     |
| _min_adv        | -3.61      |
| _min_discrew    | -0.136     |
| _min_obs        | -1.23      |
| _std_act        | 0.388846   |
| _std_adv        | 1          |
| _std_discrew    | 0.00971    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.281       |
| ExplainedVarOld | 0.277       |
| KL              | 0.00259163  |
| Phi_loss        | 29.5183     |
| PolicyEntropy   | 4.96328     |
| PolicyLoss      | -0.00112395 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00704     |
| _MeanReward     | 100         |
| _lr_multiplier  | 1           |
| _max_act        | 2.47756     |
| _max_adv        | 4.22        |
| _max_discrew    | 0.508       |
| _max_obs        | 1.56        |
| _mean_act       | 0.0124727   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.0857      |
| _mean_obs       | 0.0307      |
| _min_adv        | -3.29       |
| _min_discrew    | -0.153      |
| _min_obs        | -1.2        |
| _std_act        | 0.379799    |
| _std_adv        | 1           |
| _std_discrew    | 0.0162      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.415      |
| ExplainedVarOld | 0.346      |
| KL              | 0.00224994 |
| Phi_loss        | 26.9979    |
| PolicyEntropy   | 4.95649    |
| PolicyLoss      | 0.00224107 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00949    |
| _MeanReward     | 55.6       |
| _lr_multiplier  | 1          |
| _max_act        | 2.74699    |
| _max_adv        | 4.15       |
| _max_discrew    | 0.418      |
| _max_obs        | 1.39       |
| _mean_act       | 0.0108513  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.0327     |
| _mean_obs       | 0.0365     |
| _min_adv        | -3.64      |
| _min_discrew    | -0.207     |
| _min_obs        | -1.27      |
| _std_act        | 0.379788   |
| _std_adv        | 1          |
| _std_discrew    | 0.0109     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.367      |
| ExplainedVarOld | 0.368      |
| KL              | 0.00314853 |
| Phi_loss        | 27.7527    |
| PolicyEntropy   | 4.93622    |
| PolicyLoss      | 0.00465626 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00711    |
| _MeanReward     | 153        |
| _lr_multiplier  | 1          |
| _max_act        | 2.85313    |
| _max_adv        | 3.02       |
| _max_discrew    | 0.43       |
| _max_obs        | 1.34       |
| _mean_act       | 0.001137   |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.12       |
| _mean_obs       | 0.0288     |
| _min_adv        | -3.83      |
| _min_discrew    | -0.124     |
| _min_obs        | -1.19      |
| _std_act        | 0.384719   |
| _std_adv        | 1          |
| _std_discrew    | 0.0136     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.337      |
| ExplainedVarOld | 0.285      |
| KL              | 0.00261956 |
| Phi_loss        | 26.6327    |
| PolicyEntropy   | 4.92698    |
| PolicyLoss      | -0.0016794 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00978    |
| _MeanReward     | 180        |
| _lr_multiplier  | 1          |
| _max_act        | 2.73133    |
| _max_adv        | 3.72       |
| _max_discrew    | 0.506      |
| _max_obs        | 1.6        |
| _mean_act       | 0.00892596 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.147      |
| _mean_obs       | 0.0282     |
| _min_adv        | -3.75      |
| _min_discrew    | -0.159     |
| _min_obs        | -1.37      |
| _std_act        | 0.391214   |
| _std_adv        | 1          |
| _std_discrew    | 0.0159     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.467      |
| ExplainedVarOld | 0.444      |
| KL              | 0.00265993 |
| Phi_loss        | 27.5912    |
| PolicyEntropy   | 4.89601    |
| PolicyLoss      | 0.00358591 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00855    |
| _MeanReward     | 171        |
| _lr_multiplier  | 1          |
| _max_act        | 2.85546    |
| _max_adv        | 3.85       |
| _max_discrew    | 0.447      |
| _max_obs        | 1.35       |
| _mean_act       | 0.00715961 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.135      |
| _mean_obs       | 0.0326     |
| _min_adv        | -4.08      |
| _min_discrew    | -0.127     |
| _min_obs        | -1.39      |
| _std_act        | 0.384445   |
| _std_adv        | 1          |
| _std_discrew    | 0.0174     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.517      |
| ExplainedVarOld | 0.486      |
| KL              | 0.00257285 |
| Phi_loss        | 28.2161    |
| PolicyEntropy   | 4.86016    |
| PolicyLoss      | 0.00794096 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00841    |
| _MeanReward     | 188        |
| _lr_multiplier  | 1          |
| _max_act        | 2.69803    |
| _max_adv        | 3.71       |
| _max_discrew    | 0.547      |
| _max_obs        | 1.38       |
| _mean_act       | 0.00496361 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.141      |
| _mean_obs       | 0.0277     |
| _min_adv        | -3.54      |
| _min_discrew    | -0.126     |
| _min_obs        | -1.33      |
| _std_act        | 0.382597   |
| _std_adv        | 1          |
| _std_discrew    | 0.0238     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.452      |
| ExplainedVarOld | 0.431      |
| KL              | 0.00284784 |
| Phi_loss        | 28.2225    |
| PolicyEntropy   | 4.83136    |
| PolicyLoss      | -0.0021047 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 203        |
| _lr_multiplier  | 1          |
| _max_act        | 2.82053    |
| _max_adv        | 4.12       |
| _max_discrew    | 0.656      |
| _max_obs        | 1.43       |
| _mean_act       | 0.005509   |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 0.142      |
| _mean_obs       | 0.03       |
| _min_adv        | -3.37      |
| _min_discrew    | -0.205     |
| _min_obs        | -1.21      |
| _std_act        | 0.386917   |
| _std_adv        | 1          |
| _std_discrew    | 0.0286     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.624       |
| ExplainedVarOld | 0.554       |
| KL              | 0.00341455  |
| Phi_loss        | 26.9764     |
| PolicyEntropy   | 4.82571     |
| PolicyLoss      | -0.00195839 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0109      |
| _MeanReward     | 242         |
| _lr_multiplier  | 1           |
| _max_act        | 2.77499     |
| _max_adv        | 4.04        |
| _max_discrew    | 0.545       |
| _max_obs        | 1.39        |
| _mean_act       | 0.00515331  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.188       |
| _mean_obs       | 0.0303      |
| _min_adv        | -5.21       |
| _min_discrew    | -0.113      |
| _min_obs        | -1.33       |
| _std_act        | 0.384786    |
| _std_adv        | 1           |
| _std_discrew    | 0.0233      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.535      |
| ExplainedVarOld | 0.514      |
| KL              | 0.00320395 |
| Phi_loss        | 28.7599    |
| PolicyEntropy   | 4.79739    |
| PolicyLoss      | 0.00354285 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 209        |
| _lr_multiplier  | 1          |
| _max_act        | 2.69246    |
| _max_adv        | 3.95       |
| _max_discrew    | 0.552      |
| _max_obs        | 1.43       |
| _mean_act       | 0.00062582 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.163      |
| _mean_obs       | 0.0298     |
| _min_adv        | -4.67      |
| _min_discrew    | -0.0974    |
| _min_obs        | -1.23      |
| _std_act        | 0.380642   |
| _std_adv        | 1          |
| _std_discrew    | 0.0217     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.491      |
| ExplainedVarOld | 0.441      |
| KL              | 0.00303357 |
| Phi_loss        | 29.1586    |
| PolicyEntropy   | 4.81073    |
| PolicyLoss      | -0.0052029 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0111     |
| _MeanReward     | 253        |
| _lr_multiplier  | 1          |
| _max_act        | 2.89845    |
| _max_adv        | 3.27       |
| _max_discrew    | 0.666      |
| _max_obs        | 1.36       |
| _mean_act       | 0.011924   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.206      |
| _mean_obs       | 0.0279     |
| _min_adv        | -4.77      |
| _min_discrew    | -0.1       |
| _min_obs        | -1.21      |
| _std_act        | 0.383856   |
| _std_adv        | 1          |
| _std_discrew    | 0.0284     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.537      |
| ExplainedVarOld | 0.505      |
| KL              | 0.00274113 |
| Phi_loss        | 29.5635    |
| PolicyEntropy   | 4.8214     |
| PolicyLoss      | -0.0035236 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 221        |
| _lr_multiplier  | 1          |
| _max_act        | 2.58238    |
| _max_adv        | 4.02       |
| _max_discrew    | 0.55       |
| _max_obs        | 1.38       |
| _mean_act       | 0.00112068 |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 0.171      |
| _mean_obs       | 0.0292     |
| _min_adv        | -5.11      |
| _min_discrew    | -0.271     |
| _min_obs        | -1.26      |
| _std_act        | 0.397662   |
| _std_adv        | 1          |
| _std_discrew    | 0.0291     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.601       |
| ExplainedVarOld | 0.572       |
| KL              | 0.00694677  |
| Phi_loss        | 32.6404     |
| PolicyEntropy   | 4.80468     |
| PolicyLoss      | -0.00788468 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0116      |
| _MeanReward     | 301         |
| _lr_multiplier  | 1           |
| _max_act        | 2.88705     |
| _max_adv        | 3.6         |
| _max_discrew    | 0.735       |
| _max_obs        | 1.42        |
| _mean_act       | 0.00662446  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.241       |
| _mean_obs       | 0.0292      |
| _min_adv        | -4.76       |
| _min_discrew    | -0.0945     |
| _min_obs        | -1.25       |
| _std_act        | 0.383494    |
| _std_adv        | 1           |
| _std_discrew    | 0.0274      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.483      |
| ExplainedVarOld | 0.438      |
| KL              | 0.0014901  |
| Phi_loss        | 31.229     |
| PolicyEntropy   | 4.78821    |
| PolicyLoss      | 0.0057459  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0149     |
| _MeanReward     | 299        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8688     |
| _max_adv        | 3.29       |
| _max_discrew    | 0.684      |
| _max_obs        | 1.55       |
| _mean_act       | 0.00687345 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.248      |
| _mean_obs       | 0.0271     |
| _min_adv        | -4.7       |
| _min_discrew    | -0.108     |
| _min_obs        | -1.24      |
| _std_act        | 0.386109   |
| _std_adv        | 1          |
| _std_discrew    | 0.032      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.484       |
| ExplainedVarOld | 0.463       |
| KL              | 0.00299382  |
| Phi_loss        | 33.3699     |
| PolicyEntropy   | 4.77672     |
| PolicyLoss      | -0.00422473 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 320         |
| _lr_multiplier  | 1           |
| _max_act        | 2.66312     |
| _max_adv        | 3.11        |
| _max_discrew    | 0.61        |
| _max_obs        | 1.31        |
| _mean_act       | 0.00925258  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.247       |
| _mean_obs       | 0.0295      |
| _min_adv        | -4.93       |
| _min_discrew    | -0.126      |
| _min_obs        | -1.25       |
| _std_act        | 0.386785    |
| _std_adv        | 1           |
| _std_discrew    | 0.0338      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.587        |
| ExplainedVarOld | 0.533        |
| KL              | 0.00281254   |
| Phi_loss        | 30.4788      |
| PolicyEntropy   | 4.76531      |
| PolicyLoss      | -0.000509677 |
| Steps           | 10000        |
| VarFuncLoss     | 0.014        |
| _MeanReward     | 305          |
| _lr_multiplier  | 1            |
| _max_act        | 2.70441      |
| _max_adv        | 3.53         |
| _max_discrew    | 0.666        |
| _max_obs        | 1.44         |
| _mean_act       | 0.00512315   |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | 0.23         |
| _mean_obs       | 0.0319       |
| _min_adv        | -5.37        |
| _min_discrew    | -0.157       |
| _min_obs        | -1.25        |
| _std_act        | 0.387287     |
| _std_adv        | 1            |
| _std_discrew    | 0.0462       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.629        |
| ExplainedVarOld | 0.592        |
| KL              | 0.00293757   |
| Phi_loss        | 30.3406      |
| PolicyEntropy   | 4.73719      |
| PolicyLoss      | -0.000397515 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0172       |
| _MeanReward     | 370          |
| _lr_multiplier  | 1            |
| _max_act        | 2.64584      |
| _max_adv        | 3.75         |
| _max_discrew    | 0.79         |
| _max_obs        | 1.42         |
| _mean_act       | 0.00606621   |
| _mean_adv       | -1.56e-17    |
| _mean_discrew   | 0.291        |
| _mean_obs       | 0.0307       |
| _min_adv        | -4.23        |
| _min_discrew    | -0.0712      |
| _min_obs        | -1.28        |
| _std_act        | 0.383414     |
| _std_adv        | 1            |
| _std_discrew    | 0.0443       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.636      |
| ExplainedVarOld | 0.625      |
| KL              | 0.00288311 |
| Phi_loss        | 32.1235    |
| PolicyEntropy   | 4.7106     |
| PolicyLoss      | 0.00137327 |
| Steps           | 10000      |
| VarFuncLoss     | 0.017      |
| _MeanReward     | 421        |
| _lr_multiplier  | 1          |
| _max_act        | 2.70081    |
| _max_adv        | 3.08       |
| _max_discrew    | 0.771      |
| _max_obs        | 1.52       |
| _mean_act       | 0.00276891 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.336      |
| _mean_obs       | 0.0252     |
| _min_adv        | -4.98      |
| _min_discrew    | -0.0517    |
| _min_obs        | -1.31      |
| _std_act        | 0.388583   |
| _std_adv        | 1          |
| _std_discrew    | 0.0324     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.549       |
| ExplainedVarOld | 0.49        |
| KL              | 0.00288535  |
| Phi_loss        | 33.7772     |
| PolicyEntropy   | 4.6805      |
| PolicyLoss      | 0.00157243  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0146      |
| _MeanReward     | 338         |
| _lr_multiplier  | 1           |
| _max_act        | 3.09232     |
| _max_adv        | 3.98        |
| _max_discrew    | 0.677       |
| _max_obs        | 1.45        |
| _mean_act       | -0.00132321 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.263       |
| _mean_obs       | 0.0286      |
| _min_adv        | -4.55       |
| _min_discrew    | -0.0749     |
| _min_obs        | -1.21       |
| _std_act        | 0.38531     |
| _std_adv        | 1           |
| _std_discrew    | 0.0346      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.557       |
| ExplainedVarOld | 0.541       |
| KL              | 0.00370075  |
| Phi_loss        | 35.8849     |
| PolicyEntropy   | 4.67116     |
| PolicyLoss      | -0.00316342 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0161      |
| _MeanReward     | 427         |
| _lr_multiplier  | 1           |
| _max_act        | 3.12606     |
| _max_adv        | 3.1         |
| _max_discrew    | 0.851       |
| _max_obs        | 1.47        |
| _mean_act       | 0.00591606  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.341       |
| _mean_obs       | 0.0292      |
| _min_adv        | -5          |
| _min_discrew    | -0.0819     |
| _min_obs        | -1.27       |
| _std_act        | 0.390988    |
| _std_adv        | 1           |
| _std_discrew    | 0.0394      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.609       |
| ExplainedVarOld | 0.593       |
| KL              | 0.00387717  |
| Phi_loss        | 36.2542     |
| PolicyEntropy   | 4.67193     |
| PolicyLoss      | -0.00645431 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0167      |
| _MeanReward     | 372         |
| _lr_multiplier  | 1           |
| _max_act        | 2.75435     |
| _max_adv        | 3.37        |
| _max_discrew    | 0.707       |
| _max_obs        | 1.37        |
| _mean_act       | 5.68278e-05 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.299       |
| _mean_obs       | 0.0298      |
| _min_adv        | -4.71       |
| _min_discrew    | -0.102      |
| _min_obs        | -1.26       |
| _std_act        | 0.392786    |
| _std_adv        | 1           |
| _std_discrew    | 0.0401      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.639        |
| ExplainedVarOld | 0.629        |
| KL              | 0.0032516    |
| Phi_loss        | 36.6012      |
| PolicyEntropy   | 4.67244      |
| PolicyLoss      | -0.00094765  |
| Steps           | 10000        |
| VarFuncLoss     | 0.0147       |
| _MeanReward     | 315          |
| _lr_multiplier  | 1            |
| _max_act        | 2.74013      |
| _max_adv        | 4.55         |
| _max_discrew    | 0.733        |
| _max_obs        | 1.44         |
| _mean_act       | -0.000171836 |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 0.24         |
| _mean_obs       | 0.0333       |
| _min_adv        | -5.03        |
| _min_discrew    | -0.0958      |
| _min_obs        | -1.35        |
| _std_act        | 0.391985     |
| _std_adv        | 1            |
| _std_discrew    | 0.0405       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.569       |
| ExplainedVarOld | 0.544       |
| KL              | 0.0028105   |
| Phi_loss        | 35.1877     |
| PolicyEntropy   | 4.64159     |
| PolicyLoss      | 0.00415699  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0176      |
| _MeanReward     | 450         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97783     |
| _max_adv        | 3.92        |
| _max_discrew    | 0.806       |
| _max_obs        | 1.58        |
| _mean_act       | -0.00254122 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 0.362       |
| _mean_obs       | 0.031       |
| _min_adv        | -5.08       |
| _min_discrew    | -0.0598     |
| _min_obs        | -1.38       |
| _std_act        | 0.393626    |
| _std_adv        | 1           |
| _std_discrew    | 0.0391      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.668       |
| ExplainedVarOld | 0.609       |
| KL              | 0.00329527  |
| Phi_loss        | 35.3013     |
| PolicyEntropy   | 4.64558     |
| PolicyLoss      | -0.00164908 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0153      |
| _MeanReward     | 476         |
| _lr_multiplier  | 1           |
| _max_act        | 2.88172     |
| _max_adv        | 3.89        |
| _max_discrew    | 0.8         |
| _max_obs        | 1.38        |
| _mean_act       | 0.000961479 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.397       |
| _mean_obs       | 0.0271      |
| _min_adv        | -5.45       |
| _min_discrew    | -0.0536     |
| _min_obs        | -1.44       |
| _std_act        | 0.397224    |
| _std_adv        | 1           |
| _std_discrew    | 0.0408      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.604       |
| ExplainedVarOld | 0.585       |
| KL              | 0.0036066   |
| Phi_loss        | 37.7762     |
| PolicyEntropy   | 4.6223      |
| PolicyLoss      | -0.00252263 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 556         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60712     |
| _max_adv        | 3.63        |
| _max_discrew    | 0.927       |
| _max_obs        | 1.41        |
| _mean_act       | -0.00465449 |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | 0.45        |
| _mean_obs       | 0.0272      |
| _min_adv        | -6.21       |
| _min_discrew    | -0.0548     |
| _min_obs        | -1.31       |
| _std_act        | 0.395239    |
| _std_adv        | 1           |
| _std_discrew    | 0.0479      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.627       |
| ExplainedVarOld | 0.588       |
| KL              | 0.00311895  |
| Phi_loss        | 32.7275     |
| PolicyEntropy   | 4.60314     |
| PolicyLoss      | -0.00624071 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0185      |
| _MeanReward     | 432         |
| _lr_multiplier  | 1           |
| _max_act        | 3.21408     |
| _max_adv        | 3.46        |
| _max_discrew    | 0.831       |
| _max_obs        | 1.55        |
| _mean_act       | -0.00409961 |
| _mean_adv       | -3.69e-17   |
| _mean_discrew   | 0.321       |
| _mean_obs       | 0.0297      |
| _min_adv        | -6.88       |
| _min_discrew    | -0.542      |
| _min_obs        | -1.34       |
| _std_act        | 0.44723     |
| _std_adv        | 1           |
| _std_discrew    | 0.0934      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.709       |
| ExplainedVarOld | 0.68        |
| KL              | 0.00427902  |
| Phi_loss        | 38.1487     |
| PolicyEntropy   | 4.60306     |
| PolicyLoss      | -0.00601652 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0278      |
| _MeanReward     | 391         |
| _lr_multiplier  | 1           |
| _max_act        | 2.96627     |
| _max_adv        | 3.21        |
| _max_discrew    | 0.945       |
| _max_obs        | 1.4         |
| _mean_act       | -0.00808152 |
| _mean_adv       | -1.92e-17   |
| _mean_discrew   | 0.302       |
| _mean_obs       | 0.03        |
| _min_adv        | -8.9        |
| _min_discrew    | -0.59       |
| _min_obs        | -1.23       |
| _std_act        | 0.442134    |
| _std_adv        | 1           |
| _std_discrew    | 0.0913      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.663       |
| ExplainedVarOld | 0.612       |
| KL              | 0.00329776  |
| Phi_loss        | 36.9541     |
| PolicyEntropy   | 4.59325     |
| PolicyLoss      | -0.00326154 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0308      |
| _MeanReward     | 595         |
| _lr_multiplier  | 1           |
| _max_act        | 2.73245     |
| _max_adv        | 3.64        |
| _max_discrew    | 0.966       |
| _max_obs        | 1.63        |
| _mean_act       | -0.00712429 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.491       |
| _mean_obs       | 0.0274      |
| _min_adv        | -5.05       |
| _min_discrew    | -0.0714     |
| _min_obs        | -1.25       |
| _std_act        | 0.398509    |
| _std_adv        | 1           |
| _std_discrew    | 0.0498      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.558       |
| ExplainedVarOld | 0.539       |
| KL              | 0.00344316  |
| Phi_loss        | 41.3823     |
| PolicyEntropy   | 4.57825     |
| PolicyLoss      | -0.00294806 |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 582         |
| _lr_multiplier  | 1           |
| _max_act        | 3.46135     |
| _max_adv        | 2.86        |
| _max_discrew    | 1.01        |
| _max_obs        | 1.58        |
| _mean_act       | -0.00976351 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.47        |
| _mean_obs       | 0.0278      |
| _min_adv        | -5.56       |
| _min_discrew    | -0.103      |
| _min_obs        | -1.22       |
| _std_act        | 0.400472    |
| _std_adv        | 1           |
| _std_discrew    | 0.058       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.607       |
| ExplainedVarOld | 0.569       |
| KL              | 0.00305261  |
| Phi_loss        | 41.4986     |
| PolicyEntropy   | 4.56635     |
| PolicyLoss      | -0.00309671 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0228      |
| _MeanReward     | 550         |
| _lr_multiplier  | 1           |
| _max_act        | 2.9873      |
| _max_adv        | 4.72        |
| _max_discrew    | 0.979       |
| _max_obs        | 1.56        |
| _mean_act       | -0.00512225 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.443       |
| _mean_obs       | 0.0283      |
| _min_adv        | -9          |
| _min_discrew    | -0.575      |
| _min_obs        | -1.45       |
| _std_act        | 0.440427    |
| _std_adv        | 1           |
| _std_discrew    | 0.0894      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.74        |
| ExplainedVarOld | 0.717       |
| KL              | 0.00307502  |
| Phi_loss        | 41.731      |
| PolicyEntropy   | 4.54522     |
| PolicyLoss      | -0.00398707 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 612         |
| _lr_multiplier  | 1           |
| _max_act        | 2.98682     |
| _max_adv        | 4.78        |
| _max_discrew    | 1.09        |
| _max_obs        | 1.43        |
| _mean_act       | -0.00897212 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.504       |
| _mean_obs       | 0.0282      |
| _min_adv        | -4.99       |
| _min_discrew    | -0.0633     |
| _min_obs        | -1.31       |
| _std_act        | 0.41056     |
| _std_adv        | 1           |
| _std_discrew    | 0.0721      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.599       |
| ExplainedVarOld | 0.57        |
| KL              | 0.00333026  |
| Phi_loss        | 39.6228     |
| PolicyEntropy   | 4.52924     |
| PolicyLoss      | -0.00647338 |
| Steps           | 10000       |
| VarFuncLoss     | 0.029       |
| _MeanReward     | 580         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97301     |
| _max_adv        | 3.74        |
| _max_discrew    | 0.96        |
| _max_obs        | 1.49        |
| _mean_act       | -0.00679826 |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 0.482       |
| _mean_obs       | 0.0302      |
| _min_adv        | -6.28       |
| _min_discrew    | -0.0529     |
| _min_obs        | -1.37       |
| _std_act        | 0.413421    |
| _std_adv        | 1           |
| _std_discrew    | 0.0558      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.587      |
| ExplainedVarOld | 0.534      |
| KL              | 0.00342462 |
| Phi_loss        | 38.9831    |
| PolicyEntropy   | 4.51399    |
| PolicyLoss      | 0.00213944 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 464        |
| _lr_multiplier  | 1          |
| _max_act        | 3.42106    |
| _max_adv        | 3.43       |
| _max_discrew    | 1.06       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0131711 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 0.366      |
| _mean_obs       | 0.0279     |
| _min_adv        | -8.44      |
| _min_discrew    | -0.698     |
| _min_obs        | -1.24      |
| _std_act        | 0.497306   |
| _std_adv        | 1          |
| _std_discrew    | 0.169      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.731       |
| ExplainedVarOld | 0.728       |
| KL              | 0.00688633  |
| Phi_loss        | 45.2932     |
| PolicyEntropy   | 4.51288     |
| PolicyLoss      | -0.0134304  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0457      |
| _MeanReward     | 654         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95101     |
| _max_adv        | 4.03        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.44        |
| _mean_act       | -0.00707322 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.532       |
| _mean_obs       | 0.029       |
| _min_adv        | -5.42       |
| _min_discrew    | -0.0915     |
| _min_obs        | -1.29       |
| _std_act        | 0.412421    |
| _std_adv        | 1           |
| _std_discrew    | 0.0776      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.705       |
| ExplainedVarOld | 0.653       |
| KL              | 0.00147748  |
| Phi_loss        | 49.6523     |
| PolicyEntropy   | 4.51012     |
| PolicyLoss      | -0.00788349 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0234      |
| _MeanReward     | 586         |
| _lr_multiplier  | 1           |
| _max_act        | 3.47415     |
| _max_adv        | 4.24        |
| _max_discrew    | 1.14        |
| _max_obs        | 1.67        |
| _mean_act       | -0.0141604  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.462       |
| _mean_obs       | 0.028       |
| _min_adv        | -11.2       |
| _min_discrew    | -0.719      |
| _min_obs        | -1.3        |
| _std_act        | 0.513358    |
| _std_adv        | 1           |
| _std_discrew    | 0.194       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.831       |
| ExplainedVarOld | 0.815       |
| KL              | 0.00341696  |
| Phi_loss        | 43.5741     |
| PolicyEntropy   | 4.49218     |
| PolicyLoss      | -0.00304922 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0328      |
| _MeanReward     | 732         |
| _lr_multiplier  | 1           |
| _max_act        | 2.75595     |
| _max_adv        | 5.89        |
| _max_discrew    | 1.12        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0023876  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 0.588       |
| _mean_obs       | 0.0284      |
| _min_adv        | -6.99       |
| _min_discrew    | -0.0805     |
| _min_obs        | -1.31       |
| _std_act        | 0.414358    |
| _std_adv        | 1           |
| _std_discrew    | 0.0733      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.705       |
| ExplainedVarOld | 0.687       |
| KL              | 0.00390839  |
| Phi_loss        | 46.9901     |
| PolicyEntropy   | 4.46958     |
| PolicyLoss      | -0.00576734 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0217      |
| _MeanReward     | 776         |
| _lr_multiplier  | 1           |
| _max_act        | 2.74964     |
| _max_adv        | 5.49        |
| _max_discrew    | 1.26        |
| _max_obs        | 1.44        |
| _mean_act       | -0.00351273 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.629       |
| _mean_obs       | 0.0298      |
| _min_adv        | -5.82       |
| _min_discrew    | -0.08       |
| _min_obs        | -1.29       |
| _std_act        | 0.420689    |
| _std_adv        | 1           |
| _std_discrew    | 0.0843      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.671       |
| ExplainedVarOld | 0.65        |
| KL              | 0.00328835  |
| Phi_loss        | 49.0374     |
| PolicyEntropy   | 4.45251     |
| PolicyLoss      | -0.0088806  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0286      |
| _MeanReward     | 699         |
| _lr_multiplier  | 1           |
| _max_act        | 2.8932      |
| _max_adv        | 3.31        |
| _max_discrew    | 1.22        |
| _max_obs        | 1.44        |
| _mean_act       | -0.00779544 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.563       |
| _mean_obs       | 0.0324      |
| _min_adv        | -4.84       |
| _min_discrew    | -0.0499     |
| _min_obs        | -1.28       |
| _std_act        | 0.421561    |
| _std_adv        | 1           |
| _std_discrew    | 0.104       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.693       |
| ExplainedVarOld | 0.666       |
| KL              | 0.00267275  |
| Phi_loss        | 47.4206     |
| PolicyEntropy   | 4.44953     |
| PolicyLoss      | -0.00869197 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0321      |
| _MeanReward     | 771         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06421     |
| _max_adv        | 4.44        |
| _max_discrew    | 1.26        |
| _max_obs        | 1.45        |
| _mean_act       | -0.00281506 |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.625       |
| _mean_obs       | 0.0322      |
| _min_adv        | -5.84       |
| _min_discrew    | -0.0788     |
| _min_obs        | -1.32       |
| _std_act        | 0.429797    |
| _std_adv        | 1           |
| _std_discrew    | 0.0839      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.599      |
| ExplainedVarOld | 0.586      |
| KL              | 0.00301487 |
| Phi_loss        | 46.2468    |
| PolicyEntropy   | 4.44951    |
| PolicyLoss      | -0.0113465 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0341     |
| _MeanReward     | 565        |
| _lr_multiplier  | 1          |
| _max_act        | 3.37746    |
| _max_adv        | 3.52       |
| _max_discrew    | 1.23       |
| _max_obs        | 1.6        |
| _mean_act       | -0.0232451 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 0.438      |
| _mean_obs       | 0.0301     |
| _min_adv        | -8.65      |
| _min_discrew    | -0.931     |
| _min_obs        | -1.22      |
| _std_act        | 0.591941   |
| _std_adv        | 1          |
| _std_discrew    | 0.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.868      |
| ExplainedVarOld | 0.77       |
| KL              | 0.00373381 |
| Phi_loss        | 36.6024    |
| PolicyEntropy   | 4.45151    |
| PolicyLoss      | 0.00471795 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0423     |
| _MeanReward     | 727        |
| _lr_multiplier  | 1          |
| _max_act        | 3.47842    |
| _max_adv        | 3.38       |
| _max_discrew    | 1.34       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0113263 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 0.581      |
| _mean_obs       | 0.0302     |
| _min_adv        | -12.4      |
| _min_discrew    | -0.807     |
| _min_obs        | -1.29      |
| _std_act        | 0.514372   |
| _std_adv        | 1          |
| _std_discrew    | 0.202      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.808       |
| ExplainedVarOld | 0.798       |
| KL              | 0.00334949  |
| Phi_loss        | 42.1306     |
| PolicyEntropy   | 4.43869     |
| PolicyLoss      | 0.00584407  |
| Steps           | 10000       |
| VarFuncLoss     | 0.039       |
| _MeanReward     | 811         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06292     |
| _max_adv        | 5.14        |
| _max_discrew    | 1.25        |
| _max_obs        | 1.42        |
| _mean_act       | -0.00554354 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.662       |
| _mean_obs       | 0.0301      |
| _min_adv        | -7.96       |
| _min_discrew    | -0.502      |
| _min_obs        | -1.27       |
| _std_act        | 0.462842    |
| _std_adv        | 1           |
| _std_discrew    | 0.0881      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.696       |
| ExplainedVarOld | 0.682       |
| KL              | 0.0034358   |
| Phi_loss        | 48.1372     |
| PolicyEntropy   | 4.42161     |
| PolicyLoss      | 0.00107941  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0269      |
| _MeanReward     | 808         |
| _lr_multiplier  | 1           |
| _max_act        | 2.74265     |
| _max_adv        | 3.95        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.41        |
| _mean_act       | -0.00532783 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.671       |
| _mean_obs       | 0.0311      |
| _min_adv        | -5.66       |
| _min_discrew    | -0.227      |
| _min_obs        | -1.34       |
| _std_act        | 0.442777    |
| _std_adv        | 1           |
| _std_discrew    | 0.0968      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.693        |
| ExplainedVarOld | 0.661        |
| KL              | 0.00294003   |
| Phi_loss        | 44.2666      |
| PolicyEntropy   | 4.42809      |
| PolicyLoss      | -0.0012203   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0298       |
| _MeanReward     | 868          |
| _lr_multiplier  | 1            |
| _max_act        | 3.22555      |
| _max_adv        | 3.9          |
| _max_discrew    | 1.41         |
| _max_obs        | 1.52         |
| _mean_act       | -0.000935068 |
| _mean_adv       | 0            |
| _mean_discrew   | 0.712        |
| _mean_obs       | 0.0321       |
| _min_adv        | -6           |
| _min_discrew    | -0.115       |
| _min_obs        | -1.31        |
| _std_act        | 0.444423     |
| _std_adv        | 1            |
| _std_discrew    | 0.105        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.731       |
| ExplainedVarOld | 0.696       |
| KL              | 0.00322576  |
| Phi_loss        | 46.7176     |
| PolicyEntropy   | 4.40364     |
| PolicyLoss      | 0.000676789 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0285      |
| _MeanReward     | 838         |
| _lr_multiplier  | 1           |
| _max_act        | 3.3148      |
| _max_adv        | 5.27        |
| _max_discrew    | 1.23        |
| _max_obs        | 1.41        |
| _mean_act       | -0.00566247 |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 0.672       |
| _mean_obs       | 0.0312      |
| _min_adv        | -6.58       |
| _min_discrew    | -0.134      |
| _min_obs        | -1.21       |
| _std_act        | 0.436088    |
| _std_adv        | 1           |
| _std_discrew    | 0.0865      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.613        |
| ExplainedVarOld | 0.525        |
| KL              | 0.00314211   |
| Phi_loss        | 46.2134      |
| PolicyEntropy   | 4.40124      |
| PolicyLoss      | -0.00836516  |
| Steps           | 10000        |
| VarFuncLoss     | 0.034        |
| _MeanReward     | 901          |
| _lr_multiplier  | 1            |
| _max_act        | 3.08166      |
| _max_adv        | 3.58         |
| _max_discrew    | 1.48         |
| _max_obs        | 1.47         |
| _mean_act       | -0.000854918 |
| _mean_adv       | 1.71e-17     |
| _mean_discrew   | 0.735        |
| _mean_obs       | 0.0337       |
| _min_adv        | -5.79        |
| _min_discrew    | -0.0949      |
| _min_obs        | -1.36        |
| _std_act        | 0.442906     |
| _std_adv        | 1            |
| _std_discrew    | 0.122        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.687      |
| ExplainedVarOld | 0.674      |
| KL              | 0.0032846  |
| Phi_loss        | 50.8345    |
| PolicyEntropy   | 4.38088    |
| PolicyLoss      | -0.0116576 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0389     |
| _MeanReward     | 790        |
| _lr_multiplier  | 1          |
| _max_act        | 3.26572    |
| _max_adv        | 3.08       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0116465 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.612      |
| _mean_obs       | 0.0315     |
| _min_adv        | -9.81      |
| _min_discrew    | -0.856     |
| _min_obs        | -1.27      |
| _std_act        | 0.56042    |
| _std_adv        | 1          |
| _std_discrew    | 0.297      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.785      |
| ExplainedVarOld | 0.761      |
| KL              | 0.0059714  |
| Phi_loss        | 53.5705    |
| PolicyEntropy   | 4.364      |
| PolicyLoss      | 0.00956001 |
| Steps           | 10000      |
| VarFuncLoss     | 0.064      |
| _MeanReward     | 923        |
| _lr_multiplier  | 1          |
| _max_act        | 3.34588    |
| _max_adv        | 3.82       |
| _max_discrew    | 1.34       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0066219 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.74       |
| _mean_obs       | 0.0327     |
| _min_adv        | -6.06      |
| _min_discrew    | -0.301     |
| _min_obs        | -1.37      |
| _std_act        | 0.459924   |
| _std_adv        | 1          |
| _std_discrew    | 0.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.746       |
| ExplainedVarOld | 0.705       |
| KL              | 0.00323848  |
| Phi_loss        | 52.2134     |
| PolicyEntropy   | 4.34563     |
| PolicyLoss      | 0.000177886 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0332      |
| _MeanReward     | 979         |
| _lr_multiplier  | 1           |
| _max_act        | 3.07251     |
| _max_adv        | 7.05        |
| _max_discrew    | 1.33        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0049332  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 0.828       |
| _mean_obs       | 0.0322      |
| _min_adv        | -6.97       |
| _min_discrew    | -0.00101    |
| _min_obs        | -1.24       |
| _std_act        | 0.449975    |
| _std_adv        | 1           |
| _std_discrew    | 0.102       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.675       |
| ExplainedVarOld | 0.622       |
| KL              | 0.00387482  |
| Phi_loss        | 42.769      |
| PolicyEntropy   | 4.33484     |
| PolicyLoss      | -0.00434113 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0342      |
| _MeanReward     | 926         |
| _lr_multiplier  | 1           |
| _max_act        | 3.65049     |
| _max_adv        | 4.5         |
| _max_discrew    | 1.47        |
| _max_obs        | 1.52        |
| _mean_act       | -0.00584171 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.746       |
| _mean_obs       | 0.0342      |
| _min_adv        | -8.2        |
| _min_discrew    | -0.659      |
| _min_obs        | -1.27       |
| _std_act        | 0.487325    |
| _std_adv        | 1           |
| _std_discrew    | 0.154       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.722       |
| ExplainedVarOld | 0.692       |
| KL              | 0.00346226  |
| Phi_loss        | 47.339      |
| PolicyEntropy   | 4.33781     |
| PolicyLoss      | -0.0119106  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0431      |
| _MeanReward     | 952         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87404     |
| _max_adv        | 3.52        |
| _max_discrew    | 1.37        |
| _max_obs        | 1.57        |
| _mean_act       | -0.00731308 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.782       |
| _mean_obs       | 0.0326      |
| _min_adv        | -5.8        |
| _min_discrew    | -0.064      |
| _min_obs        | -1.3        |
| _std_act        | 0.444807    |
| _std_adv        | 1           |
| _std_discrew    | 0.115       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.695       |
| ExplainedVarOld | 0.677       |
| KL              | 0.00296631  |
| Phi_loss        | 54.9603     |
| PolicyEntropy   | 4.3063      |
| PolicyLoss      | -0.00408142 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0352      |
| _MeanReward     | 798         |
| _lr_multiplier  | 1           |
| _max_act        | 3.37188     |
| _max_adv        | 3.02        |
| _max_discrew    | 1.47        |
| _max_obs        | 1.55        |
| _mean_act       | -0.021015   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.612       |
| _mean_obs       | 0.0317      |
| _min_adv        | -9.7        |
| _min_discrew    | -0.847      |
| _min_obs        | -1.25       |
| _std_act        | 0.603952    |
| _std_adv        | 1           |
| _std_discrew    | 0.368       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.764       |
| ExplainedVarOld | 0.753       |
| KL              | 0.00314     |
| Phi_loss        | 53.8122     |
| PolicyEntropy   | 4.26951     |
| PolicyLoss      | 0.021626    |
| Steps           | 10000       |
| VarFuncLoss     | 0.0874      |
| _MeanReward     | 1.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.15703     |
| _max_adv        | 5.57        |
| _max_discrew    | 1.39        |
| _max_obs        | 1.4         |
| _mean_act       | -0.00510031 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.854       |
| _mean_obs       | 0.0323      |
| _min_adv        | -7.26       |
| _min_discrew    | -0.34       |
| _min_obs        | -1.46       |
| _std_act        | 0.465221    |
| _std_adv        | 1           |
| _std_discrew    | 0.108       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.765      |
| ExplainedVarOld | 0.714      |
| KL              | 0.00319096 |
| Phi_loss        | 47.7728    |
| PolicyEntropy   | 4.25374    |
| PolicyLoss      | -0.015667  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0265     |
| _MeanReward     | 860        |
| _lr_multiplier  | 1          |
| _max_act        | 3.3143     |
| _max_adv        | 4.65       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.43       |
| _mean_act       | -0.015236  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.678      |
| _mean_obs       | 0.0329     |
| _min_adv        | -11.1      |
| _min_discrew    | -0.954     |
| _min_obs        | -1.26      |
| _std_act        | 0.594579   |
| _std_adv        | 1          |
| _std_discrew    | 0.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.827       |
| ExplainedVarOld | 0.81        |
| KL              | 0.00290539  |
| Phi_loss        | 48.2635     |
| PolicyEntropy   | 4.28275     |
| PolicyLoss      | -0.00782873 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0642      |
| _MeanReward     | 1.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95491     |
| _max_adv        | 9.13        |
| _max_discrew    | 1.51        |
| _max_obs        | 1.46        |
| _mean_act       | -0.00565786 |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.827       |
| _mean_obs       | 0.0326      |
| _min_adv        | -4.74       |
| _min_discrew    | -0.0226     |
| _min_obs        | -1.17       |
| _std_act        | 0.458443    |
| _std_adv        | 1           |
| _std_discrew    | 0.117       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.737       |
| ExplainedVarOld | 0.706       |
| KL              | 0.0036678   |
| Phi_loss        | 47.928      |
| PolicyEntropy   | 4.28146     |
| PolicyLoss      | -0.00818626 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0309      |
| _MeanReward     | 1.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77087     |
| _max_adv        | 4.66        |
| _max_discrew    | 1.55        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00733939 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.907       |
| _mean_obs       | 0.0336      |
| _min_adv        | -6.92       |
| _min_discrew    | -0.122      |
| _min_obs        | -1.25       |
| _std_act        | 0.454938    |
| _std_adv        | 1           |
| _std_discrew    | 0.122       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.762       |
| ExplainedVarOld | 0.742       |
| KL              | 0.00322118  |
| Phi_loss        | 56.1021     |
| PolicyEntropy   | 4.24912     |
| PolicyLoss      | 0.00146004  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0299      |
| _MeanReward     | 1.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0251      |
| _max_adv        | 5.03        |
| _max_discrew    | 1.59        |
| _max_obs        | 1.56        |
| _mean_act       | -0.00446712 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.858       |
| _mean_obs       | 0.0355      |
| _min_adv        | -5.51       |
| _min_discrew    | -0.131      |
| _min_obs        | -1.21       |
| _std_act        | 0.46489     |
| _std_adv        | 1           |
| _std_discrew    | 0.161       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.715       |
| ExplainedVarOld | 0.676       |
| KL              | 0.00286592  |
| Phi_loss        | 52.4877     |
| PolicyEntropy   | 4.2339      |
| PolicyLoss      | -0.00392001 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0459      |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.39357     |
| _max_adv        | 4.31        |
| _max_discrew    | 1.6         |
| _max_obs        | 1.5         |
| _mean_act       | -0.00560922 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.87        |
| _mean_obs       | 0.0353      |
| _min_adv        | -5.36       |
| _min_discrew    | -0.000316   |
| _min_obs        | -1.23       |
| _std_act        | 0.47113     |
| _std_adv        | 1           |
| _std_discrew    | 0.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.709       |
| ExplainedVarOld | 0.685       |
| KL              | 0.00306166  |
| Phi_loss        | 54.9673     |
| PolicyEntropy   | 4.2172      |
| PolicyLoss      | -0.00803957 |
| Steps           | 10000       |
| VarFuncLoss     | 0.035       |
| _MeanReward     | 903         |
| _lr_multiplier  | 1           |
| _max_act        | 3.62918     |
| _max_adv        | 3.19        |
| _max_discrew    | 1.51        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0129156  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.713       |
| _mean_obs       | 0.0353      |
| _min_adv        | -10.7       |
| _min_discrew    | -1.03       |
| _min_obs        | -1.25       |
| _std_act        | 0.584348    |
| _std_adv        | 1           |
| _std_discrew    | 0.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.779      |
| ExplainedVarOld | 0.757      |
| KL              | 0.00474118 |
| Phi_loss        | 53.5438    |
| PolicyEntropy   | 4.20846    |
| PolicyLoss      | -0.028416  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0817     |
| _MeanReward     | 1.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.3135     |
| _max_adv        | 3.23       |
| _max_discrew    | 2          |
| _max_obs        | 1.41       |
| _mean_act       | -0.0102315 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.937      |
| _mean_obs       | 0.0361     |
| _min_adv        | -10.9      |
| _min_discrew    | -0.844     |
| _min_obs        | -1.37      |
| _std_act        | 0.517528   |
| _std_adv        | 1          |
| _std_discrew    | 0.232      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.744       |
| ExplainedVarOld | 0.729       |
| KL              | 0.00311955  |
| Phi_loss        | 61.9159     |
| PolicyEntropy   | 4.1987      |
| PolicyLoss      | -0.0130553  |
| Steps           | 10000       |
| VarFuncLoss     | 0.063       |
| _MeanReward     | 1.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.22917     |
| _max_adv        | 7.14        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00770225 |
| _mean_adv       | 5.12e-17    |
| _mean_discrew   | 0.905       |
| _mean_obs       | 0.0353      |
| _min_adv        | -5.25       |
| _min_discrew    | -0.258      |
| _min_obs        | -1.29       |
| _std_act        | 0.479027    |
| _std_adv        | 1           |
| _std_discrew    | 0.172       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.701       |
| ExplainedVarOld | 0.68        |
| KL              | 0.0028816   |
| Phi_loss        | 55.6886     |
| PolicyEntropy   | 4.18136     |
| PolicyLoss      | -0.00563584 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0519      |
| _MeanReward     | 873         |
| _lr_multiplier  | 1           |
| _max_act        | 3.42464     |
| _max_adv        | 3.38        |
| _max_discrew    | 1.73        |
| _max_obs        | 1.59        |
| _mean_act       | -0.0261156  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.692       |
| _mean_obs       | 0.0344      |
| _min_adv        | -10.3       |
| _min_discrew    | -1.14       |
| _min_obs        | -1.34       |
| _std_act        | 0.675068    |
| _std_adv        | 1           |
| _std_discrew    | 0.66        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.825       |
| ExplainedVarOld | 0.782       |
| KL              | 0.00404486  |
| Phi_loss        | 43.7839     |
| PolicyEntropy   | 4.18102     |
| PolicyLoss      | -0.00165237 |
| Steps           | 10000       |
| VarFuncLoss     | 0.116       |
| _MeanReward     | 1.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.41963     |
| _max_adv        | 6.05        |
| _max_discrew    | 1.87        |
| _max_obs        | 1.42        |
| _mean_act       | -0.00803356 |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.0357      |
| _min_adv        | -5.79       |
| _min_discrew    | -0.175      |
| _min_obs        | -1.42       |
| _std_act        | 0.478196    |
| _std_adv        | 1           |
| _std_discrew    | 0.188       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.709      |
| ExplainedVarOld | 0.696      |
| KL              | 0.00374988 |
| Phi_loss        | 55.3323    |
| PolicyEntropy   | 4.16793    |
| PolicyLoss      | -0.0120042 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0549     |
| _MeanReward     | 1.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.4585     |
| _max_adv        | 6.26       |
| _max_discrew    | 1.75       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0118412 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.844      |
| _mean_obs       | 0.0365     |
| _min_adv        | -11.8      |
| _min_discrew    | -0.998     |
| _min_obs        | -1.25      |
| _std_act        | 0.554276   |
| _std_adv        | 1          |
| _std_discrew    | 0.323      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.741        |
| ExplainedVarOld | 0.707        |
| KL              | 0.00383148   |
| Phi_loss        | 61.4305      |
| PolicyEntropy   | 4.15379      |
| PolicyLoss      | -0.000782107 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0853       |
| _MeanReward     | 1.24e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.17931      |
| _max_adv        | 4.44         |
| _max_discrew    | 1.72         |
| _max_obs        | 1.52         |
| _mean_act       | -0.0103739   |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 1.03         |
| _mean_obs       | 0.0354       |
| _min_adv        | -6.64        |
| _min_discrew    | -0.0688      |
| _min_obs        | -1.27        |
| _std_act        | 0.48091      |
| _std_adv        | 1            |
| _std_discrew    | 0.171        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.762      |
| ExplainedVarOld | 0.745      |
| KL              | 0.00330069 |
| Phi_loss        | 58.6474    |
| PolicyEntropy   | 4.14307    |
| PolicyLoss      | -0.0040524 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0429     |
| _MeanReward     | 970        |
| _lr_multiplier  | 1          |
| _max_act        | 3.59739    |
| _max_adv        | 5.25       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0202942 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.77       |
| _mean_obs       | 0.035      |
| _min_adv        | -10.5      |
| _min_discrew    | -1.14      |
| _min_obs        | -1.33      |
| _std_act        | 0.627148   |
| _std_adv        | 1          |
| _std_discrew    | 0.493      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.767      |
| ExplainedVarOld | 0.744      |
| KL              | 0.00514492 |
| Phi_loss        | 60.3183    |
| PolicyEntropy   | 4.13537    |
| PolicyLoss      | -0.0184912 |
| Steps           | 10000      |
| VarFuncLoss     | 0.116      |
| _MeanReward     | 1.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.70582    |
| _max_adv        | 6.56       |
| _max_discrew    | 1.8        |
| _max_obs        | 1.45       |
| _mean_act       | -0.0154263 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.985      |
| _mean_obs       | 0.0352     |
| _min_adv        | -13.5      |
| _min_discrew    | -1.08      |
| _min_obs        | -1.22      |
| _std_act        | 0.560802   |
| _std_adv        | 1          |
| _std_discrew    | 0.363      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.789       |
| ExplainedVarOld | 0.789       |
| KL              | 0.00238209  |
| Phi_loss        | 59.9886     |
| PolicyEntropy   | 4.12171     |
| PolicyLoss      | -0.00776826 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0789      |
| _MeanReward     | 1.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.12605     |
| _max_adv        | 7.99        |
| _max_discrew    | 1.88        |
| _max_obs        | 1.63        |
| _mean_act       | -0.0126512  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 1.09        |
| _mean_obs       | 0.0355      |
| _min_adv        | -6.36       |
| _min_discrew    | 0.00321     |
| _min_obs        | -1.21       |
| _std_act        | 0.4807      |
| _std_adv        | 1           |
| _std_discrew    | 0.176       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.82        |
| ExplainedVarOld | 0.775       |
| KL              | 0.00332794  |
| Phi_loss        | 59.4771     |
| PolicyEntropy   | 4.09953     |
| PolicyLoss      | -0.00545692 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0321      |
| _MeanReward     | 1.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11501     |
| _max_adv        | 5.73        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0112933  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.13        |
| _mean_obs       | 0.0359      |
| _min_adv        | -6.85       |
| _min_discrew    | 0.000681    |
| _min_obs        | -1.3        |
| _std_act        | 0.488144    |
| _std_adv        | 1           |
| _std_discrew    | 0.159       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.816       |
| ExplainedVarOld | 0.796       |
| KL              | 0.00332476  |
| Phi_loss        | 62.106      |
| PolicyEntropy   | 4.07401     |
| PolicyLoss      | -0.00399422 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0296      |
| _MeanReward     | 1.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.42961     |
| _max_adv        | 6.15        |
| _max_discrew    | 1.92        |
| _max_obs        | 1.46        |
| _mean_act       | -0.0152564  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.16        |
| _mean_obs       | 0.0353      |
| _min_adv        | -7.2        |
| _min_discrew    | 0.00219     |
| _min_obs        | -1.19       |
| _std_act        | 0.479055    |
| _std_adv        | 1           |
| _std_discrew    | 0.162       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.825       |
| ExplainedVarOld | 0.816       |
| KL              | 0.003284    |
| Phi_loss        | 68.3756     |
| PolicyEntropy   | 4.03244     |
| PolicyLoss      | -0.00282975 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0284      |
| _MeanReward     | 1.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.2285      |
| _max_adv        | 3.38        |
| _max_discrew    | 1.79        |
| _max_obs        | 1.52        |
| _mean_act       | -0.00708826 |
| _mean_adv       | 0           |
| _mean_discrew   | 1.1         |
| _mean_obs       | 0.0378      |
| _min_adv        | -6.22       |
| _min_discrew    | 0.00344     |
| _min_obs        | -1.26       |
| _std_act        | 0.492916    |
| _std_adv        | 1           |
| _std_discrew    | 0.167       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.711       |
| ExplainedVarOld | 0.692       |
| KL              | 0.00351755  |
| Phi_loss        | 63.4212     |
| PolicyEntropy   | 4.0199      |
| PolicyLoss      | -0.00463111 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0483      |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.37454     |
| _max_adv        | 3.03        |
| _max_discrew    | 1.99        |
| _max_obs        | 1.43        |
| _mean_act       | -0.019134   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.929       |
| _mean_obs       | 0.0366      |
| _min_adv        | -9.02       |
| _min_discrew    | -1.15       |
| _min_obs        | -1.17       |
| _std_act        | 0.608145    |
| _std_adv        | 1           |
| _std_discrew    | 0.503       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.817       |
| ExplainedVarOld | 0.748       |
| KL              | 0.0029913   |
| Phi_loss        | 52.229      |
| PolicyEntropy   | 4.02019     |
| PolicyLoss      | -0.00133759 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0923      |
| _MeanReward     | 1.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.14241     |
| _max_adv        | 8.3         |
| _max_discrew    | 1.76        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0115744  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.17        |
| _mean_obs       | 0.036       |
| _min_adv        | -6.91       |
| _min_discrew    | -0.0618     |
| _min_obs        | -1.26       |
| _std_act        | 0.488086    |
| _std_adv        | 1           |
| _std_discrew    | 0.161       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.806      |
| ExplainedVarOld | 0.781      |
| KL              | 0.00253667 |
| Phi_loss        | 62.3902    |
| PolicyEntropy   | 3.99488    |
| PolicyLoss      | 0.00335535 |
| Steps           | 10000      |
| VarFuncLoss     | 0.032      |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.11166    |
| _max_adv        | 4.82       |
| _max_discrew    | 1.98       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0118459 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0384     |
| _min_adv        | -5.81      |
| _min_discrew    | -0.0199    |
| _min_obs        | -1.2       |
| _std_act        | 0.493031   |
| _std_adv        | 1          |
| _std_discrew    | 0.227      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.708      |
| ExplainedVarOld | 0.645      |
| KL              | 0.00333652 |
| Phi_loss        | 58.9858    |
| PolicyEntropy   | 3.99117    |
| PolicyLoss      | -0.0216709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0665     |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8776     |
| _max_adv        | 3.79       |
| _max_discrew    | 2.02       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0152916 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.15       |
| _mean_obs       | 0.037      |
| _min_adv        | -5.71      |
| _min_discrew    | -0.00836   |
| _min_obs        | -1.25      |
| _std_act        | 0.49333    |
| _std_adv        | 1          |
| _std_discrew    | 0.231      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.689      |
| ExplainedVarOld | 0.677      |
| KL              | 0.00397266 |
| Phi_loss        | 72.1192    |
| PolicyEntropy   | 3.94644    |
| PolicyLoss      | 0.011613   |
| Steps           | 10000      |
| VarFuncLoss     | 0.072      |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.5444     |
| _max_adv        | 3.55       |
| _max_discrew    | 1.89       |
| _max_obs        | 1.51       |
| _mean_act       | -0.0239579 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0357     |
| _min_adv        | -10.9      |
| _min_discrew    | -1.14      |
| _min_obs        | -1.3       |
| _std_act        | 0.602644   |
| _std_adv        | 1          |
| _std_discrew    | 0.465      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.839      |
| ExplainedVarOld | 0.817      |
| KL              | 0.00513548 |
| Phi_loss        | 57.4957    |
| PolicyEntropy   | 3.9235     |
| PolicyLoss      | 0.0103422  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0754     |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.05316    |
| _max_adv        | 4.84       |
| _max_discrew    | 1.88       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0117129 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0374     |
| _min_adv        | -6.04      |
| _min_discrew    | 0.00297    |
| _min_obs        | -1.31      |
| _std_act        | 0.491247   |
| _std_adv        | 1          |
| _std_discrew    | 0.196      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.802       |
| ExplainedVarOld | 0.79        |
| KL              | 0.00322677  |
| Phi_loss        | 70.308      |
| PolicyEntropy   | 3.92343     |
| PolicyLoss      | -0.00985834 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0398      |
| _MeanReward     | 1.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.32333     |
| _max_adv        | 7.04        |
| _max_discrew    | 2.04        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0256654  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.14        |
| _mean_obs       | 0.0373      |
| _min_adv        | -14.1       |
| _min_discrew    | -1.2        |
| _min_obs        | -1.26       |
| _std_act        | 0.61343     |
| _std_adv        | 1           |
| _std_discrew    | 0.554       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.839       |
| ExplainedVarOld | 0.833       |
| KL              | 0.00430597  |
| Phi_loss        | 68.8235     |
| PolicyEntropy   | 3.9033      |
| PolicyLoss      | -0.00435898 |
| Steps           | 10000       |
| VarFuncLoss     | 0.089       |
| _MeanReward     | 1.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.52777     |
| _max_adv        | 8.4         |
| _max_discrew    | 2.1         |
| _max_obs        | 1.53        |
| _mean_act       | -0.0161541  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 1.34        |
| _mean_obs       | 0.0389      |
| _min_adv        | -6.56       |
| _min_discrew    | -0.00254    |
| _min_obs        | -1.24       |
| _std_act        | 0.499643    |
| _std_adv        | 1           |
| _std_discrew    | 0.187       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.818       |
| ExplainedVarOld | 0.808       |
| KL              | 0.00352192  |
| Phi_loss        | 72.3174     |
| PolicyEntropy   | 3.88047     |
| PolicyLoss      | -0.00484916 |
| Steps           | 10000       |
| VarFuncLoss     | 0.035       |
| _MeanReward     | 1.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.21002     |
| _max_adv        | 6.32        |
| _max_discrew    | 2.02        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0136287  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.32        |
| _mean_obs       | 0.0398      |
| _min_adv        | -7.28       |
| _min_discrew    | -0.0462     |
| _min_obs        | -1.25       |
| _std_act        | 0.501891    |
| _std_adv        | 1           |
| _std_discrew    | 0.265       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.779       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00287423  |
| Phi_loss        | 69.3745     |
| PolicyEntropy   | 3.85021     |
| PolicyLoss      | -0.00992265 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0586      |
| _MeanReward     | 1.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.27203     |
| _max_adv        | 4.75        |
| _max_discrew    | 2.04        |
| _max_obs        | 1.55        |
| _mean_act       | -0.0156041  |
| _mean_adv       | -4.97e-17   |
| _mean_discrew   | 1.4         |
| _mean_obs       | 0.039       |
| _min_adv        | -6.37       |
| _min_discrew    | -0.00198    |
| _min_obs        | -1.4        |
| _std_act        | 0.506858    |
| _std_adv        | 1           |
| _std_discrew    | 0.202       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.824      |
| ExplainedVarOld | 0.819      |
| KL              | 0.00335152 |
| Phi_loss        | 72.3086    |
| PolicyEntropy   | 3.81994    |
| PolicyLoss      | -0.0121933 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 1.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.02631    |
| _max_adv        | 4.61       |
| _max_discrew    | 2.09       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0201328 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.36       |
| _mean_obs       | 0.0389     |
| _min_adv        | -7.08      |
| _min_discrew    | -0.0137    |
| _min_obs        | -1.3       |
| _std_act        | 0.50256    |
| _std_adv        | 1          |
| _std_discrew    | 0.261      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.83       |
| ExplainedVarOld | 0.821      |
| KL              | 0.00312642 |
| Phi_loss        | 72.1817    |
| PolicyEntropy   | 3.78973    |
| PolicyLoss      | 0.0042625  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0446     |
| _MeanReward     | 1.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.16103    |
| _max_adv        | 3.95       |
| _max_discrew    | 2.15       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0157667 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.4        |
| _mean_obs       | 0.0393     |
| _min_adv        | -7.82      |
| _min_discrew    | 0.00306    |
| _min_obs        | -1.19      |
| _std_act        | 0.50271    |
| _std_adv        | 1          |
| _std_discrew    | 0.237      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.821       |
| ExplainedVarOld | 0.815       |
| KL              | 0.00382524  |
| Phi_loss        | 83.2522     |
| PolicyEntropy   | 3.78262     |
| PolicyLoss      | -0.00501262 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0424      |
| _MeanReward     | 1.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.50156     |
| _max_adv        | 4.86        |
| _max_discrew    | 2           |
| _max_obs        | 1.45        |
| _mean_act       | -0.0118153  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.28        |
| _mean_obs       | 0.0399      |
| _min_adv        | -5.35       |
| _min_discrew    | -0.000604   |
| _min_obs        | -1.29       |
| _std_act        | 0.509302    |
| _std_adv        | 1           |
| _std_discrew    | 0.236       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.697       |
| ExplainedVarOld | 0.602       |
| KL              | 0.0036817   |
| Phi_loss        | 65.8313     |
| PolicyEntropy   | 3.76281     |
| PolicyLoss      | -0.00569821 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0722      |
| _MeanReward     | 1.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.37091     |
| _max_adv        | 4.5         |
| _max_discrew    | 2.26        |
| _max_obs        | 1.46        |
| _mean_act       | -0.016094   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.42        |
| _mean_obs       | 0.0405      |
| _min_adv        | -7.08       |
| _min_discrew    | -0.0605     |
| _min_obs        | -1.15       |
| _std_act        | 0.508811    |
| _std_adv        | 1           |
| _std_discrew    | 0.277       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.828       |
| ExplainedVarOld | 0.818       |
| KL              | 0.00366283  |
| Phi_loss        | 78.1486     |
| PolicyEntropy   | 3.73956     |
| PolicyLoss      | -0.00945629 |
| Steps           | 10000       |
| VarFuncLoss     | 0.05        |
| _MeanReward     | 1.65e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.39595     |
| _max_adv        | 3.82        |
| _max_discrew    | 2.17        |
| _max_obs        | 1.54        |
| _mean_act       | -0.0251101  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.34        |
| _mean_obs       | 0.0388      |
| _min_adv        | -13.8       |
| _min_discrew    | -1.14       |
| _min_obs        | -1.28       |
| _std_act        | 0.60099     |
| _std_adv        | 1           |
| _std_discrew    | 0.509       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.781        |
| ExplainedVarOld | 0.769        |
| KL              | 0.00387291   |
| Phi_loss        | 72.6627      |
| PolicyEntropy   | 3.71485      |
| PolicyLoss      | -0.000650105 |
| Steps           | 10000        |
| VarFuncLoss     | 0.112        |
| _MeanReward     | 1.78e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.08477      |
| _max_adv        | 7.43         |
| _max_discrew    | 2.11         |
| _max_obs        | 1.4          |
| _mean_act       | -0.0121595   |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 1.47         |
| _mean_obs       | 0.0397       |
| _min_adv        | -6.98        |
| _min_discrew    | 0.00646      |
| _min_obs        | -1.26        |
| _std_act        | 0.50716      |
| _std_adv        | 1            |
| _std_discrew    | 0.211        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.864      |
| ExplainedVarOld | 0.867      |
| KL              | 0.0046034  |
| Phi_loss        | 74.5653    |
| PolicyEntropy   | 3.68763    |
| PolicyLoss      | -0.0024918 |
| Steps           | 10000      |
| VarFuncLoss     | 0.029      |
| _MeanReward     | 1.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.40837    |
| _max_adv        | 5.94       |
| _max_discrew    | 2.33       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0124476 |
| _mean_adv       | 2.98e-17   |
| _mean_discrew   | 1.53       |
| _mean_obs       | 0.0403     |
| _min_adv        | -6.77      |
| _min_discrew    | 0.00377    |
| _min_obs        | -1.4       |
| _std_act        | 0.514959   |
| _std_adv        | 1          |
| _std_discrew    | 0.273      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.87        |
| ExplainedVarOld | 0.833       |
| KL              | 0.00296204  |
| Phi_loss        | 74.2965     |
| PolicyEntropy   | 3.66838     |
| PolicyLoss      | -0.00882097 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0361      |
| _MeanReward     | 1.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.26857     |
| _max_adv        | 3.46        |
| _max_discrew    | 2.34        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0131209  |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 1.56        |
| _mean_obs       | 0.0412      |
| _min_adv        | -7.23       |
| _min_discrew    | 0.00564     |
| _min_obs        | -1.3        |
| _std_act        | 0.524748    |
| _std_adv        | 1           |
| _std_discrew    | 0.278       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.831      |
| ExplainedVarOld | 0.797      |
| KL              | 0.00489316 |
| Phi_loss        | 66.9298    |
| PolicyEntropy   | 3.64794    |
| PolicyLoss      | -0.0050637 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0475     |
| _MeanReward     | 1.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.27232    |
| _max_adv        | 3.73       |
| _max_discrew    | 2.34       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0129545 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 1.45       |
| _mean_obs       | 0.0403     |
| _min_adv        | -6.54      |
| _min_discrew    | 0.00416    |
| _min_obs        | -1.21      |
| _std_act        | 0.518236   |
| _std_adv        | 1          |
| _std_discrew    | 0.281      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.786       |
| ExplainedVarOld | 0.771       |
| KL              | 0.003932    |
| Phi_loss        | 78.3851     |
| PolicyEntropy   | 3.64949     |
| PolicyLoss      | -0.00667144 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0619      |
| _MeanReward     | 1.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.64196     |
| _max_adv        | 6.97        |
| _max_discrew    | 2.37        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0117204  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.6         |
| _mean_obs       | 0.0413      |
| _min_adv        | -7.73       |
| _min_discrew    | 0.005       |
| _min_obs        | -1.29       |
| _std_act        | 0.521695    |
| _std_adv        | 1           |
| _std_discrew    | 0.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.873       |
| ExplainedVarOld | 0.855       |
| KL              | 0.00344677  |
| Phi_loss        | 74.6902     |
| PolicyEntropy   | 3.65707     |
| PolicyLoss      | -0.00338555 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0407      |
| _MeanReward     | 1.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95176     |
| _max_adv        | 4.72        |
| _max_discrew    | 2.32        |
| _max_obs        | 1.52        |
| _mean_act       | -0.0147254  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.59        |
| _mean_obs       | 0.0407      |
| _min_adv        | -6.74       |
| _min_discrew    | -0.0476     |
| _min_obs        | -1.21       |
| _std_act        | 0.520926    |
| _std_adv        | 1           |
| _std_discrew    | 0.293       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.902       |
| ExplainedVarOld | 0.889       |
| KL              | 0.00264924  |
| Phi_loss        | 88.0983     |
| PolicyEntropy   | 3.62541     |
| PolicyLoss      | -0.00217558 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0285      |
| _MeanReward     | 1.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95932     |
| _max_adv        | 4.04        |
| _max_discrew    | 2.33        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0108972  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.57        |
| _mean_obs       | 0.0401      |
| _min_adv        | -9.57       |
| _min_discrew    | -0.000268   |
| _min_obs        | -1.2        |
| _std_act        | 0.520995    |
| _std_adv        | 1           |
| _std_discrew    | 0.281       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.848       |
| ExplainedVarOld | 0.828       |
| KL              | 0.00618021  |
| Phi_loss        | 77.3479     |
| PolicyEntropy   | 3.61176     |
| PolicyLoss      | -0.00769918 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0428      |
| _MeanReward     | 1.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.51373     |
| _max_adv        | 4.18        |
| _max_discrew    | 2.38        |
| _max_obs        | 1.37        |
| _mean_act       | -0.01848    |
| _mean_adv       | 3.2e-18     |
| _mean_discrew   | 1.47        |
| _mean_obs       | 0.0399      |
| _min_adv        | -10.7       |
| _min_discrew    | -0.948      |
| _min_obs        | -1.24       |
| _std_act        | 0.565537    |
| _std_adv        | 1           |
| _std_discrew    | 0.439       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.799      |
| ExplainedVarOld | 0.773      |
| KL              | 0.0031744  |
| Phi_loss        | 78.315     |
| PolicyEntropy   | 3.61205    |
| PolicyLoss      | 0.00409628 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0897     |
| _MeanReward     | 1.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92714    |
| _max_adv        | 4.99       |
| _max_discrew    | 2.33       |
| _max_obs        | 1.59       |
| _mean_act       | -0.0162078 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 1.64       |
| _mean_obs       | 0.0406     |
| _min_adv        | -8.16      |
| _min_discrew    | 0.00202    |
| _min_obs        | -1.19      |
| _std_act        | 0.515033   |
| _std_adv        | 1          |
| _std_discrew    | 0.306      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.86       |
| ExplainedVarOld | 0.855      |
| KL              | 0.00136503 |
| Phi_loss        | 89.3604    |
| PolicyEntropy   | 3.60125    |
| PolicyLoss      | -0.0089761 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0452     |
| _MeanReward     | 1.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.81107    |
| _max_adv        | 2.75       |
| _max_discrew    | 2.64       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0333349 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.43       |
| _mean_obs       | 0.0398     |
| _min_adv        | -14.3      |
| _min_discrew    | -1.41      |
| _min_obs        | -1.17      |
| _std_act        | 0.703293   |
| _std_adv        | 1          |
| _std_discrew    | 0.978      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.903      |
| KL              | 0.00393059 |
| Phi_loss        | 60.2653    |
| PolicyEntropy   | 3.59688    |
| PolicyLoss      | 0.0137461  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0658     |
| _MeanReward     | 1.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17074    |
| _max_adv        | 5.61       |
| _max_discrew    | 2.39       |
| _max_obs        | 1.49       |
| _mean_act       | -0.0129377 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.65       |
| _mean_obs       | 0.0405     |
| _min_adv        | -7.36      |
| _min_discrew    | 0.00255    |
| _min_obs        | -1.3       |
| _std_act        | 0.527367   |
| _std_adv        | 1          |
| _std_discrew    | 0.296      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.866       |
| ExplainedVarOld | 0.864       |
| KL              | 0.00421559  |
| Phi_loss        | 93.1612     |
| PolicyEntropy   | 3.57393     |
| PolicyLoss      | -0.00896968 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0403      |
| _MeanReward     | 2.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08999     |
| _max_adv        | 15.6        |
| _max_discrew    | 2.51        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0132243  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.64        |
| _mean_obs       | 0.0415      |
| _min_adv        | -7.07       |
| _min_discrew    | -0.0297     |
| _min_obs        | -1.22       |
| _std_act        | 0.52545     |
| _std_adv        | 1           |
| _std_discrew    | 0.346       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.887       |
| ExplainedVarOld | 0.865       |
| KL              | 0.00452081  |
| Phi_loss        | 70.7278     |
| PolicyEntropy   | 3.56767     |
| PolicyLoss      | -0.00122787 |
| Steps           | 10000       |
| VarFuncLoss     | 0.039       |
| _MeanReward     | 1.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.32084     |
| _max_adv        | 6.17        |
| _max_discrew    | 2.31        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0132962  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.62        |
| _mean_obs       | 0.039       |
| _min_adv        | -8.48       |
| _min_discrew    | 0.00348     |
| _min_obs        | -1.21       |
| _std_act        | 0.518869    |
| _std_adv        | 1           |
| _std_discrew    | 0.292       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.875      |
| ExplainedVarOld | 0.871      |
| KL              | 0.00505045 |
| Phi_loss        | 105.604    |
| PolicyEntropy   | 3.5725     |
| PolicyLoss      | -0.032413  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0365     |
| _MeanReward     | 1.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96021    |
| _max_adv        | 6.5        |
| _max_discrew    | 2.41       |
| _max_obs        | 1.46       |
| _mean_act       | -0.01099   |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 1.62       |
| _mean_obs       | 0.0399     |
| _min_adv        | -7.9       |
| _min_discrew    | -0.00368   |
| _min_obs        | -1.32      |
| _std_act        | 0.529772   |
| _std_adv        | 1          |
| _std_discrew    | 0.323      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.89       |
| ExplainedVarOld | 0.886      |
| KL              | 0.00392275 |
| Phi_loss        | 99.896     |
| PolicyEntropy   | 3.56837    |
| PolicyLoss      | -0.0154082 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 2.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15411    |
| _max_adv        | 4.65       |
| _max_discrew    | 2.57       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0124618 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.74       |
| _mean_obs       | 0.0429     |
| _min_adv        | -6.91      |
| _min_discrew    | 0.00451    |
| _min_obs        | -1.27      |
| _std_act        | 0.542793   |
| _std_adv        | 1          |
| _std_discrew    | 0.304      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.816      |
| ExplainedVarOld | 0.804      |
| KL              | 0.00303962 |
| Phi_loss        | 90.7257    |
| PolicyEntropy   | 3.55386    |
| PolicyLoss      | -0.0100233 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0591     |
| _MeanReward     | 2.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.39401    |
| _max_adv        | 5.38       |
| _max_discrew    | 2.58       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0118641 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.74       |
| _mean_obs       | 0.0428     |
| _min_adv        | -7.09      |
| _min_discrew    | 0.00172    |
| _min_obs        | -1.2       |
| _std_act        | 0.544192   |
| _std_adv        | 1          |
| _std_discrew    | 0.367      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.878      |
| ExplainedVarOld | 0.868      |
| KL              | 0.0049446  |
| Phi_loss        | 94.7615    |
| PolicyEntropy   | 3.50923    |
| PolicyLoss      | 0.00308193 |
| Steps           | 10000      |
| VarFuncLoss     | 0.045      |
| _MeanReward     | 2.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.58723    |
| _max_adv        | 2.8        |
| _max_discrew    | 2.82       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0205964 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.7        |
| _mean_obs       | 0.0436     |
| _min_adv        | -14.3      |
| _min_discrew    | -1.3       |
| _min_obs        | -1.18      |
| _std_act        | 0.655375   |
| _std_adv        | 1          |
| _std_discrew    | 0.749      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.812      |
| ExplainedVarOld | 0.786      |
| KL              | 0.00667905 |
| Phi_loss        | 82.9268    |
| PolicyEntropy   | 3.50164    |
| PolicyLoss      | -0.0552249 |
| Steps           | 10000      |
| VarFuncLoss     | 0.141      |
| _MeanReward     | 2.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95626    |
| _max_adv        | 5          |
| _max_discrew    | 2.47       |
| _max_obs        | 1.55       |
| _mean_act       | -0.0119943 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.69       |
| _mean_obs       | 0.0412     |
| _min_adv        | -8         |
| _min_discrew    | 0.00424    |
| _min_obs        | -1.31      |
| _std_act        | 0.542663   |
| _std_adv        | 1          |
| _std_discrew    | 0.336      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.869       |
| ExplainedVarOld | 0.858       |
| KL              | 0.00200404  |
| Phi_loss        | 97.0651     |
| PolicyEntropy   | 3.50389     |
| PolicyLoss      | -0.00138558 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0445      |
| _MeanReward     | 2.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07356     |
| _max_adv        | 13.6        |
| _max_discrew    | 2.49        |
| _max_obs        | 1.49        |
| _mean_act       | -0.00890395 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.69        |
| _mean_obs       | 0.042       |
| _min_adv        | -7.53       |
| _min_discrew    | -0.067      |
| _min_obs        | -1.34       |
| _std_act        | 0.547689    |
| _std_adv        | 1           |
| _std_discrew    | 0.379       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.824       |
| ExplainedVarOld | 0.801       |
| KL              | 0.00240643  |
| Phi_loss        | 84.5945     |
| PolicyEntropy   | 3.50054     |
| PolicyLoss      | -0.00607372 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0668      |
| _MeanReward     | 1.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.73168     |
| _max_adv        | 2.31        |
| _max_discrew    | 2.41        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0177897  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.49        |
| _mean_obs       | 0.0406      |
| _min_adv        | -14.9       |
| _min_discrew    | -1.43       |
| _min_obs        | -1.27       |
| _std_act        | 0.651461    |
| _std_adv        | 1           |
| _std_discrew    | 0.756       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.784      |
| ExplainedVarOld | 0.741      |
| KL              | 0.00445055 |
| Phi_loss        | 90.7178    |
| PolicyEntropy   | 3.49976    |
| PolicyLoss      | -0.0139613 |
| Steps           | 10000      |
| VarFuncLoss     | 0.164      |
| _MeanReward     | 2.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.45165    |
| _max_adv        | 8.22       |
| _max_discrew    | 2.63       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0127974 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 1.81       |
| _mean_obs       | 0.0421     |
| _min_adv        | -7.35      |
| _min_discrew    | 0.0055     |
| _min_obs        | -1.31      |
| _std_act        | 0.54982    |
| _std_adv        | 1          |
| _std_discrew    | 0.367      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.846        |
| ExplainedVarOld | 0.845        |
| KL              | 0.00187339   |
| Phi_loss        | 88.677       |
| PolicyEntropy   | 3.48814      |
| PolicyLoss      | -0.000271415 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0645       |
| _MeanReward     | 2.12e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.97189      |
| _max_adv        | 5.02         |
| _max_discrew    | 2.58         |
| _max_obs        | 1.44         |
| _mean_act       | -0.0121028   |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 1.75         |
| _mean_obs       | 0.0416       |
| _min_adv        | -8.34        |
| _min_discrew    | 0.0041       |
| _min_obs        | -1.23        |
| _std_act        | 0.546196     |
| _std_adv        | 1            |
| _std_discrew    | 0.339        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.855      |
| ExplainedVarOld | 0.833      |
| KL              | 0.00152025 |
| Phi_loss        | 94.3007    |
| PolicyEntropy   | 3.48197    |
| PolicyLoss      | -0.0130025 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0502     |
| _MeanReward     | 1.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.55142    |
| _max_adv        | 4.13       |
| _max_discrew    | 2.7        |
| _max_obs        | 1.39       |
| _mean_act       | -0.0243067 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.55       |
| _mean_obs       | 0.0406     |
| _min_adv        | -13.6      |
| _min_discrew    | -1.55      |
| _min_obs        | -1.38      |
| _std_act        | 0.726422   |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.892       |
| ExplainedVarOld | 0.85        |
| KL              | 0.00251934  |
| Phi_loss        | 90.941      |
| PolicyEntropy   | 3.46856     |
| PolicyLoss      | 0.00961455  |
| Steps           | 10000       |
| VarFuncLoss     | 0.116       |
| _MeanReward     | 2.16e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01955     |
| _max_adv        | 7.3         |
| _max_discrew    | 2.55        |
| _max_obs        | 1.38        |
| _mean_act       | -0.00917838 |
| _mean_adv       | 2.13e-17    |
| _mean_discrew   | 1.78        |
| _mean_obs       | 0.0416      |
| _min_adv        | -7.74       |
| _min_discrew    | 0.00523     |
| _min_obs        | -1.16       |
| _std_act        | 0.548483    |
| _std_adv        | 1           |
| _std_discrew    | 0.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.872       |
| ExplainedVarOld | 0.867       |
| KL              | 0.00236851  |
| Phi_loss        | 101.377     |
| PolicyEntropy   | 3.45459     |
| PolicyLoss      | 0.000764851 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0463      |
| _MeanReward     | 2.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.25302     |
| _max_adv        | 7.37        |
| _max_discrew    | 2.63        |
| _max_obs        | 1.35        |
| _mean_act       | -0.010721   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.86        |
| _mean_obs       | 0.041       |
| _min_adv        | -3.97       |
| _min_discrew    | 0.00834     |
| _min_obs        | -1.22       |
| _std_act        | 0.546658    |
| _std_adv        | 1           |
| _std_discrew    | 0.323       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.907      |
| KL              | 0.00150093 |
| Phi_loss        | 88.7042    |
| PolicyEntropy   | 3.43765    |
| PolicyLoss      | -0.0123901 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0275     |
| _MeanReward     | 2.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17338    |
| _max_adv        | 12.3       |
| _max_discrew    | 2.68       |
| _max_obs        | 1.46       |
| _mean_act       | -0.010433  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.86       |
| _mean_obs       | 0.0427     |
| _min_adv        | -9.62      |
| _min_discrew    | 0.007      |
| _min_obs        | -1.24      |
| _std_act        | 0.551605   |
| _std_adv        | 1          |
| _std_discrew    | 0.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.896       |
| ExplainedVarOld | 0.889       |
| KL              | 0.00321208  |
| Phi_loss        | 96.7619     |
| PolicyEntropy   | 3.42206     |
| PolicyLoss      | -0.00296928 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0386      |
| _MeanReward     | 2.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11083     |
| _max_adv        | 11.5        |
| _max_discrew    | 2.66        |
| _max_obs        | 1.4         |
| _mean_act       | -0.00946837 |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 1.89        |
| _mean_obs       | 0.0433      |
| _min_adv        | -10.2       |
| _min_discrew    | -0.107      |
| _min_obs        | -1.2        |
| _std_act        | 0.558655    |
| _std_adv        | 1           |
| _std_discrew    | 0.35        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.875       |
| ExplainedVarOld | 0.863       |
| KL              | 0.00186502  |
| Phi_loss        | 95.2433     |
| PolicyEntropy   | 3.40833     |
| PolicyLoss      | -0.0225018  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0441      |
| _MeanReward     | 2.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06348     |
| _max_adv        | 13.2        |
| _max_discrew    | 2.67        |
| _max_obs        | 1.53        |
| _mean_act       | -0.00563032 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.93        |
| _mean_obs       | 0.0443      |
| _min_adv        | -8.84       |
| _min_discrew    | 0.00767     |
| _min_obs        | -1.26       |
| _std_act        | 0.565342    |
| _std_adv        | 1           |
| _std_discrew    | 0.4         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.903       |
| KL              | 0.00170728  |
| Phi_loss        | 97.4328     |
| PolicyEntropy   | 3.38185     |
| PolicyLoss      | 0.00439857  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0353      |
| _MeanReward     | 2.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.20828     |
| _max_adv        | 4.2         |
| _max_discrew    | 2.71        |
| _max_obs        | 1.58        |
| _mean_act       | -0.00907248 |
| _mean_adv       | 4.26e-18    |
| _mean_discrew   | 1.92        |
| _mean_obs       | 0.0429      |
| _min_adv        | -9.83       |
| _min_discrew    | -0.000557   |
| _min_obs        | -1.22       |
| _std_act        | 0.561563    |
| _std_adv        | 1           |
| _std_discrew    | 0.373       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.883       |
| ExplainedVarOld | 0.877       |
| KL              | 0.00188078  |
| Phi_loss        | 111.349     |
| PolicyEntropy   | 3.36395     |
| PolicyLoss      | -0.0164409  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0437      |
| _MeanReward     | 2.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.42831     |
| _max_adv        | 6.21        |
| _max_discrew    | 2.69        |
| _max_obs        | 1.65        |
| _mean_act       | -0.00882551 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 1.91        |
| _mean_obs       | 0.0432      |
| _min_adv        | -8.02       |
| _min_discrew    | 0.00655     |
| _min_obs        | -1.23       |
| _std_act        | 0.573109    |
| _std_adv        | 1           |
| _std_discrew    | 0.324       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.889       |
| ExplainedVarOld | 0.871       |
| KL              | 0.00211922  |
| Phi_loss        | 99.2781     |
| PolicyEntropy   | 3.36574     |
| PolicyLoss      | -0.00420923 |
| Steps           | 10000       |
| VarFuncLoss     | 0.036       |
| _MeanReward     | 2.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.43837     |
| _max_adv        | 3.38        |
| _max_discrew    | 2.86        |
| _max_obs        | 1.54        |
| _mean_act       | -0.0186435  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.86        |
| _mean_obs       | 0.0433      |
| _min_adv        | -12.3       |
| _min_discrew    | -1.32       |
| _min_obs        | -1.18       |
| _std_act        | 0.646478    |
| _std_adv        | 1           |
| _std_discrew    | 0.725       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.82         |
| ExplainedVarOld | 0.771        |
| KL              | 0.00155008   |
| Phi_loss        | 79.4995      |
| PolicyEntropy   | 3.35504      |
| PolicyLoss      | -0.000882063 |
| Steps           | 10000        |
| VarFuncLoss     | 0.131        |
| _MeanReward     | 2.37e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.88324      |
| _max_adv        | 9.06         |
| _max_discrew    | 2.82         |
| _max_obs        | 1.37         |
| _mean_act       | -0.00811726  |
| _mean_adv       | 3.13e-17     |
| _mean_discrew   | 1.97         |
| _mean_obs       | 0.0442       |
| _min_adv        | -10.9        |
| _min_discrew    | -0.0591      |
| _min_obs        | -1.29        |
| _std_act        | 0.565931     |
| _std_adv        | 1            |
| _std_discrew    | 0.409        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.932       |
| ExplainedVarOld | 0.92        |
| KL              | 0.00338257  |
| Phi_loss        | 100.804     |
| PolicyEntropy   | 3.32944     |
| PolicyLoss      | -0.00725293 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0281      |
| _MeanReward     | 2.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.26801     |
| _max_adv        | 8.84        |
| _max_discrew    | 2.84        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0123716  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.02        |
| _mean_obs       | 0.0438      |
| _min_adv        | -8.64       |
| _min_discrew    | 0.0043      |
| _min_obs        | -1.2        |
| _std_act        | 0.563384    |
| _std_adv        | 1           |
| _std_discrew    | 0.411       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.94        |
| ExplainedVarOld | 0.935       |
| KL              | 0.00169759  |
| Phi_loss        | 106.915     |
| PolicyEntropy   | 3.30603     |
| PolicyLoss      | -0.00398355 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0247      |
| _MeanReward     | 2.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07123     |
| _max_adv        | 3.75        |
| _max_discrew    | 2.8         |
| _max_obs        | 1.34        |
| _mean_act       | -0.0130728  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 2.05        |
| _mean_obs       | 0.0441      |
| _min_adv        | -10         |
| _min_discrew    | 0.00608     |
| _min_obs        | -1.27       |
| _std_act        | 0.570733    |
| _std_adv        | 1           |
| _std_discrew    | 0.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.94        |
| ExplainedVarOld | 0.937       |
| KL              | 0.00176196  |
| Phi_loss        | 114.632     |
| PolicyEntropy   | 3.27357     |
| PolicyLoss      | -0.00232044 |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 2.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11227     |
| _max_adv        | 8.24        |
| _max_discrew    | 3.05        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0114168  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 2.01        |
| _mean_obs       | 0.0438      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.00876     |
| _min_obs        | -1.19       |
| _std_act        | 0.56309     |
| _std_adv        | 1           |
| _std_discrew    | 0.406       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.881       |
| KL              | 0.00188038  |
| Phi_loss        | 107.812     |
| PolicyEntropy   | 3.26903     |
| PolicyLoss      | -0.0131061  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0441      |
| _MeanReward     | 2.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.79227     |
| _max_adv        | 4.42        |
| _max_discrew    | 3.02        |
| _max_obs        | 1.38        |
| _mean_act       | -0.00821975 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 2.05        |
| _mean_obs       | 0.0447      |
| _min_adv        | -8.34       |
| _min_discrew    | -0.0916     |
| _min_obs        | -1.21       |
| _std_act        | 0.569501    |
| _std_adv        | 1           |
| _std_discrew    | 0.472       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.91       |
| KL              | 0.00246184 |
| Phi_loss        | 118.387    |
| PolicyEntropy   | 3.24628    |
| PolicyLoss      | -0.0169419 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0406     |
| _MeanReward     | 2.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08438    |
| _max_adv        | 3.74       |
| _max_discrew    | 2.87       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0101302 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.89       |
| _mean_obs       | 0.0426     |
| _min_adv        | -8.02      |
| _min_discrew    | 0.00444    |
| _min_obs        | -1.21      |
| _std_act        | 0.572618   |
| _std_adv        | 1          |
| _std_discrew    | 0.413      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.812      |
| ExplainedVarOld | 0.793      |
| KL              | 0.00151832 |
| Phi_loss        | 113.606    |
| PolicyEntropy   | 3.23412    |
| PolicyLoss      | -0.0120996 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0826     |
| _MeanReward     | 2.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.2391     |
| _max_adv        | 7.4        |
| _max_discrew    | 2.86       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0119087 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.09       |
| _mean_obs       | 0.0442     |
| _min_adv        | -8.92      |
| _min_discrew    | 0.00529    |
| _min_obs        | -1.29      |
| _std_act        | 0.574149   |
| _std_adv        | 1          |
| _std_discrew    | 0.435      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.933        |
| ExplainedVarOld | 0.932        |
| KL              | 0.00252801   |
| Phi_loss        | 114.062      |
| PolicyEntropy   | 3.21238      |
| PolicyLoss      | -0.000561767 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0336       |
| _MeanReward     | 2.48e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.43145      |
| _max_adv        | 5.82         |
| _max_discrew    | 2.94         |
| _max_obs        | 1.44         |
| _mean_act       | -0.00758084  |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 2.05         |
| _mean_obs       | 0.0447       |
| _min_adv        | -9.9         |
| _min_discrew    | -0.0382      |
| _min_obs        | -1.18        |
| _std_act        | 0.581004     |
| _std_adv        | 1            |
| _std_discrew    | 0.48         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.851      |
| ExplainedVarOld | 0.834      |
| KL              | 0.0021872  |
| Phi_loss        | 109.81     |
| PolicyEntropy   | 3.20951    |
| PolicyLoss      | -0.0133715 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0716     |
| _MeanReward     | 2.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19569    |
| _max_adv        | 6.66       |
| _max_discrew    | 2.86       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0103631 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.09       |
| _mean_obs       | 0.0439     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.00746    |
| _min_obs        | -1.21      |
| _std_act        | 0.581295   |
| _std_adv        | 1          |
| _std_discrew    | 0.464      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.915       |
| KL              | 0.00271347  |
| Phi_loss        | 116.117     |
| PolicyEntropy   | 3.19681     |
| PolicyLoss      | -0.00874697 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0387      |
| _MeanReward     | 2.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.40975     |
| _max_adv        | 7.71        |
| _max_discrew    | 2.87        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0118746  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 2           |
| _mean_obs       | 0.0418      |
| _min_adv        | -11.4       |
| _min_discrew    | 0.00206     |
| _min_obs        | -1.2        |
| _std_act        | 0.579947    |
| _std_adv        | 1           |
| _std_discrew    | 0.451       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.871       |
| ExplainedVarOld | 0.859       |
| KL              | 0.00215656  |
| Phi_loss        | 118.509     |
| PolicyEntropy   | 3.19202     |
| PolicyLoss      | -0.00011706 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0598      |
| _MeanReward     | 2.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.99363     |
| _max_adv        | 5.19        |
| _max_discrew    | 2.93        |
| _max_obs        | 1.38        |
| _mean_act       | -0.00436739 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2           |
| _mean_obs       | 0.0444      |
| _min_adv        | -8.36       |
| _min_discrew    | -0.0777     |
| _min_obs        | -1.28       |
| _std_act        | 0.580373    |
| _std_adv        | 1           |
| _std_discrew    | 0.516       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.815      |
| ExplainedVarOld | 0.808      |
| KL              | 0.00308565 |
| Phi_loss        | 119.279    |
| PolicyEntropy   | 3.18599    |
| PolicyLoss      | -0.0112951 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0955     |
| _MeanReward     | 2.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19108    |
| _max_adv        | 5.45       |
| _max_discrew    | 2.91       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0106317 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.09       |
| _mean_obs       | 0.043      |
| _min_adv        | -8.62      |
| _min_discrew    | 0.00735    |
| _min_obs        | -1.3       |
| _std_act        | 0.576162   |
| _std_adv        | 1          |
| _std_discrew    | 0.427      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.933      |
| KL              | 0.00149838 |
| Phi_loss        | 118.273    |
| PolicyEntropy   | 3.17532    |
| PolicyLoss      | 0.00707361 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0263     |
| _MeanReward     | 2.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1156     |
| _max_adv        | 8.27       |
| _max_discrew    | 3.19       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0126066 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.19       |
| _mean_obs       | 0.0445     |
| _min_adv        | -9.33      |
| _min_discrew    | 0.00728    |
| _min_obs        | -1.23      |
| _std_act        | 0.582254   |
| _std_adv        | 1          |
| _std_discrew    | 0.474      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.941      |
| KL              | 0.00330645 |
| Phi_loss        | 116.229    |
| PolicyEntropy   | 3.18221    |
| PolicyLoss      | -0.0181978 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 2.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19308    |
| _max_adv        | 5.22       |
| _max_discrew    | 2.95       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0121055 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.11       |
| _mean_obs       | 0.0437     |
| _min_adv        | -9.37      |
| _min_discrew    | 0.00583    |
| _min_obs        | -1.26      |
| _std_act        | 0.581286   |
| _std_adv        | 1          |
| _std_discrew    | 0.474      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.934       |
| ExplainedVarOld | 0.932       |
| KL              | 0.0063001   |
| Phi_loss        | 105.477     |
| PolicyEntropy   | 3.16872     |
| PolicyLoss      | -0.00668745 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0319      |
| _MeanReward     | 2.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0712      |
| _max_adv        | 3.56        |
| _max_discrew    | 3.01        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00696987 |
| _mean_adv       | -2.88e-17   |
| _mean_discrew   | 2.09        |
| _mean_obs       | 0.0446      |
| _min_adv        | -8.93       |
| _min_discrew    | -0.109      |
| _min_obs        | -1.19       |
| _std_act        | 0.593717    |
| _std_adv        | 1           |
| _std_discrew    | 0.554       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.876       |
| ExplainedVarOld | 0.867       |
| KL              | 0.00195333  |
| Phi_loss        | 108.69      |
| PolicyEntropy   | 3.1561      |
| PolicyLoss      | -0.00347491 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0687      |
| _MeanReward     | 2.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.48954     |
| _max_adv        | 3.17        |
| _max_discrew    | 3.09        |
| _max_obs        | 1.51        |
| _mean_act       | -0.0317475  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.9         |
| _mean_obs       | 0.042       |
| _min_adv        | -12.6       |
| _min_discrew    | -1.57       |
| _min_obs        | -1.4        |
| _std_act        | 0.727083    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.846       |
| ExplainedVarOld | 0.765       |
| KL              | 0.00239839  |
| Phi_loss        | 83.6782     |
| PolicyEntropy   | 3.13715     |
| PolicyLoss      | -0.0200136  |
| Steps           | 10000       |
| VarFuncLoss     | 0.189       |
| _MeanReward     | 2.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.26999     |
| _max_adv        | 6.11        |
| _max_discrew    | 2.9         |
| _max_obs        | 1.45        |
| _mean_act       | -0.00898915 |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.13        |
| _mean_obs       | 0.0439      |
| _min_adv        | -9.3        |
| _min_discrew    | 0.00709     |
| _min_obs        | -1.15       |
| _std_act        | 0.590156    |
| _std_adv        | 1           |
| _std_discrew    | 0.471       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.909      |
| KL              | 0.00314766 |
| Phi_loss        | 114.353    |
| PolicyEntropy   | 3.12812    |
| PolicyLoss      | -0.008048  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0415     |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.44602    |
| _max_adv        | 11.5       |
| _max_discrew    | 3.16       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0115708 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 2.26       |
| _mean_obs       | 0.0451     |
| _min_adv        | -10.5      |
| _min_discrew    | 0.00718    |
| _min_obs        | -1.41      |
| _std_act        | 0.597077   |
| _std_adv        | 1          |
| _std_discrew    | 0.466      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.938      |
| KL              | 0.00280064 |
| Phi_loss        | 96.3846    |
| PolicyEntropy   | 3.11597    |
| PolicyLoss      | 0.0114957  |
| Steps           | 10000      |
| VarFuncLoss     | 0.028      |
| _MeanReward     | 2.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.54168    |
| _max_adv        | 3.59       |
| _max_discrew    | 3.01       |
| _max_obs        | 1.37       |
| _mean_act       | -0.02798   |
| _mean_adv       | 0          |
| _mean_discrew   | 1.89       |
| _mean_obs       | 0.0422     |
| _min_adv        | -12.4      |
| _min_discrew    | -1.43      |
| _min_obs        | -1.21      |
| _std_act        | 0.696052   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.858      |
| ExplainedVarOld | 0.839      |
| KL              | 0.00948189 |
| Phi_loss        | 126.489    |
| PolicyEntropy   | 3.12069    |
| PolicyLoss      | -0.174079  |
| Steps           | 10000      |
| VarFuncLoss     | 0.155      |
| _MeanReward     | 2.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.85392    |
| _max_adv        | 4.87       |
| _max_discrew    | 2.99       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0302546 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 1.96       |
| _mean_obs       | 0.0427     |
| _min_adv        | -12.4      |
| _min_discrew    | -1.3       |
| _min_obs        | -1.24      |
| _std_act        | 0.718401   |
| _std_adv        | 1          |
| _std_discrew    | 0.987      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.81        |
| ExplainedVarOld | 0.789       |
| KL              | 0.00111932  |
| Phi_loss        | 125.591     |
| PolicyEntropy   | 3.1305      |
| PolicyLoss      | -0.00109473 |
| Steps           | 10000       |
| VarFuncLoss     | 0.187       |
| _MeanReward     | 2.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.27635     |
| _max_adv        | 12          |
| _max_discrew    | 3.23        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0107222  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.24        |
| _mean_obs       | 0.045       |
| _min_adv        | -8.5        |
| _min_discrew    | 0.00897     |
| _min_obs        | -1.23       |
| _std_act        | 0.597004    |
| _std_adv        | 1           |
| _std_discrew    | 0.526       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.878       |
| ExplainedVarOld | 0.865       |
| KL              | 0.00225361  |
| Phi_loss        | 108.147     |
| PolicyEntropy   | 3.11018     |
| PolicyLoss      | -0.00695866 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0716      |
| _MeanReward     | 2.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.49534     |
| _max_adv        | 15.7        |
| _max_discrew    | 3.01        |
| _max_obs        | 1.43        |
| _mean_act       | -0.010483   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.31        |
| _mean_obs       | 0.0452      |
| _min_adv        | -6.82       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.16       |
| _std_act        | 0.593176    |
| _std_adv        | 1           |
| _std_discrew    | 0.457       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00144774 |
| Phi_loss        | 102.637    |
| PolicyEntropy   | 3.09483    |
| PolicyLoss      | -0.0038293 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0208     |
| _MeanReward     | 2.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9635     |
| _max_adv        | 6.94       |
| _max_discrew    | 3.14       |
| _max_obs        | 1.41       |
| _mean_act       | -0.010112  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.27       |
| _mean_obs       | 0.0449     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0049     |
| _min_obs        | -1.22      |
| _std_act        | 0.595689   |
| _std_adv        | 1          |
| _std_discrew    | 0.529      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.944       |
| ExplainedVarOld | 0.937       |
| KL              | 0.00494576  |
| Phi_loss        | 131.376     |
| PolicyEntropy   | 3.06613     |
| PolicyLoss      | -0.0164434  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0297      |
| _MeanReward     | 2.72e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.28789     |
| _max_adv        | 10.5        |
| _max_discrew    | 3.25        |
| _max_obs        | 1.46        |
| _mean_act       | -0.00778941 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.25        |
| _mean_obs       | 0.045       |
| _min_adv        | -8.44       |
| _min_discrew    | 0.00693     |
| _min_obs        | -1.26       |
| _std_act        | 0.602343    |
| _std_adv        | 1           |
| _std_discrew    | 0.551       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.935      |
| ExplainedVarOld | 0.926      |
| KL              | 0.00384961 |
| Phi_loss        | 132.097    |
| PolicyEntropy   | 3.06269    |
| PolicyLoss      | -0.0278773 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 2.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.31406    |
| _max_adv        | 4.41       |
| _max_discrew    | 3.07       |
| _max_obs        | 1.51       |
| _mean_act       | -0.0101989 |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 2.31       |
| _mean_obs       | 0.0452     |
| _min_adv        | -9.01      |
| _min_discrew    | 0.00786    |
| _min_obs        | -1.25      |
| _std_act        | 0.606131   |
| _std_adv        | 1          |
| _std_discrew    | 0.484      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.934       |
| KL              | 0.00417447  |
| Phi_loss        | 125.05      |
| PolicyEntropy   | 3.06098     |
| PolicyLoss      | -0.00969379 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0255      |
| _MeanReward     | 2.53e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.68005     |
| _max_adv        | 2.97        |
| _max_discrew    | 3.17        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0284914  |
| _mean_adv       | 0           |
| _mean_discrew   | 2.07        |
| _mean_obs       | 0.0434      |
| _min_adv        | -15.9       |
| _min_discrew    | -1.59       |
| _min_obs        | -1.29       |
| _std_act        | 0.736251    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.854       |
| ExplainedVarOld | 0.809       |
| KL              | 0.0035443   |
| Phi_loss        | 87.5276     |
| PolicyEntropy   | 3.06435     |
| PolicyLoss      | 0.000746436 |
| Steps           | 10000       |
| VarFuncLoss     | 0.178       |
| _MeanReward     | 2.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.49843     |
| _max_adv        | 7.08        |
| _max_discrew    | 3.09        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00503349 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.29        |
| _mean_obs       | 0.0452      |
| _min_adv        | -11.9       |
| _min_discrew    | 0.0139      |
| _min_obs        | -1.2        |
| _std_act        | 0.608884    |
| _std_adv        | 1           |
| _std_discrew    | 0.488       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.931       |
| ExplainedVarOld | 0.93        |
| KL              | 0.00399697  |
| Phi_loss        | 120.29      |
| PolicyEntropy   | 3.04734     |
| PolicyLoss      | -0.00513064 |
| Steps           | 10000       |
| VarFuncLoss     | 0.035       |
| _MeanReward     | 2.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.54862     |
| _max_adv        | 8.18        |
| _max_discrew    | 3.1         |
| _max_obs        | 1.43        |
| _mean_act       | -0.0230457  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.05        |
| _mean_obs       | 0.0434      |
| _min_adv        | -16         |
| _min_discrew    | -1.51       |
| _min_obs        | -1.19       |
| _std_act        | 0.718128    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.814       |
| ExplainedVarOld | 0.806       |
| KL              | 0.00354914  |
| Phi_loss        | 119.664     |
| PolicyEntropy   | 3.03681     |
| PolicyLoss      | -0.00604936 |
| Steps           | 10000       |
| VarFuncLoss     | 0.205       |
| _MeanReward     | 2.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.6093      |
| _max_adv        | 10.3        |
| _max_discrew    | 3.35        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0193567  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.09        |
| _mean_obs       | 0.0443      |
| _min_adv        | -16         |
| _min_discrew    | -1.45       |
| _min_obs        | -1.12       |
| _std_act        | 0.705215    |
| _std_adv        | 1           |
| _std_discrew    | 0.964       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.831       |
| ExplainedVarOld | 0.815       |
| KL              | 0.00478617  |
| Phi_loss        | 116.046     |
| PolicyEntropy   | 3.03135     |
| PolicyLoss      | -0.00264421 |
| Steps           | 10000       |
| VarFuncLoss     | 0.163       |
| _MeanReward     | 2.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.45033     |
| _max_adv        | 7.67        |
| _max_discrew    | 3.2         |
| _max_obs        | 1.45        |
| _mean_act       | -0.0255755  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 1.98        |
| _mean_obs       | 0.0423      |
| _min_adv        | -15.6       |
| _min_discrew    | -1.6        |
| _min_obs        | -1.23       |
| _std_act        | 0.759215    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.843       |
| ExplainedVarOld | 0.836       |
| KL              | 0.00474673  |
| Phi_loss        | 120.019     |
| PolicyEntropy   | 3.01951     |
| PolicyLoss      | -0.00755962 |
| Steps           | 10000       |
| VarFuncLoss     | 0.203       |
| _MeanReward     | 2.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06677     |
| _max_adv        | 15.8        |
| _max_discrew    | 3.18        |
| _max_obs        | 1.46        |
| _mean_act       | -0.00719493 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.33        |
| _mean_obs       | 0.0451      |
| _min_adv        | -8.03       |
| _min_discrew    | 0.00975     |
| _min_obs        | -1.25       |
| _std_act        | 0.613261    |
| _std_adv        | 1           |
| _std_discrew    | 0.513       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.93        |
| KL              | 0.00340445  |
| Phi_loss        | 119.973     |
| PolicyEntropy   | 3.00118     |
| PolicyLoss      | -0.0190679  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0328      |
| _MeanReward     | 2.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12343     |
| _max_adv        | 18.3        |
| _max_discrew    | 3.13        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00862657 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 2.31        |
| _mean_obs       | 0.0452      |
| _min_adv        | -7.14       |
| _min_discrew    | 0.00458     |
| _min_obs        | -1.27       |
| _std_act        | 0.612071    |
| _std_adv        | 1           |
| _std_discrew    | 0.491       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.925       |
| ExplainedVarOld | 0.913       |
| KL              | 0.0032587   |
| Phi_loss        | 99.8211     |
| PolicyEntropy   | 2.97977     |
| PolicyLoss      | -0.00657328 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0369      |
| _MeanReward     | 2.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.21532     |
| _max_adv        | 5.01        |
| _max_discrew    | 3.3         |
| _max_obs        | 1.33        |
| _mean_act       | -0.00495909 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.4         |
| _mean_obs       | 0.0465      |
| _min_adv        | -5.71       |
| _min_discrew    | 0.00146     |
| _min_obs        | -1.29       |
| _std_act        | 0.61402     |
| _std_adv        | 1           |
| _std_discrew    | 0.588       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.964       |
| ExplainedVarOld | 0.956       |
| KL              | 0.00324538  |
| Phi_loss        | 135.417     |
| PolicyEntropy   | 2.96069     |
| PolicyLoss      | -0.0157631  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0219      |
| _MeanReward     | 2.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.04301     |
| _max_adv        | 6.24        |
| _max_discrew    | 3.23        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00851832 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.42        |
| _mean_obs       | 0.0464      |
| _min_adv        | -4.99       |
| _min_discrew    | 0.00791     |
| _min_obs        | -1.28       |
| _std_act        | 0.623395    |
| _std_adv        | 1           |
| _std_discrew    | 0.559       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00348093  |
| Phi_loss        | 148.315     |
| PolicyEntropy   | 2.93746     |
| PolicyLoss      | -0.0216338  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0117      |
| _MeanReward     | 2.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.34917     |
| _max_adv        | 4.31        |
| _max_discrew    | 3.4         |
| _max_obs        | 1.39        |
| _mean_act       | -0.00842196 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.43        |
| _mean_obs       | 0.0463      |
| _min_adv        | -9.85       |
| _min_discrew    | 0.00867     |
| _min_obs        | -1.31       |
| _std_act        | 0.617752    |
| _std_adv        | 1           |
| _std_discrew    | 0.559       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.956       |
| ExplainedVarOld | 0.955       |
| KL              | 0.00367233  |
| Phi_loss        | 160.136     |
| PolicyEntropy   | 2.9025      |
| PolicyLoss      | -0.00889468 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0244      |
| _MeanReward     | 2.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.19445     |
| _max_adv        | 10.6        |
| _max_discrew    | 3.3         |
| _max_obs        | 1.43        |
| _mean_act       | -0.00763344 |
| _mean_adv       | 0           |
| _mean_discrew   | 2.38        |
| _mean_obs       | 0.0468      |
| _min_adv        | -9.02       |
| _min_discrew    | 0.00572     |
| _min_obs        | -1.17       |
| _std_act        | 0.631581    |
| _std_adv        | 1           |
| _std_discrew    | 0.646       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.877       |
| ExplainedVarOld | 0.854       |
| KL              | 0.00481082  |
| Phi_loss        | 124.326     |
| PolicyEntropy   | 2.89045     |
| PolicyLoss      | -0.0144169  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0797      |
| _MeanReward     | 2.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06713     |
| _max_adv        | 7.97        |
| _max_discrew    | 3.42        |
| _max_obs        | 1.35        |
| _mean_act       | -0.00852607 |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 2.46        |
| _mean_obs       | 0.0466      |
| _min_adv        | -9.82       |
| _min_discrew    | 0.0147      |
| _min_obs        | -1.14       |
| _std_act        | 0.625911    |
| _std_adv        | 1           |
| _std_discrew    | 0.589       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00346435 |
| Phi_loss        | 124.408    |
| PolicyEntropy   | 2.8889     |
| PolicyLoss      | -0.0152998 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0396     |
| _MeanReward     | 2.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.53792    |
| _max_adv        | 2.32       |
| _max_discrew    | 3.27       |
| _max_obs        | 1.41       |
| _mean_act       | -0.044142  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.08       |
| _mean_obs       | 0.0426     |
| _min_adv        | -15.6      |
| _min_discrew    | -1.76      |
| _min_obs        | -1.32      |
| _std_act        | 0.818928   |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.896      |
| ExplainedVarOld | 0.879      |
| KL              | 0.012729   |
| Phi_loss        | 127.25     |
| PolicyEntropy   | 2.88741    |
| PolicyLoss      | 0.044528   |
| Steps           | 10000      |
| VarFuncLoss     | 0.18       |
| _MeanReward     | 2.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.23974    |
| _max_adv        | 14.1       |
| _max_discrew    | 3.27       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0125858 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.44       |
| _mean_obs       | 0.0453     |
| _min_adv        | -9.04      |
| _min_discrew    | 0.00979    |
| _min_obs        | -1.14      |
| _std_act        | 0.629221   |
| _std_adv        | 1          |
| _std_discrew    | 0.591      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.944       |
| KL              | 0.00259064  |
| Phi_loss        | 156.344     |
| PolicyEntropy   | 2.86919     |
| PolicyLoss      | -0.00802656 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0315      |
| _MeanReward     | 2.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.99053     |
| _max_adv        | 12.1        |
| _max_discrew    | 3.39        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00904248 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.39        |
| _mean_obs       | 0.0452      |
| _min_adv        | -11.2       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.13       |
| _std_act        | 0.636151    |
| _std_adv        | 1           |
| _std_discrew    | 0.576       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.881      |
| KL              | 0.00205451 |
| Phi_loss        | 138.387    |
| PolicyEntropy   | 2.85298    |
| PolicyLoss      | -0.0127623 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0671     |
| _MeanReward     | 2.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.6486     |
| _max_adv        | 6.19       |
| _max_discrew    | 3.47       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0179072 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.31       |
| _mean_obs       | 0.0442     |
| _min_adv        | -16        |
| _min_discrew    | -1.23      |
| _min_obs        | -1.24      |
| _std_act        | 0.693905   |
| _std_adv        | 1          |
| _std_discrew    | 0.935      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.858      |
| KL              | 0.00246488 |
| Phi_loss        | 118.476    |
| PolicyEntropy   | 2.84569    |
| PolicyLoss      | -0.0172336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.118      |
| _MeanReward     | 3.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.52765    |
| _max_adv        | 9.04       |
| _max_discrew    | 3.48       |
| _max_obs        | 1.49       |
| _mean_act       | -0.0107108 |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.0466     |
| _min_adv        | -12        |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.17      |
| _std_act        | 0.640167   |
| _std_adv        | 1          |
| _std_discrew    | 0.685      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.934      |
| KL              | 0.00249001 |
| Phi_loss        | 168.765    |
| PolicyEntropy   | 2.83349    |
| PolicyLoss      | -0.0285304 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0458     |
| _MeanReward     | 2.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9072     |
| _max_adv        | 10.2       |
| _max_discrew    | 3.37       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0123433 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0457     |
| _min_adv        | -12.8      |
| _min_discrew    | -0.196     |
| _min_obs        | -1.2       |
| _std_act        | 0.642114   |
| _std_adv        | 1          |
| _std_discrew    | 0.678      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.901       |
| KL              | 0.00184221  |
| Phi_loss        | 148.565     |
| PolicyEntropy   | 2.84101     |
| PolicyLoss      | -0.00472608 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0565      |
| _MeanReward     | 3.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.05742     |
| _max_adv        | 14.1        |
| _max_discrew    | 3.43        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0149316  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.5         |
| _mean_obs       | 0.0462      |
| _min_adv        | -11.8       |
| _min_discrew    | 0.0082      |
| _min_obs        | -1.27       |
| _std_act        | 0.650166    |
| _std_adv        | 1           |
| _std_discrew    | 0.721       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.865      |
| KL              | 0.00348593 |
| Phi_loss        | 142.902    |
| PolicyEntropy   | 2.84102    |
| PolicyLoss      | -0.019567  |
| Steps           | 10000      |
| VarFuncLoss     | 0.089      |
| _MeanReward     | 3e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 3.16357    |
| _max_adv        | 9.08       |
| _max_discrew    | 3.4        |
| _max_obs        | 1.37       |
| _mean_act       | -0.0118585 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.48       |
| _mean_obs       | 0.0457     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.00947    |
| _min_obs        | -1.18      |
| _std_act        | 0.644834   |
| _std_adv        | 1          |
| _std_discrew    | 0.592      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.9        |
| KL              | 0.00173777 |
| Phi_loss        | 135.759    |
| PolicyEntropy   | 2.85279    |
| PolicyLoss      | -0.0229384 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0538     |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93501    |
| _max_adv        | 9.76       |
| _max_discrew    | 3.34       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0123294 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.53       |
| _mean_obs       | 0.0461     |
| _min_adv        | -11.4      |
| _min_discrew    | 0.0107     |
| _min_obs        | -1.15      |
| _std_act        | 0.638655   |
| _std_adv        | 1          |
| _std_discrew    | 0.613      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.951       |
| ExplainedVarOld | 0.95        |
| KL              | 0.00191591  |
| Phi_loss        | 161.429     |
| PolicyEntropy   | 2.83553     |
| PolicyLoss      | -0.00214519 |
| Steps           | 10000       |
| VarFuncLoss     | 0.03        |
| _MeanReward     | 3.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8369      |
| _max_adv        | 15.8        |
| _max_discrew    | 3.5         |
| _max_obs        | 1.46        |
| _mean_act       | -0.0138195  |
| _mean_adv       | 2.24e-17    |
| _mean_discrew   | 2.58        |
| _mean_obs       | 0.0465      |
| _min_adv        | -11.8       |
| _min_discrew    | 0.0107      |
| _min_obs        | -1.19       |
| _std_act        | 0.641144    |
| _std_adv        | 1           |
| _std_discrew    | 0.619       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.949       |
| KL              | 0.00225618  |
| Phi_loss        | 96.4043     |
| PolicyEntropy   | 2.82974     |
| PolicyLoss      | -0.00665205 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0214      |
| _MeanReward     | 2.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.60033     |
| _max_adv        | 2.06        |
| _max_discrew    | 3.41        |
| _max_obs        | 1.36        |
| _mean_act       | -0.034316   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.24        |
| _mean_obs       | 0.0434      |
| _min_adv        | -16.6       |
| _min_discrew    | -1.68       |
| _min_obs        | -1.19       |
| _std_act        | 0.797508    |
| _std_adv        | 1           |
| _std_discrew    | 1.55        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.886       |
| ExplainedVarOld | 0.84        |
| KL              | 0.00958902  |
| Phi_loss        | 129.984     |
| PolicyEntropy   | 2.85484     |
| PolicyLoss      | -0.054411   |
| Steps           | 10000       |
| VarFuncLoss     | 0.179       |
| _MeanReward     | 2.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.2707      |
| _max_adv        | 4.57        |
| _max_discrew    | 3.38        |
| _max_obs        | 1.43        |
| _mean_act       | -0.00946457 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.43        |
| _mean_obs       | 0.0448      |
| _min_adv        | -10         |
| _min_discrew    | 0.00149     |
| _min_obs        | -1.23       |
| _std_act        | 0.638144    |
| _std_adv        | 1           |
| _std_discrew    | 0.685       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.895       |
| ExplainedVarOld | 0.876       |
| KL              | 0.00150288  |
| Phi_loss        | 132.047     |
| PolicyEntropy   | 2.85693     |
| PolicyLoss      | -0.0167599  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0722      |
| _MeanReward     | 2.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.27646     |
| _max_adv        | 14          |
| _max_discrew    | 3.38        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00883758 |
| _mean_adv       | -9.24e-18   |
| _mean_discrew   | 2.47        |
| _mean_obs       | 0.0459      |
| _min_adv        | -6.63       |
| _min_discrew    | 0.0057      |
| _min_obs        | -1.19       |
| _std_act        | 0.646747    |
| _std_adv        | 1           |
| _std_discrew    | 0.604       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.891      |
| ExplainedVarOld | 0.846      |
| KL              | 0.0087776  |
| Phi_loss        | 128.453    |
| PolicyEntropy   | 2.8294     |
| PolicyLoss      | 0.0305128  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0658     |
| _MeanReward     | 3.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14076    |
| _max_adv        | 6.89       |
| _max_discrew    | 3.36       |
| _max_obs        | 1.57       |
| _mean_act       | -0.0121757 |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.0451     |
| _min_adv        | -10.8      |
| _min_discrew    | 0.00825    |
| _min_obs        | -1.17      |
| _std_act        | 0.643695   |
| _std_adv        | 1          |
| _std_discrew    | 0.573      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.939       |
| ExplainedVarOld | 0.937       |
| KL              | 0.000736299 |
| Phi_loss        | 180.427     |
| PolicyEntropy   | 2.82355     |
| PolicyLoss      | 0.0130333   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0347      |
| _MeanReward     | 2.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.41288     |
| _max_adv        | 8.34        |
| _max_discrew    | 3.47        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00913957 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.49        |
| _mean_obs       | 0.0454      |
| _min_adv        | -10.9       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.23       |
| _std_act        | 0.645548    |
| _std_adv        | 1           |
| _std_discrew    | 0.633       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.885      |
| ExplainedVarOld | 0.875      |
| KL              | 0.00130171 |
| Phi_loss        | 148.127    |
| PolicyEntropy   | 2.82122    |
| PolicyLoss      | 0.00320941 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0731     |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00729    |
| _max_adv        | 6.89       |
| _max_discrew    | 3.31       |
| _max_obs        | 1.35       |
| _mean_act       | -0.010315  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.045      |
| _min_adv        | -11        |
| _min_discrew    | 0.0124     |
| _min_obs        | -1.2       |
| _std_act        | 0.648458   |
| _std_adv        | 1          |
| _std_discrew    | 0.632      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.875       |
| ExplainedVarOld | 0.863       |
| KL              | 0.00162513  |
| Phi_loss        | 146.258     |
| PolicyEntropy   | 2.79658     |
| PolicyLoss      | -0.00218871 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0789      |
| _MeanReward     | 3.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95498     |
| _max_adv        | 7.49        |
| _max_discrew    | 3.52        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0106823  |
| _mean_adv       | -9.95e-18   |
| _mean_discrew   | 2.55        |
| _mean_obs       | 0.046       |
| _min_adv        | -9.61       |
| _min_discrew    | -0.0351     |
| _min_obs        | -1.19       |
| _std_act        | 0.651247    |
| _std_adv        | 1           |
| _std_discrew    | 0.615       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.936      |
| ExplainedVarOld | 0.927      |
| KL              | 0.00394971 |
| Phi_loss        | 152.054    |
| PolicyEntropy   | 2.78174    |
| PolicyLoss      | -0.0190282 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0405     |
| _MeanReward     | 3.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10355    |
| _max_adv        | 6.75       |
| _max_discrew    | 3.47       |
| _max_obs        | 1.32       |
| _mean_act       | -0.010577  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.56       |
| _mean_obs       | 0.0453     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.00736    |
| _min_obs        | -1.14      |
| _std_act        | 0.648094   |
| _std_adv        | 1          |
| _std_discrew    | 0.699      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.938       |
| ExplainedVarOld | 0.93        |
| KL              | 0.00241267  |
| Phi_loss        | 147.409     |
| PolicyEntropy   | 2.78609     |
| PolicyLoss      | -0.0188689  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0437      |
| _MeanReward     | 3.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8828      |
| _max_adv        | 9.79        |
| _max_discrew    | 3.42        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00970404 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.57        |
| _mean_obs       | 0.0454      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0116      |
| _min_obs        | -1.17       |
| _std_act        | 0.647176    |
| _std_adv        | 1           |
| _std_discrew    | 0.621       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.933       |
| ExplainedVarOld | 0.93        |
| KL              | 0.00149906  |
| Phi_loss        | 140.082     |
| PolicyEntropy   | 2.79622     |
| PolicyLoss      | -0.00389169 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0417      |
| _MeanReward     | 3.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.13576     |
| _max_adv        | 8.75        |
| _max_discrew    | 3.67        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0102466  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.6         |
| _mean_obs       | 0.046       |
| _min_adv        | -11.2       |
| _min_discrew    | 0.0111      |
| _min_obs        | -1.36       |
| _std_act        | 0.650646    |
| _std_adv        | 1           |
| _std_discrew    | 0.657       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.953       |
| ExplainedVarOld | 0.949       |
| KL              | 0.00415896  |
| Phi_loss        | 154.329     |
| PolicyEntropy   | 2.77674     |
| PolicyLoss      | 0.00880017  |
| Steps           | 10000       |
| VarFuncLoss     | 0.031       |
| _MeanReward     | 3.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.99647     |
| _max_adv        | 5.17        |
| _max_discrew    | 3.58        |
| _max_obs        | 1.4         |
| _mean_act       | -0.00884382 |
| _mean_adv       | 4.12e-17    |
| _mean_discrew   | 2.57        |
| _mean_obs       | 0.0452      |
| _min_adv        | -9.84       |
| _min_discrew    | 0.00682     |
| _min_obs        | -1.19       |
| _std_act        | 0.645717    |
| _std_adv        | 1           |
| _std_discrew    | 0.618       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.945       |
| ExplainedVarOld | 0.943       |
| KL              | 0.00305547  |
| Phi_loss        | 178.199     |
| PolicyEntropy   | 2.74781     |
| PolicyLoss      | -0.0100792  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0344      |
| _MeanReward     | 3.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.49291     |
| _max_adv        | 7.59        |
| _max_discrew    | 3.55        |
| _max_obs        | 1.48        |
| _mean_act       | -0.00596698 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 2.6         |
| _mean_obs       | 0.046       |
| _min_adv        | -13         |
| _min_discrew    | 0.0105      |
| _min_obs        | -1.19       |
| _std_act        | 0.645107    |
| _std_adv        | 1           |
| _std_discrew    | 0.628       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.955       |
| ExplainedVarOld | 0.954       |
| KL              | 0.00302604  |
| Phi_loss        | 176.802     |
| PolicyEntropy   | 2.73412     |
| PolicyLoss      | -0.00302803 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0284      |
| _MeanReward     | 3.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87043     |
| _max_adv        | 4.91        |
| _max_discrew    | 3.59        |
| _max_obs        | 1.44        |
| _mean_act       | -0.00729367 |
| _mean_adv       | -9.95e-18   |
| _mean_discrew   | 2.51        |
| _mean_obs       | 0.0447      |
| _min_adv        | -10.5       |
| _min_discrew    | 0.00555     |
| _min_obs        | -1.3        |
| _std_act        | 0.648041    |
| _std_adv        | 1           |
| _std_discrew    | 0.665       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.909       |
| KL              | 0.00420421  |
| Phi_loss        | 137.106     |
| PolicyEntropy   | 2.69478     |
| PolicyLoss      | -0.00113574 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0591      |
| _MeanReward     | 3.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.50957     |
| _max_adv        | 4.5         |
| _max_discrew    | 3.51        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00735208 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.57        |
| _mean_obs       | 0.0457      |
| _min_adv        | -9.46       |
| _min_discrew    | 0.00946     |
| _min_obs        | -1.14       |
| _std_act        | 0.665377    |
| _std_adv        | 1           |
| _std_discrew    | 0.722       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.887       |
| ExplainedVarOld | 0.87        |
| KL              | 0.00408987  |
| Phi_loss        | 136.85      |
| PolicyEntropy   | 2.68576     |
| PolicyLoss      | 0.00117985  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0827      |
| _MeanReward     | 3.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.45499     |
| _max_adv        | 9.7         |
| _max_discrew    | 3.52        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00686992 |
| _mean_adv       | 0           |
| _mean_discrew   | 2.66        |
| _mean_obs       | 0.0461      |
| _min_adv        | -5.27       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.26       |
| _std_act        | 0.650226    |
| _std_adv        | 1           |
| _std_discrew    | 0.631       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.969       |
| KL              | 0.00418642  |
| Phi_loss        | 159.504     |
| PolicyEntropy   | 2.65036     |
| PolicyLoss      | 0.00345537  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0189      |
| _MeanReward     | 3.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01021     |
| _max_adv        | 4.02        |
| _max_discrew    | 3.48        |
| _max_obs        | 1.35        |
| _mean_act       | -0.00512634 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 2.56        |
| _mean_obs       | 0.0459      |
| _min_adv        | -10.5       |
| _min_discrew    | 0.0076      |
| _min_obs        | -1.19       |
| _std_act        | 0.661856    |
| _std_adv        | 1           |
| _std_discrew    | 0.68        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.888       |
| ExplainedVarOld | 0.875       |
| KL              | 0.00665026  |
| Phi_loss        | 162.613     |
| PolicyEntropy   | 2.63173     |
| PolicyLoss      | 0.00471254  |
| Steps           | 10000       |
| VarFuncLoss     | 0.077       |
| _MeanReward     | 3.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86861     |
| _max_adv        | 10.9        |
| _max_discrew    | 3.61        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00507897 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.7         |
| _mean_obs       | 0.0475      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.0127      |
| _min_obs        | -1.17       |
| _std_act        | 0.653704    |
| _std_adv        | 1           |
| _std_discrew    | 0.658       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.954       |
| ExplainedVarOld | 0.949       |
| KL              | 0.00215381  |
| Phi_loss        | 153.254     |
| PolicyEntropy   | 2.60972     |
| PolicyLoss      | 0.00362132  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0329      |
| _MeanReward     | 3.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.48784     |
| _max_adv        | 12          |
| _max_discrew    | 3.62        |
| _max_obs        | 1.31        |
| _mean_act       | -0.00324564 |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0467      |
| _min_adv        | -3.57       |
| _min_discrew    | 0.01        |
| _min_obs        | -1.23       |
| _std_act        | 0.65154     |
| _std_adv        | 1           |
| _std_discrew    | 0.652       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.966       |
| KL              | 0.0014825   |
| Phi_loss        | 171.028     |
| PolicyEntropy   | 2.61457     |
| PolicyLoss      | -0.0132162  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0192      |
| _MeanReward     | 3.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08383     |
| _max_adv        | 3.07        |
| _max_discrew    | 3.59        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00224393 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.58        |
| _mean_obs       | 0.0455      |
| _min_adv        | -9.7        |
| _min_discrew    | 0.014       |
| _min_obs        | -1.24       |
| _std_act        | 0.66824     |
| _std_adv        | 1           |
| _std_discrew    | 0.757       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.889       |
| ExplainedVarOld | 0.857       |
| KL              | 0.00703324  |
| Phi_loss        | 160.123     |
| PolicyEntropy   | 2.58064     |
| PolicyLoss      | 0.021026    |
| Steps           | 10000       |
| VarFuncLoss     | 0.0837      |
| _MeanReward     | 3.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00402     |
| _max_adv        | 14.5        |
| _max_discrew    | 3.57        |
| _max_obs        | 1.41        |
| _mean_act       | -0.00640122 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.63        |
| _mean_obs       | 0.0455      |
| _min_adv        | -8.71       |
| _min_discrew    | 0.00925     |
| _min_obs        | -1.28       |
| _std_act        | 0.667666    |
| _std_adv        | 1           |
| _std_discrew    | 0.732       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.881       |
| ExplainedVarOld | 0.846       |
| KL              | 0.00235373  |
| Phi_loss        | 109.22      |
| PolicyEntropy   | 2.59331     |
| PolicyLoss      | -0.0217717  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0879      |
| _MeanReward     | 3.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11028     |
| _max_adv        | 12.9        |
| _max_discrew    | 3.73        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00762117 |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 2.75        |
| _mean_obs       | 0.0466      |
| _min_adv        | -4.67       |
| _min_discrew    | 0.00937     |
| _min_obs        | -1.33       |
| _std_act        | 0.658987    |
| _std_adv        | 1           |
| _std_discrew    | 0.695       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.966       |
| ExplainedVarOld | 0.959       |
| KL              | 0.00155455  |
| Phi_loss        | 155.957     |
| PolicyEntropy   | 2.58001     |
| PolicyLoss      | -0.00404549 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0248      |
| _MeanReward     | 2.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.36462     |
| _max_adv        | 3.28        |
| _max_discrew    | 3.63        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0357989  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.34        |
| _mean_obs       | 0.0435      |
| _min_adv        | -15.3       |
| _min_discrew    | -1.57       |
| _min_obs        | -1.15       |
| _std_act        | 0.820096    |
| _std_adv        | 1           |
| _std_discrew    | 1.87        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.87        |
| KL              | 0.00519565  |
| Phi_loss        | 154.713     |
| PolicyEntropy   | 2.58238     |
| PolicyLoss      | 0.0117666   |
| Steps           | 10000       |
| VarFuncLoss     | 0.205       |
| _MeanReward     | 3.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0711      |
| _max_adv        | 20.9        |
| _max_discrew    | 3.61        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00788767 |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0458      |
| _min_adv        | -8.47       |
| _min_discrew    | 0.00208     |
| _min_obs        | -1.16       |
| _std_act        | 0.649597    |
| _std_adv        | 1           |
| _std_discrew    | 0.683       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.961       |
| KL              | 0.0120081   |
| Phi_loss        | 159.898     |
| PolicyEntropy   | 2.57785     |
| PolicyLoss      | -0.0787152  |
| Steps           | 10000       |
| VarFuncLoss     | 0.023       |
| _MeanReward     | 3.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94348     |
| _max_adv        | 7.23        |
| _max_discrew    | 3.65        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00710024 |
| _mean_adv       | -7.96e-17   |
| _mean_discrew   | 2.76        |
| _mean_obs       | 0.0465      |
| _min_adv        | -3.95       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.26       |
| _std_act        | 0.662295    |
| _std_adv        | 1           |
| _std_discrew    | 0.722       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.978       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00179101  |
| Phi_loss        | 194.78      |
| PolicyEntropy   | 2.57521     |
| PolicyLoss      | -0.0123409  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0177      |
| _MeanReward     | 3.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.15817     |
| _max_adv        | 9.92        |
| _max_discrew    | 3.61        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00378411 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.7         |
| _mean_obs       | 0.0465      |
| _min_adv        | -12         |
| _min_discrew    | 0.011       |
| _min_obs        | -1.23       |
| _std_act        | 0.667141    |
| _std_adv        | 1           |
| _std_discrew    | 0.701       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.953       |
| ExplainedVarOld | 0.947       |
| KL              | 0.00141716  |
| Phi_loss        | 195.166     |
| PolicyEntropy   | 2.56833     |
| PolicyLoss      | -0.00313483 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0332      |
| _MeanReward     | 3.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00529     |
| _max_adv        | 5.67        |
| _max_discrew    | 3.58        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00766431 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.73        |
| _mean_obs       | 0.0457      |
| _min_adv        | -4.44       |
| _min_discrew    | 0.0097      |
| _min_obs        | -1.29       |
| _std_act        | 0.666806    |
| _std_adv        | 1           |
| _std_discrew    | 0.665       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00158315  |
| Phi_loss        | 214.05      |
| PolicyEntropy   | 2.55032     |
| PolicyLoss      | -0.0106024  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0138      |
| _MeanReward     | 3.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.16772     |
| _max_adv        | 7.17        |
| _max_discrew    | 3.71        |
| _max_obs        | 1.41        |
| _mean_act       | -0.00521321 |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 2.72        |
| _mean_obs       | 0.0464      |
| _min_adv        | -11.9       |
| _min_discrew    | 0.0132      |
| _min_obs        | -1.16       |
| _std_act        | 0.675542    |
| _std_adv        | 1           |
| _std_discrew    | 0.721       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.898      |
| KL              | 0.00195327 |
| Phi_loss        | 150.991    |
| PolicyEntropy   | 2.53862    |
| PolicyLoss      | 0.00169924 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0576     |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.54192    |
| _max_adv        | 13.6       |
| _max_discrew    | 3.68       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0066388 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.82       |
| _mean_obs       | 0.0478     |
| _min_adv        | -4.65      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.12      |
| _std_act        | 0.672321   |
| _std_adv        | 1          |
| _std_discrew    | 0.726      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00183894 |
| Phi_loss        | 204.307    |
| PolicyEntropy   | 2.52576    |
| PolicyLoss      | -0.0217571 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0184     |
| _MeanReward     | 3.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01523    |
| _max_adv        | 17.7       |
| _max_discrew    | 3.82       |
| _max_obs        | 1.29       |
| _mean_act       | -0.01004   |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.84       |
| _mean_obs       | 0.0469     |
| _min_adv        | -3.91      |
| _min_discrew    | 0.00941    |
| _min_obs        | -1.23      |
| _std_act        | 0.670418   |
| _std_adv        | 1          |
| _std_discrew    | 0.712      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00218135  |
| Phi_loss        | 216.463     |
| PolicyEntropy   | 2.51329     |
| PolicyLoss      | 0.00141864  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0189      |
| _MeanReward     | 3.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11818     |
| _max_adv        | 9.68        |
| _max_discrew    | 3.78        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00487345 |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0459      |
| _min_adv        | -8.62       |
| _min_discrew    | -0.0157     |
| _min_obs        | -1.18       |
| _std_act        | 0.663995    |
| _std_adv        | 1           |
| _std_discrew    | 0.747       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.929       |
| ExplainedVarOld | 0.92        |
| KL              | 0.0023141   |
| Phi_loss        | 187.791     |
| PolicyEntropy   | 2.50753     |
| PolicyLoss      | -0.0189515  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0573      |
| _MeanReward     | 3.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.17789     |
| _max_adv        | 5.29        |
| _max_discrew    | 3.69        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00904036 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.78        |
| _mean_obs       | 0.0466      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0122      |
| _min_obs        | -1.11       |
| _std_act        | 0.675142    |
| _std_adv        | 1           |
| _std_discrew    | 0.744       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.928       |
| ExplainedVarOld | 0.921       |
| KL              | 0.00176516  |
| Phi_loss        | 171.655     |
| PolicyEntropy   | 2.49603     |
| PolicyLoss      | -0.0130277  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0565      |
| _MeanReward     | 3.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96809     |
| _max_adv        | 12.2        |
| _max_discrew    | 3.67        |
| _max_obs        | 1.32        |
| _mean_act       | -0.00789898 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.78        |
| _mean_obs       | 0.0463      |
| _min_adv        | -14.3       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.09       |
| _std_act        | 0.678185    |
| _std_adv        | 1           |
| _std_discrew    | 0.751       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.893       |
| KL              | 0.00617438  |
| Phi_loss        | 148.486     |
| PolicyEntropy   | 2.48964     |
| PolicyLoss      | 0.0206946   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0654      |
| _MeanReward     | 3.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.10154     |
| _max_adv        | 21.4        |
| _max_discrew    | 3.72        |
| _max_obs        | 1.45        |
| _mean_act       | -0.00816516 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.82        |
| _mean_obs       | 0.0466      |
| _min_adv        | -5.62       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.3        |
| _std_act        | 0.67446     |
| _std_adv        | 1           |
| _std_discrew    | 0.709       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00117486 |
| Phi_loss        | 158.139    |
| PolicyEntropy   | 2.4854     |
| PolicyLoss      | 0.00249164 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0154     |
| _MeanReward     | 2.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.46284    |
| _max_adv        | 2.35       |
| _max_discrew    | 3.72       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0458476 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 2.38       |
| _mean_obs       | 0.043      |
| _min_adv        | -18.2      |
| _min_discrew    | -1.62      |
| _min_obs        | -1.18      |
| _std_act        | 0.876382   |
| _std_adv        | 1          |
| _std_discrew    | 2.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.939      |
| KL              | 0.0205144  |
| Phi_loss        | 260.102    |
| PolicyEntropy   | 2.48167    |
| PolicyLoss      | 0.324957   |
| Steps           | 10000      |
| VarFuncLoss     | 0.092      |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.16147    |
| _max_adv        | 15.6       |
| _max_discrew    | 3.75       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0061057 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.84       |
| _mean_obs       | 0.0464     |
| _min_adv        | -4.9       |
| _min_discrew    | 0.016      |
| _min_obs        | -1.16      |
| _std_act        | 0.671697   |
| _std_adv        | 1          |
| _std_discrew    | 0.729      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00398313  |
| Phi_loss        | 238.725     |
| PolicyEntropy   | 2.47147     |
| PolicyLoss      | 0.0144873   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 3.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06074     |
| _max_adv        | 20.7        |
| _max_discrew    | 3.63        |
| _max_obs        | 1.4         |
| _mean_act       | -0.00939703 |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.85        |
| _mean_obs       | 0.0469      |
| _min_adv        | -5.28       |
| _min_discrew    | -0.0178     |
| _min_obs        | -1.36       |
| _std_act        | 0.674048    |
| _std_adv        | 1           |
| _std_discrew    | 0.715       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.978       |
| KL              | 0.000939292 |
| Phi_loss        | 192.403     |
| PolicyEntropy   | 2.46022     |
| PolicyLoss      | 0.00361442  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0124      |
| _MeanReward     | 3.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90807     |
| _max_adv        | 11          |
| _max_discrew    | 3.76        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00855458 |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 2.83        |
| _mean_obs       | 0.0463      |
| _min_adv        | -11.9       |
| _min_discrew    | 0.0113      |
| _min_obs        | -1.33       |
| _std_act        | 0.664749    |
| _std_adv        | 1           |
| _std_discrew    | 0.751       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.958       |
| ExplainedVarOld | 0.937       |
| KL              | 0.00206454  |
| Phi_loss        | 158.209     |
| PolicyEntropy   | 2.44221     |
| PolicyLoss      | -0.0145417  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0314      |
| _MeanReward     | 3.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.14303     |
| _max_adv        | 5.59        |
| _max_discrew    | 3.87        |
| _max_obs        | 1.35        |
| _mean_act       | -0.00642996 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.82        |
| _mean_obs       | 0.0472      |
| _min_adv        | -9.32       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.18       |
| _std_act        | 0.671158    |
| _std_adv        | 1           |
| _std_discrew    | 0.805       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00316826 |
| Phi_loss        | 241.829    |
| PolicyEntropy   | 2.43006    |
| PolicyLoss      | -0.0114974 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0492     |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.3001     |
| _max_adv        | 3.89       |
| _max_discrew    | 3.87       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0442489 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0437     |
| _min_adv        | -17.2      |
| _min_discrew    | -1.37      |
| _min_obs        | -1.19      |
| _std_act        | 0.826001   |
| _std_adv        | 1          |
| _std_discrew    | 2.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.882      |
| KL              | 0.00510403 |
| Phi_loss        | 154.157    |
| PolicyEntropy   | 2.44184    |
| PolicyLoss      | 0.0360715  |
| Steps           | 10000      |
| VarFuncLoss     | 0.158      |
| _MeanReward     | 3.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1126     |
| _max_adv        | 5.85       |
| _max_discrew    | 3.72       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0292019 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.54       |
| _mean_obs       | 0.0437     |
| _min_adv        | -16.5      |
| _min_discrew    | -1.28      |
| _min_obs        | -1.25      |
| _std_act        | 0.77888    |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.85        |
| ExplainedVarOld | 0.836       |
| KL              | 0.00285826  |
| Phi_loss        | 204.226     |
| PolicyEntropy   | 2.4277      |
| PolicyLoss      | -0.0107467  |
| Steps           | 10000       |
| VarFuncLoss     | 0.231       |
| _MeanReward     | 3.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93231     |
| _max_adv        | 20.8        |
| _max_discrew    | 3.81        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00579401 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.86        |
| _mean_obs       | 0.0466      |
| _min_adv        | -4.39       |
| _min_discrew    | 0.0143      |
| _min_obs        | -1.19       |
| _std_act        | 0.671982    |
| _std_adv        | 1           |
| _std_discrew    | 0.785       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.963        |
| ExplainedVarOld | 0.957        |
| KL              | 0.00264102   |
| Phi_loss        | 187.133      |
| PolicyEntropy   | 2.42519      |
| PolicyLoss      | -0.000873156 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0309       |
| _MeanReward     | 3.46e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.96824      |
| _max_adv        | 20.2         |
| _max_discrew    | 3.84         |
| _max_obs        | 1.38         |
| _mean_act       | -0.0113393   |
| _mean_adv       | 1.42e-17     |
| _mean_discrew   | 2.89         |
| _mean_obs       | 0.0466       |
| _min_adv        | -13.1        |
| _min_discrew    | 0.0132       |
| _min_obs        | -1.24        |
| _std_act        | 0.673429     |
| _std_adv        | 1            |
| _std_discrew    | 0.756        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00214659 |
| Phi_loss        | 166.471    |
| PolicyEntropy   | 2.40551    |
| PolicyLoss      | 0.00797774 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0375     |
| _MeanReward     | 3.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.0529     |
| _max_adv        | 4.13       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.46       |
| _mean_act       | -0.0203924 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 2.65       |
| _mean_obs       | 0.0448     |
| _min_adv        | -16.4      |
| _min_discrew    | -1.08      |
| _min_obs        | -1.16      |
| _std_act        | 0.731448   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.873      |
| ExplainedVarOld | 0.862      |
| KL              | 0.00192079 |
| Phi_loss        | 214.47     |
| PolicyEntropy   | 2.4021     |
| PolicyLoss      | -0.0128595 |
| Steps           | 10000      |
| VarFuncLoss     | 0.161      |
| _MeanReward     | 3.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.25598    |
| _max_adv        | 4.59       |
| _max_discrew    | 3.82       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0395323 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.55       |
| _mean_obs       | 0.0438     |
| _min_adv        | -17.9      |
| _min_discrew    | -1.28      |
| _min_obs        | -1.22      |
| _std_act        | 0.808075   |
| _std_adv        | 1          |
| _std_discrew    | 2          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.925       |
| ExplainedVarOld | 0.918       |
| KL              | 0.00182183  |
| Phi_loss        | 172.374     |
| PolicyEntropy   | 2.39093     |
| PolicyLoss      | 0.0133799   |
| Steps           | 10000       |
| VarFuncLoss     | 0.154       |
| _MeanReward     | 3.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93411     |
| _max_adv        | 12.2        |
| _max_discrew    | 3.83        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00764523 |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 2.87        |
| _mean_obs       | 0.0467      |
| _min_adv        | -9.85       |
| _min_discrew    | 0.0137      |
| _min_obs        | -1.25       |
| _std_act        | 0.672559    |
| _std_adv        | 1           |
| _std_discrew    | 0.744       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.954       |
| KL              | 0.00181053  |
| Phi_loss        | 177.934     |
| PolicyEntropy   | 2.3815      |
| PolicyLoss      | -0.00827822 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0301      |
| _MeanReward     | 3.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.87288     |
| _max_adv        | 21.6        |
| _max_discrew    | 3.85        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0094955  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.9         |
| _mean_obs       | 0.0465      |
| _min_adv        | -3.9        |
| _min_discrew    | 0.014       |
| _min_obs        | -1.13       |
| _std_act        | 0.675461    |
| _std_adv        | 1           |
| _std_discrew    | 0.736       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00157215 |
| Phi_loss        | 204.027    |
| PolicyEntropy   | 2.35023    |
| PolicyLoss      | 0.00974723 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0171     |
| _MeanReward     | 3.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91877    |
| _max_adv        | 6.33       |
| _max_discrew    | 3.88       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0100473 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.78       |
| _mean_obs       | 0.0452     |
| _min_adv        | -8.99      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.19      |
| _std_act        | 0.685009   |
| _std_adv        | 1          |
| _std_discrew    | 0.927      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.898       |
| ExplainedVarOld | 0.789       |
| KL              | 0.00185796  |
| Phi_loss        | 98.5312     |
| PolicyEntropy   | 2.33389     |
| PolicyLoss      | -0.00928682 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0951      |
| _MeanReward     | 3.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0463      |
| _max_adv        | 6.39        |
| _max_discrew    | 3.83        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0222146  |
| _mean_adv       | 4.26e-18    |
| _mean_discrew   | 2.77        |
| _mean_obs       | 0.0456      |
| _min_adv        | -18.1       |
| _min_discrew    | -1.15       |
| _min_obs        | -1.12       |
| _std_act        | 0.744513    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.877       |
| ExplainedVarOld | 0.851       |
| KL              | 0.00243756  |
| Phi_loss        | 200.331     |
| PolicyEntropy   | 2.32084     |
| PolicyLoss      | -0.0269194  |
| Steps           | 10000       |
| VarFuncLoss     | 0.152       |
| _MeanReward     | 3.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.21734     |
| _max_adv        | 10.1        |
| _max_discrew    | 3.92        |
| _max_obs        | 1.39        |
| _mean_act       | -0.00721597 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.82        |
| _mean_obs       | 0.0461      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0124      |
| _min_obs        | -1.18       |
| _std_act        | 0.681299    |
| _std_adv        | 1           |
| _std_discrew    | 0.887       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.897       |
| ExplainedVarOld | 0.885       |
| KL              | 0.00162943  |
| Phi_loss        | 228.578     |
| PolicyEntropy   | 2.31269     |
| PolicyLoss      | 0.000222604 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0915      |
| _MeanReward     | 3.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81291     |
| _max_adv        | 10.8        |
| _max_discrew    | 3.93        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00763039 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.89        |
| _mean_obs       | 0.0466      |
| _min_adv        | -14.8       |
| _min_discrew    | 0.0155      |
| _min_obs        | -1.14       |
| _std_act        | 0.670634    |
| _std_adv        | 1           |
| _std_discrew    | 0.869       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.915       |
| ExplainedVarOld | 0.89        |
| KL              | 0.00296251  |
| Phi_loss        | 228.445     |
| PolicyEntropy   | 2.29469     |
| PolicyLoss      | 0.000364372 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0763      |
| _MeanReward     | 3.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93575     |
| _max_adv        | 6.68        |
| _max_discrew    | 3.98        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00975343 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.96        |
| _mean_obs       | 0.0472      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.27       |
| _std_act        | 0.672739    |
| _std_adv        | 1           |
| _std_discrew    | 0.819       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.952       |
| KL              | 0.00157566  |
| Phi_loss        | 215.266     |
| PolicyEntropy   | 2.29106     |
| PolicyLoss      | -0.0204442  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0353      |
| _MeanReward     | 3.53e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88838     |
| _max_adv        | 12.7        |
| _max_discrew    | 3.86        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00898776 |
| _mean_adv       | 1.85e-17    |
| _mean_discrew   | 2.94        |
| _mean_obs       | 0.0463      |
| _min_adv        | -11.1       |
| _min_discrew    | 0.011       |
| _min_obs        | -1.31       |
| _std_act        | 0.676463    |
| _std_adv        | 1           |
| _std_discrew    | 0.773       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00308096 |
| Phi_loss        | 163.933    |
| PolicyEntropy   | 2.28681    |
| PolicyLoss      | 0.0174356  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 3.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83799    |
| _max_adv        | 13.2       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.26       |
| _mean_act       | -0.010523  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.0463     |
| _min_adv        | -4.03      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.22      |
| _std_act        | 0.677471   |
| _std_adv        | 1          |
| _std_discrew    | 0.808      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00143392 |
| Phi_loss        | 221.351    |
| PolicyEntropy   | 2.27393    |
| PolicyLoss      | -0.014653  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 3.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96474    |
| _max_adv        | 3.74       |
| _max_discrew    | 4.1        |
| _max_obs        | 1.31       |
| _mean_act       | -0.0135045 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.96       |
| _mean_obs       | 0.0462     |
| _min_adv        | -12.5      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.22      |
| _std_act        | 0.676411   |
| _std_adv        | 1          |
| _std_discrew    | 0.801      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00443939 |
| Phi_loss        | 217.854    |
| PolicyEntropy   | 2.26804    |
| PolicyLoss      | -0.0103835 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 3.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05908    |
| _max_adv        | 3.4        |
| _max_discrew    | 3.92       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0127397 |
| _mean_adv       | -6.25e-17  |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0468     |
| _min_adv        | -3.99      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.36      |
| _std_act        | 0.679762   |
| _std_adv        | 1          |
| _std_discrew    | 0.858      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00292777  |
| Phi_loss        | 255.18      |
| PolicyEntropy   | 2.24888     |
| PolicyLoss      | -0.0138757  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0133      |
| _MeanReward     | 3.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.092       |
| _max_adv        | 26.5        |
| _max_discrew    | 3.92        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00807558 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.99        |
| _mean_obs       | 0.0464      |
| _min_adv        | -7.16       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.12       |
| _std_act        | 0.68773     |
| _std_adv        | 1           |
| _std_discrew    | 0.803       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.984     |
| ExplainedVarOld | 0.979     |
| KL              | 0.0103818 |
| Phi_loss        | 198.891   |
| PolicyEntropy   | 2.2291    |
| PolicyLoss      | 0.0336867 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0132    |
| _MeanReward     | 3.62e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.88091   |
| _max_adv        | 7.99      |
| _max_discrew    | 3.93      |
| _max_obs        | 1.33      |
| _mean_act       | -0.013751 |
| _mean_adv       | -3.41e-17 |
| _mean_discrew   | 3         |
| _mean_obs       | 0.0469    |
| _min_adv        | -9.99     |
| _min_discrew    | 0.00967   |
| _min_obs        | -1.16     |
| _std_act        | 0.683485  |
| _std_adv        | 1         |
| _std_discrew    | 0.788     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00273549 |
| Phi_loss        | 264.314    |
| PolicyEntropy   | 2.21536    |
| PolicyLoss      | 0.00225647 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 3.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.07194    |
| _max_adv        | 3.89       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0130877 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0464     |
| _min_adv        | -4.18      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.36      |
| _std_act        | 0.681373   |
| _std_adv        | 1          |
| _std_discrew    | 0.812      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00157866 |
| Phi_loss        | 271.958    |
| PolicyEntropy   | 2.20156    |
| PolicyLoss      | 0.00359202 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0164     |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13324    |
| _max_adv        | 6.84       |
| _max_discrew    | 3.97       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0131804 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.99       |
| _mean_obs       | 0.0461     |
| _min_adv        | -11.6      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.26      |
| _std_act        | 0.67706    |
| _std_adv        | 1          |
| _std_discrew    | 0.858      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00186028 |
| Phi_loss        | 262.201    |
| PolicyEntropy   | 2.18925    |
| PolicyLoss      | -0.0150199 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0243     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91949    |
| _max_adv        | 2.96       |
| _max_discrew    | 4.11       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0121708 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.94       |
| _mean_obs       | 0.0463     |
| _min_adv        | -9.05      |
| _min_discrew    | 0.00986    |
| _min_obs        | -1.12      |
| _std_act        | 0.688352   |
| _std_adv        | 1          |
| _std_discrew    | 0.968      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.863      |
| KL              | 0.00473037 |
| Phi_loss        | 178.365    |
| PolicyEntropy   | 2.18242    |
| PolicyLoss      | 0.0150472  |
| Steps           | 10000      |
| VarFuncLoss     | 0.114      |
| _MeanReward     | 3.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81028    |
| _max_adv        | 7.96       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0118832 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0468     |
| _min_adv        | -4.12      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.26      |
| _std_act        | 0.676311   |
| _std_adv        | 1          |
| _std_discrew    | 0.863      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00210641  |
| Phi_loss        | 262.569     |
| PolicyEntropy   | 2.17782     |
| PolicyLoss      | 7.72372e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0183      |
| _MeanReward     | 3.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01132     |
| _max_adv        | 9.95        |
| _max_discrew    | 3.98        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0111446  |
| _mean_adv       | 4.26e-18    |
| _mean_discrew   | 3.08        |
| _mean_obs       | 0.0471      |
| _min_adv        | -8.45       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.26       |
| _std_act        | 0.690097    |
| _std_adv        | 1           |
| _std_discrew    | 0.873       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.977       |
| KL              | 0.00176294  |
| Phi_loss        | 245.484     |
| PolicyEntropy   | 2.16816     |
| PolicyLoss      | -0.0140312  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0173      |
| _MeanReward     | 3.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8487      |
| _max_adv        | 3.74        |
| _max_discrew    | 4.02        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00873019 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.047       |
| _min_adv        | -11.1       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.16       |
| _std_act        | 0.687495    |
| _std_adv        | 1           |
| _std_discrew    | 0.95        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.959       |
| KL              | 0.00278281  |
| Phi_loss        | 239.436     |
| PolicyEntropy   | 2.15337     |
| PolicyLoss      | -0.00693948 |
| Steps           | 10000       |
| VarFuncLoss     | 0.038       |
| _MeanReward     | 3.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.95622     |
| _max_adv        | 4.09        |
| _max_discrew    | 4.08        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0111826  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0472      |
| _min_adv        | -12.2       |
| _min_discrew    | 0.015       |
| _min_obs        | -1.21       |
| _std_act        | 0.692764    |
| _std_adv        | 1           |
| _std_discrew    | 0.998       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.946       |
| KL              | 0.00206963  |
| Phi_loss        | 240.556     |
| PolicyEntropy   | 2.14677     |
| PolicyLoss      | 0.000528405 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0514      |
| _MeanReward     | 3.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.02974     |
| _max_adv        | 10.9        |
| _max_discrew    | 4.09        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0102883  |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0472      |
| _min_adv        | -9.89       |
| _min_discrew    | 0.0111      |
| _min_obs        | -1.13       |
| _std_act        | 0.686035    |
| _std_adv        | 1           |
| _std_discrew    | 0.925       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.96       |
| KL              | 0.00560048 |
| Phi_loss        | 248.565    |
| PolicyEntropy   | 2.12214    |
| PolicyLoss      | 0.0182366  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0336     |
| _MeanReward     | 3.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84569    |
| _max_adv        | 8.94       |
| _max_discrew    | 4.11       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0112342 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.1        |
| _mean_obs       | 0.0471     |
| _min_adv        | -14        |
| _min_discrew    | 0.0105     |
| _min_obs        | -1.23      |
| _std_act        | 0.68727    |
| _std_adv        | 1          |
| _std_discrew    | 0.908      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.959        |
| ExplainedVarOld | 0.955        |
| KL              | 0.00259078   |
| Phi_loss        | 218.58       |
| PolicyEntropy   | 2.11363      |
| PolicyLoss      | -0.000504124 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0378       |
| _MeanReward     | 3.71e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.75318      |
| _max_adv        | 4.81         |
| _max_discrew    | 4.15         |
| _max_obs        | 1.32         |
| _mean_act       | -0.0103052   |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | 3.07         |
| _mean_obs       | 0.0475       |
| _min_adv        | -13.6        |
| _min_discrew    | 0.0159       |
| _min_obs        | -1.08        |
| _std_act        | 0.685414     |
| _std_adv        | 1            |
| _std_discrew    | 0.901        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.949      |
| KL              | 0.00158512 |
| Phi_loss        | 284.816    |
| PolicyEntropy   | 2.10684    |
| PolicyLoss      | 0.00237354 |
| Steps           | 10000      |
| VarFuncLoss     | 0.045      |
| _MeanReward     | 3.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8548     |
| _max_adv        | 10.9       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0111826 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.08       |
| _mean_obs       | 0.0466     |
| _min_adv        | -12.9      |
| _min_discrew    | 0.00955    |
| _min_obs        | -1.2       |
| _std_act        | 0.689021   |
| _std_adv        | 1          |
| _std_discrew    | 0.849      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00197224 |
| Phi_loss        | 292.253    |
| PolicyEntropy   | 2.09955    |
| PolicyLoss      | 0.0149498  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0245     |
| _MeanReward     | 3.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87225    |
| _max_adv        | 17.2       |
| _max_discrew    | 4.1        |
| _max_obs        | 1.28       |
| _mean_act       | -0.0107636 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.1        |
| _mean_obs       | 0.0463     |
| _min_adv        | -7.38      |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.24      |
| _std_act        | 0.690032   |
| _std_adv        | 1          |
| _std_discrew    | 0.891      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.0107694   |
| Phi_loss        | 332.693     |
| PolicyEntropy   | 2.08045     |
| PolicyLoss      | 0.0479859   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0118      |
| _MeanReward     | 3.72e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.16089     |
| _max_adv        | 7.42        |
| _max_discrew    | 4.04        |
| _max_obs        | 1.32        |
| _mean_act       | -0.00887396 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.09        |
| _mean_obs       | 0.0474      |
| _min_adv        | -9.75       |
| _min_discrew    | 0.016       |
| _min_obs        | -1.2        |
| _std_act        | 0.692036    |
| _std_adv        | 1           |
| _std_discrew    | 0.96        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.963       |
| KL              | 0.00392802  |
| Phi_loss        | 310.098     |
| PolicyEntropy   | 2.07063     |
| PolicyLoss      | -0.0111265  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0289      |
| _MeanReward     | 3.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07624     |
| _max_adv        | 5.01        |
| _max_discrew    | 4.08        |
| _max_obs        | 1.32        |
| _mean_act       | -0.00578913 |
| _mean_adv       | -2.77e-17   |
| _mean_discrew   | 3.14        |
| _mean_obs       | 0.0468      |
| _min_adv        | -4.48       |
| _min_discrew    | 0.0147      |
| _min_obs        | -1.14       |
| _std_act        | 0.691022    |
| _std_adv        | 1           |
| _std_discrew    | 0.886       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00111533  |
| Phi_loss        | 333.646     |
| PolicyEntropy   | 2.0575      |
| PolicyLoss      | -0.0142995  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0158      |
| _MeanReward     | 3.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07944     |
| _max_adv        | 5.32        |
| _max_discrew    | 4.15        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00984767 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.09        |
| _mean_obs       | 0.0466      |
| _min_adv        | -12.6       |
| _min_discrew    | -0.0183     |
| _min_obs        | -1.21       |
| _std_act        | 0.699968    |
| _std_adv        | 1           |
| _std_discrew    | 0.941       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00192579 |
| Phi_loss        | 309.946    |
| PolicyEntropy   | 2.04398    |
| PolicyLoss      | 0.0113199  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0488     |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91086    |
| _max_adv        | 22.4       |
| _max_discrew    | 4.04       |
| _max_obs        | 1.28       |
| _mean_act       | -0.010281  |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0467     |
| _min_adv        | -7.29      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.14      |
| _std_act        | 0.68861    |
| _std_adv        | 1          |
| _std_discrew    | 0.921      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.981        |
| ExplainedVarOld | 0.978        |
| KL              | 0.00294467   |
| Phi_loss        | 264.258      |
| PolicyEntropy   | 2.0245       |
| PolicyLoss      | -0.000730007 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0175       |
| _MeanReward     | 3.72e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.99958      |
| _max_adv        | 10           |
| _max_discrew    | 4.29         |
| _max_obs        | 1.34         |
| _mean_act       | -0.00650251  |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 3.09         |
| _mean_obs       | 0.0464       |
| _min_adv        | -10.1        |
| _min_discrew    | 0.0131       |
| _min_obs        | -1.15        |
| _std_act        | 0.693486     |
| _std_adv        | 1            |
| _std_discrew    | 0.9          |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.935       |
| KL              | 0.00249226  |
| Phi_loss        | 299.212     |
| PolicyEntropy   | 1.9976      |
| PolicyLoss      | 0.0192393   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0522      |
| _MeanReward     | 3.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08384     |
| _max_adv        | 16.4        |
| _max_discrew    | 4.13        |
| _max_obs        | 1.31        |
| _mean_act       | -0.00521723 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.13        |
| _mean_obs       | 0.0469      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0154      |
| _min_obs        | -1.17       |
| _std_act        | 0.692965    |
| _std_adv        | 1           |
| _std_discrew    | 0.951       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00350244  |
| Phi_loss        | 269.993     |
| PolicyEntropy   | 1.98629     |
| PolicyLoss      | 0.00300464  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0317      |
| _MeanReward     | 3.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84152     |
| _max_adv        | 8.48        |
| _max_discrew    | 4.15        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00446391 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.13        |
| _mean_obs       | 0.0469      |
| _min_adv        | -10.8       |
| _min_discrew    | 0.0177      |
| _min_obs        | -1.1        |
| _std_act        | 0.684851    |
| _std_adv        | 1           |
| _std_discrew    | 0.914       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.964       |
| ExplainedVarOld | 0.96        |
| KL              | 0.0023461   |
| Phi_loss        | 311.044     |
| PolicyEntropy   | 1.97093     |
| PolicyLoss      | -0.00439733 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0332      |
| _MeanReward     | 3.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.80661     |
| _max_adv        | 7.64        |
| _max_discrew    | 4.23        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00445096 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.16        |
| _mean_obs       | 0.0468      |
| _min_adv        | -4.69       |
| _min_discrew    | 0.0141      |
| _min_obs        | -1.13       |
| _std_act        | 0.686041    |
| _std_adv        | 1           |
| _std_discrew    | 0.93        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00227161  |
| Phi_loss        | 329.795     |
| PolicyEntropy   | 1.96404     |
| PolicyLoss      | 0.00331232  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0191      |
| _MeanReward     | 3.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87508     |
| _max_adv        | 3.22        |
| _max_discrew    | 4.24        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00563702 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.18        |
| _mean_obs       | 0.0474      |
| _min_adv        | -11.9       |
| _min_discrew    | 0.0125      |
| _min_obs        | -1.18       |
| _std_act        | 0.68748     |
| _std_adv        | 1           |
| _std_discrew    | 0.908       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.956       |
| ExplainedVarOld | 0.953       |
| KL              | 0.00215863  |
| Phi_loss        | 266.706     |
| PolicyEntropy   | 1.96142     |
| PolicyLoss      | 0.0211884   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0396      |
| _MeanReward     | 3.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81339     |
| _max_adv        | 4.43        |
| _max_discrew    | 4.1         |
| _max_obs        | 1.3         |
| _mean_act       | -0.00379122 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.18        |
| _mean_obs       | 0.0477      |
| _min_adv        | -13.2       |
| _min_discrew    | 0.0153      |
| _min_obs        | -1.13       |
| _std_act        | 0.686769    |
| _std_adv        | 1           |
| _std_discrew    | 0.936       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.978       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00193409  |
| Phi_loss        | 303.889     |
| PolicyEntropy   | 1.93427     |
| PolicyLoss      | -0.00313536 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0208      |
| _MeanReward     | 3.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81036     |
| _max_adv        | 9.63        |
| _max_discrew    | 4.25        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00302958 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.21        |
| _mean_obs       | 0.0477      |
| _min_adv        | -7.16       |
| _min_discrew    | 0.0184      |
| _min_obs        | -1.15       |
| _std_act        | 0.689703    |
| _std_adv        | 1           |
| _std_discrew    | 0.957       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.978       |
| KL              | 0.00242282  |
| Phi_loss        | 317.22      |
| PolicyEntropy   | 1.90826     |
| PolicyLoss      | -0.00829285 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0194      |
| _MeanReward     | 3.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11425     |
| _max_adv        | 9.61        |
| _max_discrew    | 4.14        |
| _max_obs        | 1.35        |
| _mean_act       | -0.00200772 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.18        |
| _mean_obs       | 0.0476      |
| _min_adv        | -11.4       |
| _min_discrew    | 0.019       |
| _min_obs        | -1.23       |
| _std_act        | 0.684493    |
| _std_adv        | 1           |
| _std_discrew    | 0.91        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00245814  |
| Phi_loss        | 290.476     |
| PolicyEntropy   | 1.90142     |
| PolicyLoss      | -0.0128184  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0239      |
| _MeanReward     | 3.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77767     |
| _max_adv        | 4.84        |
| _max_discrew    | 4.16        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00486411 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.26        |
| _mean_obs       | 0.0478      |
| _min_adv        | -3.98       |
| _min_discrew    | 0.0149      |
| _min_obs        | -1.19       |
| _std_act        | 0.689736    |
| _std_adv        | 1           |
| _std_discrew    | 0.924       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00212009  |
| Phi_loss        | 334.129     |
| PolicyEntropy   | 1.88883     |
| PolicyLoss      | -0.0312913  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0143      |
| _MeanReward     | 3.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94211     |
| _max_adv        | 11.4        |
| _max_discrew    | 4.28        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00500274 |
| _mean_adv       | 4.26e-17    |
| _mean_discrew   | 3.3         |
| _mean_obs       | 0.0492      |
| _min_adv        | -4.32       |
| _min_discrew    | 0.0136      |
| _min_obs        | -1.18       |
| _std_act        | 0.69026     |
| _std_adv        | 1           |
| _std_discrew    | 0.993       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00208006  |
| Phi_loss        | 315.903     |
| PolicyEntropy   | 1.86961     |
| PolicyLoss      | -0.0186006  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0169      |
| _MeanReward     | 3.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9545      |
| _max_adv        | 3.97        |
| _max_discrew    | 4.29        |
| _max_obs        | 1.31        |
| _mean_act       | -0.00261791 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.12        |
| _mean_obs       | 0.0472      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0141      |
| _min_obs        | -1.2        |
| _std_act        | 0.688537    |
| _std_adv        | 1           |
| _std_discrew    | 0.954       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.89        |
| KL              | 0.00279551  |
| Phi_loss        | 211.736     |
| PolicyEntropy   | 1.85952     |
| PolicyLoss      | 0.0106833   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0938      |
| _MeanReward     | 3.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83901     |
| _max_adv        | 12.8        |
| _max_discrew    | 4.19        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00333198 |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.26        |
| _mean_obs       | 0.0489      |
| _min_adv        | -12.3       |
| _min_discrew    | 0.00772     |
| _min_obs        | -1.21       |
| _std_act        | 0.691789    |
| _std_adv        | 1           |
| _std_discrew    | 0.947       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.971       |
| KL              | 0.0021484   |
| Phi_loss        | 298.356     |
| PolicyEntropy   | 1.85047     |
| PolicyLoss      | -0.0237663  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0292      |
| _MeanReward     | 3.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87206     |
| _max_adv        | 6.03        |
| _max_discrew    | 4.33        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00269277 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0486      |
| _min_adv        | -5.06       |
| _min_discrew    | 0.0179      |
| _min_obs        | -1.11       |
| _std_act        | 0.695692    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00170413 |
| Phi_loss        | 275.007    |
| PolicyEntropy   | 1.8245     |
| PolicyLoss      | -0.0101999 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0139     |
| _MeanReward     | 3.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82226    |
| _max_adv        | 11.8       |
| _max_discrew    | 4.31       |
| _max_obs        | 1.39       |
| _mean_act       | -0.003719  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0488     |
| _min_adv        | -5.32      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.28      |
| _std_act        | 0.690781   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00216597  |
| Phi_loss        | 309.11      |
| PolicyEntropy   | 1.80574     |
| PolicyLoss      | -0.0178988  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0118      |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83696     |
| _max_adv        | 15.2        |
| _max_discrew    | 4.31        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00402922 |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 3.28        |
| _mean_obs       | 0.0481      |
| _min_adv        | -4.21       |
| _min_discrew    | 0.016       |
| _min_obs        | -1.11       |
| _std_act        | 0.699004    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.00170459  |
| Phi_loss        | 307.265     |
| PolicyEntropy   | 1.77842     |
| PolicyLoss      | 0.00597898  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0105      |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.04636     |
| _max_adv        | 5.17        |
| _max_discrew    | 4.32        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00398345 |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.28        |
| _mean_obs       | 0.0493      |
| _min_adv        | -12.1       |
| _min_discrew    | 0.00852     |
| _min_obs        | -1.15       |
| _std_act        | 0.694714    |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.966       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00249986  |
| Phi_loss        | 300.691     |
| PolicyEntropy   | 1.75573     |
| PolicyLoss      | 0.00352716  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0354      |
| _MeanReward     | 4.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02039     |
| _max_adv        | 4.69        |
| _max_discrew    | 4.31        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00551508 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0488      |
| _min_adv        | -4.41       |
| _min_discrew    | 0.016       |
| _min_obs        | -1.09       |
| _std_act        | 0.695575    |
| _std_adv        | 1           |
| _std_discrew    | 1.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00190021  |
| Phi_loss        | 348.792     |
| PolicyEntropy   | 1.72216     |
| PolicyLoss      | 0.0131264   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0137      |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06811     |
| _max_adv        | 5.66        |
| _max_discrew    | 4.42        |
| _max_obs        | 1.37        |
| _mean_act       | -0.00265519 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.34        |
| _mean_obs       | 0.049       |
| _min_adv        | -4.91       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.15       |
| _std_act        | 0.694804    |
| _std_adv        | 1           |
| _std_discrew    | 1.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00199347  |
| Phi_loss        | 346.838     |
| PolicyEntropy   | 1.70306     |
| PolicyLoss      | -0.0139916  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0152      |
| _MeanReward     | 3.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00832     |
| _max_adv        | 7.28        |
| _max_discrew    | 4.37        |
| _max_obs        | 1.33        |
| _mean_act       | -0.00546032 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0488      |
| _min_adv        | -13.1       |
| _min_discrew    | -0.139      |
| _min_obs        | -1.18       |
| _std_act        | 0.692972    |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.972        |
| ExplainedVarOld | 0.97         |
| KL              | 0.00360828   |
| Phi_loss        | 260.092      |
| PolicyEntropy   | 1.6926       |
| PolicyLoss      | 0.0235709    |
| Steps           | 10000        |
| VarFuncLoss     | 0.0301       |
| _MeanReward     | 4.01e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.96689      |
| _max_adv        | 5.68         |
| _max_discrew    | 4.37         |
| _max_obs        | 1.24         |
| _mean_act       | -0.000177366 |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 3.32         |
| _mean_obs       | 0.049        |
| _min_adv        | -13.9        |
| _min_discrew    | 0.0144       |
| _min_obs        | -1.15        |
| _std_act        | 0.69726      |
| _std_adv        | 1            |
| _std_discrew    | 1.03         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.963       |
| KL              | 0.00320455  |
| Phi_loss        | 313.07      |
| PolicyEntropy   | 1.68156     |
| PolicyLoss      | -0.0215933  |
| Steps           | 10000       |
| VarFuncLoss     | 0.036       |
| _MeanReward     | 4.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.84059     |
| _max_adv        | 4.71        |
| _max_discrew    | 4.39        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00234841 |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 3.39        |
| _mean_obs       | 0.0496      |
| _min_adv        | -4.62       |
| _min_discrew    | 0.0161      |
| _min_obs        | -1.08       |
| _std_act        | 0.703423    |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.989        |
| ExplainedVarOld | 0.987        |
| KL              | 0.00185255   |
| Phi_loss        | 358.422      |
| PolicyEntropy   | 1.65859      |
| PolicyLoss      | 0.00339994   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0131       |
| _MeanReward     | 4.05e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.03917      |
| _max_adv        | 11.6         |
| _max_discrew    | 4.31         |
| _max_obs        | 1.27         |
| _mean_act       | -0.000244737 |
| _mean_adv       | 4.26e-18     |
| _mean_discrew   | 3.36         |
| _mean_obs       | 0.0493       |
| _min_adv        | -4.47        |
| _min_discrew    | 0.016        |
| _min_obs        | -1.2         |
| _std_act        | 0.699948     |
| _std_adv        | 1            |
| _std_discrew    | 1.06         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00209831 |
| Phi_loss        | 356.933    |
| PolicyEntropy   | 1.63826    |
| PolicyLoss      | 0.00931397 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 3.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.02179    |
| _max_adv        | 5.41       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00112247 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.29       |
| _mean_obs       | 0.0486     |
| _min_adv        | -13.7      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.12      |
| _std_act        | 0.693704   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.968       |
| KL              | 0.001788    |
| Phi_loss        | 330.11      |
| PolicyEntropy   | 1.63956     |
| PolicyLoss      | -0.015594   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0333      |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85314     |
| _max_adv        | 3.48        |
| _max_discrew    | 4.58        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00133443 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.36        |
| _mean_obs       | 0.0488      |
| _min_adv        | -12         |
| _min_discrew    | 0.0173      |
| _min_obs        | -1.14       |
| _std_act        | 0.699123    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.954        |
| ExplainedVarOld | 0.948        |
| KL              | 0.00387456   |
| Phi_loss        | 318.293      |
| PolicyEntropy   | 1.61895      |
| PolicyLoss      | 0.0167709    |
| Steps           | 10000        |
| VarFuncLoss     | 0.0497       |
| _MeanReward     | 4.07e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.03511      |
| _max_adv        | 11.9         |
| _max_discrew    | 4.38         |
| _max_obs        | 1.26         |
| _mean_act       | -0.000635691 |
| _mean_adv       | -3.41e-17    |
| _mean_discrew   | 3.36         |
| _mean_obs       | 0.0489       |
| _min_adv        | -6.59        |
| _min_discrew    | 8.07e-05     |
| _min_obs        | -1.15        |
| _std_act        | 0.702361     |
| _std_adv        | 1            |
| _std_discrew    | 1.07         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.985        |
| ExplainedVarOld | 0.983        |
| KL              | 0.00278398   |
| Phi_loss        | 302.215      |
| PolicyEntropy   | 1.59763      |
| PolicyLoss      | 0.00858463   |
| Steps           | 10000        |
| VarFuncLoss     | 0.016        |
| _MeanReward     | 4.06e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.24284      |
| _max_adv        | 14           |
| _max_discrew    | 4.37         |
| _max_obs        | 1.31         |
| _mean_act       | -0.000986448 |
| _mean_adv       | -8.53e-18    |
| _mean_discrew   | 3.36         |
| _mean_obs       | 0.049        |
| _min_adv        | -6.75        |
| _min_discrew    | 0.0153       |
| _min_obs        | -1.19        |
| _std_act        | 0.694139     |
| _std_adv        | 1            |
| _std_discrew    | 1.04         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.987        |
| ExplainedVarOld | 0.985        |
| KL              | 0.00268978   |
| Phi_loss        | 321.526      |
| PolicyEntropy   | 1.58728      |
| PolicyLoss      | 0.0253249    |
| Steps           | 10000        |
| VarFuncLoss     | 0.0133       |
| _MeanReward     | 4.08e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.93967      |
| _max_adv        | 5.07         |
| _max_discrew    | 4.41         |
| _max_obs        | 1.28         |
| _mean_act       | -0.000579677 |
| _mean_adv       | 0            |
| _mean_discrew   | 3.38         |
| _mean_obs       | 0.0486       |
| _min_adv        | -4.51        |
| _min_discrew    | 0.0202       |
| _min_obs        | -1.11        |
| _std_act        | 0.696978     |
| _std_adv        | 1            |
| _std_discrew    | 1.05         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.99         |
| ExplainedVarOld | 0.99         |
| KL              | 0.00210313   |
| Phi_loss        | 403.42       |
| PolicyEntropy   | 1.58544      |
| PolicyLoss      | -0.016058    |
| Steps           | 10000        |
| VarFuncLoss     | 0.0106       |
| _MeanReward     | 4.05e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.97456      |
| _max_adv        | 5.75         |
| _max_discrew    | 4.39         |
| _max_obs        | 1.25         |
| _mean_act       | -0.000242619 |
| _mean_adv       | -5.68e-18    |
| _mean_discrew   | 3.34         |
| _mean_obs       | 0.0487       |
| _min_adv        | -10.2        |
| _min_discrew    | 0.0166       |
| _min_obs        | -1.12        |
| _std_act        | 0.689425     |
| _std_adv        | 1            |
| _std_discrew    | 1.05         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00432927  |
| Phi_loss        | 363.587     |
| PolicyEntropy   | 1.58588     |
| PolicyLoss      | -0.00365236 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0278      |
| _MeanReward     | 4.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96724     |
| _max_adv        | 11.6        |
| _max_discrew    | 4.4         |
| _max_obs        | 1.27        |
| _mean_act       | -0.00440811 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.43        |
| _mean_obs       | 0.0493      |
| _min_adv        | -6.53       |
| _min_discrew    | 0.0138      |
| _min_obs        | -1.12       |
| _std_act        | 0.69252     |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.00267137  |
| Phi_loss        | 353.138     |
| PolicyEntropy   | 1.56361     |
| PolicyLoss      | 0.00718147  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0129      |
| _MeanReward     | 4.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0809      |
| _max_adv        | 5.49        |
| _max_discrew    | 4.42        |
| _max_obs        | 1.23        |
| _mean_act       | -0.00220745 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.42        |
| _mean_obs       | 0.0489      |
| _min_adv        | -10.3       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.21       |
| _std_act        | 0.696341    |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.986        |
| ExplainedVarOld | 0.984        |
| KL              | 0.00216575   |
| Phi_loss        | 415.881      |
| PolicyEntropy   | 1.55385      |
| PolicyLoss      | -0.000166791 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0157       |
| _MeanReward     | 4.11e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.03444      |
| _max_adv        | 2.78         |
| _max_discrew    | 4.58         |
| _max_obs        | 1.29         |
| _mean_act       | -0.0031709   |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 3.43         |
| _mean_obs       | 0.0492       |
| _min_adv        | -12.1        |
| _min_discrew    | 0.0165       |
| _min_obs        | -1.15        |
| _std_act        | 0.697095     |
| _std_adv        | 1            |
| _std_discrew    | 1.11         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.959       |
| KL              | 0.00483589  |
| Phi_loss        | 328.911     |
| PolicyEntropy   | 1.54104     |
| PolicyLoss      | 0.0158419   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0409      |
| _MeanReward     | 4.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72809     |
| _max_adv        | 13.7        |
| _max_discrew    | 4.52        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00366513 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.46        |
| _mean_obs       | 0.0492      |
| _min_adv        | -5.36       |
| _min_discrew    | 0.0154      |
| _min_obs        | -1.15       |
| _std_act        | 0.694971    |
| _std_adv        | 1           |
| _std_discrew    | 1.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00200973  |
| Phi_loss        | 412.679     |
| PolicyEntropy   | 1.52333     |
| PolicyLoss      | -0.0130743  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0137      |
| _MeanReward     | 4.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.13431     |
| _max_adv        | 3.74        |
| _max_discrew    | 4.44        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00447388 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.45        |
| _mean_obs       | 0.0489      |
| _min_adv        | -5.14       |
| _min_discrew    | 0.0174      |
| _min_obs        | -1.15       |
| _std_act        | 0.694433    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00208484  |
| Phi_loss        | 402.99      |
| PolicyEntropy   | 1.51152     |
| PolicyLoss      | -0.0184705  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0127      |
| _MeanReward     | 4.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.97727     |
| _max_adv        | 3.55        |
| _max_discrew    | 4.48        |
| _max_obs        | 1.2         |
| _mean_act       | -0.00448643 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.46        |
| _mean_obs       | 0.0492      |
| _min_adv        | -4.62       |
| _min_discrew    | 0.0147      |
| _min_obs        | -1.1        |
| _std_act        | 0.691598    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00178311  |
| Phi_loss        | 408.742     |
| PolicyEntropy   | 1.49883     |
| PolicyLoss      | -0.00972232 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0136      |
| _MeanReward     | 4.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74142     |
| _max_adv        | 3.22        |
| _max_discrew    | 4.56        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00331031 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.51        |
| _mean_obs       | 0.0502      |
| _min_adv        | -4.34       |
| _min_discrew    | 0.0198      |
| _min_obs        | -1.21       |
| _std_act        | 0.693487    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00187004  |
| Phi_loss        | 393.118     |
| PolicyEntropy   | 1.47892     |
| PolicyLoss      | -0.00226037 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0153      |
| _MeanReward     | 4.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85501     |
| _max_adv        | 4.75        |
| _max_discrew    | 4.45        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00429995 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.45        |
| _mean_obs       | 0.0487      |
| _min_adv        | -5.35       |
| _min_discrew    | 0.0115      |
| _min_obs        | -1.16       |
| _std_act        | 0.694021    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00182904 |
| Phi_loss        | 388.237    |
| PolicyEntropy   | 1.46624    |
| PolicyLoss      | 0.00113989 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0151     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7733     |
| _max_adv        | 3.55       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0021306 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.5        |
| _mean_obs       | 0.0497     |
| _min_adv        | -3.99      |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.13      |
| _std_act        | 0.69543    |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00195501  |
| Phi_loss        | 433.194     |
| PolicyEntropy   | 1.44087     |
| PolicyLoss      | -0.00838639 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0136      |
| _MeanReward     | 4.21e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74393     |
| _max_adv        | 4.87        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00256357 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.49        |
| _mean_obs       | 0.0498      |
| _min_adv        | -8.13       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.15       |
| _std_act        | 0.697212    |
| _std_adv        | 1           |
| _std_discrew    | 1.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.0020349   |
| Phi_loss        | 414.429     |
| PolicyEntropy   | 1.41461     |
| PolicyLoss      | -0.00821401 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0153      |
| _MeanReward     | 4.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95469     |
| _max_adv        | 2.69        |
| _max_discrew    | 4.6         |
| _max_obs        | 1.26        |
| _mean_act       | -0.00201591 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.49        |
| _mean_obs       | 0.0497      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0161      |
| _min_obs        | -1.15       |
| _std_act        | 0.687172    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00247713  |
| Phi_loss        | 383.389     |
| PolicyEntropy   | 1.41049     |
| PolicyLoss      | -0.0114424  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0165      |
| _MeanReward     | 4.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78562     |
| _max_adv        | 4.85        |
| _max_discrew    | 4.55        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00439583 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.47        |
| _mean_obs       | 0.0495      |
| _min_adv        | -11.2       |
| _min_discrew    | 0.0185      |
| _min_obs        | -1.15       |
| _std_act        | 0.694394    |
| _std_adv        | 1           |
| _std_discrew    | 1.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.962       |
| ExplainedVarOld | 0.948       |
| KL              | 0.00254401  |
| Phi_loss        | 218.122     |
| PolicyEntropy   | 1.39923     |
| PolicyLoss      | 0.00620027  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0427      |
| _MeanReward     | 4.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69435     |
| _max_adv        | 16.4        |
| _max_discrew    | 4.58        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00103639 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.5         |
| _mean_obs       | 0.0495      |
| _min_adv        | -4.64       |
| _min_discrew    | 0.0155      |
| _min_obs        | -1.12       |
| _std_act        | 0.6957      |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00480552  |
| Phi_loss        | 376.252     |
| PolicyEntropy   | 1.38719     |
| PolicyLoss      | -0.0170959  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 4.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83009     |
| _max_adv        | 19.4        |
| _max_discrew    | 4.55        |
| _max_obs        | 1.3         |
| _mean_act       | -0.00268396 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.49        |
| _mean_obs       | 0.0492      |
| _min_adv        | -8.87       |
| _min_discrew    | 0.0179      |
| _min_obs        | -1.2        |
| _std_act        | 0.694922    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.985       |
| KL              | 0.00159419  |
| Phi_loss        | 245.086     |
| PolicyEntropy   | 1.37501     |
| PolicyLoss      | -0.00341654 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0111      |
| _MeanReward     | 4.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63229     |
| _max_adv        | 3.36        |
| _max_discrew    | 4.55        |
| _max_obs        | 1.32        |
| _mean_act       | -0.00347196 |
| _mean_adv       | -2.7e-17    |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0493      |
| _min_adv        | -5.15       |
| _min_discrew    | 0.0148      |
| _min_obs        | -1.1        |
| _std_act        | 0.695239    |
| _std_adv        | 1           |
| _std_discrew    | 1.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00179427  |
| Phi_loss        | 459.987     |
| PolicyEntropy   | 1.35367     |
| PolicyLoss      | -0.00290841 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0107      |
| _MeanReward     | 4.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08383     |
| _max_adv        | 3.48        |
| _max_discrew    | 4.58        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00798429 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.51        |
| _mean_obs       | 0.0493      |
| _min_adv        | -6.78       |
| _min_discrew    | 0.0156      |
| _min_obs        | -1.18       |
| _std_act        | 0.695458    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00198013  |
| Phi_loss        | 447.901     |
| PolicyEntropy   | 1.33925     |
| PolicyLoss      | 0.00216701  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0177      |
| _MeanReward     | 4.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.89746     |
| _max_adv        | 4.5         |
| _max_discrew    | 4.57        |
| _max_obs        | 1.24        |
| _mean_act       | -0.00376942 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0495      |
| _min_adv        | -6.56       |
| _min_discrew    | 0.0154      |
| _min_obs        | -1.12       |
| _std_act        | 0.697776    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00177776  |
| Phi_loss        | 481.968     |
| PolicyEntropy   | 1.32607     |
| PolicyLoss      | 0.0174172   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0158      |
| _MeanReward     | 4.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.94323     |
| _max_adv        | 3.98        |
| _max_discrew    | 4.53        |
| _max_obs        | 1.34        |
| _mean_act       | -0.00377818 |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.0494      |
| _min_adv        | -4.59       |
| _min_discrew    | 0.0179      |
| _min_obs        | -1.14       |
| _std_act        | 0.699841    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.994        |
| ExplainedVarOld | 0.994        |
| KL              | 0.00184635   |
| Phi_loss        | 464.766      |
| PolicyEntropy   | 1.29562      |
| PolicyLoss      | -0.000773828 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00648      |
| _MeanReward     | 4.28e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.88373      |
| _max_adv        | 5.43         |
| _max_discrew    | 4.53         |
| _max_obs        | 1.25         |
| _mean_act       | -0.00746936  |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 3.54         |
| _mean_obs       | 0.0491       |
| _min_adv        | -4.26        |
| _min_discrew    | 0.0203       |
| _min_obs        | -1.24        |
| _std_act        | 0.690986     |
| _std_adv        | 1            |
| _std_discrew    | 1.14         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.988        |
| ExplainedVarOld | 0.988        |
| KL              | 0.00242311   |
| Phi_loss        | 452.956      |
| PolicyEntropy   | 1.28054      |
| PolicyLoss      | -0.017991    |
| Steps           | 10000        |
| VarFuncLoss     | 0.0139       |
| _MeanReward     | 4.34e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.83392      |
| _max_adv        | 3.31         |
| _max_discrew    | 4.72         |
| _max_obs        | 1.21         |
| _mean_act       | -0.000161769 |
| _mean_adv       | 1.99e-17     |
| _mean_discrew   | 3.59         |
| _mean_obs       | 0.0503       |
| _min_adv        | -3.98        |
| _min_discrew    | 0.0163       |
| _min_obs        | -1.18        |
| _std_act        | 0.692459     |
| _std_adv        | 1            |
| _std_discrew    | 1.21         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00219841  |
| Phi_loss        | 465.777     |
| PolicyEntropy   | 1.26254     |
| PolicyLoss      | 0.00668405  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0101      |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7327      |
| _max_adv        | 3.48        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00350579 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0501      |
| _min_adv        | -5.88       |
| _min_discrew    | 0.0166      |
| _min_obs        | -1.11       |
| _std_act        | 0.697177    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00233137  |
| Phi_loss        | 496.869     |
| PolicyEntropy   | 1.22805     |
| PolicyLoss      | -0.0139225  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0153      |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68468     |
| _max_adv        | 4           |
| _max_discrew    | 4.72        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00051135 |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.57        |
| _mean_obs       | 0.0496      |
| _min_adv        | -4.47       |
| _min_discrew    | 0.0197      |
| _min_obs        | -1.17       |
| _std_act        | 0.698292    |
| _std_adv        | 1           |
| _std_discrew    | 1.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00180666  |
| Phi_loss        | 475.88      |
| PolicyEntropy   | 1.21042     |
| PolicyLoss      | 0.0130084   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0136      |
| _MeanReward     | 4.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78296     |
| _max_adv        | 2.27        |
| _max_discrew    | 4.65        |
| _max_obs        | 1.22        |
| _mean_act       | -0.00646116 |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.48        |
| _mean_obs       | 0.0486      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0214      |
| _min_obs        | -1.11       |
| _std_act        | 0.701524    |
| _std_adv        | 1           |
| _std_discrew    | 1.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.854       |
| KL              | 0.00418728  |
| Phi_loss        | 229.713     |
| PolicyEntropy   | 1.19272     |
| PolicyLoss      | -0.00917938 |
| Steps           | 10000       |
| VarFuncLoss     | 0.108       |
| _MeanReward     | 4.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7843      |
| _max_adv        | 22.5        |
| _max_discrew    | 4.7         |
| _max_obs        | 1.27        |
| _mean_act       | -0.00288699 |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | 3.63        |
| _mean_obs       | 0.0504      |
| _min_adv        | -5.23       |
| _min_discrew    | 0.0149      |
| _min_obs        | -1.16       |
| _std_act        | 0.695005    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00280363  |
| Phi_loss        | 322.665     |
| PolicyEntropy   | 1.17794     |
| PolicyLoss      | -0.012642   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 4.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00576     |
| _max_adv        | 13.9        |
| _max_discrew    | 4.65        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00457969 |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 3.58        |
| _mean_obs       | 0.0498      |
| _min_adv        | -3.94       |
| _min_discrew    | 0.0169      |
| _min_obs        | -1.14       |
| _std_act        | 0.692358    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00214779  |
| Phi_loss        | 372.692     |
| PolicyEntropy   | 1.16141     |
| PolicyLoss      | -0.0224185  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00978     |
| _MeanReward     | 4.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72909     |
| _max_adv        | 4.84        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00243961 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0496      |
| _min_adv        | -3.16       |
| _min_discrew    | 0.0141      |
| _min_obs        | -1.16       |
| _std_act        | 0.696807    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.989       |
| KL              | 0.00234688  |
| Phi_loss        | 556.013     |
| PolicyEntropy   | 1.14387     |
| PolicyLoss      | 0.0051135   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0132      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78581     |
| _max_adv        | 8.07        |
| _max_discrew    | 4.84        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00615537 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0505      |
| _min_adv        | -4.6        |
| _min_discrew    | 0.0125      |
| _min_obs        | -1.1        |
| _std_act        | 0.693037    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.00195607  |
| Phi_loss        | 536.411     |
| PolicyEntropy   | 1.11384     |
| PolicyLoss      | 0.00329823  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0132      |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59121     |
| _max_adv        | 6.32        |
| _max_discrew    | 4.63        |
| _max_obs        | 1.24        |
| _mean_act       | -0.00514563 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.6         |
| _mean_obs       | 0.0497      |
| _min_adv        | -4.35       |
| _min_discrew    | 0.0172      |
| _min_obs        | -1.12       |
| _std_act        | 0.698429    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00183658  |
| Phi_loss        | 487.324     |
| PolicyEntropy   | 1.0913      |
| PolicyLoss      | -0.00145304 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00891     |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91494     |
| _max_adv        | 6.06        |
| _max_discrew    | 4.91        |
| _max_obs        | 1.29        |
| _mean_act       | -0.00565951 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0498      |
| _min_adv        | -8.72       |
| _min_discrew    | 0.019       |
| _min_obs        | -1.18       |
| _std_act        | 0.697075    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00171098 |
| Phi_loss        | 480.756    |
| PolicyEntropy   | 1.08365    |
| PolicyLoss      | 0.00128899 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0172     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71407    |
| _max_adv        | 3.55       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0046025 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0501     |
| _min_adv        | -4.91      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.17      |
| _std_act        | 0.69465    |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.0024818   |
| Phi_loss        | 489.071     |
| PolicyEntropy   | 1.06821     |
| PolicyLoss      | 0.00889351  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0181      |
| _MeanReward     | 4.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77973     |
| _max_adv        | 2.43        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.22        |
| _mean_act       | -0.00574512 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.42        |
| _mean_obs       | 0.0481      |
| _min_adv        | -13.3       |
| _min_discrew    | 0.0166      |
| _min_obs        | -1.15       |
| _std_act        | 0.712419    |
| _std_adv        | 1           |
| _std_discrew    | 1.55        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.837       |
| ExplainedVarOld | 0.782       |
| KL              | 0.00550078  |
| Phi_loss        | 289.633     |
| PolicyEntropy   | 1.06137     |
| PolicyLoss      | 0.0206138   |
| Steps           | 10000       |
| VarFuncLoss     | 0.253       |
| _MeanReward     | 4.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87662     |
| _max_adv        | 24.2        |
| _max_discrew    | 4.71        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00479854 |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0488      |
| _min_adv        | -4.11       |
| _min_discrew    | 0.0179      |
| _min_obs        | -1.15       |
| _std_act        | 0.695023    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00356487  |
| Phi_loss        | 376.325     |
| PolicyEntropy   | 1.03962     |
| PolicyLoss      | 0.0189239   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0203      |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71339     |
| _max_adv        | 22.4        |
| _max_discrew    | 4.76        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00147516 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0501      |
| _min_adv        | -4.87       |
| _min_discrew    | 0.0153      |
| _min_obs        | -1.16       |
| _std_act        | 0.695569    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.984       |
| KL              | 0.00161716  |
| Phi_loss        | 373.293     |
| PolicyEntropy   | 1.03039     |
| PolicyLoss      | -0.00792231 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0132      |
| _MeanReward     | 4.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.65085     |
| _max_adv        | 6.31        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00448751 |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0508      |
| _min_adv        | -4.39       |
| _min_discrew    | 0.0176      |
| _min_obs        | -1.16       |
| _std_act        | 0.694419    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00269415  |
| Phi_loss        | 595.41      |
| PolicyEntropy   | 1.02631     |
| PolicyLoss      | -0.00910044 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0127      |
| _MeanReward     | 4.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.65248     |
| _max_adv        | 3.52        |
| _max_discrew    | 4.95        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00514196 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0507      |
| _min_adv        | -5.52       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.21       |
| _std_act        | 0.693802    |
| _std_adv        | 1           |
| _std_discrew    | 1.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00241731  |
| Phi_loss        | 523.293     |
| PolicyEntropy   | 0.998965    |
| PolicyLoss      | 0.0200276   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0182      |
| _MeanReward     | 4.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67965     |
| _max_adv        | 17.9        |
| _max_discrew    | 4.86        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00410456 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.69        |
| _mean_obs       | 0.0503      |
| _min_adv        | -7.6        |
| _min_discrew    | 0.0188      |
| _min_obs        | -1.16       |
| _std_act        | 0.696545    |
| _std_adv        | 1           |
| _std_discrew    | 1.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00208227  |
| Phi_loss        | 490.781     |
| PolicyEntropy   | 0.982191    |
| PolicyLoss      | -0.00312065 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 4.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.04671     |
| _max_adv        | 27.3        |
| _max_discrew    | 4.84        |
| _max_obs        | 1.23        |
| _mean_act       | -0.00423811 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0501      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.0109      |
| _min_obs        | -1.14       |
| _std_act        | 0.697457    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00221986  |
| Phi_loss        | 300.447     |
| PolicyEntropy   | 0.979509    |
| PolicyLoss      | -0.00301242 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0157      |
| _MeanReward     | 4.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72961     |
| _max_adv        | 3.25        |
| _max_discrew    | 4.82        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00248635 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0503      |
| _min_adv        | -7.06       |
| _min_discrew    | 0.0131      |
| _min_obs        | -1.08       |
| _std_act        | 0.696161    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.002264    |
| Phi_loss        | 566.901     |
| PolicyEntropy   | 0.948491    |
| PolicyLoss      | 0.00919048  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 4.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73603     |
| _max_adv        | 4.95        |
| _max_discrew    | 4.89        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00107766 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.69        |
| _mean_obs       | 0.0499      |
| _min_adv        | -4.25       |
| _min_discrew    | 0.0185      |
| _min_obs        | -1.15       |
| _std_act        | 0.700022    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00206053  |
| Phi_loss        | 595.892     |
| PolicyEntropy   | 0.94089     |
| PolicyLoss      | 0.0161587   |
| Steps           | 10000       |
| VarFuncLoss     | 0.02        |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8582      |
| _max_adv        | 12.7        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00263252 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0494      |
| _min_adv        | -8.13       |
| _min_discrew    | 0.0175      |
| _min_obs        | -1.14       |
| _std_act        | 0.694347    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.983        |
| ExplainedVarOld | 0.982        |
| KL              | 0.00217331   |
| Phi_loss        | 569.788      |
| PolicyEntropy   | 0.917368     |
| PolicyLoss      | 0.02527      |
| Steps           | 10000        |
| VarFuncLoss     | 0.0213       |
| _MeanReward     | 4.52e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.92967      |
| _max_adv        | 3.51         |
| _max_discrew    | 4.9          |
| _max_obs        | 1.23         |
| _mean_act       | -0.000372401 |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 3.74         |
| _mean_obs       | 0.0508       |
| _min_adv        | -5.25        |
| _min_discrew    | 0.0179       |
| _min_obs        | -1.19        |
| _std_act        | 0.692459     |
| _std_adv        | 1            |
| _std_discrew    | 1.29         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00199229  |
| Phi_loss        | 573.177     |
| PolicyEntropy   | 0.904561    |
| PolicyLoss      | 0.0105539   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0197      |
| _MeanReward     | 4.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67725     |
| _max_adv        | 4.24        |
| _max_discrew    | 4.85        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00280673 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.05        |
| _min_adv        | -5.13       |
| _min_discrew    | 0.0161      |
| _min_obs        | -1.14       |
| _std_act        | 0.68917     |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00204162  |
| Phi_loss        | 614.465     |
| PolicyEntropy   | 0.881759    |
| PolicyLoss      | 0.000989716 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0115      |
| _MeanReward     | 4.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69784     |
| _max_adv        | 8.74        |
| _max_discrew    | 4.73        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00117253 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.7         |
| _mean_obs       | 0.05        |
| _min_adv        | -9.5        |
| _min_discrew    | 0.0152      |
| _min_obs        | -1.13       |
| _std_act        | 0.692383    |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.0026537   |
| Phi_loss        | 652.864     |
| PolicyEntropy   | 0.862242    |
| PolicyLoss      | 0.00469377  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0187      |
| _MeanReward     | 4.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.72543     |
| _max_adv        | 14.4        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.22        |
| _mean_act       | -0.00152021 |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 3.73        |
| _mean_obs       | 0.0499      |
| _min_adv        | -10.9       |
| _min_discrew    | 0.0186      |
| _min_obs        | -1.17       |
| _std_act        | 0.688835    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00203548 |
| Phi_loss        | 506.628    |
| PolicyEntropy   | 0.869101   |
| PolicyLoss      | -0.0281328 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8321     |
| _max_adv        | 4.39       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0105468 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0481     |
| _min_adv        | -8.62      |
| _min_discrew    | -0.0718    |
| _min_obs        | -1.17      |
| _std_act        | 0.706872   |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.799      |
| KL              | 0.0139746  |
| Phi_loss        | 261.137    |
| PolicyEntropy   | 0.866015   |
| PolicyLoss      | 0.0767381  |
| Steps           | 10000      |
| VarFuncLoss     | 0.142      |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88453    |
| _max_adv        | 4.71       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00357817 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0508     |
| _min_adv        | -4.71      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.16      |
| _std_act        | 0.691044   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.991      |
| KL              | 0.0141602  |
| Phi_loss        | 620.928    |
| PolicyEntropy   | 0.866857   |
| PolicyLoss      | 0.0220781  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68711    |
| _max_adv        | 32.8       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.25       |
| _mean_act       | 0.00739844 |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0512     |
| _min_adv        | -3.84      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.14      |
| _std_act        | 0.691228   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00105135 |
| Phi_loss        | 461.515    |
| PolicyEntropy   | 0.868268   |
| PolicyLoss      | -0.0197895 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0161     |
| _MeanReward     | 4.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73632    |
| _max_adv        | 3.29       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.28       |
| _mean_act       | 0.00608947 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0512     |
| _min_adv        | -4.4       |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.19      |
| _std_act        | 0.695792   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.99        |
| KL              | 0.000990204 |
| Phi_loss        | 694.059     |
| PolicyEntropy   | 0.857375    |
| PolicyLoss      | 0.00835249  |
| Steps           | 10000       |
| VarFuncLoss     | 0.011       |
| _MeanReward     | 4.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85517     |
| _max_adv        | 23          |
| _max_discrew    | 5.01        |
| _max_obs        | 1.23        |
| _mean_act       | 0.00459459  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0513      |
| _min_adv        | -4.26       |
| _min_discrew    | 0.0179      |
| _min_obs        | -1.15       |
| _std_act        | 0.689538    |
| _std_adv        | 1           |
| _std_discrew    | 1.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00405366  |
| Phi_loss        | 589.106     |
| PolicyEntropy   | 0.849042    |
| PolicyLoss      | 0.000517003 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 4.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91909     |
| _max_adv        | 3.52        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.24        |
| _mean_act       | 0.00485135  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0512      |
| _min_adv        | -4.89       |
| _min_discrew    | 0.0205      |
| _min_obs        | -1.13       |
| _std_act        | 0.696182    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00198586 |
| Phi_loss        | 656.06     |
| PolicyEntropy   | 0.831803   |
| PolicyLoss      | -0.0085651 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0123     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73999    |
| _max_adv        | 2.86       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.28       |
| _mean_act       | 0.0048841  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0512     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.00567    |
| _min_obs        | -1.12      |
| _std_act        | 0.690732   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00171506 |
| Phi_loss        | 681.955    |
| PolicyEntropy   | 0.811658   |
| PolicyLoss      | 0.00219248 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70424    |
| _max_adv        | 2.72       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00574997 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0512     |
| _min_adv        | -3.74      |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.17      |
| _std_act        | 0.693659   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00131688 |
| Phi_loss        | 710.573    |
| PolicyEntropy   | 0.800026   |
| PolicyLoss      | -0.0147144 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0128     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86436    |
| _max_adv        | 18.3       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00859179 |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0507     |
| _min_adv        | -6.89      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.17      |
| _std_act        | 0.697262   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00306365 |
| Phi_loss        | 623.338    |
| PolicyEntropy   | 0.784694   |
| PolicyLoss      | 0.00275501 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0118     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77126    |
| _max_adv        | 12.9       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00840675 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0511     |
| _min_adv        | -6.54      |
| _min_discrew    | 0.0184     |
| _min_obs        | -1.18      |
| _std_act        | 0.69654    |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00302185  |
| Phi_loss        | 654.295     |
| PolicyEntropy   | 0.758184    |
| PolicyLoss      | 0.000846443 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0149      |
| _MeanReward     | 4.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71339     |
| _max_adv        | 2.79        |
| _max_discrew    | 4.9         |
| _max_obs        | 1.25        |
| _mean_act       | 0.000719962 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0496      |
| _min_adv        | -17.3       |
| _min_discrew    | -0.02       |
| _min_obs        | -1.16       |
| _std_act        | 0.710307    |
| _std_adv        | 1           |
| _std_discrew    | 1.71        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00787813 |
| Phi_loss        | 460.706    |
| PolicyEntropy   | 0.765946   |
| PolicyLoss      | 0.0389313  |
| Steps           | 10000      |
| VarFuncLoss     | 0.127      |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80341    |
| _max_adv        | 8.01       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.26       |
| _mean_act       | 0.00675734 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0504     |
| _min_adv        | -4.15      |
| _min_discrew    | 0.021      |
| _min_obs        | -1.1       |
| _std_act        | 0.698138   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00254654 |
| Phi_loss        | 581.869    |
| PolicyEntropy   | 0.751665   |
| PolicyLoss      | -0.010503  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0166     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72717    |
| _max_adv        | 14.3       |
| _max_discrew    | 5.09       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00774536 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0518     |
| _min_adv        | -13.1      |
| _min_discrew    | 0.00751    |
| _min_obs        | -1.12      |
| _std_act        | 0.694176   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.985      |
| KL              | 0.00147132 |
| Phi_loss        | 558.958    |
| PolicyEntropy   | 0.728074   |
| PolicyLoss      | -0.024358  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0163     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79495    |
| _max_adv        | 11.7       |
| _max_discrew    | 5.06       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00681173 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0513     |
| _min_adv        | -4.17      |
| _min_discrew    | 0.0185     |
| _min_obs        | -1.13      |
| _std_act        | 0.700666   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00377451 |
| Phi_loss        | 709.715    |
| PolicyEntropy   | 0.690596   |
| PolicyLoss      | -0.0174456 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0127     |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.0826     |
| _max_adv        | 22.8       |
| _max_discrew    | 4.98       |
| _max_obs        | 1.23       |
| _mean_act       | 0.00637399 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0505     |
| _min_adv        | -9.52      |
| _min_discrew    | 0.0198     |
| _min_obs        | -1.19      |
| _std_act        | 0.698725   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.964       |
| ExplainedVarOld | 0.957       |
| KL              | 0.00772244  |
| Phi_loss        | 623.924     |
| PolicyEntropy   | 0.676712    |
| PolicyLoss      | -0.00227398 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0488      |
| _MeanReward     | 4.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79874     |
| _max_adv        | 3.39        |
| _max_discrew    | 5.13        |
| _max_obs        | 1.24        |
| _mean_act       | 0.00810172  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.71        |
| _mean_obs       | 0.05        |
| _min_adv        | -10.7       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.14       |
| _std_act        | 0.701908    |
| _std_adv        | 1           |
| _std_discrew    | 1.61        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.907      |
| ExplainedVarOld | 0.877      |
| KL              | 0.0020204  |
| Phi_loss        | 446.774    |
| PolicyEntropy   | 0.678611   |
| PolicyLoss      | -0.0196679 |
| Steps           | 10000      |
| VarFuncLoss     | 0.15       |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62598    |
| _max_adv        | 12.7       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00667834 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0506     |
| _min_adv        | -4.61      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.14      |
| _std_act        | 0.695863   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0192236  |
| Phi_loss        | 923.607    |
| PolicyEntropy   | 0.691309   |
| PolicyLoss      | -1.60665   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0166     |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78447    |
| _max_adv        | 16.2       |
| _max_discrew    | 5.02       |
| _max_obs        | 1.26       |
| _mean_act       | 0.00271825 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.0516     |
| _min_adv        | -4.42      |
| _min_discrew    | 0.0212     |
| _min_obs        | -1.16      |
| _std_act        | 0.70916    |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00315698  |
| Phi_loss        | 703.394     |
| PolicyEntropy   | 0.686653    |
| PolicyLoss      | 0.00724918  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0203      |
| _MeanReward     | 4.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02515     |
| _max_adv        | 25.1        |
| _max_discrew    | 4.91        |
| _max_obs        | 1.23        |
| _mean_act       | 0.000700094 |
| _mean_adv       | 1.85e-17    |
| _mean_discrew   | 3.83        |
| _mean_obs       | 0.0503      |
| _min_adv        | -7.58       |
| _min_discrew    | 0.0188      |
| _min_obs        | -1.18       |
| _std_act        | 0.708279    |
| _std_adv        | 1           |
| _std_discrew    | 1.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00117991  |
| Phi_loss        | 676.008     |
| PolicyEntropy   | 0.678481    |
| PolicyLoss      | -0.00783938 |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90392     |
| _max_adv        | 16.1        |
| _max_discrew    | 4.97        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00127856 |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 3.82        |
| _mean_obs       | 0.0498      |
| _min_adv        | -8.64       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.14       |
| _std_act        | 0.710998    |
| _std_adv        | 1           |
| _std_discrew    | 1.35        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.988        |
| ExplainedVarOld | 0.986        |
| KL              | 0.00169281   |
| Phi_loss        | 784.878      |
| PolicyEntropy   | 0.68383      |
| PolicyLoss      | -0.00185018  |
| Steps           | 10000        |
| VarFuncLoss     | 0.0169       |
| _MeanReward     | 4.63e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.9025       |
| _max_adv        | 3.64         |
| _max_discrew    | 5.04         |
| _max_obs        | 1.24         |
| _mean_act       | -0.000170318 |
| _mean_adv       | -2.56e-17    |
| _mean_discrew   | 3.83         |
| _mean_obs       | 0.0504       |
| _min_adv        | -6.25        |
| _min_discrew    | 0.0146       |
| _min_obs        | -1.14        |
| _std_act        | 0.712448     |
| _std_adv        | 1            |
| _std_discrew    | 1.44         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00156659  |
| Phi_loss        | 852.167     |
| PolicyEntropy   | 0.68367     |
| PolicyLoss      | -0.0153334  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0187      |
| _MeanReward     | 4.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.65667     |
| _max_adv        | 1.04        |
| _max_discrew    | 4.97        |
| _max_obs        | 1.22        |
| _mean_act       | -0.00810403 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.49        |
| _mean_obs       | 0.0474      |
| _min_adv        | -14.8       |
| _min_discrew    | -0.702      |
| _min_obs        | -1.12       |
| _std_act        | 0.749389    |
| _std_adv        | 1           |
| _std_discrew    | 2.65        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.793       |
| KL              | 0.00785563  |
| Phi_loss        | 562.58      |
| PolicyEntropy   | 0.694905    |
| PolicyLoss      | 0.0613196   |
| Steps           | 10000       |
| VarFuncLoss     | 0.229       |
| _MeanReward     | 4.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66524     |
| _max_adv        | 9.98        |
| _max_discrew    | 4.94        |
| _max_obs        | 1.21        |
| _mean_act       | 0.000761997 |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.68        |
| _mean_obs       | 0.0491      |
| _min_adv        | -16.1       |
| _min_discrew    | -0.463      |
| _min_obs        | -1.14       |
| _std_act        | 0.723381    |
| _std_adv        | 1           |
| _std_discrew    | 1.94        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.902       |
| KL              | 0.00108696  |
| Phi_loss        | 725.12      |
| PolicyEntropy   | 0.693336    |
| PolicyLoss      | -0.0114599  |
| Steps           | 10000       |
| VarFuncLoss     | 0.173       |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74449     |
| _max_adv        | 12.7        |
| _max_discrew    | 5.11        |
| _max_obs        | 1.21        |
| _mean_act       | 0.000195437 |
| _mean_adv       | 7.11e-19    |
| _mean_discrew   | 3.63        |
| _mean_obs       | 0.0486      |
| _min_adv        | -14.1       |
| _min_discrew    | -0.489      |
| _min_obs        | -1.17       |
| _std_act        | 0.725917    |
| _std_adv        | 1           |
| _std_discrew    | 2.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00371601 |
| Phi_loss        | 731.771    |
| PolicyEntropy   | 0.670005   |
| PolicyLoss      | 0.00939581 |
| Steps           | 10000      |
| VarFuncLoss     | 0.208      |
| _MeanReward     | 4.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80468    |
| _max_adv        | 4.19       |
| _max_discrew    | 5.07       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0106207 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0469     |
| _min_adv        | -16.5      |
| _min_discrew    | -0.648     |
| _min_obs        | -1.13      |
| _std_act        | 0.744469   |
| _std_adv        | 1          |
| _std_discrew    | 2.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.911       |
| KL              | 0.00210742  |
| Phi_loss        | 568.945     |
| PolicyEntropy   | 0.677693    |
| PolicyLoss      | 0.000160238 |
| Steps           | 10000       |
| VarFuncLoss     | 0.214       |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82991     |
| _max_adv        | 22.7        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.24        |
| _mean_act       | 0.000892081 |
| _mean_adv       | -1.21e-17   |
| _mean_discrew   | 3.82        |
| _mean_obs       | 0.0495      |
| _min_adv        | -6.15       |
| _min_discrew    | 0.00555     |
| _min_obs        | -1.16       |
| _std_act        | 0.710477    |
| _std_adv        | 1           |
| _std_discrew    | 1.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00266699 |
| Phi_loss        | 668.763    |
| PolicyEntropy   | 0.683788   |
| PolicyLoss      | 0.0210704  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0158     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73477    |
| _max_adv        | 23.6       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00316569 |
| _mean_adv       | 4.62e-18   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0504     |
| _min_adv        | -8.8       |
| _min_discrew    | -0.0943    |
| _min_obs        | -1.16      |
| _std_act        | 0.710826   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00227394 |
| Phi_loss        | 634.225    |
| PolicyEntropy   | 0.685368   |
| PolicyLoss      | -0.0266325 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0268     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88819    |
| _max_adv        | 33.2       |
| _max_discrew    | 5.04       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00317388 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.0499     |
| _min_adv        | -8.92      |
| _min_discrew    | -0.0958    |
| _min_obs        | -1.14      |
| _std_act        | 0.713496   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.977      |
| KL              | 0.00239021 |
| Phi_loss        | 528.348    |
| PolicyEntropy   | 0.676247   |
| PolicyLoss      | -0.0178245 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0303     |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78716    |
| _max_adv        | 4.37       |
| _max_discrew    | 5.14       |
| _max_obs        | 1.23       |
| _mean_act       | 0.0038615  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0496     |
| _min_adv        | -4.56      |
| _min_discrew    | 0.0195     |
| _min_obs        | -1.13      |
| _std_act        | 0.713977   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00158509 |
| Phi_loss        | 699.029    |
| PolicyEntropy   | 0.667578   |
| PolicyLoss      | -0.0114695 |
| Steps           | 10000      |
| VarFuncLoss     | 0.02       |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77042    |
| _max_adv        | 3.93       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.22       |
| _mean_act       | 0.0042769  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.05       |
| _min_adv        | -4.55      |
| _min_discrew    | 0.0139     |
| _min_obs        | -1.16      |
| _std_act        | 0.712309   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.0016818  |
| Phi_loss        | 773.223    |
| PolicyEntropy   | 0.647681   |
| PolicyLoss      | 0.0075258  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0116     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77297    |
| _max_adv        | 5.88       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.24       |
| _mean_act       | 0.00534147 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0494     |
| _min_adv        | -4.51      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.17      |
| _std_act        | 0.718103   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.987       |
| KL              | 0.0017836   |
| Phi_loss        | 738.679     |
| PolicyEntropy   | 0.639086    |
| PolicyLoss      | -0.0115695  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0145      |
| _MeanReward     | 4.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77085     |
| _max_adv        | 1.9         |
| _max_discrew    | 4.99        |
| _max_obs        | 1.2         |
| _mean_act       | 0.000601137 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.63        |
| _mean_obs       | 0.0481      |
| _min_adv        | -16.3       |
| _min_discrew    | -0.493      |
| _min_obs        | -1.19       |
| _std_act        | 0.729322    |
| _std_adv        | 1           |
| _std_discrew    | 2.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.918        |
| ExplainedVarOld | 0.894        |
| KL              | 0.00215208   |
| Phi_loss        | 453.15       |
| PolicyEntropy   | 0.62844      |
| PolicyLoss      | 0.00909829   |
| Steps           | 10000        |
| VarFuncLoss     | 0.17         |
| _MeanReward     | 4.62e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.98534      |
| _max_adv        | 22.8         |
| _max_discrew    | 4.92         |
| _max_obs        | 1.2          |
| _mean_act       | -0.000451727 |
| _mean_adv       | -2.84e-18    |
| _mean_discrew   | 3.83         |
| _mean_obs       | 0.0499       |
| _min_adv        | -4.55        |
| _min_discrew    | 0.0161       |
| _min_obs        | -1.12        |
| _std_act        | 0.708298     |
| _std_adv        | 1            |
| _std_discrew    | 1.36         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00526253 |
| Phi_loss        | 470.303    |
| PolicyEntropy   | 0.63614    |
| PolicyLoss      | -0.0744741 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0212     |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.93427    |
| _max_adv        | 26.3       |
| _max_discrew    | 5.09       |
| _max_obs        | 1.23       |
| _mean_act       | 0.00419542 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0504     |
| _min_adv        | -9.21      |
| _min_discrew    | 0.0176     |
| _min_obs        | -1.13      |
| _std_act        | 0.715381   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00344069 |
| Phi_loss        | 472.408    |
| PolicyEntropy   | 0.641581   |
| PolicyLoss      | 0.0211119  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0256     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6733     |
| _max_adv        | 10.2       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00524516 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0496     |
| _min_adv        | -5.8       |
| _min_discrew    | 0.018      |
| _min_obs        | -1.15      |
| _std_act        | 0.712184   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00210567 |
| Phi_loss        | 822.083    |
| PolicyEntropy   | 0.623444   |
| PolicyLoss      | 0.00310101 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 4.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78937    |
| _max_adv        | 3.64       |
| _max_discrew    | 5.16       |
| _max_obs        | 1.26       |
| _mean_act       | 0.00461163 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.0509     |
| _min_adv        | -4.17      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.19      |
| _std_act        | 0.718766   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00167134 |
| Phi_loss        | 792.115    |
| PolicyEntropy   | 0.601418   |
| PolicyLoss      | 0.0141948  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87599    |
| _max_adv        | 4.7        |
| _max_discrew    | 4.97       |
| _max_obs        | 1.24       |
| _mean_act       | 0.00302565 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0492     |
| _min_adv        | -4.5       |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.15      |
| _std_act        | 0.715183   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00151781 |
| Phi_loss        | 784.86     |
| PolicyEntropy   | 0.58408    |
| PolicyLoss      | 0.00891789 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0159     |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.77496    |
| _max_adv        | 5.85       |
| _max_discrew    | 5.19       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00161917 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.0502     |
| _min_adv        | -7.41      |
| _min_discrew    | 0.0187     |
| _min_obs        | -1.16      |
| _std_act        | 0.714771   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00201137 |
| Phi_loss        | 817.027    |
| PolicyEntropy   | 0.573058   |
| PolicyLoss      | -0.0153183 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0236     |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74914    |
| _max_adv        | 8.97       |
| _max_discrew    | 5.18       |
| _max_obs        | 1.25       |
| _mean_act       | 0.00140976 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.0498     |
| _min_adv        | -5.91      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.14      |
| _std_act        | 0.712421   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.986        |
| ExplainedVarOld | 0.986        |
| KL              | 0.00149485   |
| Phi_loss        | 741.077      |
| PolicyEntropy   | 0.572779     |
| PolicyLoss      | -0.0325021   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0198       |
| _MeanReward     | 4.71e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.63619      |
| _max_adv        | 9.95         |
| _max_discrew    | 5.09         |
| _max_obs        | 1.21         |
| _mean_act       | -0.000251002 |
| _mean_adv       | 0            |
| _mean_discrew   | 3.91         |
| _mean_obs       | 0.0496       |
| _min_adv        | -5.6         |
| _min_discrew    | 0.0152       |
| _min_obs        | -1.21        |
| _std_act        | 0.718064     |
| _std_adv        | 1            |
| _std_discrew    | 1.36         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00296875  |
| Phi_loss        | 798.236     |
| PolicyEntropy   | 0.560184    |
| PolicyLoss      | 0.00789839  |
| Steps           | 10000       |
| VarFuncLoss     | 0.021       |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64163     |
| _max_adv        | 1.12        |
| _max_discrew    | 5.16        |
| _max_obs        | 1.27        |
| _mean_act       | -0.00467043 |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 3.6         |
| _mean_obs       | 0.0471      |
| _min_adv        | -18         |
| _min_discrew    | -0.525      |
| _min_obs        | -1.18       |
| _std_act        | 0.734808    |
| _std_adv        | 1           |
| _std_discrew    | 2.44        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.904        |
| ExplainedVarOld | 0.888        |
| KL              | 0.00767332   |
| Phi_loss        | 554.313      |
| PolicyEntropy   | 0.575592     |
| PolicyLoss      | -0.0411243   |
| Steps           | 10000        |
| VarFuncLoss     | 0.235        |
| _MeanReward     | 4.72e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.07646      |
| _max_adv        | 8.89         |
| _max_discrew    | 5.05         |
| _max_obs        | 1.21         |
| _mean_act       | -0.000928467 |
| _mean_adv       | 3.98e-17     |
| _mean_discrew   | 3.91         |
| _mean_obs       | 0.0498       |
| _min_adv        | -7.55        |
| _min_discrew    | 0.0181       |
| _min_obs        | -1.12        |
| _std_act        | 0.715499     |
| _std_adv        | 1            |
| _std_discrew    | 1.44         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00185161 |
| Phi_loss        | 715.864    |
| PolicyEntropy   | 0.559198   |
| PolicyLoss      | -0.0208966 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0177     |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.81051    |
| _max_adv        | 14.5       |
| _max_discrew    | 5.08       |
| _max_obs        | 1.21       |
| _mean_act       | 0.00360191 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.0496     |
| _min_adv        | -5.29      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.19      |
| _std_act        | 0.724201   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00175642  |
| Phi_loss        | 722.168     |
| PolicyEntropy   | 0.551825    |
| PolicyLoss      | 0.0196551   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 4.67e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06828     |
| _max_adv        | 7.03        |
| _max_discrew    | 4.93        |
| _max_obs        | 1.22        |
| _mean_act       | 6.22833e-05 |
| _mean_adv       | 3.55e-17    |
| _mean_discrew   | 3.88        |
| _mean_obs       | 0.049       |
| _min_adv        | -4.99       |
| _min_discrew    | 0.0177      |
| _min_obs        | -1.18       |
| _std_act        | 0.723133    |
| _std_adv        | 1           |
| _std_discrew    | 1.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00174554 |
| Phi_loss        | 785.298    |
| PolicyEntropy   | 0.539379   |
| PolicyLoss      | -0.0166147 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0152     |
| _MeanReward     | 4.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70784    |
| _max_adv        | 21         |
| _max_discrew    | 5.03       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00298281 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0489     |
| _min_adv        | -9.99      |
| _min_discrew    | 0.0172     |
| _min_obs        | -1.16      |
| _std_act        | 0.713782   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00177138  |
| Phi_loss        | 672.302     |
| PolicyEntropy   | 0.511779    |
| PolicyLoss      | -0.00161565 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0198      |
| _MeanReward     | 4.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.89081     |
| _max_adv        | 3.31        |
| _max_discrew    | 5.17        |
| _max_obs        | 1.23        |
| _mean_act       | 0.00272614  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.95        |
| _mean_obs       | 0.0503      |
| _min_adv        | -6.45       |
| _min_discrew    | 0.0209      |
| _min_obs        | -1.18       |
| _std_act        | 0.719197    |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00168509  |
| Phi_loss        | 801.642     |
| PolicyEntropy   | 0.489818    |
| PolicyLoss      | 0.000192416 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0191      |
| _MeanReward     | 4.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11984     |
| _max_adv        | 33.1        |
| _max_discrew    | 5           |
| _max_obs        | 1.24        |
| _mean_act       | 0.00163418  |
| _mean_adv       | 7.11e-18    |
| _mean_discrew   | 3.92        |
| _mean_obs       | 0.0495      |
| _min_adv        | -8.76       |
| _min_discrew    | 0.0187      |
| _min_obs        | -1.17       |
| _std_act        | 0.715198    |
| _std_adv        | 1           |
| _std_discrew    | 1.4         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.987       |
| KL              | 0.00844013  |
| Phi_loss        | 693.731     |
| PolicyEntropy   | 0.46288     |
| PolicyLoss      | 0.0313971   |
| Steps           | 10000       |
| VarFuncLoss     | 0.014       |
| _MeanReward     | 4.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.81731     |
| _max_adv        | 2.11        |
| _max_discrew    | 5.14        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00719551 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0472      |
| _min_adv        | -14         |
| _min_discrew    | -0.579      |
| _min_obs        | -1.16       |
| _std_act        | 0.739641    |
| _std_adv        | 1           |
| _std_discrew    | 2.86        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
---------------------------------
| Beta            | 1           |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.828       |
| KL              | 0.00975441  |
| Phi_loss        | 637.267     |
| PolicyEntropy   | 0.462933    |
| PolicyLoss      | -0.162091   |
| Steps           | 10000       |
| VarFuncLoss     | 0.249       |
| _MeanReward     | 4.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75822     |
| _max_adv        | 24.3        |
| _max_discrew    | 5.06        |
| _max_obs        | 1.19        |
| _mean_act       | 0.000484108 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.93        |
| _mean_obs       | 0.0499      |
| _min_adv        | -6.47       |
| _min_discrew    | 0.0191      |
| _min_obs        | -1.14       |
| _std_act        | 0.716189    |
| _std_adv        | 1           |
| _std_discrew    | 1.45        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00115583  |
| Phi_loss        | 933.357     |
| PolicyEntropy   | 0.462434    |
| PolicyLoss      | -0.00635312 |
| Steps           | 10000       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 4.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.87008     |
| _max_adv        | 9.36        |
| _max_discrew    | 5.08        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00325236  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.9         |
| _mean_obs       | 0.049       |
| _min_adv        | -6.4        |
| _min_discrew    | 0.0175      |
| _min_obs        | -1.15       |
| _std_act        | 0.714996    |
| _std_adv        | 1           |
| _std_discrew    | 1.44        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00126067  |
| Phi_loss        | 685.372     |
| PolicyEntropy   | 0.466331    |
| PolicyLoss      | -0.00239923 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0211      |
| _MeanReward     | 4.55e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74816     |
| _max_adv        | 3.86        |
| _max_discrew    | 5.26        |
| _max_obs        | 1.23        |
| _mean_act       | 3.24656e-06 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.74        |
| _mean_obs       | 0.0483      |
| _min_adv        | -16.1       |
| _min_discrew    | -0.452      |
| _min_obs        | -1.12       |
| _std_act        | 0.733442    |
| _std_adv        | 1           |
| _std_discrew    | 2.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.906       |
| KL              | 0.00195357  |
| Phi_loss        | 753.545     |
| PolicyEntropy   | 0.463254    |
| PolicyLoss      | -0.00817518 |
| Steps           | 10000       |
| VarFuncLoss     | 0.188       |
| _MeanReward     | 4.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94215     |
| _max_adv        | 24.1        |
| _max_discrew    | 5.19        |
| _max_obs        | 1.2         |
| _mean_act       | 0.00163344  |
| _mean_adv       | -6.39e-18   |
| _mean_discrew   | 3.95        |
| _mean_obs       | 0.0499      |
| _min_adv        | -6.65       |
| _min_discrew    | 0.0192      |
| _min_obs        | -1.19       |
| _std_act        | 0.713367    |
| _std_adv        | 1           |
| _std_discrew    | 1.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.967       |
| KL              | 0.0062051   |
| Phi_loss        | 364.966     |
| PolicyEntropy   | 0.456544    |
| PolicyLoss      | -0.00265608 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0347      |
| _MeanReward     | 4.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7139      |
| _max_adv        | 16.7        |
| _max_discrew    | 5.23        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00128311  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.97        |
| _mean_obs       | 0.0497      |
| _min_adv        | -5.45       |
| _min_discrew    | 0.02        |
| _min_obs        | -1.12       |
| _std_act        | 0.717271    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00123696 |
| Phi_loss        | 662.438    |
| PolicyEntropy   | 0.454252   |
| PolicyLoss      | -0.0206784 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89424    |
| _max_adv        | 3.79       |
| _max_discrew    | 5.1        |
| _max_obs        | 1.19       |
| _mean_act       | 0.00506343 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.049      |
| _min_adv        | -4.81      |
| _min_discrew    | 0.0182     |
| _min_obs        | -1.15      |
| _std_act        | 0.717994   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00191891 |
| Phi_loss        | 840.853    |
| PolicyEntropy   | 0.435251   |
| PolicyLoss      | 0.00498213 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0171     |
| _MeanReward     | 4.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71781    |
| _max_adv        | 6.84       |
| _max_discrew    | 5.13       |
| _max_obs        | 1.23       |
| _mean_act       | 0.00300012 |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.94       |
| _mean_obs       | 0.0497     |
| _min_adv        | -14.8      |
| _min_discrew    | 0.0179     |
| _min_obs        | -1.15      |
| _std_act        | 0.716396   |
| _std_adv        | 1          |
| _std_discrew    | 1.47       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00365645 |
| Phi_loss        | 746.342    |
| PolicyEntropy   | 0.417613   |
| PolicyLoss      | 0.00617828 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0154     |
| _MeanReward     | 4.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59658    |
| _max_adv        | 3.5        |
| _max_discrew    | 5.23       |
| _max_obs        | 1.18       |
| _mean_act       | 0.00368031 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.94       |
| _mean_obs       | 0.05       |
| _min_adv        | -8.11      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.16      |
| _std_act        | 0.717543   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00190974 |
| Phi_loss        | 849.469    |
| PolicyEntropy   | 0.408711   |
| PolicyLoss      | 0.00677369 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0203     |
| _MeanReward     | 4.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.71925    |
| _max_adv        | 4.44       |
| _max_discrew    | 5.25       |
| _max_obs        | 1.21       |
| _mean_act       | 0.00387322 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.0503     |
| _min_adv        | -9.99      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.16      |
| _std_act        | 0.714582   |
| _std_adv        | 1          |
| _std_discrew    | 1.63       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00152951  |
| Phi_loss        | 772.537     |
| PolicyEntropy   | 0.393664    |
| PolicyLoss      | -0.00355136 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0198      |
| _MeanReward     | 4.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00737     |
| _max_adv        | 3.2         |
| _max_discrew    | 5.25        |
| _max_obs        | 1.17        |
| _mean_act       | 0.000460544 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.98        |
| _mean_obs       | 0.0499      |
| _min_adv        | -5.24       |
| _min_discrew    | 0.0183      |
| _min_obs        | -1.17       |
| _std_act        | 0.717362    |
| _std_adv        | 1           |
| _std_discrew    | 1.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00165276 |
| Phi_loss        | 825.831    |
| PolicyEntropy   | 0.375942   |
| PolicyLoss      | 0.015437   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0184     |
| _MeanReward     | 4.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62204    |
| _max_adv        | 3.6        |
| _max_discrew    | 5.28       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00324655 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 4.03       |
| _mean_obs       | 0.0506     |
| _min_adv        | -4.63      |
| _min_discrew    | 0.0191     |
| _min_obs        | -1.33      |
| _std_act        | 0.719394   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.988      |
| KL              | 0.0016416  |
| Phi_loss        | 849.77     |
| PolicyEntropy   | 0.371297   |
| PolicyLoss      | -0.0103629 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0159     |
| _MeanReward     | 4.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83639    |
| _max_adv        | 3.72       |
| _max_discrew    | 5.22       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00403157 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.98       |
| _mean_obs       | 0.0498     |
| _min_adv        | -4.62      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.17      |
| _std_act        | 0.717016   |
| _std_adv        | 1          |
| _std_discrew    | 1.53       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00187486  |
| Phi_loss        | 865.313     |
| PolicyEntropy   | 0.355837    |
| PolicyLoss      | 0.00844182  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0234      |
| _MeanReward     | 4.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64072     |
| _max_adv        | 3.24        |
| _max_discrew    | 5.34        |
| _max_obs        | 1.21        |
| _mean_act       | 0.000596777 |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 3.98        |
| _mean_obs       | 0.0496      |
| _min_adv        | -4.69       |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.21       |
| _std_act        | 0.715634    |
| _std_adv        | 1           |
| _std_discrew    | 1.54        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00166198 |
| Phi_loss        | 822.097    |
| PolicyEntropy   | 0.35052    |
| PolicyLoss      | -0.0357449 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0211     |
| _MeanReward     | 4.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7185     |
| _max_adv        | 3.68       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.26       |
| _mean_act       | 0.00181232 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.98       |
| _mean_obs       | 0.0502     |
| _min_adv        | -5.4       |
| _min_discrew    | 0.021      |
| _min_obs        | -1.16      |
| _std_act        | 0.719947   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00169509 |
| Phi_loss        | 814.993    |
| PolicyEntropy   | 0.357453   |
| PolicyLoss      | -0.0294533 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0166     |
| _MeanReward     | 4.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00695    |
| _max_adv        | 3.66       |
| _max_discrew    | 5.1        |
| _max_obs        | 1.21       |
| _mean_act       | 0.00274182 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.99       |
| _mean_obs       | 0.05       |
| _min_adv        | -4.43      |
| _min_discrew    | 0.0186     |
| _min_obs        | -1.13      |
| _std_act        | 0.714837   |
| _std_adv        | 1          |
| _std_discrew    | 1.5        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.988        |
| ExplainedVarOld | 0.987        |
| KL              | 0.00192002   |
| Phi_loss        | 784.325      |
| PolicyEntropy   | 0.359525     |
| PolicyLoss      | -0.0213384   |
| Steps           | 10000        |
| VarFuncLoss     | 0.018        |
| _MeanReward     | 4.89e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.67307      |
| _max_adv        | 4.01         |
| _max_discrew    | 5.25         |
| _max_obs        | 1.24         |
| _mean_act       | -0.000115124 |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 4.06         |
| _mean_obs       | 0.051        |
| _min_adv        | -5.23        |
| _min_discrew    | 0.0188       |
| _min_obs        | -1.17        |
| _std_act        | 0.719947     |
| _std_adv        | 1            |
| _std_discrew    | 1.52         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00195808 |
| Phi_loss        | 820.781    |
| PolicyEntropy   | 0.337075   |
| PolicyLoss      | 0.00153355 |
| Steps           | 10000      |
| VarFuncLoss     | 0.022      |
| _MeanReward     | 4.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81098    |
| _max_adv        | 3.59       |
| _max_discrew    | 5.31       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00351127 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4          |
| _mean_obs       | 0.0502     |
| _min_adv        | -6.85      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.15      |
| _std_act        | 0.72516    |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00200794  |
| Phi_loss        | 914.381     |
| PolicyEntropy   | 0.325639    |
| PolicyLoss      | -0.00463837 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0243      |
| _MeanReward     | 4.74e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74791     |
| _max_adv        | 9.98        |
| _max_discrew    | 5.08        |
| _max_obs        | 1.2         |
| _mean_act       | 0.00596995  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 3.92        |
| _mean_obs       | 0.0492      |
| _min_adv        | -6.85       |
| _min_discrew    | 0.0144      |
| _min_obs        | -1.16       |
| _std_act        | 0.720372    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00255642  |
| Phi_loss        | 816.81      |
| PolicyEntropy   | 0.32518     |
| PolicyLoss      | -0.00992307 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0218      |
| _MeanReward     | 4.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73402     |
| _max_adv        | 3.27        |
| _max_discrew    | 5.27        |
| _max_obs        | 1.2         |
| _mean_act       | 0.00308002  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.98        |
| _mean_obs       | 0.0501      |
| _min_adv        | -7.26       |
| _min_discrew    | 0.0174      |
| _min_obs        | -1.13       |
| _std_act        | 0.723902    |
| _std_adv        | 1           |
| _std_discrew    | 1.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00164664 |
| Phi_loss        | 909.837    |
| PolicyEntropy   | 0.3193     |
| PolicyLoss      | -0.0110131 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 4.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64063    |
| _max_adv        | 2.84       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.24       |
| _mean_act       | 0.00454701 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.98       |
| _mean_obs       | 0.0497     |
| _min_adv        | -6.38      |
| _min_discrew    | 0.0221     |
| _min_obs        | -1.16      |
| _std_act        | 0.726294   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00157851  |
| Phi_loss        | 871.853     |
| PolicyEntropy   | 0.298075    |
| PolicyLoss      | 0.00434188  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0197      |
| _MeanReward     | 4.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69782     |
| _max_adv        | 4.04        |
| _max_discrew    | 5.22        |
| _max_obs        | 1.2         |
| _mean_act       | -0.00312507 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 4.04        |
| _mean_obs       | 0.0501      |
| _min_adv        | -4.84       |
| _min_discrew    | 0.0165      |
| _min_obs        | -1.14       |
| _std_act        | 0.717486    |
| _std_adv        | 1           |
| _std_discrew    | 1.55        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00231416 |
| Phi_loss        | 945.554    |
| PolicyEntropy   | 0.279788   |
| PolicyLoss      | -0.0185508 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0178     |
| _MeanReward     | 4.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88057    |
| _max_adv        | 5.93       |
| _max_discrew    | 5.25       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00189946 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.01       |
| _mean_obs       | 0.05       |
| _min_adv        | -6.85      |
| _min_discrew    | 0.0198     |
| _min_obs        | -1.12      |
| _std_act        | 0.724469   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00227025  |
| Phi_loss        | 905.525     |
| PolicyEntropy   | 0.275327    |
| PolicyLoss      | -0.00137338 |
| Steps           | 10000       |
| VarFuncLoss     | 0.02        |
| _MeanReward     | 4.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0736      |
| _max_adv        | 3.3         |
| _max_discrew    | 5.27        |
| _max_obs        | 1.18        |
| _mean_act       | -0.00979386 |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.74        |
| _mean_obs       | 0.0477      |
| _min_adv        | -15.8       |
| _min_discrew    | -0.494      |
| _min_obs        | -1.14       |
| _std_act        | 0.741734    |
| _std_adv        | 1           |
| _std_discrew    | 2.44        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.869       |
| KL              | 0.00459861  |
| Phi_loss        | 419.762     |
| PolicyEntropy   | 0.303144    |
| PolicyLoss      | -0.0203264  |
| Steps           | 10000       |
| VarFuncLoss     | 0.228       |
| _MeanReward     | 4.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90224     |
| _max_adv        | 3.9         |
| _max_discrew    | 5.2         |
| _max_obs        | 1.22        |
| _mean_act       | -0.00993267 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.68        |
| _mean_obs       | 0.0471      |
| _min_adv        | -14.9       |
| _min_discrew    | -0.47       |
| _min_obs        | -1.16       |
| _std_act        | 0.741745    |
| _std_adv        | 1           |
| _std_discrew    | 2.52        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.878       |
| KL              | 0.00214804  |
| Phi_loss        | 694.142     |
| PolicyEntropy   | 0.304848    |
| PolicyLoss      | -0.00597451 |
| Steps           | 10000       |
| VarFuncLoss     | 0.296       |
| _MeanReward     | 4.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.70144     |
| _max_adv        | 22.6        |
| _max_discrew    | 5.45        |
| _max_obs        | 1.24        |
| _mean_act       | 0.00240974  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 4.09        |
| _mean_obs       | 0.0513      |
| _min_adv        | -7.2        |
| _min_discrew    | 0.0214      |
| _min_obs        | -1.16       |
| _std_act        | 0.721552    |
| _std_adv        | 1           |
| _std_discrew    | 1.55        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00170132  |
| Phi_loss        | 605.313     |
| PolicyEntropy   | 0.288946    |
| PolicyLoss      | -0.00926918 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0391      |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74868     |
| _max_adv        | 2.96        |
| _max_discrew    | 5.32        |
| _max_obs        | 1.27        |
| _mean_act       | -0.0173996  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.63        |
| _mean_obs       | 0.0461      |
| _min_adv        | -17.7       |
| _min_discrew    | -0.673      |
| _min_obs        | -1.11       |
| _std_act        | 0.75779     |
| _std_adv        | 1           |
| _std_discrew    | 2.83        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.911      |
| ExplainedVarOld | 0.903      |
| KL              | 0.00334814 |
| Phi_loss        | 940.101    |
| PolicyEntropy   | 0.288609   |
| PolicyLoss      | -0.0279568 |
| Steps           | 10000      |
| VarFuncLoss     | 0.255      |
| _MeanReward     | 4.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6335     |
| _max_adv        | 6.71       |
| _max_discrew    | 5.26       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0022477  |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0505     |
| _min_adv        | -4.23      |
| _min_discrew    | 0.0194     |
| _min_obs        | -1.13      |
| _std_act        | 0.726498   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00164471 |
| Phi_loss        | 952.186    |
| PolicyEntropy   | 0.289447   |
| PolicyLoss      | -0.0304791 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08322    |
| _max_adv        | 18.8       |
| _max_discrew    | 5.43       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00326873 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0512     |
| _min_adv        | -4.95      |
| _min_discrew    | 0.0194     |
| _min_obs        | -1.18      |
| _std_act        | 0.72669    |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00220973 |
| Phi_loss        | 846.801    |
| PolicyEntropy   | 0.290339   |
| PolicyLoss      | 0.0064961  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 4.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76064    |
| _max_adv        | 33.6       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0031144  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.05       |
| _mean_obs       | 0.0507     |
| _min_adv        | -7.84      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.15      |
| _std_act        | 0.724052   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00288216 |
| Phi_loss        | 474.823    |
| PolicyEntropy   | 0.281278   |
| PolicyLoss      | -0.0269409 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 4.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.72454    |
| _max_adv        | 10.3       |
| _max_discrew    | 5.29       |
| _max_obs        | 1.18       |
| _mean_act       | 0.00663358 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0505     |
| _min_adv        | -6.99      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.15      |
| _std_act        | 0.726917   |
| _std_adv        | 1          |
| _std_discrew    | 1.52       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.983        |
| ExplainedVarOld | 0.982        |
| KL              | 0.00183519   |
| Phi_loss        | 896.8        |
| PolicyEntropy   | 0.277719     |
| PolicyLoss      | -0.000793918 |
| Steps           | 10000        |
| VarFuncLoss     | 0.026        |
| _MeanReward     | 4.91e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.71171      |
| _max_adv        | 23           |
| _max_discrew    | 5.48         |
| _max_obs        | 1.22         |
| _mean_act       | 0.00404752   |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 4.06         |
| _mean_obs       | 0.0507       |
| _min_adv        | -5.38        |
| _min_discrew    | 0.0181       |
| _min_obs        | -1.12        |
| _std_act        | 0.728291     |
| _std_adv        | 1            |
| _std_discrew    | 1.61         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00209998 |
| Phi_loss        | 706.543    |
| PolicyEntropy   | 0.26258    |
| PolicyLoss      | 0.00214801 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0276     |
| _MeanReward     | 4.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73624    |
| _max_adv        | 30.4       |
| _max_discrew    | 5.49       |
| _max_obs        | 1.17       |
| _mean_act       | 0.00330028 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 4.08       |
| _mean_obs       | 0.0504     |
| _min_adv        | -7.5       |
| _min_discrew    | 0.0181     |
| _min_obs        | -1.15      |
| _std_act        | 0.728036   |
| _std_adv        | 1          |
| _std_discrew    | 1.62       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00129811  |
| Phi_loss        | 449.524     |
| PolicyEntropy   | 0.262746    |
| PolicyLoss      | 0.0107451   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0197      |
| _MeanReward     | 4.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72284     |
| _max_adv        | 2           |
| _max_discrew    | 5.44        |
| _max_obs        | 1.2         |
| _mean_act       | 3.09917e-05 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.99        |
| _mean_obs       | 0.05        |
| _min_adv        | -8.71       |
| _min_discrew    | -0.286      |
| _min_obs        | -1.11       |
| _std_act        | 0.734366    |
| _std_adv        | 1           |
| _std_discrew    | 1.99        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.937      |
| ExplainedVarOld | 0.883      |
| KL              | 0.010546   |
| Phi_loss        | 347.776    |
| PolicyEntropy   | 0.269681   |
| PolicyLoss      | 0.0107347  |
| Steps           | 10000      |
| VarFuncLoss     | 0.127      |
| _MeanReward     | 4.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.6421     |
| _max_adv        | 23.3       |
| _max_discrew    | 5.32       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00502719 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.05       |
| _min_adv        | -10.2      |
| _min_discrew    | 0.0184     |
| _min_obs        | -1.11      |
| _std_act        | 0.728574   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.967       |
| KL              | 0.00601622  |
| Phi_loss        | 504.407     |
| PolicyEntropy   | 0.260083    |
| PolicyLoss      | -0.00197492 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0384      |
| _MeanReward     | 4.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85787     |
| _max_adv        | 5.81        |
| _max_discrew    | 5.53        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00468061  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.11        |
| _mean_obs       | 0.051       |
| _min_adv        | -4.15       |
| _min_discrew    | 0.0174      |
| _min_obs        | -1.17       |
| _std_act        | 0.726181    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00125349  |
| Phi_loss        | 947.405     |
| PolicyEntropy   | 0.248263    |
| PolicyLoss      | -0.00219768 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0299      |
| _MeanReward     | 4.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73463     |
| _max_adv        | 14.1        |
| _max_discrew    | 5.54        |
| _max_obs        | 1.17        |
| _mean_act       | 0.0030615   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 4.09        |
| _mean_obs       | 0.0507      |
| _min_adv        | -9.62       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.14       |
| _std_act        | 0.723673    |
| _std_adv        | 1           |
| _std_discrew    | 1.58        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00216123  |
| Phi_loss        | 832.157     |
| PolicyEntropy   | 0.238283    |
| PolicyLoss      | -0.00521339 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0264      |
| _MeanReward     | 4.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6937      |
| _max_adv        | 2.82        |
| _max_discrew    | 5.53        |
| _max_obs        | 1.19        |
| _mean_act       | 0.00325048  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 4.09        |
| _mean_obs       | 0.0501      |
| _min_adv        | -5.64       |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.13       |
| _std_act        | 0.728373    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.0014097   |
| Phi_loss        | 1008.15     |
| PolicyEntropy   | 0.224555    |
| PolicyLoss      | -0.00872346 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0259      |
| _MeanReward     | 4.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82612     |
| _max_adv        | 3.06        |
| _max_discrew    | 5.45        |
| _max_obs        | 1.21        |
| _mean_act       | 0.00137583  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 4.11        |
| _mean_obs       | 0.0506      |
| _min_adv        | -4.34       |
| _min_discrew    | 0.0201      |
| _min_obs        | -1.14       |
| _std_act        | 0.728399    |
| _std_adv        | 1           |
| _std_discrew    | 1.56        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00325991 |
| Phi_loss        | 989.196    |
| PolicyEntropy   | 0.204847   |
| PolicyLoss      | 0.00438589 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0228     |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7792     |
| _max_adv        | 3.11       |
| _max_discrew    | 5.31       |
| _max_obs        | 1.16       |
| _mean_act       | 0.00626622 |
| _mean_adv       | 0          |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0505     |
| _min_adv        | -4.5       |
| _min_discrew    | 0.014      |
| _min_obs        | -1.12      |
| _std_act        | 0.727688   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00305253  |
| Phi_loss        | 984.557     |
| PolicyEntropy   | 0.192798    |
| PolicyLoss      | -0.00620686 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0177      |
| _MeanReward     | 4.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.70052     |
| _max_adv        | 4.58        |
| _max_discrew    | 5.35        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00642943  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 4.11        |
| _mean_obs       | 0.0505      |
| _min_adv        | -5.23       |
| _min_discrew    | 0.0208      |
| _min_obs        | -1.15       |
| _std_act        | 0.725912    |
| _std_adv        | 1           |
| _std_discrew    | 1.61        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00346218 |
| Phi_loss        | 926.883    |
| PolicyEntropy   | 0.171237   |
| PolicyLoss      | -0.0282605 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0263     |
| _MeanReward     | 4.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91792    |
| _max_adv        | 3.58       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0077     |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.12       |
| _mean_obs       | 0.0507     |
| _min_adv        | -6.54      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.15      |
| _std_act        | 0.730424   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00274654  |
| Phi_loss        | 1116.43     |
| PolicyEntropy   | 0.15558     |
| PolicyLoss      | -0.0133531  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0198      |
| _MeanReward     | 4.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72341     |
| _max_adv        | 4.22        |
| _max_discrew    | 5.44        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00475722 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0465      |
| _min_adv        | -10.1       |
| _min_discrew    | -0.561      |
| _min_obs        | -1.14       |
| _std_act        | 0.755897    |
| _std_adv        | 1           |
| _std_discrew    | 3.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.93       |
| ExplainedVarOld | 0.836      |
| KL              | 0.00954017 |
| Phi_loss        | 339.705    |
| PolicyEntropy   | 0.163077   |
| PolicyLoss      | 0.0130121  |
| Steps           | 10000      |
| VarFuncLoss     | 0.215      |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66077    |
| _max_adv        | 21.2       |
| _max_discrew    | 5.4        |
| _max_obs        | 1.2        |
| _mean_act       | 0.0086018  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0509     |
| _min_adv        | -4.86      |
| _min_discrew    | 0.021      |
| _min_obs        | -1.15      |
| _std_act        | 0.732501   |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00218916 |
| Phi_loss        | 959.119    |
| PolicyEntropy   | 0.164868   |
| PolicyLoss      | 0.0126795  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0249     |
| _MeanReward     | 4.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72179    |
| _max_adv        | 14.6       |
| _max_discrew    | 5.39       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0098069  |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0508     |
| _min_adv        | -3.91      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.13      |
| _std_act        | 0.731583   |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00192811 |
| Phi_loss        | 970.562    |
| PolicyEntropy   | 0.146567   |
| PolicyLoss      | 0.0217933  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59763    |
| _max_adv        | 30.5       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00815381 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0507     |
| _min_adv        | -9.29      |
| _min_discrew    | 0.0218     |
| _min_obs        | -1.17      |
| _std_act        | 0.735043   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0166222  |
| Phi_loss        | 1066.26    |
| PolicyEntropy   | 0.14206    |
| PolicyLoss      | 0.342456   |
| Steps           | 10000      |
| VarFuncLoss     | 0.02       |
| _MeanReward     | 5.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69941    |
| _max_adv        | 12         |
| _max_discrew    | 5.4        |
| _max_obs        | 1.18       |
| _mean_act       | 0.00837834 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.15       |
| _mean_obs       | 0.0509     |
| _min_adv        | -4.79      |
| _min_discrew    | 0.0217     |
| _min_obs        | -1.16      |
| _std_act        | 0.731392   |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.0026396  |
| Phi_loss        | 1153.67    |
| PolicyEntropy   | 0.129223   |
| PolicyLoss      | -0.0154646 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 5.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6145     |
| _max_adv        | 3.3        |
| _max_discrew    | 5.44       |
| _max_obs        | 1.18       |
| _mean_act       | 0.00581877 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.14       |
| _mean_obs       | 0.0506     |
| _min_adv        | -4.74      |
| _min_discrew    | 0.00947    |
| _min_obs        | -1.17      |
| _std_act        | 0.733098   |
| _std_adv        | 1          |
| _std_discrew    | 1.63       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.000975526 |
| Phi_loss        | 1292.61     |
| PolicyEntropy   | 0.124373    |
| PolicyLoss      | -0.00050678 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0232      |
| _MeanReward     | 4.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81371     |
| _max_adv        | 14          |
| _max_discrew    | 5.4         |
| _max_obs        | 1.18        |
| _mean_act       | 0.00580621  |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 4.05        |
| _mean_obs       | 0.0497      |
| _min_adv        | -6.79       |
| _min_discrew    | 0.0151      |
| _min_obs        | -1.13       |
| _std_act        | 0.734155    |
| _std_adv        | 1           |
| _std_discrew    | 1.54        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00192427 |
| Phi_loss        | 1228.59    |
| PolicyEntropy   | 0.109559   |
| PolicyLoss      | -0.0171539 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0337     |
| _MeanReward     | 5.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94867    |
| _max_adv        | 14.7       |
| _max_discrew    | 5.49       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00465626 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.0513     |
| _min_adv        | -9.11      |
| _min_discrew    | 0.017      |
| _min_obs        | -1.13      |
| _std_act        | 0.732802   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00269807 |
| Phi_loss        | 1117.24    |
| PolicyEntropy   | 0.106126   |
| PolicyLoss      | -0.0180161 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0319     |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63872    |
| _max_adv        | 5.77       |
| _max_discrew    | 5.56       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00634996 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 4.13       |
| _mean_obs       | 0.0501     |
| _min_adv        | -5.13      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.13      |
| _std_act        | 0.736015   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00226757  |
| Phi_loss        | 1158.8      |
| PolicyEntropy   | 0.0950861   |
| PolicyLoss      | 0.0474917   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0317      |
| _MeanReward     | 5e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 2.74149     |
| _max_adv        | 6.24        |
| _max_discrew    | 5.37        |
| _max_obs        | 1.2         |
| _mean_act       | 0.000928985 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 4.14        |
| _mean_obs       | 0.0503      |
| _min_adv        | -5.67       |
| _min_discrew    | 0.0211      |
| _min_obs        | -1.15       |
| _std_act        | 0.732384    |
| _std_adv        | 1           |
| _std_discrew    | 1.63        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00192928 |
| Phi_loss        | 1188.75    |
| PolicyEntropy   | 0.0763254  |
| PolicyLoss      | -0.0141351 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 5.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59353    |
| _max_adv        | 25.9       |
| _max_discrew    | 5.53       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00549424 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.0511     |
| _min_adv        | -8.38      |
| _min_discrew    | 0.0193     |
| _min_obs        | -1.16      |
| _std_act        | 0.728075   |
| _std_adv        | 1          |
| _std_discrew    | 1.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00472452 |
| Phi_loss        | 829.594    |
| PolicyEntropy   | 0.0642138  |
| PolicyLoss      | -0.0104426 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0269     |
| _MeanReward     | 5e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.78846    |
| _max_adv        | 4.89       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00461407 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.15       |
| _mean_obs       | 0.0503     |
| _min_adv        | -4.51      |
| _min_discrew    | 0.021      |
| _min_obs        | -1.16      |
| _std_act        | 0.734685   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00220703 |
| Phi_loss        | 1156.74    |
| PolicyEntropy   | 0.0535269  |
| PolicyLoss      | 0.00217256 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0261     |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78528    |
| _max_adv        | 3.16       |
| _max_discrew    | 5.45       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00446334 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.14       |
| _mean_obs       | 0.0501     |
| _min_adv        | -6.23      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.23      |
| _std_act        | 0.733036   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00222319 |
| Phi_loss        | 1216.52    |
| PolicyEntropy   | 0.0388308  |
| PolicyLoss      | 0.00444731 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 5.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61265    |
| _max_adv        | 2.8        |
| _max_discrew    | 5.53       |
| _max_obs        | 1.17       |
| _mean_act       | 0.00926194 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.051      |
| _min_adv        | -6.07      |
| _min_discrew    | 0.0232     |
| _min_obs        | -1.13      |
| _std_act        | 0.733591   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.988        |
| ExplainedVarOld | 0.987        |
| KL              | 0.00199312   |
| Phi_loss        | 1220.75      |
| PolicyEntropy   | 0.018261     |
| PolicyLoss      | -0.000969377 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0201       |
| _MeanReward     | 4.48e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.79899      |
| _max_adv        | 3.32         |
| _max_discrew    | 5.54         |
| _max_obs        | 1.19         |
| _mean_act       | -0.0326367   |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | 3.73         |
| _mean_obs       | 0.0449       |
| _min_adv        | -18.1        |
| _min_discrew    | -0.884       |
| _min_obs        | -1.16        |
| _std_act        | 0.799464     |
| _std_adv        | 1            |
| _std_discrew    | 3.56         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.902      |
| KL              | 0.00624639 |
| Phi_loss        | 344.77     |
| PolicyEntropy   | 0.0181475  |
| PolicyLoss      | 0.0508272  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0356     |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64075    |
| _max_adv        | 10.7       |
| _max_discrew    | 5.6        |
| _max_obs        | 1.16       |
| _mean_act       | -0.0187196 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0459     |
| _min_adv        | -16.8      |
| _min_discrew    | -0.717     |
| _min_obs        | -1.18      |
| _std_act        | 0.775995   |
| _std_adv        | 1          |
| _std_discrew    | 3.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.902      |
| KL              | 0.00198398 |
| Phi_loss        | 997.403    |
| PolicyEntropy   | 0.0124636  |
| PolicyLoss      | -0.0195403 |
| Steps           | 10000      |
| VarFuncLoss     | 0.258      |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66798    |
| _max_adv        | 4.17       |
| _max_discrew    | 5.51       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0138213 |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0468     |
| _min_adv        | -19.9      |
| _min_discrew    | -0.715     |
| _min_obs        | -1.15      |
| _std_act        | 0.773307   |
| _std_adv        | 1          |
| _std_discrew    | 3.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.911       |
| KL              | 0.000887137 |
| Phi_loss        | 1111.39     |
| PolicyEntropy   | 0.0110226   |
| PolicyLoss      | -0.017912   |
| Steps           | 10000       |
| VarFuncLoss     | 0.261       |
| _MeanReward     | 5.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78191     |
| _max_adv        | 31.6        |
| _max_discrew    | 5.48        |
| _max_obs        | 1.19        |
| _mean_act       | 0.0115835   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 4.21        |
| _mean_obs       | 0.0517      |
| _min_adv        | -4.03       |
| _min_discrew    | 0.0187      |
| _min_obs        | -1.23       |
| _std_act        | 0.733223    |
| _std_adv        | 1           |
| _std_discrew    | 1.61        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.981       |
| KL              | 0.0126316   |
| Phi_loss        | 1042.91     |
| PolicyEntropy   | -0.00539684 |
| PolicyLoss      | -0.0874637  |
| Steps           | 10000       |
| VarFuncLoss     | 0.022       |
| _MeanReward     | 5e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 2.88411     |
| _max_adv        | 25.1        |
| _max_discrew    | 5.39        |
| _max_obs        | 1.18        |
| _mean_act       | 0.0100171   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.15        |
| _mean_obs       | 0.0509      |
| _min_adv        | -7.56       |
| _min_discrew    | 0.0195      |
| _min_obs        | -1.14       |
| _std_act        | 0.737347    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.973      |
| KL              | 0.0130018  |
| Phi_loss        | 2489.81    |
| PolicyEntropy   | 0.00722218 |
| PolicyLoss      | -0.228525  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0313     |
| _MeanReward     | 5.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75824    |
| _max_adv        | 5.13       |
| _max_discrew    | 5.52       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00680231 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0508     |
| _min_adv        | -4.46      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.17      |
| _std_act        | 0.733568   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00266234 |
| Phi_loss        | 1707.0     |
| PolicyEntropy   | 0.0143061  |
| PolicyLoss      | 0.0294284  |
| Steps           | 10000      |
| VarFuncLoss     | 0.023      |
| _MeanReward     | 5.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.62931    |
| _max_adv        | 17.6       |
| _max_discrew    | 5.48       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0015263 |
| _mean_adv       | 0          |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0505     |
| _min_adv        | -4.63      |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.18      |
| _std_act        | 0.730836   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.000688034 |
| Phi_loss        | 1282.77     |
| PolicyEntropy   | 0.0138807   |
| PolicyLoss      | -0.00931493 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0185      |
| _MeanReward     | 5.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.74524     |
| _max_adv        | 3.25        |
| _max_discrew    | 5.48        |
| _max_obs        | 1.21        |
| _mean_act       | 0.00681847  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 4.22        |
| _mean_obs       | 0.0507      |
| _min_adv        | -4.97       |
| _min_discrew    | 0.0206      |
| _min_obs        | -1.15       |
| _std_act        | 0.736287    |
| _std_adv        | 1           |
| _std_discrew    | 1.62        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00100563 |
| Phi_loss        | 1414.34    |
| PolicyEntropy   | 0.00707626 |
| PolicyLoss      | 0.0015412  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0249     |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79404    |
| _max_adv        | 4.2        |
| _max_discrew    | 5.48       |
| _max_obs        | 1.23       |
| _mean_act       | 0.00770582 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.2        |
| _mean_obs       | 0.0505     |
| _min_adv        | -5.76      |
| _min_discrew    | 0.0209     |
| _min_obs        | -1.13      |
| _std_act        | 0.732482   |
| _std_adv        | 1          |
| _std_discrew    | 1.62       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00190836  |
| Phi_loss        | 1472.17     |
| PolicyEntropy   | -0.00690746 |
| PolicyLoss      | -0.0133493  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0232      |
| _MeanReward     | 5.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66744     |
| _max_adv        | 7.11        |
| _max_discrew    | 5.57        |
| _max_obs        | 1.2         |
| _mean_act       | 0.00498301  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 4.22        |
| _mean_obs       | 0.0504      |
| _min_adv        | -5.57       |
| _min_discrew    | 0.0175      |
| _min_obs        | -1.17       |
| _std_act        | 0.73125     |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00178856  |
| Phi_loss        | 1348.72     |
| PolicyEntropy   | -0.00601578 |
| PolicyLoss      | -0.019795   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0199      |
| _MeanReward     | 4.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83896     |
| _max_adv        | 2.4         |
| _max_discrew    | 5.53        |
| _max_obs        | 1.17        |
| _mean_act       | 0.00397921  |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 4.13        |
| _mean_obs       | 0.0493      |
| _min_adv        | -4.29       |
| _min_discrew    | 0.02        |
| _min_obs        | -1.14       |
| _std_act        | 0.735937    |
| _std_adv        | 1           |
| _std_discrew    | 1.65        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00238175  |
| Phi_loss        | 1360.2      |
| PolicyEntropy   | -0.0210419  |
| PolicyLoss      | -0.00317567 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0278      |
| _MeanReward     | 5.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.99817     |
| _max_adv        | 6.43        |
| _max_discrew    | 5.47        |
| _max_obs        | 1.21        |
| _mean_act       | 0.00411645  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 4.17        |
| _mean_obs       | 0.0503      |
| _min_adv        | -7.06       |
| _min_discrew    | 0.0198      |
| _min_obs        | -1.15       |
| _std_act        | 0.736007    |
| _std_adv        | 1           |
| _std_discrew    | 1.67        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00204535  |
| Phi_loss        | 1435.24     |
| PolicyEntropy   | -0.0435781  |
| PolicyLoss      | 0.0182721   |
| Steps           | 10000       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 5.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68208     |
| _max_adv        | 4.55        |
| _max_discrew    | 5.49        |
| _max_obs        | 1.19        |
| _mean_act       | 0.000563988 |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 4.21        |
| _mean_obs       | 0.0503      |
| _min_adv        | -4.68       |
| _min_discrew    | 0.0229      |
| _min_obs        | -1.21       |
| _std_act        | 0.731824    |
| _std_adv        | 1           |
| _std_discrew    | 1.69        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.0019901  |
| Phi_loss        | 1342.97    |
| PolicyEntropy   | -0.0613546 |
| PolicyLoss      | -0.0282925 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0266     |
| _MeanReward     | 5.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63749    |
| _max_adv        | 3.37       |
| _max_discrew    | 5.53       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00444912 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.25       |
| _mean_obs       | 0.0505     |
| _min_adv        | -4.33      |
| _min_discrew    | 0.0196     |
| _min_obs        | -1.14      |
| _std_act        | 0.738193   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00171845  |
| Phi_loss        | 1252.23     |
| PolicyEntropy   | -0.0646725  |
| PolicyLoss      | -0.00669422 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0224      |
| _MeanReward     | 5.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76307     |
| _max_adv        | 4.55        |
| _max_discrew    | 5.43        |
| _max_obs        | 1.21        |
| _mean_act       | 0.00464472  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 4.23        |
| _mean_obs       | 0.0502      |
| _min_adv        | -6.92       |
| _min_discrew    | 0.0172      |
| _min_obs        | -1.14       |
| _std_act        | 0.738848    |
| _std_adv        | 1           |
| _std_discrew    | 1.66        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00180155 |
| Phi_loss        | 1321.1     |
| PolicyEntropy   | -0.0947046 |
| PolicyLoss      | 0.00296293 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0215     |
| _MeanReward     | 5.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79833    |
| _max_adv        | 3.21       |
| _max_discrew    | 5.52       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00581743 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0502     |
| _min_adv        | -7.67      |
| _min_discrew    | 0.0187     |
| _min_obs        | -1.17      |
| _std_act        | 0.73608    |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00209707 |
| Phi_loss        | 1217.79    |
| PolicyEntropy   | -0.0961046 |
| PolicyLoss      | -0.004595  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0251     |
| _MeanReward     | 5.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68112    |
| _max_adv        | 9.26       |
| _max_discrew    | 5.68       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0019696  |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 4.25       |
| _mean_obs       | 0.0504     |
| _min_adv        | -5.31      |
| _min_discrew    | 0.0191     |
| _min_obs        | -1.17      |
| _std_act        | 0.735471   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.0014315   |
| Phi_loss        | 1235.08     |
| PolicyEntropy   | -0.0956297  |
| PolicyLoss      | -0.00164637 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 5.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91361     |
| _max_adv        | 3.19        |
| _max_discrew    | 5.57        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00233874  |
| _mean_adv       | -2.42e-17   |
| _mean_discrew   | 4.2         |
| _mean_obs       | 0.05        |
| _min_adv        | -5.74       |
| _min_discrew    | 0.0154      |
| _min_obs        | -1.17       |
| _std_act        | 0.739588    |
| _std_adv        | 1           |
| _std_discrew    | 1.74        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00256812  |
| Phi_loss        | 1278.67     |
| PolicyEntropy   | -0.119118   |
| PolicyLoss      | -0.00262739 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0248      |
| _MeanReward     | 5.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68347     |
| _max_adv        | 3.17        |
| _max_discrew    | 5.62        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00441999  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 4.16        |
| _mean_obs       | 0.0492      |
| _min_adv        | -6.16       |
| _min_discrew    | 0.0228      |
| _min_obs        | -1.16       |
| _std_act        | 0.740785    |
| _std_adv        | 1           |
| _std_discrew    | 1.62        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00330575  |
| Phi_loss        | 1304.73     |
| PolicyEntropy   | -0.144784   |
| PolicyLoss      | 0.000317851 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0348      |
| _MeanReward     | 5.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77411     |
| _max_adv        | 4.67        |
| _max_discrew    | 5.61        |
| _max_obs        | 1.24        |
| _mean_act       | 0.00448354  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 4.29        |
| _mean_obs       | 0.051       |
| _min_adv        | -7.91       |
| _min_discrew    | 0.0161      |
| _min_obs        | -1.17       |
| _std_act        | 0.73568     |
| _std_adv        | 1           |
| _std_discrew    | 1.72        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00330815 |
| Phi_loss        | 1146.21    |
| PolicyEntropy   | -0.141862  |
| PolicyLoss      | -0.0208414 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0335     |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69949    |
| _max_adv        | 4.04       |
| _max_discrew    | 5.47       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00465077 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0498     |
| _min_adv        | -5.02      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.11      |
| _std_act        | 0.741549   |
| _std_adv        | 1          |
| _std_discrew    | 1.74       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00415017 |
| Phi_loss        | 1272.11    |
| PolicyEntropy   | -0.146922  |
| PolicyLoss      | -0.0117696 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 5.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81141    |
| _max_adv        | 4.02       |
| _max_discrew    | 5.54       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00391213 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.3        |
| _mean_obs       | 0.0506     |
| _min_adv        | -4.63      |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.17      |
| _std_act        | 0.739283   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00425142  |
| Phi_loss        | 1319.69     |
| PolicyEntropy   | -0.156844   |
| PolicyLoss      | -0.00917293 |
| Steps           | 10000       |
| VarFuncLoss     | 0.021       |
| _MeanReward     | 5.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.65409     |
| _max_adv        | 4.12        |
| _max_discrew    | 5.71        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00574036  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 4.31        |
| _mean_obs       | 0.0511      |
| _min_adv        | -8.74       |
| _min_discrew    | 0.0215      |
| _min_obs        | -1.15       |
| _std_act        | 0.737288    |
| _std_adv        | 1           |
| _std_discrew    | 1.76        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00306391 |
| Phi_loss        | 1178.13    |
| PolicyEntropy   | -0.169056  |
| PolicyLoss      | 0.00558185 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0247     |
| _MeanReward     | 5.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63807    |
| _max_adv        | 6.13       |
| _max_discrew    | 5.61       |
| _max_obs        | 1.17       |
| _mean_act       | 0.00279129 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.29       |
| _mean_obs       | 0.0504     |
| _min_adv        | -4.59      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.14      |
| _std_act        | 0.736998   |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.981       |
| KL              | 0.0029368   |
| Phi_loss        | 1330.93     |
| PolicyEntropy   | -0.168622   |
| PolicyLoss      | -0.0308041  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0303      |
| _MeanReward     | 5.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.69479     |
| _max_adv        | 3.16        |
| _max_discrew    | 5.5         |
| _max_obs        | 1.17        |
| _mean_act       | 0.000293271 |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | 4.22        |
| _mean_obs       | 0.0497      |
| _min_adv        | -13.9       |
| _min_discrew    | -0.146      |
| _min_obs        | -1.17       |
| _std_act        | 0.744182    |
| _std_adv        | 1           |
| _std_discrew    | 1.82        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00341454  |
| Phi_loss        | 945.972     |
| PolicyEntropy   | -0.181937   |
| PolicyLoss      | -0.00411633 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0447      |
| _MeanReward     | 5.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75797     |
| _max_adv        | 4.55        |
| _max_discrew    | 5.62        |
| _max_obs        | 1.23        |
| _mean_act       | 0.00602483  |
| _mean_adv       | 5.68e-17    |
| _mean_discrew   | 4.29        |
| _mean_obs       | 0.0508      |
| _min_adv        | -7.15       |
| _min_discrew    | 0.0193      |
| _min_obs        | -1.16       |
| _std_act        | 0.744297    |
| _std_adv        | 1           |
| _std_discrew    | 1.71        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00345282 |
| Phi_loss        | 1289.72    |
| PolicyEntropy   | -0.192102  |
| PolicyLoss      | 0.034068   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0239     |
| _MeanReward     | 5.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68447    |
| _max_adv        | 3.18       |
| _max_discrew    | 5.61       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0024326  |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 4.32       |
| _mean_obs       | 0.0511     |
| _min_adv        | -5.59      |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.13      |
| _std_act        | 0.737946   |
| _std_adv        | 1          |
| _std_discrew    | 1.8        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00339161  |
| Phi_loss        | 1193.15     |
| PolicyEntropy   | -0.20143    |
| PolicyLoss      | -0.00947607 |
| Steps           | 10000       |
| VarFuncLoss     | 0.028       |
| _MeanReward     | 5.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81188     |
| _max_adv        | 3.83        |
| _max_discrew    | 5.68        |
| _max_obs        | 1.19        |
| _mean_act       | 0.00597726  |
| _mean_adv       | 0           |
| _mean_discrew   | 4.3         |
| _mean_obs       | 0.0503      |
| _min_adv        | -5.03       |
| _min_discrew    | 0.0172      |
| _min_obs        | -1.14       |
| _std_act        | 0.739998    |
| _std_adv        | 1           |
| _std_discrew    | 1.67        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00395223  |
| Phi_loss        | 1427.28     |
| PolicyEntropy   | -0.217305   |
| PolicyLoss      | -0.0220475  |
| Steps           | 10000       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 5.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82773     |
| _max_adv        | 3.22        |
| _max_discrew    | 5.66        |
| _max_obs        | 1.17        |
| _mean_act       | -0.00087781 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 4.36        |
| _mean_obs       | 0.0508      |
| _min_adv        | -4.72       |
| _min_discrew    | 0.024       |
| _min_obs        | -1.16       |
| _std_act        | 0.744528    |
| _std_adv        | 1           |
| _std_discrew    | 1.7         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
