Logging to halfcheetah_unbiased--state-only_144
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
------------------------------
| Steps         | 10000      |
| _MeanReward   | -413       |
| _max_act      | 3.185      |
| _max_adv      | 3.4        |
| _max_discrew  | 0.039      |
| _max_obs      | 1.41       |
| _mean_act     | -0.0225239 |
| _mean_adv     | -3.13e-17  |
| _mean_discrew | -0.337     |
| _mean_obs     | 0.0646     |
| _min_adv      | -3.34      |
| _min_discrew  | -0.729     |
| _min_obs      | -1.27      |
| _std_act      | 0.418793   |
| _std_adv      | 1          |
| _std_discrew  | 0.0216     |
------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.314       |
| ExplainedVarOld | -1.68       |
| KL              | 0.000249937 |
| Phi_loss        | 2.17681     |
| PolicyEntropy   | 5.51606     |
| PolicyLoss      | -0.00248456 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0148      |
| _MeanReward     | -405        |
| _lr_multiplier  | 1           |
| _max_act        | 2.56649     |
| _max_adv        | 5.25        |
| _max_discrew    | 0.00211     |
| _max_obs        | 1.36        |
| _mean_act       | -0.0497075  |
| _mean_adv       | -1.25e-16   |
| _mean_discrew   | -0.326      |
| _mean_obs       | 0.0353      |
| _min_adv        | -3.52       |
| _min_discrew    | -0.613      |
| _min_obs        | -1.29       |
| _std_act        | 0.434831    |
| _std_adv        | 1           |
| _std_discrew    | 0.0161      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.461      |
| ExplainedVarOld | -0.224     |
| KL              | 0.00134693 |
| Phi_loss        | 13.9789    |
| PolicyEntropy   | 5.5171     |
| PolicyLoss      | 0.00106093 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0087     |
| _MeanReward     | -428       |
| _lr_multiplier  | 1          |
| _max_act        | 2.86108    |
| _max_adv        | 4.16       |
| _max_discrew    | 0.0314     |
| _max_obs        | 1.47       |
| _mean_act       | -0.0343286 |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | -0.342     |
| _mean_obs       | 0.0278     |
| _min_adv        | -3.86      |
| _min_discrew    | -0.672     |
| _min_obs        | -1.38      |
| _std_act        | 0.429664   |
| _std_adv        | 1          |
| _std_discrew    | 0.0176     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.5         |
| ExplainedVarOld | 0.413       |
| KL              | 0.00212739  |
| Phi_loss        | 23.988      |
| PolicyEntropy   | 5.51626     |
| PolicyLoss      | 0.000651556 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0088      |
| _MeanReward     | -361        |
| _lr_multiplier  | 1           |
| _max_act        | 2.60096     |
| _max_adv        | 3.21        |
| _max_discrew    | 0.0439      |
| _max_obs        | 1.32        |
| _mean_act       | -0.0459463  |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | -0.287      |
| _mean_obs       | 0.0253      |
| _min_adv        | -3.3        |
| _min_discrew    | -0.617      |
| _min_obs        | -1.23       |
| _std_act        | 0.43181     |
| _std_adv        | 1           |
| _std_discrew    | 0.0142      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.412      |
| ExplainedVarOld | 0.377      |
| KL              | 0.00145432 |
| Phi_loss        | 23.0705    |
| PolicyEntropy   | 5.50345    |
| PolicyLoss      | 0.00517589 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00903    |
| _MeanReward     | -343       |
| _lr_multiplier  | 1          |
| _max_act        | 2.61955    |
| _max_adv        | 4.29       |
| _max_discrew    | 0.0301     |
| _max_obs        | 1.26       |
| _mean_act       | -0.0444103 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.288     |
| _mean_obs       | 0.0238     |
| _min_adv        | -3.79      |
| _min_discrew    | -0.556     |
| _min_obs        | -1.79      |
| _std_act        | 0.428615   |
| _std_adv        | 1          |
| _std_discrew    | 0.0177     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.557      |
| ExplainedVarOld | 0.436      |
| KL              | 0.00662894 |
| Phi_loss        | 20.7464    |
| PolicyEntropy   | 5.53099    |
| PolicyLoss      | -0.008931  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00781    |
| _MeanReward     | -305       |
| _lr_multiplier  | 1          |
| _max_act        | 2.59413    |
| _max_adv        | 4.91       |
| _max_discrew    | 0.0648     |
| _max_obs        | 1.3        |
| _mean_act       | -0.0492485 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | -0.247     |
| _mean_obs       | 0.0351     |
| _min_adv        | -4.43      |
| _min_discrew    | -0.584     |
| _min_obs        | -1.52      |
| _std_act        | 0.439279   |
| _std_adv        | 1          |
| _std_discrew    | 0.0131     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.461      |
| ExplainedVarOld | 0.454      |
| KL              | 0.00153436 |
| Phi_loss        | 23.9715    |
| PolicyEntropy   | 5.53493    |
| PolicyLoss      | 0.00201472 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00759    |
| _MeanReward     | -318       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75276    |
| _max_adv        | 3.36       |
| _max_discrew    | 0.0587     |
| _max_obs        | 1.33       |
| _mean_act       | -0.0540357 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | -0.258     |
| _mean_obs       | 0.0338     |
| _min_adv        | -4.38      |
| _min_discrew    | -0.562     |
| _min_obs        | -1.61      |
| _std_act        | 0.438912   |
| _std_adv        | 1          |
| _std_discrew    | 0.0134     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.493       |
| ExplainedVarOld | 0.481       |
| KL              | 0.00131942  |
| Phi_loss        | 23.2162     |
| PolicyEntropy   | 5.53149     |
| PolicyLoss      | -0.00160551 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00682     |
| _MeanReward     | -276        |
| _lr_multiplier  | 1           |
| _max_act        | 2.6045      |
| _max_adv        | 3.58        |
| _max_discrew    | 0.0492      |
| _max_obs        | 1.42        |
| _mean_act       | -0.0526691  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | -0.223      |
| _mean_obs       | 0.0224      |
| _min_adv        | -3.4        |
| _min_discrew    | -0.509      |
| _min_obs        | -1.27       |
| _std_act        | 0.441058    |
| _std_adv        | 1           |
| _std_discrew    | 0.0129      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.464      |
| ExplainedVarOld | 0.412      |
| KL              | 0.00423989 |
| Phi_loss        | 23.4085    |
| PolicyEntropy   | 5.51993    |
| PolicyLoss      | 0.00392991 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00709    |
| _MeanReward     | -238       |
| _lr_multiplier  | 1          |
| _max_act        | 2.7005     |
| _max_adv        | 3.83       |
| _max_discrew    | 0.0802     |
| _max_obs        | 1.4        |
| _mean_act       | -0.0550508 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | -0.195     |
| _mean_obs       | 0.0303     |
| _min_adv        | -3.63      |
| _min_discrew    | -0.423     |
| _min_obs        | -1.43      |
| _std_act        | 0.442476   |
| _std_adv        | 1          |
| _std_discrew    | 0.0112     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.457       |
| ExplainedVarOld | 0.392       |
| KL              | 0.00269588  |
| Phi_loss        | 22.7994     |
| PolicyEntropy   | 5.52865     |
| PolicyLoss      | -0.00143966 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00642     |
| _MeanReward     | -276        |
| _lr_multiplier  | 1           |
| _max_act        | 2.8797      |
| _max_adv        | 3.37        |
| _max_discrew    | 0.035       |
| _max_obs        | 1.33        |
| _mean_act       | -0.0529005  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | -0.229      |
| _mean_obs       | 0.0314      |
| _min_adv        | -4.53       |
| _min_discrew    | -0.581      |
| _min_obs        | -1.22       |
| _std_act        | 0.44278     |
| _std_adv        | 1           |
| _std_discrew    | 0.0113      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.449      |
| ExplainedVarOld | 0.413      |
| KL              | 0.00331813 |
| Phi_loss        | 22.9715    |
| PolicyEntropy   | 5.50086    |
| PolicyLoss      | 0.00616169 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0066     |
| _MeanReward     | -238       |
| _lr_multiplier  | 1          |
| _max_act        | 2.69649    |
| _max_adv        | 3.47       |
| _max_discrew    | 0.0719     |
| _max_obs        | 1.39       |
| _mean_act       | -0.045265  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.189     |
| _mean_obs       | 0.0359     |
| _min_adv        | -3.66      |
| _min_discrew    | -0.503     |
| _min_obs        | -1.34      |
| _std_act        | 0.436675   |
| _std_adv        | 1          |
| _std_discrew    | 0.0103     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.323       |
| ExplainedVarOld | 0.286       |
| KL              | 0.00289678  |
| Phi_loss        | 23.7956     |
| PolicyEntropy   | 5.50133     |
| PolicyLoss      | -0.00153584 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00727     |
| _MeanReward     | -213        |
| _lr_multiplier  | 1           |
| _max_act        | 2.6644      |
| _max_adv        | 3.83        |
| _max_discrew    | 0.0536      |
| _max_obs        | 1.33        |
| _mean_act       | -0.0479157  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | -0.189      |
| _mean_obs       | 0.0408      |
| _min_adv        | -4.53       |
| _min_discrew    | -0.476      |
| _min_obs        | -1.42       |
| _std_act        | 0.434622    |
| _std_adv        | 1           |
| _std_discrew    | 0.0108      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.39       |
| ExplainedVarOld | 0.237      |
| KL              | 0.00348101 |
| Phi_loss        | 19.7576    |
| PolicyEntropy   | 5.45128    |
| PolicyLoss      | 0.0117678  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00664    |
| _MeanReward     | -192       |
| _lr_multiplier  | 1          |
| _max_act        | 3.45545    |
| _max_adv        | 3.1        |
| _max_discrew    | 0.089      |
| _max_obs        | 1.39       |
| _mean_act       | -0.0461201 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.156     |
| _mean_obs       | 0.0348     |
| _min_adv        | -3.68      |
| _min_discrew    | -0.513     |
| _min_obs        | -1.27      |
| _std_act        | 0.430277   |
| _std_adv        | 1          |
| _std_discrew    | 0.0116     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.271      |
| ExplainedVarOld | 0.231      |
| KL              | 0.00329621 |
| Phi_loss        | 22.4694    |
| PolicyEntropy   | 5.43057    |
| PolicyLoss      | 0.00177965 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00856    |
| _MeanReward     | -141       |
| _lr_multiplier  | 1          |
| _max_act        | 2.665      |
| _max_adv        | 3.82       |
| _max_discrew    | 0.141      |
| _max_obs        | 1.57       |
| _mean_act       | -0.0516129 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | -0.113     |
| _mean_obs       | 0.0312     |
| _min_adv        | -4.67      |
| _min_discrew    | -0.418     |
| _min_obs        | -1.39      |
| _std_act        | 0.430155   |
| _std_adv        | 1          |
| _std_discrew    | 0.00961    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.141      |
| ExplainedVarOld | 0.0424     |
| KL              | 0.00346998 |
| Phi_loss        | 22.5308    |
| PolicyEntropy   | 5.40934    |
| PolicyLoss      | 0.00517405 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00849    |
| _MeanReward     | -139       |
| _lr_multiplier  | 1          |
| _max_act        | 2.64594    |
| _max_adv        | 3.63       |
| _max_discrew    | 0.185      |
| _max_obs        | 1.27       |
| _mean_act       | -0.0555897 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.117     |
| _mean_obs       | 0.0341     |
| _min_adv        | -3.64      |
| _min_discrew    | -0.35      |
| _min_obs        | -1.25      |
| _std_act        | 0.430904   |
| _std_adv        | 1          |
| _std_discrew    | 0.00967    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.281      |
| ExplainedVarOld | 0.264      |
| KL              | 0.00548508 |
| Phi_loss        | 24.8986    |
| PolicyEntropy   | 5.37855    |
| PolicyLoss      | 0.00121466 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00698    |
| _MeanReward     | -91.2      |
| _lr_multiplier  | 1          |
| _max_act        | 3.27074    |
| _max_adv        | 3.98       |
| _max_discrew    | 0.216      |
| _max_obs        | 1.33       |
| _mean_act       | -0.057804  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.0803    |
| _mean_obs       | 0.0338     |
| _min_adv        | -3.82      |
| _min_discrew    | -0.349     |
| _min_obs        | -1.3       |
| _std_act        | 0.432636   |
| _std_adv        | 1          |
| _std_discrew    | 0.0134     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.242       |
| ExplainedVarOld | 0.162       |
| KL              | 0.00397999  |
| Phi_loss        | 23.2963     |
| PolicyEntropy   | 5.35933     |
| PolicyLoss      | -0.00218216 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0104      |
| _MeanReward     | -57         |
| _lr_multiplier  | 1           |
| _max_act        | 2.94431     |
| _max_adv        | 4.15        |
| _max_discrew    | 0.277       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0630053  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.0473     |
| _mean_obs       | 0.0336      |
| _min_adv        | -3.62       |
| _min_discrew    | -0.324      |
| _min_obs        | -1.31       |
| _std_act        | 0.432948    |
| _std_adv        | 1           |
| _std_discrew    | 0.0148      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.284      |
| ExplainedVarOld | 0.229      |
| KL              | 0.00302836 |
| Phi_loss        | 21.5292    |
| PolicyEntropy   | 5.36088    |
| PolicyLoss      | 0.00060298 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0108     |
| _MeanReward     | -52.5      |
| _lr_multiplier  | 1          |
| _max_act        | 2.98839    |
| _max_adv        | 4.17       |
| _max_discrew    | 0.248      |
| _max_obs        | 1.46       |
| _mean_act       | -0.0596652 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.0555    |
| _mean_obs       | 0.0367     |
| _min_adv        | -4         |
| _min_discrew    | -0.368     |
| _min_obs        | -1.41      |
| _std_act        | 0.430614   |
| _std_adv        | 1          |
| _std_discrew    | 0.0124     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.362       |
| ExplainedVarOld | 0.321       |
| KL              | 0.00263605  |
| Phi_loss        | 24.0808     |
| PolicyEntropy   | 5.36262     |
| PolicyLoss      | -0.00343428 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0079      |
| _MeanReward     | -55.1       |
| _lr_multiplier  | 1           |
| _max_act        | 2.7801      |
| _max_adv        | 3.59        |
| _max_discrew    | 0.366       |
| _max_obs        | 1.32        |
| _mean_act       | -0.0612345  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | -0.0396     |
| _mean_obs       | 0.0397      |
| _min_adv        | -4.5        |
| _min_discrew    | -0.384      |
| _min_obs        | -1.31       |
| _std_act        | 0.431006    |
| _std_adv        | 1           |
| _std_discrew    | 0.0134      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.413      |
| ExplainedVarOld | 0.373      |
| KL              | 0.00318904 |
| Phi_loss        | 21.9322    |
| PolicyEntropy   | 5.32816    |
| PolicyLoss      | 0.00600898 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00812    |
| _MeanReward     | -12.1      |
| _lr_multiplier  | 1          |
| _max_act        | 2.69241    |
| _max_adv        | 3.86       |
| _max_discrew    | 0.386      |
| _max_obs        | 1.29       |
| _mean_act       | -0.0593346 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.00727   |
| _mean_obs       | 0.0353     |
| _min_adv        | -3.2       |
| _min_discrew    | -0.255     |
| _min_obs        | -1.29      |
| _std_act        | 0.42851    |
| _std_adv        | 1          |
| _std_discrew    | 0.0106     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.227       |
| ExplainedVarOld | 0.199       |
| KL              | 0.00306156  |
| Phi_loss        | 24.7355     |
| PolicyEntropy   | 5.32558     |
| PolicyLoss      | -0.00534258 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00823     |
| _MeanReward     | 10.1        |
| _lr_multiplier  | 1           |
| _max_act        | 3.09148     |
| _max_adv        | 3.13        |
| _max_discrew    | 0.476       |
| _max_obs        | 1.28        |
| _mean_act       | -0.0629535  |
| _mean_adv       | 0           |
| _mean_discrew   | -0.00581    |
| _mean_obs       | 0.0303      |
| _min_adv        | -3.86       |
| _min_discrew    | -0.528      |
| _min_obs        | -1.4        |
| _std_act        | 0.431106    |
| _std_adv        | 1           |
| _std_discrew    | 0.0328      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.594       |
| ExplainedVarOld | 0.0365      |
| KL              | 0.00442593  |
| Phi_loss        | 15.0612     |
| PolicyEntropy   | 5.3127      |
| PolicyLoss      | -0.00521791 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0135      |
| _MeanReward     | 51.9        |
| _lr_multiplier  | 1           |
| _max_act        | 3.2722      |
| _max_adv        | 4.14        |
| _max_discrew    | 0.373       |
| _max_obs        | 1.32        |
| _mean_act       | -0.0620984  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 0.0493      |
| _mean_obs       | 0.0346      |
| _min_adv        | -4.82       |
| _min_discrew    | -0.235      |
| _min_obs        | -1.27       |
| _std_act        | 0.433873    |
| _std_adv        | 1           |
| _std_discrew    | 0.0115      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.195       |
| ExplainedVarOld | 0.153       |
| KL              | 0.00313381  |
| Phi_loss        | 24.7619     |
| PolicyEntropy   | 5.29404     |
| PolicyLoss      | 0.000382845 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00942     |
| _MeanReward     | -31.6       |
| _lr_multiplier  | 1           |
| _max_act        | 2.88412     |
| _max_adv        | 3.83        |
| _max_discrew    | 0.309       |
| _max_obs        | 1.33        |
| _mean_act       | -0.0615191  |
| _mean_adv       | 6.25e-17    |
| _mean_discrew   | -0.0328     |
| _mean_obs       | 0.0409      |
| _min_adv        | -3.9        |
| _min_discrew    | -0.401      |
| _min_obs        | -1.34       |
| _std_act        | 0.432287    |
| _std_adv        | 1           |
| _std_discrew    | 0.0225      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.484       |
| ExplainedVarOld | 0.422       |
| KL              | 0.00265148  |
| Phi_loss        | 25.3481     |
| PolicyEntropy   | 5.27906     |
| PolicyLoss      | -0.00220824 |
| Steps           | 10000       |
| VarFuncLoss     | 0.012       |
| _MeanReward     | 87.7        |
| _lr_multiplier  | 1           |
| _max_act        | 2.90096     |
| _max_adv        | 3.63        |
| _max_discrew    | 0.509       |
| _max_obs        | 1.44        |
| _mean_act       | -0.066025   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.0742      |
| _mean_obs       | 0.0372      |
| _min_adv        | -4.66       |
| _min_discrew    | -0.321      |
| _min_obs        | -1.28       |
| _std_act        | 0.438268    |
| _std_adv        | 1           |
| _std_discrew    | 0.0266      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.42        |
| ExplainedVarOld | 0.338       |
| KL              | 0.00275163  |
| Phi_loss        | 25.9021     |
| PolicyEntropy   | 5.27322     |
| PolicyLoss      | -0.00968924 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0163      |
| _MeanReward     | 80.9        |
| _lr_multiplier  | 1           |
| _max_act        | 2.8594      |
| _max_adv        | 4.15        |
| _max_discrew    | 0.473       |
| _max_obs        | 1.35        |
| _mean_act       | -0.0656843  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.0661      |
| _mean_obs       | 0.0386      |
| _min_adv        | -4.31       |
| _min_discrew    | -0.269      |
| _min_obs        | -1.41       |
| _std_act        | 0.446149    |
| _std_adv        | 1           |
| _std_discrew    | 0.0199      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.439       |
| ExplainedVarOld | 0.382       |
| KL              | 0.00306775  |
| Phi_loss        | 27.4103     |
| PolicyEntropy   | 5.2626      |
| PolicyLoss      | 0.000416215 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0111      |
| _MeanReward     | 56.5        |
| _lr_multiplier  | 1           |
| _max_act        | 2.90864     |
| _max_adv        | 3.54        |
| _max_discrew    | 0.451       |
| _max_obs        | 1.36        |
| _mean_act       | -0.0683169  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.0288      |
| _mean_obs       | 0.0359      |
| _min_adv        | -5.79       |
| _min_discrew    | -0.436      |
| _min_obs        | -1.37       |
| _std_act        | 0.439573    |
| _std_adv        | 1           |
| _std_discrew    | 0.0302      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.653       |
| ExplainedVarOld | 0.606       |
| KL              | 0.00421426  |
| Phi_loss        | 24.1349     |
| PolicyEntropy   | 5.26678     |
| PolicyLoss      | -0.00837967 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0105      |
| _MeanReward     | 175         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93178     |
| _max_adv        | 2.98        |
| _max_discrew    | 0.528       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0735436  |
| _mean_adv       | 9.95e-18    |
| _mean_discrew   | 0.133       |
| _mean_obs       | 0.0328      |
| _min_adv        | -4.57       |
| _min_discrew    | -0.25       |
| _min_obs        | -1.23       |
| _std_act        | 0.446132    |
| _std_adv        | 1           |
| _std_discrew    | 0.0255      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.306      |
| ExplainedVarOld | 0.278      |
| KL              | 0.00253264 |
| Phi_loss        | 28.5038    |
| PolicyEntropy   | 5.22495    |
| PolicyLoss      | 0.00230179 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 116        |
| _lr_multiplier  | 1          |
| _max_act        | 2.78505    |
| _max_adv        | 3.67       |
| _max_discrew    | 0.479      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0665421 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.0936     |
| _mean_obs       | 0.0357     |
| _min_adv        | -3.9       |
| _min_discrew    | -0.218     |
| _min_obs        | -1.33      |
| _std_act        | 0.439099   |
| _std_adv        | 1          |
| _std_discrew    | 0.0207     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.344      |
| ExplainedVarOld | 0.325      |
| KL              | 0.00328864 |
| Phi_loss        | 29.7575    |
| PolicyEntropy   | 5.19122    |
| PolicyLoss      | 0.00563574 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0137     |
| _MeanReward     | 136        |
| _lr_multiplier  | 1          |
| _max_act        | 3.18917    |
| _max_adv        | 2.99       |
| _max_discrew    | 0.577      |
| _max_obs        | 1.44       |
| _mean_act       | -0.0711655 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.112      |
| _mean_obs       | 0.0353     |
| _min_adv        | -4.9       |
| _min_discrew    | -0.259     |
| _min_obs        | -1.44      |
| _std_act        | 0.438509   |
| _std_adv        | 1          |
| _std_discrew    | 0.0289     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.494       |
| ExplainedVarOld | 0.469       |
| KL              | 0.00259615  |
| Phi_loss        | 27.6555     |
| PolicyEntropy   | 5.18976     |
| PolicyLoss      | -0.00437846 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0148      |
| _MeanReward     | 215         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02353     |
| _max_adv        | 3.55        |
| _max_discrew    | 0.54        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0730596  |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 0.179       |
| _mean_obs       | 0.0334      |
| _min_adv        | -5.56       |
| _min_discrew    | -0.195      |
| _min_obs        | -1.3        |
| _std_act        | 0.444535    |
| _std_adv        | 1           |
| _std_discrew    | 0.0224      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.433       |
| ExplainedVarOld | 0.386       |
| KL              | 0.00320878  |
| Phi_loss        | 28.0209     |
| PolicyEntropy   | 5.1633      |
| PolicyLoss      | -0.00174149 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0131      |
| _MeanReward     | 215         |
| _lr_multiplier  | 1           |
| _max_act        | 2.74434     |
| _max_adv        | 3.75        |
| _max_discrew    | 0.523       |
| _max_obs        | 1.33        |
| _mean_act       | -0.0806873  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.167       |
| _mean_obs       | 0.0309      |
| _min_adv        | -4.73       |
| _min_discrew    | -0.315      |
| _min_obs        | -1.33       |
| _std_act        | 0.451786    |
| _std_adv        | 1           |
| _std_discrew    | 0.0301      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.641       |
| ExplainedVarOld | 0.609       |
| KL              | 0.00383719  |
| Phi_loss        | 27.7792     |
| PolicyEntropy   | 5.14124     |
| PolicyLoss      | -0.00652442 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0108      |
| _MeanReward     | 265         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86438     |
| _max_adv        | 4.79        |
| _max_discrew    | 0.535       |
| _max_obs        | 1.48        |
| _mean_act       | -0.0790184  |
| _mean_adv       | 5.68e-17    |
| _mean_discrew   | 0.213       |
| _mean_obs       | 0.0314      |
| _min_adv        | -5.07       |
| _min_discrew    | -0.25       |
| _min_obs        | -1.44       |
| _std_act        | 0.448901    |
| _std_adv        | 1           |
| _std_discrew    | 0.0198      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.461       |
| ExplainedVarOld | 0.435       |
| KL              | 0.00288446  |
| Phi_loss        | 26.5368     |
| PolicyEntropy   | 5.1336      |
| PolicyLoss      | -0.00158632 |
| Steps           | 10000       |
| VarFuncLoss     | 0.011       |
| _MeanReward     | 290         |
| _lr_multiplier  | 1           |
| _max_act        | 2.75553     |
| _max_adv        | 3.4         |
| _max_discrew    | 0.584       |
| _max_obs        | 1.34        |
| _mean_act       | -0.0821429  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.244       |
| _mean_obs       | 0.0337      |
| _min_adv        | -4.67       |
| _min_discrew    | -0.222      |
| _min_obs        | -1.42       |
| _std_act        | 0.452904    |
| _std_adv        | 1           |
| _std_discrew    | 0.0229      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.357       |
| ExplainedVarOld | 0.333       |
| KL              | 0.00262332  |
| Phi_loss        | 30.2665     |
| PolicyEntropy   | 5.11581     |
| PolicyLoss      | -0.00706836 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0149      |
| _MeanReward     | 264         |
| _lr_multiplier  | 1           |
| _max_act        | 2.76522     |
| _max_adv        | 4.94        |
| _max_discrew    | 0.71        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0812043  |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.218       |
| _mean_obs       | 0.0358      |
| _min_adv        | -5.49       |
| _min_discrew    | -0.268      |
| _min_obs        | -1.46       |
| _std_act        | 0.459071    |
| _std_adv        | 1           |
| _std_discrew    | 0.0377      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.499      |
| ExplainedVarOld | 0.448      |
| KL              | 0.00297653 |
| Phi_loss        | 28.2769    |
| PolicyEntropy   | 5.08033    |
| PolicyLoss      | 0.00165465 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 292        |
| _lr_multiplier  | 1          |
| _max_act        | 2.77616    |
| _max_adv        | 3.38       |
| _max_discrew    | 0.679      |
| _max_obs        | 1.54       |
| _mean_act       | -0.0812934 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.24       |
| _mean_obs       | 0.0335     |
| _min_adv        | -4.77      |
| _min_discrew    | -0.183     |
| _min_obs        | -1.48      |
| _std_act        | 0.455227   |
| _std_adv        | 1          |
| _std_discrew    | 0.0283     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.519       |
| ExplainedVarOld | 0.5         |
| KL              | 0.00262245  |
| Phi_loss        | 31.0638     |
| PolicyEntropy   | 5.05215     |
| PolicyLoss      | -0.00303058 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0137      |
| _MeanReward     | 300         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87287     |
| _max_adv        | 3.72        |
| _max_discrew    | 0.739       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0823241  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 0.238       |
| _mean_obs       | 0.0209      |
| _min_adv        | -4.8        |
| _min_discrew    | -0.452      |
| _min_obs        | -1.32       |
| _std_act        | 0.46002     |
| _std_adv        | 1           |
| _std_discrew    | 0.0624      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.712      |
| ExplainedVarOld | 0.378      |
| KL              | 0.00313282 |
| Phi_loss        | 21.7643    |
| PolicyEntropy   | 5.0314     |
| PolicyLoss      | 0.00495432 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 366        |
| _lr_multiplier  | 1          |
| _max_act        | 3.30068    |
| _max_adv        | 4.77       |
| _max_discrew    | 0.65       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0900977 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.298      |
| _mean_obs       | 0.0299     |
| _min_adv        | -4.46      |
| _min_discrew    | -0.134     |
| _min_obs        | -1.27      |
| _std_act        | 0.452062   |
| _std_adv        | 1          |
| _std_discrew    | 0.0209     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.484       |
| ExplainedVarOld | 0.427       |
| KL              | 0.00315121  |
| Phi_loss        | 30.0422     |
| PolicyEntropy   | 5.03196     |
| PolicyLoss      | -0.00721489 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0108      |
| _MeanReward     | 378         |
| _lr_multiplier  | 1           |
| _max_act        | 2.79223     |
| _max_adv        | 3.3         |
| _max_discrew    | 0.733       |
| _max_obs        | 1.38        |
| _mean_act       | -0.0903476  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.292       |
| _mean_obs       | 0.0333      |
| _min_adv        | -4.41       |
| _min_discrew    | -0.402      |
| _min_obs        | -1.48       |
| _std_act        | 0.474515    |
| _std_adv        | 1           |
| _std_discrew    | 0.0507      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.542      |
| ExplainedVarOld | 0.317      |
| KL              | 0.00562782 |
| Phi_loss        | 26.7553    |
| PolicyEntropy   | 4.99668    |
| PolicyLoss      | 0.00967202 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0233     |
| _MeanReward     | 331        |
| _lr_multiplier  | 1          |
| _max_act        | 2.83783    |
| _max_adv        | 4.55       |
| _max_discrew    | 0.691      |
| _max_obs        | 1.38       |
| _mean_act       | -0.0917248 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.258      |
| _mean_obs       | 0.0327     |
| _min_adv        | -5.42      |
| _min_discrew    | -0.211     |
| _min_obs        | -1.31      |
| _std_act        | 0.45439    |
| _std_adv        | 1          |
| _std_discrew    | 0.0315     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.543      |
| ExplainedVarOld | 0.508      |
| KL              | 0.00448931 |
| Phi_loss        | 35.2096    |
| PolicyEntropy   | 5.00013    |
| PolicyLoss      | -0.0170745 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0148     |
| _MeanReward     | 423        |
| _lr_multiplier  | 1          |
| _max_act        | 3.74356    |
| _max_adv        | 3.54       |
| _max_discrew    | 0.732      |
| _max_obs        | 1.6        |
| _mean_act       | -0.0916942 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.33       |
| _mean_obs       | 0.0342     |
| _min_adv        | -5.51      |
| _min_discrew    | -0.0723    |
| _min_obs        | -1.7       |
| _std_act        | 0.46674    |
| _std_adv        | 1          |
| _std_discrew    | 0.0341     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.502       |
| ExplainedVarOld | 0.49        |
| KL              | 0.0029774   |
| Phi_loss        | 35.4184     |
| PolicyEntropy   | 4.98016     |
| PolicyLoss      | -0.00407943 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0181      |
| _MeanReward     | 475         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86691     |
| _max_adv        | 4           |
| _max_discrew    | 0.856       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0947271  |
| _mean_adv       | 5.26e-17    |
| _mean_discrew   | 0.374       |
| _mean_obs       | 0.0313      |
| _min_adv        | -5.79       |
| _min_discrew    | -0.11       |
| _min_obs        | -1.19       |
| _std_act        | 0.465591    |
| _std_adv        | 1           |
| _std_discrew    | 0.0342      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.695        |
| ExplainedVarOld | 0.629        |
| KL              | 0.00266648   |
| Phi_loss        | 33.1015      |
| PolicyEntropy   | 4.97637      |
| PolicyLoss      | -0.000345203 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0108       |
| _MeanReward     | 511          |
| _lr_multiplier  | 1            |
| _max_act        | 2.82369      |
| _max_adv        | 2.95         |
| _max_discrew    | 0.876        |
| _max_obs        | 1.43         |
| _mean_act       | -0.0959878   |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 0.424        |
| _mean_obs       | 0.0307       |
| _min_adv        | -5.58        |
| _min_discrew    | -0.0103      |
| _min_obs        | -1.42        |
| _std_act        | 0.468523     |
| _std_adv        | 1            |
| _std_discrew    | 0.0323       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.656       |
| ExplainedVarOld | 0.615       |
| KL              | 0.00320861  |
| Phi_loss        | 34.2837     |
| PolicyEntropy   | 4.95627     |
| PolicyLoss      | -0.00509041 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0118      |
| _MeanReward     | 449         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90156     |
| _max_adv        | 2.95        |
| _max_discrew    | 0.907       |
| _max_obs        | 1.57        |
| _mean_act       | -0.097884   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.363       |
| _mean_obs       | 0.03        |
| _min_adv        | -4.57       |
| _min_discrew    | -0.128      |
| _min_obs        | -1.36       |
| _std_act        | 0.472002    |
| _std_adv        | 1           |
| _std_discrew    | 0.0386      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.526       |
| ExplainedVarOld | 0.5         |
| KL              | 0.0064314   |
| Phi_loss        | 36.58       |
| PolicyEntropy   | 4.93714     |
| PolicyLoss      | -0.00530682 |
| Steps           | 10000       |
| VarFuncLoss     | 0.019       |
| _MeanReward     | 439         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19414     |
| _max_adv        | 3.8         |
| _max_discrew    | 0.868       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0867826  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.334       |
| _mean_obs       | 0.0364      |
| _min_adv        | -4.96       |
| _min_discrew    | -0.425      |
| _min_obs        | -1.37       |
| _std_act        | 0.501867    |
| _std_adv        | 1           |
| _std_discrew    | 0.0556      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.74        |
| ExplainedVarOld | 0.637       |
| KL              | 0.00119908  |
| Phi_loss        | 31.3718     |
| PolicyEntropy   | 4.92908     |
| PolicyLoss      | -0.00107005 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0145      |
| _MeanReward     | 485         |
| _lr_multiplier  | 1           |
| _max_act        | 3.26886     |
| _max_adv        | 3.79        |
| _max_discrew    | 0.941       |
| _max_obs        | 1.36        |
| _mean_act       | -0.0925441  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.383       |
| _mean_obs       | 0.0331      |
| _min_adv        | -7.78       |
| _min_discrew    | -0.462      |
| _min_obs        | -1.36       |
| _std_act        | 0.499156    |
| _std_adv        | 1           |
| _std_discrew    | 0.0654      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.672      |
| ExplainedVarOld | 0.656      |
| KL              | 0.00284751 |
| Phi_loss        | 34.678     |
| PolicyEntropy   | 4.90769    |
| PolicyLoss      | 0.00366823 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 490        |
| _lr_multiplier  | 1          |
| _max_act        | 2.80825    |
| _max_adv        | 5.96       |
| _max_discrew    | 0.863      |
| _max_obs        | 1.52       |
| _mean_act       | -0.0939297 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.395      |
| _mean_obs       | 0.033      |
| _min_adv        | -5.15      |
| _min_discrew    | -0.201     |
| _min_obs        | -1.42      |
| _std_act        | 0.472142   |
| _std_adv        | 1          |
| _std_discrew    | 0.0486     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.607       |
| ExplainedVarOld | 0.573       |
| KL              | 0.00396907  |
| Phi_loss        | 34.9623     |
| PolicyEntropy   | 4.87911     |
| PolicyLoss      | -0.00312403 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0191      |
| _MeanReward     | 595         |
| _lr_multiplier  | 1           |
| _max_act        | 2.78353     |
| _max_adv        | 3.11        |
| _max_discrew    | 0.966       |
| _max_obs        | 1.37        |
| _mean_act       | -0.102372   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.478       |
| _mean_obs       | 0.0319      |
| _min_adv        | -4.91       |
| _min_discrew    | -0.0177     |
| _min_obs        | -1.49       |
| _std_act        | 0.472295    |
| _std_adv        | 1           |
| _std_discrew    | 0.0439      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.618      |
| ExplainedVarOld | 0.616      |
| KL              | 0.00345114 |
| Phi_loss        | 39.2848    |
| PolicyEntropy   | 4.83783    |
| PolicyLoss      | 0.00574101 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0174     |
| _MeanReward     | 615        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0787     |
| _max_adv        | 5.69       |
| _max_discrew    | 1.07       |
| _max_obs        | 1.63       |
| _mean_act       | -0.0947495 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.489      |
| _mean_obs       | 0.0349     |
| _min_adv        | -7.7       |
| _min_discrew    | -0.416     |
| _min_obs        | -1.47      |
| _std_act        | 0.504694   |
| _std_adv        | 1          |
| _std_discrew    | 0.078      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.722      |
| ExplainedVarOld | 0.708      |
| KL              | 0.00439936 |
| Phi_loss        | 38.0505    |
| PolicyEntropy   | 4.81818    |
| PolicyLoss      | -0.0041525 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0219     |
| _MeanReward     | 721        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8383     |
| _max_adv        | 5.39       |
| _max_discrew    | 1.12       |
| _max_obs        | 1.39       |
| _mean_act       | -0.109092  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.584      |
| _mean_obs       | 0.0324     |
| _min_adv        | -5.57      |
| _min_discrew    | -0.00438   |
| _min_obs        | -1.53      |
| _std_act        | 0.479349   |
| _std_adv        | 1          |
| _std_discrew    | 0.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.737       |
| ExplainedVarOld | 0.718       |
| KL              | 0.00349138  |
| Phi_loss        | 39.8962     |
| PolicyEntropy   | 4.78441     |
| PolicyLoss      | -0.00360373 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0142      |
| _MeanReward     | 660         |
| _lr_multiplier  | 1           |
| _max_act        | 3.29973     |
| _max_adv        | 3.49        |
| _max_discrew    | 1.05        |
| _max_obs        | 1.35        |
| _mean_act       | -0.106346   |
| _mean_adv       | -2.13e-17   |
| _mean_discrew   | 0.532       |
| _mean_obs       | 0.0344      |
| _min_adv        | -10.6       |
| _min_discrew    | -0.555      |
| _min_obs        | -1.33       |
| _std_act        | 0.528281    |
| _std_adv        | 1           |
| _std_discrew    | 0.124       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.816      |
| ExplainedVarOld | 0.794      |
| KL              | 0.00566307 |
| Phi_loss        | 38.8017    |
| PolicyEntropy   | 4.80814    |
| PolicyLoss      | -0.0138343 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0227     |
| _MeanReward     | 635        |
| _lr_multiplier  | 1          |
| _max_act        | 2.9303     |
| _max_adv        | 6.94       |
| _max_discrew    | 1.01       |
| _max_obs        | 1.42       |
| _mean_act       | -0.102181  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.521      |
| _mean_obs       | 0.0351     |
| _min_adv        | -6.81      |
| _min_discrew    | -0.0288    |
| _min_obs        | -1.36      |
| _std_act        | 0.501162   |
| _std_adv        | 1          |
| _std_discrew    | 0.0514     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.628      |
| ExplainedVarOld | 0.606      |
| KL              | 0.00304585 |
| Phi_loss        | 36.5112    |
| PolicyEntropy   | 4.78345    |
| PolicyLoss      | 0.00379535 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 531        |
| _lr_multiplier  | 1          |
| _max_act        | 3.33039    |
| _max_adv        | 3.16       |
| _max_discrew    | 1.06       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0945645 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.405      |
| _mean_obs       | 0.0378     |
| _min_adv        | -10.5      |
| _min_discrew    | -0.54      |
| _min_obs        | -1.35      |
| _std_act        | 0.572877   |
| _std_adv        | 1          |
| _std_discrew    | 0.186      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.824      |
| ExplainedVarOld | 0.816      |
| KL              | 0.00377504 |
| Phi_loss        | 37.1869    |
| PolicyEntropy   | 4.75957    |
| PolicyLoss      | 0.00521939 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0326     |
| _MeanReward     | 793        |
| _lr_multiplier  | 1          |
| _max_act        | 2.59729    |
| _max_adv        | 4.65       |
| _max_discrew    | 1.1        |
| _max_obs        | 1.53       |
| _mean_act       | -0.115203  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.643      |
| _mean_obs       | 0.0329     |
| _min_adv        | -5.45      |
| _min_discrew    | 0.000365   |
| _min_obs        | -1.41      |
| _std_act        | 0.48995    |
| _std_adv        | 1          |
| _std_discrew    | 0.0546     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.695       |
| ExplainedVarOld | 0.692       |
| KL              | 0.00286644  |
| Phi_loss        | 44.752      |
| PolicyEntropy   | 4.73868     |
| PolicyLoss      | -0.00589441 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0188      |
| _MeanReward     | 655         |
| _lr_multiplier  | 1           |
| _max_act        | 3.50467     |
| _max_adv        | 6.69        |
| _max_discrew    | 1.25        |
| _max_obs        | 1.56        |
| _mean_act       | -0.104613   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.536       |
| _mean_obs       | 0.0368      |
| _min_adv        | -10.3       |
| _min_discrew    | -0.552      |
| _min_obs        | -1.54       |
| _std_act        | 0.541435    |
| _std_adv        | 1           |
| _std_discrew    | 0.155       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.773       |
| ExplainedVarOld | 0.749       |
| KL              | 0.00289369  |
| Phi_loss        | 36.6867     |
| PolicyEntropy   | 4.72465     |
| PolicyLoss      | -0.00505761 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0352      |
| _MeanReward     | 748         |
| _lr_multiplier  | 1           |
| _max_act        | 2.79291     |
| _max_adv        | 5.99        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.54        |
| _mean_act       | -0.114386   |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | 0.619       |
| _mean_obs       | 0.034       |
| _min_adv        | -5.07       |
| _min_discrew    | -0.0705     |
| _min_obs        | -1.29       |
| _std_act        | 0.490359    |
| _std_adv        | 1           |
| _std_discrew    | 0.073       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.673       |
| ExplainedVarOld | 0.649       |
| KL              | 0.00358852  |
| Phi_loss        | 40.2953     |
| PolicyEntropy   | 4.70145     |
| PolicyLoss      | -0.00295876 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0239      |
| _MeanReward     | 791         |
| _lr_multiplier  | 1           |
| _max_act        | 3.09115     |
| _max_adv        | 4.6         |
| _max_discrew    | 1.29        |
| _max_obs        | 1.52        |
| _mean_act       | -0.113295   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.624       |
| _mean_obs       | 0.0365      |
| _min_adv        | -5.84       |
| _min_discrew    | -0.0908     |
| _min_obs        | -1.47       |
| _std_act        | 0.503525    |
| _std_adv        | 1           |
| _std_discrew    | 0.115       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.752      |
| ExplainedVarOld | 0.625      |
| KL              | 0.00361794 |
| Phi_loss        | 36.5382    |
| PolicyEntropy   | 4.69136    |
| PolicyLoss      | -0.0139326 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0285     |
| _MeanReward     | 810        |
| _lr_multiplier  | 1          |
| _max_act        | 2.76969    |
| _max_adv        | 4.08       |
| _max_discrew    | 1.29       |
| _max_obs        | 1.51       |
| _mean_act       | -0.120547  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.665      |
| _mean_obs       | 0.0338     |
| _min_adv        | -6.66      |
| _min_discrew    | -0.0601    |
| _min_obs        | -1.34      |
| _std_act        | 0.504216   |
| _std_adv        | 1          |
| _std_discrew    | 0.0791     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.58        |
| ExplainedVarOld | 0.517       |
| KL              | 0.00430868  |
| Phi_loss        | 40.279      |
| PolicyEntropy   | 4.65982     |
| PolicyLoss      | -0.00308016 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0337      |
| _MeanReward     | 899         |
| _lr_multiplier  | 1           |
| _max_act        | 3.17992     |
| _max_adv        | 4.94        |
| _max_discrew    | 1.49        |
| _max_obs        | 1.49        |
| _mean_act       | -0.114002   |
| _mean_adv       | -5.26e-17   |
| _mean_discrew   | 0.743       |
| _mean_obs       | 0.0362      |
| _min_adv        | -6.04       |
| _min_discrew    | -0.0665     |
| _min_obs        | -1.45       |
| _std_act        | 0.521777    |
| _std_adv        | 1           |
| _std_discrew    | 0.085       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.724       |
| ExplainedVarOld | 0.724       |
| KL              | 0.00375075  |
| Phi_loss        | 47.4041     |
| PolicyEntropy   | 4.63772     |
| PolicyLoss      | -0.00573162 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0243      |
| _MeanReward     | 915         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03783     |
| _max_adv        | 3.65        |
| _max_discrew    | 1.39        |
| _max_obs        | 1.51        |
| _mean_act       | -0.12074    |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.747       |
| _mean_obs       | 0.0365      |
| _min_adv        | -5.84       |
| _min_discrew    | -0.0551     |
| _min_obs        | -1.35       |
| _std_act        | 0.520809    |
| _std_adv        | 1           |
| _std_discrew    | 0.116       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.658       |
| ExplainedVarOld | 0.636       |
| KL              | 0.0034607   |
| Phi_loss        | 46.7659     |
| PolicyEntropy   | 4.63329     |
| PolicyLoss      | -0.00834837 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0399      |
| _MeanReward     | 892         |
| _lr_multiplier  | 1           |
| _max_act        | 2.80519     |
| _max_adv        | 4.3         |
| _max_discrew    | 1.33        |
| _max_obs        | 1.43        |
| _mean_act       | -0.118513   |
| _mean_adv       | 4.97e-18    |
| _mean_discrew   | 0.728       |
| _mean_obs       | 0.0381      |
| _min_adv        | -4.93       |
| _min_discrew    | -0.00455    |
| _min_obs        | -1.37       |
| _std_act        | 0.524281    |
| _std_adv        | 1           |
| _std_discrew    | 0.0902      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.63       |
| ExplainedVarOld | 0.613      |
| KL              | 0.00253032 |
| Phi_loss        | 45.4433    |
| PolicyEntropy   | 4.60107    |
| PolicyLoss      | 0.00139837 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0335     |
| _MeanReward     | 883        |
| _lr_multiplier  | 1          |
| _max_act        | 2.75974    |
| _max_adv        | 2.95       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.45       |
| _mean_act       | -0.112542  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.72       |
| _mean_obs       | 0.0392     |
| _min_adv        | -4.92      |
| _min_discrew    | -0.166     |
| _min_obs        | -1.35      |
| _std_act        | 0.521888   |
| _std_adv        | 1          |
| _std_discrew    | 0.136      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.563      |
| ExplainedVarOld | 0.523      |
| KL              | 0.0028787  |
| Phi_loss        | 41.5712    |
| PolicyEntropy   | 4.60717    |
| PolicyLoss      | -0.0117525 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0597     |
| _MeanReward     | 968        |
| _lr_multiplier  | 1          |
| _max_act        | 2.87223    |
| _max_adv        | 4.16       |
| _max_discrew    | 1.42       |
| _max_obs        | 1.41       |
| _mean_act       | -0.118174  |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 0.784      |
| _mean_obs       | 0.0375     |
| _min_adv        | -5.64      |
| _min_discrew    | -0.00225   |
| _min_obs        | -1.45      |
| _std_act        | 0.532623   |
| _std_adv        | 1          |
| _std_discrew    | 0.0923     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.677      |
| ExplainedVarOld | 0.678      |
| KL              | 0.00365713 |
| Phi_loss        | 41.6873    |
| PolicyEntropy   | 4.58291    |
| PolicyLoss      | 0.00103288 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0299     |
| _MeanReward     | 971        |
| _lr_multiplier  | 1          |
| _max_act        | 2.796      |
| _max_adv        | 4.78       |
| _max_discrew    | 1.58       |
| _max_obs        | 1.46       |
| _mean_act       | -0.120441  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.798      |
| _mean_obs       | 0.0379     |
| _min_adv        | -5.62      |
| _min_discrew    | -0.0243    |
| _min_obs        | -1.38      |
| _std_act        | 0.528356   |
| _std_adv        | 1          |
| _std_discrew    | 0.135      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.709       |
| ExplainedVarOld | 0.675       |
| KL              | 0.00313042  |
| Phi_loss        | 42.3371     |
| PolicyEntropy   | 4.56728     |
| PolicyLoss      | -0.00222297 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0392      |
| _MeanReward     | 979         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06581     |
| _max_adv        | 4.67        |
| _max_discrew    | 1.36        |
| _max_obs        | 1.39        |
| _mean_act       | -0.119047   |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.804       |
| _mean_obs       | 0.0369      |
| _min_adv        | -5.78       |
| _min_discrew    | -0.00653    |
| _min_obs        | -1.78       |
| _std_act        | 0.534673    |
| _std_adv        | 1           |
| _std_discrew    | 0.0996      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.639       |
| ExplainedVarOld | 0.6         |
| KL              | 0.00375106  |
| Phi_loss        | 44.2681     |
| PolicyEntropy   | 4.5432      |
| PolicyLoss      | -0.00416699 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0359      |
| _MeanReward     | 942         |
| _lr_multiplier  | 1           |
| _max_act        | 3.28393     |
| _max_adv        | 3.45        |
| _max_discrew    | 1.59        |
| _max_obs        | 1.6         |
| _mean_act       | -0.117124   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.751       |
| _mean_obs       | 0.0405      |
| _min_adv        | -7.73       |
| _min_discrew    | -0.774      |
| _min_obs        | -1.5        |
| _std_act        | 0.616347    |
| _std_adv        | 1           |
| _std_discrew    | 0.264       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.761       |
| ExplainedVarOld | 0.637       |
| KL              | 0.0034936   |
| Phi_loss        | 39.1372     |
| PolicyEntropy   | 4.52702     |
| PolicyLoss      | -0.00725291 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0631      |
| _MeanReward     | 1.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.31712     |
| _max_adv        | 3.36        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.46        |
| _mean_act       | -0.122444   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.89        |
| _mean_obs       | 0.0391      |
| _min_adv        | -11.5       |
| _min_discrew    | -0.662      |
| _min_obs        | -1.42       |
| _std_act        | 0.595552    |
| _std_adv        | 1           |
| _std_discrew    | 0.254       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.796      |
| ExplainedVarOld | 0.755      |
| KL              | 0.00270962 |
| Phi_loss        | 42.5925    |
| PolicyEntropy   | 4.51266    |
| PolicyLoss      | 0.00248128 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0529     |
| _MeanReward     | 1.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06343    |
| _max_adv        | 5.47       |
| _max_discrew    | 1.68       |
| _max_obs        | 1.49       |
| _mean_act       | -0.124694  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.935      |
| _mean_obs       | 0.0378     |
| _min_adv        | -5.91      |
| _min_discrew    | -0.00282   |
| _min_obs        | -1.34      |
| _std_act        | 0.546146   |
| _std_adv        | 1          |
| _std_discrew    | 0.129      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.719       |
| ExplainedVarOld | 0.712       |
| KL              | 0.0025657   |
| Phi_loss        | 47.219      |
| PolicyEntropy   | 4.4945      |
| PolicyLoss      | -0.00648427 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0362      |
| _MeanReward     | 1.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.69682     |
| _max_adv        | 3.29        |
| _max_discrew    | 1.58        |
| _max_obs        | 1.45        |
| _mean_act       | -0.115257   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.805       |
| _mean_obs       | 0.0414      |
| _min_adv        | -10.5       |
| _min_discrew    | -0.769      |
| _min_obs        | -1.39       |
| _std_act        | 0.616064    |
| _std_adv        | 1           |
| _std_discrew    | 0.307       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.735       |
| ExplainedVarOld | 0.708       |
| KL              | 0.00323022  |
| Phi_loss        | 44.5229     |
| PolicyEntropy   | 4.46651     |
| PolicyLoss      | -0.00378345 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0815      |
| _MeanReward     | 1.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.5153      |
| _max_adv        | 3.66        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.4         |
| _mean_act       | -0.122041   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.908       |
| _mean_obs       | 0.0398      |
| _min_adv        | -10.4       |
| _min_discrew    | -0.682      |
| _min_obs        | -1.3        |
| _std_act        | 0.598975    |
| _std_adv        | 1           |
| _std_discrew    | 0.219       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.746      |
| ExplainedVarOld | 0.738      |
| KL              | 0.0041397  |
| Phi_loss        | 47.7455    |
| PolicyEntropy   | 4.45547    |
| PolicyLoss      | -0.0132003 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0557     |
| _MeanReward     | 1.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.02649    |
| _max_adv        | 6.37       |
| _max_discrew    | 1.66       |
| _max_obs        | 1.45       |
| _mean_act       | -0.12439   |
| _mean_adv       | -7.11e-18  |
| _mean_discrew   | 0.922      |
| _mean_obs       | 0.0382     |
| _min_adv        | -7.43      |
| _min_discrew    | 0.000757   |
| _min_obs        | -1.41      |
| _std_act        | 0.550931   |
| _std_adv        | 1          |
| _std_discrew    | 0.127      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.684      |
| ExplainedVarOld | 0.663      |
| KL              | 0.00363543 |
| Phi_loss        | 48.905     |
| PolicyEntropy   | 4.41345    |
| PolicyLoss      | -0.0035636 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0401     |
| _MeanReward     | 1.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.29229    |
| _max_adv        | 6.89       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.41       |
| _mean_act       | -0.123258  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.948      |
| _mean_obs       | 0.039      |
| _min_adv        | -6.82      |
| _min_discrew    | -0.336     |
| _min_obs        | -1.49      |
| _std_act        | 0.569827   |
| _std_adv        | 1          |
| _std_discrew    | 0.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.702       |
| ExplainedVarOld | 0.689       |
| KL              | 0.00244033  |
| Phi_loss        | 54.9723     |
| PolicyEntropy   | 4.40983     |
| PolicyLoss      | -0.00972045 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0536      |
| _MeanReward     | 1.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0568      |
| _max_adv        | 6.77        |
| _max_discrew    | 1.71        |
| _max_obs        | 1.39        |
| _mean_act       | -0.127245   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.0392      |
| _min_adv        | -5.92       |
| _min_discrew    | -0.0054     |
| _min_obs        | -1.41       |
| _std_act        | 0.562003    |
| _std_adv        | 1           |
| _std_discrew    | 0.155       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.762      |
| ExplainedVarOld | 0.744      |
| KL              | 0.00201015 |
| Phi_loss        | 54.274     |
| PolicyEntropy   | 4.38739    |
| PolicyLoss      | 0.00275408 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0373     |
| _MeanReward     | 1.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14578    |
| _max_adv        | 4.53       |
| _max_discrew    | 1.88       |
| _max_obs        | 1.64       |
| _mean_act       | -0.135946  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0389     |
| _min_adv        | -5.57      |
| _min_discrew    | -0.00395   |
| _min_obs        | -1.54      |
| _std_act        | 0.565704   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.815      |
| ExplainedVarOld | 0.806      |
| KL              | 0.00241397 |
| Phi_loss        | 54.1468    |
| PolicyEntropy   | 4.36753    |
| PolicyLoss      | -0.0104561 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0297     |
| _MeanReward     | 1.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.52332    |
| _max_adv        | 3.07       |
| _max_discrew    | 1.99       |
| _max_obs        | 1.42       |
| _mean_act       | -0.124351  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.989      |
| _mean_obs       | 0.0405     |
| _min_adv        | -10.6      |
| _min_discrew    | -0.745     |
| _min_obs        | -1.36      |
| _std_act        | 0.640243   |
| _std_adv        | 1          |
| _std_discrew    | 0.378      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.784      |
| ExplainedVarOld | 0.743      |
| KL              | 0.00319963 |
| Phi_loss        | 45.0506    |
| PolicyEntropy   | 4.36473    |
| PolicyLoss      | -0.0214507 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0817     |
| _MeanReward     | 1.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08901    |
| _max_adv        | 5.21       |
| _max_discrew    | 1.85       |
| _max_obs        | 1.52       |
| _mean_act       | -0.120567  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0425     |
| _min_adv        | -5.94      |
| _min_discrew    | -0.0778    |
| _min_obs        | -1.75      |
| _std_act        | 0.581313   |
| _std_adv        | 1          |
| _std_discrew    | 0.186      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.654       |
| ExplainedVarOld | 0.634       |
| KL              | 0.00337676  |
| Phi_loss        | 50.2303     |
| PolicyEntropy   | 4.34603     |
| PolicyLoss      | -0.00510757 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0653      |
| _MeanReward     | 1.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.39349     |
| _max_adv        | 4.44        |
| _max_discrew    | 1.96        |
| _max_obs        | 1.4         |
| _mean_act       | -0.122913   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0431      |
| _min_adv        | -9.56       |
| _min_discrew    | -0.702      |
| _min_obs        | -1.47       |
| _std_act        | 0.629754    |
| _std_adv        | 1           |
| _std_discrew    | 0.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.766       |
| ExplainedVarOld | 0.738       |
| KL              | 0.00383446  |
| Phi_loss        | 50.8274     |
| PolicyEntropy   | 4.33392     |
| PolicyLoss      | -0.00447437 |
| Steps           | 10000       |
| VarFuncLoss     | 0.066       |
| _MeanReward     | 1.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.56485     |
| _max_adv        | 4.31        |
| _max_discrew    | 1.78        |
| _max_obs        | 1.39        |
| _mean_act       | -0.122315   |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 0.943       |
| _mean_obs       | 0.0412      |
| _min_adv        | -9.71       |
| _min_discrew    | -0.729      |
| _min_obs        | -1.36       |
| _std_act        | 0.633698    |
| _std_adv        | 1           |
| _std_discrew    | 0.251       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.76        |
| ExplainedVarOld | 0.736       |
| KL              | 0.00295408  |
| Phi_loss        | 52.0205     |
| PolicyEntropy   | 4.31733     |
| PolicyLoss      | -0.00754425 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0613      |
| _MeanReward     | 1.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.33272     |
| _max_adv        | 4.23        |
| _max_discrew    | 1.77        |
| _max_obs        | 1.38        |
| _mean_act       | -0.129556   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.07        |
| _mean_obs       | 0.0406      |
| _min_adv        | -9.65       |
| _min_discrew    | -0.466      |
| _min_obs        | -1.35       |
| _std_act        | 0.610019    |
| _std_adv        | 1           |
| _std_discrew    | 0.228       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.764      |
| ExplainedVarOld | 0.757      |
| KL              | 0.00367552 |
| Phi_loss        | 55.5384    |
| PolicyEntropy   | 4.30283    |
| PolicyLoss      | 0.00316641 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0555     |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.22888    |
| _max_adv        | 4.75       |
| _max_discrew    | 1.95       |
| _max_obs        | 1.37       |
| _mean_act       | -0.130023  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.041      |
| _min_adv        | -6.03      |
| _min_discrew    | 0.00354    |
| _min_obs        | -1.41      |
| _std_act        | 0.586135   |
| _std_adv        | 1          |
| _std_discrew    | 0.188      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.733      |
| ExplainedVarOld | 0.708      |
| KL              | 0.00306978 |
| Phi_loss        | 52.0051    |
| PolicyEntropy   | 4.25951    |
| PolicyLoss      | 0.00293424 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0508     |
| _MeanReward     | 1.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03927    |
| _max_adv        | 6.92       |
| _max_discrew    | 2.08       |
| _max_obs        | 1.37       |
| _mean_act       | -0.135556  |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0413     |
| _min_adv        | -5.87      |
| _min_discrew    | -0.0339    |
| _min_obs        | -1.39      |
| _std_act        | 0.59086    |
| _std_adv        | 1          |
| _std_discrew    | 0.227      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.792      |
| ExplainedVarOld | 0.765      |
| KL              | 0.00362918 |
| Phi_loss        | 54.9782    |
| PolicyEntropy   | 4.26018    |
| PolicyLoss      | -0.0131164 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0475     |
| _MeanReward     | 1.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.2107     |
| _max_adv        | 5.52       |
| _max_discrew    | 2          |
| _max_obs        | 1.41       |
| _mean_act       | -0.129395  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.042      |
| _min_adv        | -6.69      |
| _min_discrew    | -0.0591    |
| _min_obs        | -1.64      |
| _std_act        | 0.602658   |
| _std_adv        | 1          |
| _std_discrew    | 0.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.782        |
| ExplainedVarOld | 0.767        |
| KL              | 0.00338481   |
| Phi_loss        | 54.6607      |
| PolicyEntropy   | 4.25339      |
| PolicyLoss      | -0.000441694 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0504       |
| _MeanReward     | 1.55e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.05085      |
| _max_adv        | 4.02         |
| _max_discrew    | 2.03         |
| _max_obs        | 1.32         |
| _mean_act       | -0.131558    |
| _mean_adv       | -5.68e-18    |
| _mean_discrew   | 1.27         |
| _mean_obs       | 0.0405       |
| _min_adv        | -7.34        |
| _min_discrew    | -0.0029      |
| _min_obs        | -1.45        |
| _std_act        | 0.583941     |
| _std_adv        | 1            |
| _std_discrew    | 0.197        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.799      |
| ExplainedVarOld | 0.781      |
| KL              | 0.00312355 |
| Phi_loss        | 53.9943    |
| PolicyEntropy   | 4.25132    |
| PolicyLoss      | -0.0085409 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0398     |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1066     |
| _max_adv        | 3.71       |
| _max_discrew    | 2.27       |
| _max_obs        | 1.52       |
| _mean_act       | -0.13801   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0405     |
| _min_adv        | -5.91      |
| _min_discrew    | -0.00106   |
| _min_obs        | -1.44      |
| _std_act        | 0.597055   |
| _std_adv        | 1          |
| _std_discrew    | 0.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.736      |
| ExplainedVarOld | 0.715      |
| KL              | 0.00339826 |
| Phi_loss        | 59.3648    |
| PolicyEntropy   | 4.21727    |
| PolicyLoss      | 0.00781522 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0662     |
| _MeanReward     | 1.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.23696    |
| _max_adv        | 3.6        |
| _max_discrew    | 2.09       |
| _max_obs        | 1.42       |
| _mean_act       | -0.128874  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0422     |
| _min_adv        | -6.2       |
| _min_discrew    | -0.121     |
| _min_obs        | -1.54      |
| _std_act        | 0.604953   |
| _std_adv        | 1          |
| _std_discrew    | 0.203      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.692       |
| ExplainedVarOld | 0.684       |
| KL              | 0.00372641  |
| Phi_loss        | 59.5089     |
| PolicyEntropy   | 4.2032      |
| PolicyLoss      | -0.00880567 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0632      |
| _MeanReward     | 1.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.82708     |
| _max_adv        | 5.05        |
| _max_discrew    | 2.02        |
| _max_obs        | 1.34        |
| _mean_act       | -0.118406   |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.0424      |
| _min_adv        | -10.8       |
| _min_discrew    | -0.94       |
| _min_obs        | -1.27       |
| _std_act        | 0.699494    |
| _std_adv        | 1           |
| _std_discrew    | 0.602       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.867      |
| ExplainedVarOld | 0.836      |
| KL              | 0.00509937 |
| Phi_loss        | 49.7868    |
| PolicyEntropy   | 4.20571    |
| PolicyLoss      | 0.0236617  |
| Steps           | 10000      |
| VarFuncLoss     | 0.08       |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.53628    |
| _max_adv        | 4.5        |
| _max_discrew    | 2.03       |
| _max_obs        | 1.4        |
| _mean_act       | -0.125782  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0419     |
| _min_adv        | -12.9      |
| _min_discrew    | -0.85      |
| _min_obs        | -1.34      |
| _std_act        | 0.675563   |
| _std_adv        | 1          |
| _std_discrew    | 0.483      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.847       |
| ExplainedVarOld | 0.843       |
| KL              | 0.00330391  |
| Phi_loss        | 58.4958     |
| PolicyEntropy   | 4.18676     |
| PolicyLoss      | -0.00236343 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0742      |
| _MeanReward     | 1.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.78512     |
| _max_adv        | 5.07        |
| _max_discrew    | 2.11        |
| _max_obs        | 1.37        |
| _mean_act       | -0.12008    |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0422      |
| _min_adv        | -12.1       |
| _min_discrew    | -0.815      |
| _min_obs        | -1.4        |
| _std_act        | 0.708684    |
| _std_adv        | 1           |
| _std_discrew    | 0.589       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.843       |
| ExplainedVarOld | 0.833       |
| KL              | 0.00332768  |
| Phi_loss        | 60.029      |
| PolicyEntropy   | 4.17364     |
| PolicyLoss      | -0.00651184 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0927      |
| _MeanReward     | 1.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.66586     |
| _max_adv        | 7.05        |
| _max_discrew    | 2.15        |
| _max_obs        | 1.32        |
| _mean_act       | -0.114608   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.0423      |
| _min_adv        | -11.7       |
| _min_discrew    | -0.833      |
| _min_obs        | -1.51       |
| _std_act        | 0.716397    |
| _std_adv        | 1           |
| _std_discrew    | 0.622       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.849       |
| ExplainedVarOld | 0.846       |
| KL              | 0.00312941  |
| Phi_loss        | 49.3297     |
| PolicyEntropy   | 4.14407     |
| PolicyLoss      | 0.000240963 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0941      |
| _MeanReward     | 1.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.50144     |
| _max_adv        | 6.65        |
| _max_discrew    | 2.39        |
| _max_obs        | 1.43        |
| _mean_act       | -0.127819   |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 1.22        |
| _mean_obs       | 0.0415      |
| _min_adv        | -12.4       |
| _min_discrew    | -0.761      |
| _min_obs        | -1.55       |
| _std_act        | 0.654791    |
| _std_adv        | 1           |
| _std_discrew    | 0.424       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.816       |
| ExplainedVarOld | 0.807       |
| KL              | 0.00292683  |
| Phi_loss        | 56.5946     |
| PolicyEntropy   | 4.11355     |
| PolicyLoss      | -0.00956065 |
| Steps           | 10000       |
| VarFuncLoss     | 0.078       |
| _MeanReward     | 1.66e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.28938     |
| _max_adv        | 5.26        |
| _max_discrew    | 2.17        |
| _max_obs        | 1.33        |
| _mean_act       | -0.138042   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.37        |
| _mean_obs       | 0.0397      |
| _min_adv        | -6.56       |
| _min_discrew    | -0.0598     |
| _min_obs        | -1.52       |
| _std_act        | 0.588325    |
| _std_adv        | 1           |
| _std_discrew    | 0.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.833       |
| ExplainedVarOld | 0.822       |
| KL              | 0.00365443  |
| Phi_loss        | 63.9535     |
| PolicyEntropy   | 4.04816     |
| PolicyLoss      | -0.00128652 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0409      |
| _MeanReward     | 1.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.97226     |
| _max_adv        | 8.17        |
| _max_discrew    | 2.28        |
| _max_obs        | 1.33        |
| _mean_act       | -0.14811    |
| _mean_adv       | 7.39e-17    |
| _mean_discrew   | 1.48        |
| _mean_obs       | 0.0408      |
| _min_adv        | -7.11       |
| _min_discrew    | -0.148      |
| _min_obs        | -1.48       |
| _std_act        | 0.605688    |
| _std_adv        | 1           |
| _std_discrew    | 0.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.874       |
| KL              | 0.00279236  |
| Phi_loss        | 71.0122     |
| PolicyEntropy   | 4.03625     |
| PolicyLoss      | -0.00516341 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0335      |
| _MeanReward     | 1.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.43418     |
| _max_adv        | 3.02        |
| _max_discrew    | 2.24        |
| _max_obs        | 1.42        |
| _mean_act       | -0.140672   |
| _mean_adv       | -1.28e-17   |
| _mean_discrew   | 1.41        |
| _mean_obs       | 0.0412      |
| _min_adv        | -9.45       |
| _min_discrew    | -0.465      |
| _min_obs        | -1.35       |
| _std_act        | 0.614359    |
| _std_adv        | 1           |
| _std_discrew    | 0.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.809      |
| ExplainedVarOld | 0.794      |
| KL              | 0.00433129 |
| Phi_loss        | 71.9339    |
| PolicyEntropy   | 4.00508    |
| PolicyLoss      | 0.0103048  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0635     |
| _MeanReward     | 1.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.51451    |
| _max_adv        | 5.54       |
| _max_discrew    | 2.24       |
| _max_obs        | 1.42       |
| _mean_act       | -0.132115  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0389     |
| _min_adv        | -6.17      |
| _min_discrew    | -0.682     |
| _min_obs        | -1.4       |
| _std_act        | 0.614907   |
| _std_adv        | 1          |
| _std_discrew    | 0.338      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.743       |
| ExplainedVarOld | 0.639       |
| KL              | 0.00254443  |
| Phi_loss        | 61.0155     |
| PolicyEntropy   | 3.98579     |
| PolicyLoss      | -0.00157473 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0876      |
| _MeanReward     | 1.69e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.39255     |
| _max_adv        | 2.57        |
| _max_discrew    | 2.52        |
| _max_obs        | 1.3         |
| _mean_act       | -0.132516   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.38        |
| _mean_obs       | 0.0422      |
| _min_adv        | -12.6       |
| _min_discrew    | -0.772      |
| _min_obs        | -1.43       |
| _std_act        | 0.680748    |
| _std_adv        | 1           |
| _std_discrew    | 0.576       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.845      |
| ExplainedVarOld | 0.827      |
| KL              | 0.00288504 |
| Phi_loss        | 65.0656    |
| PolicyEntropy   | 3.96517    |
| PolicyLoss      | 0.00223771 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0935     |
| _MeanReward     | 1.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8232     |
| _max_adv        | 5.36       |
| _max_discrew    | 2.43       |
| _max_obs        | 1.35       |
| _mean_act       | -0.148313  |
| _mean_adv       | 9.09e-17   |
| _mean_discrew   | 1.56       |
| _mean_obs       | 0.0411     |
| _min_adv        | -6.71      |
| _min_discrew    | -0.0711    |
| _min_obs        | -1.35      |
| _std_act        | 0.59787    |
| _std_adv        | 1          |
| _std_discrew    | 0.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.887      |
| ExplainedVarOld | 0.866      |
| KL              | 0.0025009  |
| Phi_loss        | 69.7436    |
| PolicyEntropy   | 3.94942    |
| PolicyLoss      | -0.0131988 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0329     |
| _MeanReward     | 1.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05054    |
| _max_adv        | 7.85       |
| _max_discrew    | 2.42       |
| _max_obs        | 1.39       |
| _mean_act       | -0.136549  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.44       |
| _mean_obs       | 0.0419     |
| _min_adv        | -6.35      |
| _min_discrew    | 0.00462    |
| _min_obs        | -1.58      |
| _std_act        | 0.605966   |
| _std_adv        | 1          |
| _std_discrew    | 0.279      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.749       |
| ExplainedVarOld | 0.704       |
| KL              | 0.00317091  |
| Phi_loss        | 59.5246     |
| PolicyEntropy   | 3.93528     |
| PolicyLoss      | -0.00600672 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0702      |
| _MeanReward     | 1.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.56485     |
| _max_adv        | 4.09        |
| _max_discrew    | 2.36        |
| _max_obs        | 1.35        |
| _mean_act       | -0.143664   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.49        |
| _mean_obs       | 0.0415      |
| _min_adv        | -11.5       |
| _min_discrew    | -0.735      |
| _min_obs        | -1.63       |
| _std_act        | 0.654831    |
| _std_adv        | 1           |
| _std_discrew    | 0.471       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.797      |
| ExplainedVarOld | 0.785      |
| KL              | 0.00633494 |
| Phi_loss        | 64.5683    |
| PolicyEntropy   | 3.90795    |
| PolicyLoss      | 0.00432686 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0969     |
| _MeanReward     | 1.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.16538    |
| _max_adv        | 6.71       |
| _max_discrew    | 2.36       |
| _max_obs        | 1.46       |
| _mean_act       | -0.147715  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.56       |
| _mean_obs       | 0.0407     |
| _min_adv        | -6.74      |
| _min_discrew    | -0.0495    |
| _min_obs        | -1.36      |
| _std_act        | 0.601788   |
| _std_adv        | 1          |
| _std_discrew    | 0.288      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.857       |
| ExplainedVarOld | 0.849       |
| KL              | 0.00195725  |
| Phi_loss        | 79.3094     |
| PolicyEntropy   | 3.88596     |
| PolicyLoss      | -0.00688342 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0411      |
| _MeanReward     | 1.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9989      |
| _max_adv        | 6.92        |
| _max_discrew    | 2.47        |
| _max_obs        | 1.29        |
| _mean_act       | -0.143938   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.55        |
| _mean_obs       | 0.0417      |
| _min_adv        | -6.71       |
| _min_discrew    | 0.0068      |
| _min_obs        | -1.4        |
| _std_act        | 0.608668    |
| _std_adv        | 1           |
| _std_discrew    | 0.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.776       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00254871  |
| Phi_loss        | 69.4907     |
| PolicyEntropy   | 3.85998     |
| PolicyLoss      | -0.00424265 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0696      |
| _MeanReward     | 1.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.76686     |
| _max_adv        | 3.72        |
| _max_discrew    | 2.64        |
| _max_obs        | 1.41        |
| _mean_act       | -0.121715   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.17        |
| _mean_obs       | 0.0401      |
| _min_adv        | -11         |
| _min_discrew    | -0.865      |
| _min_obs        | -1.43       |
| _std_act        | 0.781542    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.841      |
| ExplainedVarOld | 0.818      |
| KL              | 0.00625736 |
| Phi_loss        | 63.9995    |
| PolicyEntropy   | 3.8819     |
| PolicyLoss      | 0.0190118  |
| Steps           | 10000      |
| VarFuncLoss     | 0.18       |
| _MeanReward     | 1.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82401    |
| _max_adv        | 6.25       |
| _max_discrew    | 2.53       |
| _max_obs        | 1.58       |
| _mean_act       | -0.148721  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.59       |
| _mean_obs       | 0.0408     |
| _min_adv        | -6.83      |
| _min_discrew    | -0.00331   |
| _min_obs        | -1.45      |
| _std_act        | 0.607477   |
| _std_adv        | 1          |
| _std_discrew    | 0.293      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.805       |
| ExplainedVarOld | 0.787       |
| KL              | 0.000903559 |
| Phi_loss        | 78.9825     |
| PolicyEntropy   | 3.87285     |
| PolicyLoss      | -0.00266786 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0574      |
| _MeanReward     | 1.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.55919     |
| _max_adv        | 3.77        |
| _max_discrew    | 2.52        |
| _max_obs        | 1.39        |
| _mean_act       | -0.121318   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.26        |
| _mean_obs       | 0.0431      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.815      |
| _min_obs        | -1.32       |
| _std_act        | 0.732431    |
| _std_adv        | 1           |
| _std_discrew    | 0.872       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.813      |
| ExplainedVarOld | 0.799      |
| KL              | 0.00168956 |
| Phi_loss        | 75.4632    |
| PolicyEntropy   | 3.86751    |
| PolicyLoss      | 0.00360549 |
| Steps           | 10000      |
| VarFuncLoss     | 0.164      |
| _MeanReward     | 1.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.34719    |
| _max_adv        | 7.4        |
| _max_discrew    | 2.45       |
| _max_obs        | 1.29       |
| _mean_act       | -0.142041  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.52       |
| _mean_obs       | 0.0425     |
| _min_adv        | -10.5      |
| _min_discrew    | -0.629     |
| _min_obs        | -1.38      |
| _std_act        | 0.677563   |
| _std_adv        | 1          |
| _std_discrew    | 0.526      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.783      |
| ExplainedVarOld | 0.762      |
| KL              | 0.00173046 |
| Phi_loss        | 84.69      |
| PolicyEntropy   | 3.85045    |
| PolicyLoss      | 0.00242266 |
| Steps           | 10000      |
| VarFuncLoss     | 0.116      |
| _MeanReward     | 1.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.40077    |
| _max_adv        | 5.26       |
| _max_discrew    | 2.32       |
| _max_obs        | 1.32       |
| _mean_act       | -0.130651  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.37       |
| _mean_obs       | 0.0409     |
| _min_adv        | -12        |
| _min_discrew    | -0.77      |
| _min_obs        | -1.43      |
| _std_act        | 0.705208   |
| _std_adv        | 1          |
| _std_discrew    | 0.681      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.818       |
| ExplainedVarOld | 0.814       |
| KL              | 0.00176232  |
| Phi_loss        | 86.5872     |
| PolicyEntropy   | 3.83801     |
| PolicyLoss      | -0.00326797 |
| Steps           | 10000       |
| VarFuncLoss     | 0.124       |
| _MeanReward     | 1.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.34138     |
| _max_adv        | 6.63        |
| _max_discrew    | 2.47        |
| _max_obs        | 1.31        |
| _mean_act       | -0.125021   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.29        |
| _mean_obs       | 0.0418      |
| _min_adv        | -11.6       |
| _min_discrew    | -0.832      |
| _min_obs        | -1.29       |
| _std_act        | 0.737637    |
| _std_adv        | 1           |
| _std_discrew    | 0.885       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.867      |
| ExplainedVarOld | 0.862      |
| KL              | 0.00188627 |
| Phi_loss        | 76.3584    |
| PolicyEntropy   | 3.83228    |
| PolicyLoss      | 0.0023341  |
| Steps           | 10000      |
| VarFuncLoss     | 0.118      |
| _MeanReward     | 1.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.47675    |
| _max_adv        | 5.83       |
| _max_discrew    | 2.49       |
| _max_obs        | 1.47       |
| _mean_act       | -0.134451  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.42       |
| _mean_obs       | 0.0419     |
| _min_adv        | -11.8      |
| _min_discrew    | -0.767     |
| _min_obs        | -1.23      |
| _std_act        | 0.708852   |
| _std_adv        | 1          |
| _std_discrew    | 0.755      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.769      |
| ExplainedVarOld | 0.753      |
| KL              | 0.00154088 |
| Phi_loss        | 73.8769    |
| PolicyEntropy   | 3.82108    |
| PolicyLoss      | 0.00484818 |
| Steps           | 10000      |
| VarFuncLoss     | 0.174      |
| _MeanReward     | 1.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.50584    |
| _max_adv        | 7.05       |
| _max_discrew    | 2.48       |
| _max_obs        | 1.3        |
| _mean_act       | -0.132573  |
| _mean_adv       | -2.13e-18  |
| _mean_discrew   | 1.43       |
| _mean_obs       | 0.0411     |
| _min_adv        | -13.6      |
| _min_discrew    | -0.818     |
| _min_obs        | -1.3       |
| _std_act        | 0.672267   |
| _std_adv        | 1          |
| _std_discrew    | 0.619      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.858       |
| ExplainedVarOld | 0.852       |
| KL              | 0.00174708  |
| Phi_loss        | 78.2191     |
| PolicyEntropy   | 3.803       |
| PolicyLoss      | -0.00504681 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0882      |
| _MeanReward     | 1.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.38713     |
| _max_adv        | 8.25        |
| _max_discrew    | 2.55        |
| _max_obs        | 1.26        |
| _mean_act       | -0.140425   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 1.56        |
| _mean_obs       | 0.041       |
| _min_adv        | -10.2       |
| _min_discrew    | -0.439      |
| _min_obs        | -1.34       |
| _std_act        | 0.626405    |
| _std_adv        | 1           |
| _std_discrew    | 0.383       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.827      |
| ExplainedVarOld | 0.808      |
| KL              | 0.00157918 |
| Phi_loss        | 75.6956    |
| PolicyEntropy   | 3.79314    |
| PolicyLoss      | -0.0102318 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0664     |
| _MeanReward     | 2.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09024    |
| _max_adv        | 9.18       |
| _max_discrew    | 2.82       |
| _max_obs        | 1.25       |
| _mean_act       | -0.145971  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.76       |
| _mean_obs       | 0.0411     |
| _min_adv        | -7.99      |
| _min_discrew    | -0.0364    |
| _min_obs        | -1.41      |
| _std_act        | 0.600488   |
| _std_adv        | 1          |
| _std_discrew    | 0.356      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.86       |
| ExplainedVarOld | 0.849      |
| KL              | 0.00137644 |
| Phi_loss        | 81.8025    |
| PolicyEntropy   | 3.7783     |
| PolicyLoss      | 0.00150339 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0535     |
| _MeanReward     | 2.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06683    |
| _max_adv        | 9.16       |
| _max_discrew    | 2.54       |
| _max_obs        | 1.36       |
| _mean_act       | -0.147342  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.71       |
| _mean_obs       | 0.0408     |
| _min_adv        | -6.84      |
| _min_discrew    | 0.000996   |
| _min_obs        | -1.6       |
| _std_act        | 0.602955   |
| _std_adv        | 1          |
| _std_discrew    | 0.327      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.838       |
| ExplainedVarOld | 0.827       |
| KL              | 0.00294907  |
| Phi_loss        | 81.5232     |
| PolicyEntropy   | 3.76619     |
| PolicyLoss      | -0.00916293 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0536      |
| _MeanReward     | 2.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.80523     |
| _max_adv        | 6.91        |
| _max_discrew    | 2.51        |
| _max_obs        | 1.3         |
| _mean_act       | -0.145112   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.75        |
| _mean_obs       | 0.0406      |
| _min_adv        | -5.81       |
| _min_discrew    | 0.00395     |
| _min_obs        | -1.35       |
| _std_act        | 0.596326    |
| _std_adv        | 1           |
| _std_discrew    | 0.287       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.893       |
| KL              | 0.00289203  |
| Phi_loss        | 87.4366     |
| PolicyEntropy   | 3.7273      |
| PolicyLoss      | -0.00582607 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0275      |
| _MeanReward     | 2.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.1875      |
| _max_adv        | 2.82        |
| _max_discrew    | 2.84        |
| _max_obs        | 1.27        |
| _mean_act       | -0.150546   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.81        |
| _mean_obs       | 0.0406      |
| _min_adv        | -6.5        |
| _min_discrew    | 0.00252     |
| _min_obs        | -1.56       |
| _std_act        | 0.604597    |
| _std_adv        | 1           |
| _std_discrew    | 0.379       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.868       |
| KL              | 0.00409812  |
| Phi_loss        | 86.9788     |
| PolicyEntropy   | 3.69655     |
| PolicyLoss      | -0.00221486 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0444      |
| _MeanReward     | 1.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.53755     |
| _max_adv        | 3.92        |
| _max_discrew    | 2.75        |
| _max_obs        | 1.35        |
| _mean_act       | -0.134802   |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 1.54        |
| _mean_obs       | 0.0419      |
| _min_adv        | -9.88       |
| _min_discrew    | -0.747      |
| _min_obs        | -1.37       |
| _std_act        | 0.694354    |
| _std_adv        | 1           |
| _std_discrew    | 0.755       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.784      |
| ExplainedVarOld | 0.731      |
| KL              | 0.00735842 |
| Phi_loss        | 76.7667    |
| PolicyEntropy   | 3.6848     |
| PolicyLoss      | -0.0336052 |
| Steps           | 10000      |
| VarFuncLoss     | 0.165      |
| _MeanReward     | 2.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17977    |
| _max_adv        | 4.64       |
| _max_discrew    | 2.75       |
| _max_obs        | 1.28       |
| _mean_act       | -0.152608  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 1.94       |
| _mean_obs       | 0.0417     |
| _min_adv        | -8.05      |
| _min_discrew    | 0.00332    |
| _min_obs        | -1.25      |
| _std_act        | 0.614253   |
| _std_adv        | 1          |
| _std_discrew    | 0.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.907      |
| KL              | 0.00188838 |
| Phi_loss        | 93.6601    |
| PolicyEntropy   | 3.66243    |
| PolicyLoss      | -0.0119349 |
| Steps           | 10000      |
| VarFuncLoss     | 0.046      |
| _MeanReward     | 2.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.42322    |
| _max_adv        | 7.79       |
| _max_discrew    | 2.73       |
| _max_obs        | 1.3        |
| _mean_act       | -0.148724  |
| _mean_adv       | 3.84e-17   |
| _mean_discrew   | 1.88       |
| _mean_obs       | 0.0417     |
| _min_adv        | -12.9      |
| _min_discrew    | -0.51      |
| _min_obs        | -1.66      |
| _std_act        | 0.633762   |
| _std_adv        | 1          |
| _std_discrew    | 0.492      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.865      |
| KL              | 0.00227754 |
| Phi_loss        | 91.2388    |
| PolicyEntropy   | 3.6573     |
| PolicyLoss      | -0.013713  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0607     |
| _MeanReward     | 2.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91778    |
| _max_adv        | 4.67       |
| _max_discrew    | 2.95       |
| _max_obs        | 1.26       |
| _mean_act       | -0.148337  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.94       |
| _mean_obs       | 0.0419     |
| _min_adv        | -6.74      |
| _min_discrew    | 0.00199    |
| _min_obs        | -1.5       |
| _std_act        | 0.61085    |
| _std_adv        | 1          |
| _std_discrew    | 0.391      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.879       |
| KL              | 0.00156017  |
| Phi_loss        | 98.901      |
| PolicyEntropy   | 3.64034     |
| PolicyLoss      | -0.00411422 |
| Steps           | 10000       |
| VarFuncLoss     | 0.045       |
| _MeanReward     | 2.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.86327     |
| _max_adv        | 5.07        |
| _max_discrew    | 2.76        |
| _max_obs        | 1.26        |
| _mean_act       | -0.147848   |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 1.9         |
| _mean_obs       | 0.0412      |
| _min_adv        | -6.65       |
| _min_discrew    | 0.00905     |
| _min_obs        | -1.31       |
| _std_act        | 0.615576    |
| _std_adv        | 1           |
| _std_discrew    | 0.368       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.874       |
| ExplainedVarOld | 0.87        |
| KL              | 0.00128468  |
| Phi_loss        | 104.533     |
| PolicyEntropy   | 3.6299      |
| PolicyLoss      | -0.00834358 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0463      |
| _MeanReward     | 2.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08265     |
| _max_adv        | 5.72        |
| _max_discrew    | 2.69        |
| _max_obs        | 1.26        |
| _mean_act       | -0.148979   |
| _mean_adv       | -1.56e-17   |
| _mean_discrew   | 1.88        |
| _mean_obs       | 0.0411      |
| _min_adv        | -8          |
| _min_discrew    | 0.00172     |
| _min_obs        | -1.3        |
| _std_act        | 0.618628    |
| _std_adv        | 1           |
| _std_discrew    | 0.359       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.884       |
| KL              | 0.00396335  |
| Phi_loss        | 95.6752     |
| PolicyEntropy   | 3.61431     |
| PolicyLoss      | -0.00475272 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0393      |
| _MeanReward     | 2.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.94339     |
| _max_adv        | 4.97        |
| _max_discrew    | 2.69        |
| _max_obs        | 1.3         |
| _mean_act       | -0.128761   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.68        |
| _mean_obs       | 0.0425      |
| _min_adv        | -11.9       |
| _min_discrew    | -0.803      |
| _min_obs        | -1.61       |
| _std_act        | 0.699747    |
| _std_adv        | 1           |
| _std_discrew    | 0.761       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.859      |
| KL              | 0.00553775 |
| Phi_loss        | 75.7767    |
| PolicyEntropy   | 3.58298    |
| PolicyLoss      | 0.00366734 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0962     |
| _MeanReward     | 2.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64161    |
| _max_adv        | 13.1       |
| _max_discrew    | 2.76       |
| _max_obs        | 1.37       |
| _mean_act       | -0.148118  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.96       |
| _mean_obs       | 0.0425     |
| _min_adv        | -8.04      |
| _min_discrew    | 0.00164    |
| _min_obs        | -1.33      |
| _std_act        | 0.621394   |
| _std_adv        | 1          |
| _std_discrew    | 0.402      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.887       |
| ExplainedVarOld | 0.879       |
| KL              | 0.005671    |
| Phi_loss        | 92.0241     |
| PolicyEntropy   | 3.52117     |
| PolicyLoss      | -0.00252012 |
| Steps           | 10000       |
| VarFuncLoss     | 0.048       |
| _MeanReward     | 2.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9124      |
| _max_adv        | 4.15        |
| _max_discrew    | 2.87        |
| _max_obs        | 1.23        |
| _mean_act       | -0.147553   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.97        |
| _mean_obs       | 0.0421      |
| _min_adv        | -6.69       |
| _min_discrew    | -0.0411     |
| _min_obs        | -1.27       |
| _std_act        | 0.621461    |
| _std_adv        | 1           |
| _std_discrew    | 0.438       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.895      |
| ExplainedVarOld | 0.879      |
| KL              | 0.00316552 |
| Phi_loss        | 98.454     |
| PolicyEntropy   | 3.49873    |
| PolicyLoss      | -0.0125963 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0462     |
| _MeanReward     | 2.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.4524     |
| _max_adv        | 3.24       |
| _max_discrew    | 3.12       |
| _max_obs        | 1.31       |
| _mean_act       | -0.136734  |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 1.87       |
| _mean_obs       | 0.0437     |
| _min_adv        | -12.3      |
| _min_discrew    | -0.783     |
| _min_obs        | -1.39      |
| _std_act        | 0.688057   |
| _std_adv        | 1          |
| _std_discrew    | 0.74       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.827        |
| ExplainedVarOld | 0.806        |
| KL              | 0.00697762   |
| Phi_loss        | 92.5919      |
| PolicyEntropy   | 3.4807       |
| PolicyLoss      | -0.000718404 |
| Steps           | 10000        |
| VarFuncLoss     | 0.128        |
| _MeanReward     | 2.45e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.95844      |
| _max_adv        | 9.21         |
| _max_discrew    | 2.98         |
| _max_obs        | 1.23         |
| _mean_act       | -0.149024    |
| _mean_adv       | 3.41e-17     |
| _mean_discrew   | 2.03         |
| _mean_obs       | 0.0433       |
| _min_adv        | -6.72        |
| _min_discrew    | -0.0113      |
| _min_obs        | -1.32        |
| _std_act        | 0.62963      |
| _std_adv        | 1            |
| _std_discrew    | 0.509        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.893      |
| KL              | 0.0077707  |
| Phi_loss        | 110.636    |
| PolicyEntropy   | 3.48556    |
| PolicyLoss      | -0.0637661 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0492     |
| _MeanReward     | 2.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82874    |
| _max_adv        | 6.33       |
| _max_discrew    | 2.93       |
| _max_obs        | 1.24       |
| _mean_act       | -0.14263   |
| _mean_adv       | 0          |
| _mean_discrew   | 1.92       |
| _mean_obs       | 0.0429     |
| _min_adv        | -7.54      |
| _min_discrew    | 0.00683    |
| _min_obs        | -1.58      |
| _std_act        | 0.627702   |
| _std_adv        | 1          |
| _std_discrew    | 0.415      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.812      |
| ExplainedVarOld | 0.806      |
| KL              | 0.00123659 |
| Phi_loss        | 129.331    |
| PolicyEntropy   | 3.47172    |
| PolicyLoss      | 0.00867026 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0799     |
| _MeanReward     | 2.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7366     |
| _max_adv        | 5.77       |
| _max_discrew    | 2.92       |
| _max_obs        | 1.28       |
| _mean_act       | -0.145728  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 2.01       |
| _mean_obs       | 0.0432     |
| _min_adv        | -8.82      |
| _min_discrew    | -0.0587    |
| _min_obs        | -1.47      |
| _std_act        | 0.63475    |
| _std_adv        | 1          |
| _std_discrew    | 0.426      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.877      |
| KL              | 0.00168465 |
| Phi_loss        | 113.469    |
| PolicyEntropy   | 3.45148    |
| PolicyLoss      | -0.0128437 |
| Steps           | 10000      |
| VarFuncLoss     | 0.05       |
| _MeanReward     | 2.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91026    |
| _max_adv        | 4.9        |
| _max_discrew    | 3.05       |
| _max_obs        | 1.38       |
| _mean_act       | -0.139785  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.95       |
| _mean_obs       | 0.0442     |
| _min_adv        | -6.27      |
| _min_discrew    | 0.00296    |
| _min_obs        | -1.24      |
| _std_act        | 0.64259    |
| _std_adv        | 1          |
| _std_discrew    | 0.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.799      |
| ExplainedVarOld | 0.778      |
| KL              | 0.00188881 |
| Phi_loss        | 112.845    |
| PolicyEntropy   | 3.43074    |
| PolicyLoss      | -0.0029562 |
| Steps           | 10000      |
| VarFuncLoss     | 0.103      |
| _MeanReward     | 2.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77787    |
| _max_adv        | 3.8        |
| _max_discrew    | 3          |
| _max_obs        | 1.25       |
| _mean_act       | -0.14803   |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.04       |
| _mean_obs       | 0.0436     |
| _min_adv        | -7.09      |
| _min_discrew    | 0.00856    |
| _min_obs        | -1.3       |
| _std_act        | 0.635692   |
| _std_adv        | 1          |
| _std_discrew    | 0.491      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.83        |
| ExplainedVarOld | 0.825       |
| KL              | 0.00163816  |
| Phi_loss        | 123.903     |
| PolicyEntropy   | 3.41357     |
| PolicyLoss      | 0.000847432 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0856      |
| _MeanReward     | 2.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08514     |
| _max_adv        | 3.12        |
| _max_discrew    | 3.09        |
| _max_obs        | 1.33        |
| _mean_act       | -0.151923   |
| _mean_adv       | 2.03e-17    |
| _mean_discrew   | 2.11        |
| _mean_obs       | 0.0427      |
| _min_adv        | -7.78       |
| _min_discrew    | -0.00531    |
| _min_obs        | -1.25       |
| _std_act        | 0.634793    |
| _std_adv        | 1           |
| _std_discrew    | 0.483       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.9         |
| ExplainedVarOld | 0.894       |
| KL              | 0.00136491  |
| Phi_loss        | 112.675     |
| PolicyEntropy   | 3.40089     |
| PolicyLoss      | -0.00891361 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0492      |
| _MeanReward     | 2.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82994     |
| _max_adv        | 3.42        |
| _max_discrew    | 3.18        |
| _max_obs        | 1.32        |
| _mean_act       | -0.144994   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.04        |
| _mean_obs       | 0.043       |
| _min_adv        | -6.67       |
| _min_discrew    | -0.0137     |
| _min_obs        | -1.35       |
| _std_act        | 0.639774    |
| _std_adv        | 1           |
| _std_discrew    | 0.488       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.844      |
| ExplainedVarOld | 0.831      |
| KL              | 0.00294086 |
| Phi_loss        | 111.408    |
| PolicyEntropy   | 3.38185    |
| PolicyLoss      | -0.0130287 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0765     |
| _MeanReward     | 2.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6901     |
| _max_adv        | 6.15       |
| _max_discrew    | 3.26       |
| _max_obs        | 1.27       |
| _mean_act       | -0.144696  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.02       |
| _mean_obs       | 0.0436     |
| _min_adv        | -7.17      |
| _min_discrew    | -0.0639    |
| _min_obs        | -1.51      |
| _std_act        | 0.641691   |
| _std_adv        | 1          |
| _std_discrew    | 0.492      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.854      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00465141 |
| Phi_loss        | 113.963    |
| PolicyEntropy   | 3.36207    |
| PolicyLoss      | -0.0318641 |
| Steps           | 10000      |
| VarFuncLoss     | 0.072      |
| _MeanReward     | 2.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84989    |
| _max_adv        | 5          |
| _max_discrew    | 3.11       |
| _max_obs        | 1.31       |
| _mean_act       | -0.149898  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.14       |
| _mean_obs       | 0.0438     |
| _min_adv        | -8.56      |
| _min_discrew    | 0.01       |
| _min_obs        | -1.36      |
| _std_act        | 0.643572   |
| _std_adv        | 1          |
| _std_discrew    | 0.502      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.858      |
| ExplainedVarOld | 0.847      |
| KL              | 0.00391383 |
| Phi_loss        | 113.851    |
| PolicyEntropy   | 3.34099    |
| PolicyLoss      | -0.0154    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0744     |
| _MeanReward     | 2.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76183    |
| _max_adv        | 9.43       |
| _max_discrew    | 3.21       |
| _max_obs        | 1.2        |
| _mean_act       | -0.156596  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.17       |
| _mean_obs       | 0.0431     |
| _min_adv        | -8.71      |
| _min_discrew    | 0.00516    |
| _min_obs        | -1.57      |
| _std_act        | 0.644492   |
| _std_adv        | 1          |
| _std_discrew    | 0.516      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.88        |
| ExplainedVarOld | 0.875       |
| KL              | 0.0032359   |
| Phi_loss        | 112.886     |
| PolicyEntropy   | 3.30613     |
| PolicyLoss      | -0.00476017 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0618      |
| _MeanReward     | 2.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.06093     |
| _max_adv        | 5.3         |
| _max_discrew    | 3.35        |
| _max_obs        | 1.24        |
| _mean_act       | -0.153737   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.13        |
| _mean_obs       | 0.0432      |
| _min_adv        | -9.05       |
| _min_discrew    | 0.00719     |
| _min_obs        | -1.31       |
| _std_act        | 0.647358    |
| _std_adv        | 1           |
| _std_discrew    | 0.618       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.82         |
| ExplainedVarOld | 0.803        |
| KL              | 0.00279489   |
| Phi_loss        | 116.702      |
| PolicyEntropy   | 3.28493      |
| PolicyLoss      | -0.000566244 |
| Steps           | 10000        |
| VarFuncLoss     | 0.111        |
| _MeanReward     | 2.66e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.70019      |
| _max_adv        | 7.18         |
| _max_discrew    | 3.16         |
| _max_obs        | 1.3          |
| _mean_act       | -0.160883    |
| _mean_adv       | -1.42e-18    |
| _mean_discrew   | 2.22         |
| _mean_obs       | 0.0429       |
| _min_adv        | -8.82        |
| _min_discrew    | -0.0106      |
| _min_obs        | -1.45        |
| _std_act        | 0.65061      |
| _std_adv        | 1            |
| _std_discrew    | 0.535        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00433318 |
| Phi_loss        | 93.4718    |
| PolicyEntropy   | 3.26264    |
| PolicyLoss      | -0.0251645 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0611     |
| _MeanReward     | 2.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.42314    |
| _max_adv        | 6.44       |
| _max_discrew    | 3.24       |
| _max_obs        | 1.38       |
| _mean_act       | -0.15839   |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.18       |
| _mean_obs       | 0.0433     |
| _min_adv        | -12.5      |
| _min_discrew    | -0.627     |
| _min_obs        | -1.26      |
| _std_act        | 0.679486   |
| _std_adv        | 1          |
| _std_discrew    | 0.659      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.865      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00589276 |
| Phi_loss        | 101.512    |
| PolicyEntropy   | 3.25491    |
| PolicyLoss      | 0.0131056  |
| Steps           | 10000      |
| VarFuncLoss     | 0.089      |
| _MeanReward     | 2.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.67709    |
| _max_adv        | 4.36       |
| _max_discrew    | 3.15       |
| _max_obs        | 1.37       |
| _mean_act       | -0.144241  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.01       |
| _mean_obs       | 0.0437     |
| _min_adv        | -12.5      |
| _min_discrew    | -0.904     |
| _min_obs        | -1.46      |
| _std_act        | 0.722186   |
| _std_adv        | 1          |
| _std_discrew    | 0.999      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.855       |
| ExplainedVarOld | 0.847       |
| KL              | 0.00304899  |
| Phi_loss        | 99.7995     |
| PolicyEntropy   | 3.23742     |
| PolicyLoss      | -0.00482498 |
| Steps           | 10000       |
| VarFuncLoss     | 0.145       |
| _MeanReward     | 2.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.30416     |
| _max_adv        | 7.52        |
| _max_discrew    | 3.27        |
| _max_obs        | 1.28        |
| _mean_act       | -0.161935   |
| _mean_adv       | 5.12e-17    |
| _mean_discrew   | 2.28        |
| _mean_obs       | 0.0428      |
| _min_adv        | -7.98       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.43       |
| _std_act        | 0.652759    |
| _std_adv        | 1           |
| _std_discrew    | 0.514       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.899       |
| ExplainedVarOld | 0.893       |
| KL              | 0.00246525  |
| Phi_loss        | 130.275     |
| PolicyEntropy   | 3.20613     |
| PolicyLoss      | -0.00304136 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0556      |
| _MeanReward     | 2.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.64696     |
| _max_adv        | 13.1        |
| _max_discrew    | 3.34        |
| _max_obs        | 1.38        |
| _mean_act       | -0.160454   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.29        |
| _mean_obs       | 0.0434      |
| _min_adv        | -8.66       |
| _min_discrew    | -0.26       |
| _min_obs        | -1.31       |
| _std_act        | 0.659392    |
| _std_adv        | 1           |
| _std_discrew    | 0.577       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.892      |
| KL              | 0.00685666 |
| Phi_loss        | 115.881    |
| PolicyEntropy   | 3.20214    |
| PolicyLoss      | 0.0103444  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0567     |
| _MeanReward     | 2.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91299    |
| _max_adv        | 4.97       |
| _max_discrew    | 3.48       |
| _max_obs        | 1.24       |
| _mean_act       | -0.158085  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.34       |
| _mean_obs       | 0.044      |
| _min_adv        | -7.44      |
| _min_discrew    | 0.00585    |
| _min_obs        | -1.4       |
| _std_act        | 0.655657   |
| _std_adv        | 1          |
| _std_discrew    | 0.597      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.89       |
| ExplainedVarOld | 0.885      |
| KL              | 0.00201733 |
| Phi_loss        | 136.324    |
| PolicyEntropy   | 3.19149    |
| PolicyLoss      | -0.023053  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0665     |
| _MeanReward     | 2.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.92438    |
| _max_adv        | 3.32       |
| _max_discrew    | 3.31       |
| _max_obs        | 1.29       |
| _mean_act       | -0.154889  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.23       |
| _mean_obs       | 0.0438     |
| _min_adv        | -6.38      |
| _min_discrew    | 0.00718    |
| _min_obs        | -1.46      |
| _std_act        | 0.659197   |
| _std_adv        | 1          |
| _std_discrew    | 0.607      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.846      |
| ExplainedVarOld | 0.837      |
| KL              | 0.00170719 |
| Phi_loss        | 122.493    |
| PolicyEntropy   | 3.18285    |
| PolicyLoss      | -0.01963   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0948     |
| _MeanReward     | 2.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00593    |
| _max_adv        | 5.13       |
| _max_discrew    | 3.12       |
| _max_obs        | 1.24       |
| _mean_act       | -0.158689  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.22       |
| _mean_obs       | 0.0423     |
| _min_adv        | -7.66      |
| _min_discrew    | 0.00532    |
| _min_obs        | -1.43      |
| _std_act        | 0.661636   |
| _std_adv        | 1          |
| _std_discrew    | 0.474      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.902       |
| ExplainedVarOld | 0.891       |
| KL              | 0.00171199  |
| Phi_loss        | 140.191     |
| PolicyEntropy   | 3.16241     |
| PolicyLoss      | -0.00946926 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0466      |
| _MeanReward     | 2.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87167     |
| _max_adv        | 8.9         |
| _max_discrew    | 3.47        |
| _max_obs        | 1.28        |
| _mean_act       | -0.166481   |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 2.39        |
| _mean_obs       | 0.0436      |
| _min_adv        | -8.46       |
| _min_discrew    | 0.00967     |
| _min_obs        | -1.25       |
| _std_act        | 0.665753    |
| _std_adv        | 1           |
| _std_discrew    | 0.632       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.895      |
| KL              | 0.00171059 |
| Phi_loss        | 132.591    |
| PolicyEntropy   | 3.13682    |
| PolicyLoss      | 0.00924451 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0632     |
| _MeanReward     | 2.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.01992    |
| _max_adv        | 3.97       |
| _max_discrew    | 3.45       |
| _max_obs        | 1.25       |
| _mean_act       | -0.167143  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.4        |
| _mean_obs       | 0.0434     |
| _min_adv        | -9.01      |
| _min_discrew    | 0.00675    |
| _min_obs        | -1.51      |
| _std_act        | 0.662815   |
| _std_adv        | 1          |
| _std_discrew    | 0.596      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.93        |
| ExplainedVarOld | 0.927       |
| KL              | 0.00185719  |
| Phi_loss        | 142.382     |
| PolicyEntropy   | 3.12307     |
| PolicyLoss      | -0.00779636 |
| Steps           | 10000       |
| VarFuncLoss     | 0.042       |
| _MeanReward     | 2.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7447      |
| _max_adv        | 4.72        |
| _max_discrew    | 3.41        |
| _max_obs        | 1.23        |
| _mean_act       | -0.163028   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.34        |
| _mean_obs       | 0.0425      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.00733     |
| _min_obs        | -1.32       |
| _std_act        | 0.656298    |
| _std_adv        | 1           |
| _std_discrew    | 0.575       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.908       |
| KL              | 0.00159772  |
| Phi_loss        | 147.51      |
| PolicyEntropy   | 3.09702     |
| PolicyLoss      | 0.000668099 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0512      |
| _MeanReward     | 2.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84502     |
| _max_adv        | 4.28        |
| _max_discrew    | 3.43        |
| _max_obs        | 1.3         |
| _mean_act       | -0.163781   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.39        |
| _mean_obs       | 0.0434      |
| _min_adv        | -8.81       |
| _min_discrew    | 0.00842     |
| _min_obs        | -1.38       |
| _std_act        | 0.672736    |
| _std_adv        | 1           |
| _std_discrew    | 0.624       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.901      |
| KL              | 0.0017122  |
| Phi_loss        | 118.398    |
| PolicyEntropy   | 3.08385    |
| PolicyLoss      | -0.0044462 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0529     |
| _MeanReward     | 3.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77792    |
| _max_adv        | 4.36       |
| _max_discrew    | 3.7        |
| _max_obs        | 1.24       |
| _mean_act       | -0.1755    |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.54       |
| _mean_obs       | 0.0436     |
| _min_adv        | -9.11      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.27      |
| _std_act        | 0.669003   |
| _std_adv        | 1          |
| _std_discrew    | 0.635      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.934      |
| KL              | 0.00218201 |
| Phi_loss        | 153.424    |
| PolicyEntropy   | 3.06476    |
| PolicyLoss      | -0.0160879 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0416     |
| _MeanReward     | 2.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95063    |
| _max_adv        | 7.14       |
| _max_discrew    | 3.44       |
| _max_obs        | 1.29       |
| _mean_act       | -0.173109  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.43       |
| _mean_obs       | 0.0428     |
| _min_adv        | -8.64      |
| _min_discrew    | 0.00747    |
| _min_obs        | -1.39      |
| _std_act        | 0.674041   |
| _std_adv        | 1          |
| _std_discrew    | 0.711      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.921      |
| KL              | 0.00178323 |
| Phi_loss        | 144.817    |
| PolicyEntropy   | 3.04881    |
| PolicyLoss      | -0.008384  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0544     |
| _MeanReward     | 2.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.45095    |
| _max_adv        | 3.08       |
| _max_discrew    | 3.53       |
| _max_obs        | 1.42       |
| _mean_act       | -0.157186  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.0439     |
| _min_adv        | -12.1      |
| _min_discrew    | -0.749     |
| _min_obs        | -1.24      |
| _std_act        | 0.720793   |
| _std_adv        | 1          |
| _std_discrew    | 0.967      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.846       |
| ExplainedVarOld | 0.833       |
| KL              | 0.00236145  |
| Phi_loss        | 134.403     |
| PolicyEntropy   | 3.04456     |
| PolicyLoss      | -0.00688469 |
| Steps           | 10000       |
| VarFuncLoss     | 0.15        |
| _MeanReward     | 2.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73464     |
| _max_adv        | 6.81        |
| _max_discrew    | 3.31        |
| _max_obs        | 1.28        |
| _mean_act       | -0.164007   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.39        |
| _mean_obs       | 0.0433      |
| _min_adv        | -7.17       |
| _min_discrew    | 0.00967     |
| _min_obs        | -1.41       |
| _std_act        | 0.676166    |
| _std_adv        | 1           |
| _std_discrew    | 0.585       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.86         |
| ExplainedVarOld | 0.835        |
| KL              | 0.00189246   |
| Phi_loss        | 131.297      |
| PolicyEntropy   | 3.03226      |
| PolicyLoss      | -0.000923071 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0822       |
| _MeanReward     | 2.82e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.07985      |
| _max_adv        | 5.72         |
| _max_discrew    | 3.45         |
| _max_obs        | 1.2          |
| _mean_act       | -0.160793    |
| _mean_adv       | 1.42e-17     |
| _mean_discrew   | 2.34         |
| _mean_obs       | 0.0438       |
| _min_adv        | -8.03        |
| _min_discrew    | 0.00216      |
| _min_obs        | -1.32        |
| _std_act        | 0.682317     |
| _std_adv        | 1            |
| _std_discrew    | 0.707        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.83       |
| ExplainedVarOld | 0.811      |
| KL              | 0.00174626 |
| Phi_loss        | 130.652    |
| PolicyEntropy   | 3.02539    |
| PolicyLoss      | 0.00299235 |
| Steps           | 10000      |
| VarFuncLoss     | 0.12       |
| _MeanReward     | 2.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.49744    |
| _max_adv        | 6.18       |
| _max_discrew    | 3.5        |
| _max_obs        | 1.55       |
| _mean_act       | -0.150468  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.18       |
| _mean_obs       | 0.0435     |
| _min_adv        | -14.4      |
| _min_discrew    | -0.808     |
| _min_obs        | -1.34      |
| _std_act        | 0.752164   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.909      |
| KL              | 0.00482049 |
| Phi_loss        | 123.523    |
| PolicyEntropy   | 3.01711    |
| PolicyLoss      | -0.0428134 |
| Steps           | 10000      |
| VarFuncLoss     | 0.122      |
| _MeanReward     | 2.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01043    |
| _max_adv        | 9.44       |
| _max_discrew    | 3.49       |
| _max_obs        | 1.22       |
| _mean_act       | -0.167891  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 2.43       |
| _mean_obs       | 0.0427     |
| _min_adv        | -7.52      |
| _min_discrew    | -0.0881    |
| _min_obs        | -1.26      |
| _std_act        | 0.667951   |
| _std_adv        | 1          |
| _std_discrew    | 0.674      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00204845 |
| Phi_loss        | 141.575    |
| PolicyEntropy   | 2.99619    |
| PolicyLoss      | 0.00200731 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0551     |
| _MeanReward     | 2.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.36133    |
| _max_adv        | 11.7       |
| _max_discrew    | 3.36       |
| _max_obs        | 1.42       |
| _mean_act       | -0.153212  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.2        |
| _mean_obs       | 0.0432     |
| _min_adv        | -14        |
| _min_discrew    | -0.827     |
| _min_obs        | -1.45      |
| _std_act        | 0.727545   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.845     |
| ExplainedVarOld | 0.829     |
| KL              | 0.0018327 |
| Phi_loss        | 161.958   |
| PolicyEntropy   | 2.97401   |
| PolicyLoss      | 0.0102221 |
| Steps           | 10000     |
| VarFuncLoss     | 0.161     |
| _MeanReward     | 3.05e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.9617    |
| _max_adv        | 8.07      |
| _max_discrew    | 3.46      |
| _max_obs        | 1.21      |
| _mean_act       | -0.171198 |
| _mean_adv       | 3.41e-17  |
| _mean_discrew   | 2.52      |
| _mean_obs       | 0.0427    |
| _min_adv        | -10.1     |
| _min_discrew    | 0.00789   |
| _min_obs        | -1.41     |
| _std_act        | 0.665583  |
| _std_adv        | 1         |
| _std_discrew    | 0.626     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.938       |
| ExplainedVarOld | 0.937       |
| KL              | 0.00138076  |
| Phi_loss        | 162.562     |
| PolicyEntropy   | 2.95773     |
| PolicyLoss      | -0.00178129 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0461      |
| _MeanReward     | 2.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67535     |
| _max_adv        | 8.57        |
| _max_discrew    | 3.51        |
| _max_obs        | 1.23        |
| _mean_act       | -0.162216   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 2.39        |
| _mean_obs       | 0.043       |
| _min_adv        | -7.1        |
| _min_discrew    | 0.00757     |
| _min_obs        | -1.26       |
| _std_act        | 0.675158    |
| _std_adv        | 1           |
| _std_discrew    | 0.668       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.818      |
| ExplainedVarOld | 0.81       |
| KL              | 0.00438968 |
| Phi_loss        | 142.221    |
| PolicyEntropy   | 2.94933    |
| PolicyLoss      | 0.0012448  |
| Steps           | 10000      |
| VarFuncLoss     | 0.123      |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64629    |
| _max_adv        | 7.37       |
| _max_discrew    | 3.51       |
| _max_obs        | 1.24       |
| _mean_act       | -0.172303  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.51       |
| _mean_obs       | 0.0424     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.00523    |
| _min_obs        | -1.37      |
| _std_act        | 0.672933   |
| _std_adv        | 1          |
| _std_discrew    | 0.622      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.895       |
| ExplainedVarOld | 0.893       |
| KL              | 0.00394164  |
| Phi_loss        | 150.583     |
| PolicyEntropy   | 2.95146     |
| PolicyLoss      | -0.00382292 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0669      |
| _MeanReward     | 3e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 3.19072     |
| _max_adv        | 7.67        |
| _max_discrew    | 3.56        |
| _max_obs        | 1.24        |
| _mean_act       | -0.167529   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 2.48        |
| _mean_obs       | 0.0423      |
| _min_adv        | -9.92       |
| _min_discrew    | -0.0155     |
| _min_obs        | -1.48       |
| _std_act        | 0.670023    |
| _std_adv        | 1           |
| _std_discrew    | 0.664       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.911       |
| KL              | 0.00417102  |
| Phi_loss        | 150.628     |
| PolicyEntropy   | 2.91946     |
| PolicyLoss      | -0.00499768 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0525      |
| _MeanReward     | 2.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.27292     |
| _max_adv        | 2.74        |
| _max_discrew    | 3.5         |
| _max_obs        | 1.42        |
| _mean_act       | -0.164743   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.3         |
| _mean_obs       | 0.0419      |
| _min_adv        | -14.3       |
| _min_discrew    | -0.758      |
| _min_obs        | -1.33       |
| _std_act        | 0.714104    |
| _std_adv        | 1           |
| _std_discrew    | 0.969       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.85        |
| ExplainedVarOld | 0.844       |
| KL              | 0.00332607  |
| Phi_loss        | 141.902     |
| PolicyEntropy   | 2.90318     |
| PolicyLoss      | -0.00117615 |
| Steps           | 10000       |
| VarFuncLoss     | 0.146       |
| _MeanReward     | 2.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.27984     |
| _max_adv        | 4.82        |
| _max_discrew    | 3.7         |
| _max_obs        | 1.43        |
| _mean_act       | -0.159232   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.27        |
| _mean_obs       | 0.0424      |
| _min_adv        | -15.5       |
| _min_discrew    | -0.8        |
| _min_obs        | -1.4        |
| _std_act        | 0.721529    |
| _std_adv        | 1           |
| _std_discrew    | 1.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.869      |
| ExplainedVarOld | 0.868      |
| KL              | 0.00274624 |
| Phi_loss        | 125.729    |
| PolicyEntropy   | 2.89227    |
| PolicyLoss      | -0.0116688 |
| Steps           | 10000      |
| VarFuncLoss     | 0.16       |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95306    |
| _max_adv        | 12.3       |
| _max_discrew    | 3.58       |
| _max_obs        | 1.21       |
| _mean_act       | -0.166367  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.0428     |
| _min_adv        | -6.93      |
| _min_discrew    | 0.00604    |
| _min_obs        | -1.35      |
| _std_act        | 0.675083   |
| _std_adv        | 1          |
| _std_discrew    | 0.652      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.893      |
| KL              | 0.00641346 |
| Phi_loss        | 158.815    |
| PolicyEntropy   | 2.87769    |
| PolicyLoss      | -0.016704  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0672     |
| _MeanReward     | 2.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75765    |
| _max_adv        | 11.3       |
| _max_discrew    | 3.49       |
| _max_obs        | 1.24       |
| _mean_act       | -0.164319  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.41       |
| _mean_obs       | 0.0422     |
| _min_adv        | -7.78      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.38      |
| _std_act        | 0.681237   |
| _std_adv        | 1          |
| _std_discrew    | 0.679      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.851      |
| ExplainedVarOld | 0.822      |
| KL              | 0.00181797 |
| Phi_loss        | 140.447    |
| PolicyEntropy   | 2.87236    |
| PolicyLoss      | -0.0127714 |
| Steps           | 10000      |
| VarFuncLoss     | 0.102      |
| _MeanReward     | 3.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86555    |
| _max_adv        | 6.8        |
| _max_discrew    | 3.62       |
| _max_obs        | 1.16       |
| _mean_act       | -0.167696  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.54       |
| _mean_obs       | 0.0431     |
| _min_adv        | -9.86      |
| _min_discrew    | 0.0022     |
| _min_obs        | -1.49      |
| _std_act        | 0.683548   |
| _std_adv        | 1          |
| _std_discrew    | 0.702      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.86       |
| ExplainedVarOld | 0.853      |
| KL              | 0.00158602 |
| Phi_loss        | 178.094    |
| PolicyEntropy   | 2.85989    |
| PolicyLoss      | 0.00758943 |
| Steps           | 10000      |
| VarFuncLoss     | 0.102      |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89612    |
| _max_adv        | 5.98       |
| _max_discrew    | 3.6        |
| _max_obs        | 1.57       |
| _mean_act       | -0.165807  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.0427     |
| _min_adv        | -10.2      |
| _min_discrew    | -0.396     |
| _min_obs        | -1.47      |
| _std_act        | 0.696806   |
| _std_adv        | 1          |
| _std_discrew    | 0.932      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.853      |
| KL              | 0.00374991 |
| Phi_loss        | 159.463    |
| PolicyEntropy   | 2.84122    |
| PolicyLoss      | -0.0122853 |
| Steps           | 10000      |
| VarFuncLoss     | 0.118      |
| _MeanReward     | 2.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93099    |
| _max_adv        | 4.56       |
| _max_discrew    | 3.75       |
| _max_obs        | 1.17       |
| _mean_act       | -0.161834  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 2.48       |
| _mean_obs       | 0.0428     |
| _min_adv        | -9.08      |
| _min_discrew    | 0.00147    |
| _min_obs        | -1.27      |
| _std_act        | 0.690564   |
| _std_adv        | 1          |
| _std_discrew    | 0.791      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.822      |
| ExplainedVarOld | 0.813      |
| KL              | 0.00134173 |
| Phi_loss        | 178.972    |
| PolicyEntropy   | 2.83651    |
| PolicyLoss      | 0.0114649  |
| Steps           | 10000      |
| VarFuncLoss     | 0.141      |
| _MeanReward     | 3.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9412     |
| _max_adv        | 9.12       |
| _max_discrew    | 3.62       |
| _max_obs        | 1.25       |
| _mean_act       | -0.17089   |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.61       |
| _mean_obs       | 0.0418     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.00892    |
| _min_obs        | -1.16      |
| _std_act        | 0.675426   |
| _std_adv        | 1          |
| _std_discrew    | 0.718      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.951       |
| ExplainedVarOld | 0.952       |
| KL              | 0.00498674  |
| Phi_loss        | 160.543     |
| PolicyEntropy   | 2.80455     |
| PolicyLoss      | -0.00787066 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0361      |
| _MeanReward     | 2.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.05587     |
| _max_adv        | 7.22        |
| _max_discrew    | 3.56        |
| _max_obs        | 1.43        |
| _mean_act       | -0.165966   |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 2.27        |
| _mean_obs       | 0.0422      |
| _min_adv        | -14.4       |
| _min_discrew    | -0.781      |
| _min_obs        | -1.34       |
| _std_act        | 0.740165    |
| _std_adv        | 1           |
| _std_discrew    | 1.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.878      |
| KL              | 0.00691188 |
| Phi_loss        | 150.119    |
| PolicyEntropy   | 2.79773    |
| PolicyLoss      | -0.0488311 |
| Steps           | 10000      |
| VarFuncLoss     | 0.162      |
| _MeanReward     | 2.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.28824    |
| _max_adv        | 7.26       |
| _max_discrew    | 3.54       |
| _max_obs        | 1.43       |
| _mean_act       | -0.164432  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.28       |
| _mean_obs       | 0.041      |
| _min_adv        | -17.3      |
| _min_discrew    | -0.802     |
| _min_obs        | -1.45      |
| _std_act        | 0.732242   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.888       |
| ExplainedVarOld | 0.881       |
| KL              | 0.00213481  |
| Phi_loss        | 142.556     |
| PolicyEntropy   | 2.79507     |
| PolicyLoss      | -0.00153486 |
| Steps           | 10000       |
| VarFuncLoss     | 0.143       |
| _MeanReward     | 3.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92167     |
| _max_adv        | 9.19        |
| _max_discrew    | 3.68        |
| _max_obs        | 1.21        |
| _mean_act       | -0.168936   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.62        |
| _mean_obs       | 0.0421      |
| _min_adv        | -7.5        |
| _min_discrew    | 0.00102     |
| _min_obs        | -1.22       |
| _std_act        | 0.684025    |
| _std_adv        | 1           |
| _std_discrew    | 0.708       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.933      |
| KL              | 0.0015754  |
| Phi_loss        | 176.347    |
| PolicyEntropy   | 2.77055    |
| PolicyLoss      | 0.00313511 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0454     |
| _MeanReward     | 3.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.86418    |
| _max_adv        | 14.5       |
| _max_discrew    | 3.62       |
| _max_obs        | 1.25       |
| _mean_act       | -0.169616  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.55       |
| _mean_obs       | 0.0415     |
| _min_adv        | -8.56      |
| _min_discrew    | 0.00533    |
| _min_obs        | -1.34      |
| _std_act        | 0.680273   |
| _std_adv        | 1          |
| _std_discrew    | 0.713      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.894      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00217875 |
| Phi_loss        | 172.536    |
| PolicyEntropy   | 2.77233    |
| PolicyLoss      | -0.0011176 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0768     |
| _MeanReward     | 3.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68785    |
| _max_adv        | 5.43       |
| _max_discrew    | 3.6        |
| _max_obs        | 1.25       |
| _mean_act       | -0.171192  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.58       |
| _mean_obs       | 0.0413     |
| _min_adv        | -9.07      |
| _min_discrew    | 0.00885    |
| _min_obs        | -1.51      |
| _std_act        | 0.681668   |
| _std_adv        | 1          |
| _std_discrew    | 0.757      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.921      |
| ExplainedVarOld | 0.915      |
| KL              | 0.00181468 |
| Phi_loss        | 178.824    |
| PolicyEntropy   | 2.78127    |
| PolicyLoss      | -0.0115588 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0602     |
| _MeanReward     | 3.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79299    |
| _max_adv        | 7.37       |
| _max_discrew    | 3.54       |
| _max_obs        | 1.18       |
| _mean_act       | -0.17114   |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 2.55       |
| _mean_obs       | 0.0408     |
| _min_adv        | -7.79      |
| _min_discrew    | 0.00999    |
| _min_obs        | -1.38      |
| _std_act        | 0.678203   |
| _std_adv        | 1          |
| _std_discrew    | 0.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00189194 |
| Phi_loss        | 190.1      |
| PolicyEntropy   | 2.7765     |
| PolicyLoss      | -0.0156897 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0237     |
| _MeanReward     | 3.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75762    |
| _max_adv        | 3.08       |
| _max_discrew    | 3.68       |
| _max_obs        | 1.18       |
| _mean_act       | -0.173829  |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 2.64       |
| _mean_obs       | 0.042      |
| _min_adv        | -10.4      |
| _min_discrew    | 0.00519    |
| _min_obs        | -1.29      |
| _std_act        | 0.679568   |
| _std_adv        | 1          |
| _std_discrew    | 0.765      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.901      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00245714 |
| Phi_loss        | 150.886    |
| PolicyEntropy   | 2.78015    |
| PolicyLoss      | -0.0227117 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0793     |
| _MeanReward     | 3.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79253    |
| _max_adv        | 7.72       |
| _max_discrew    | 3.65       |
| _max_obs        | 1.19       |
| _mean_act       | -0.17774   |
| _mean_adv       | 0          |
| _mean_discrew   | 2.66       |
| _mean_obs       | 0.0407     |
| _min_adv        | -8.97      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.29      |
| _std_act        | 0.68024    |
| _std_adv        | 1          |
| _std_discrew    | 0.676      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.943       |
| ExplainedVarOld | 0.941       |
| KL              | 0.0023593   |
| Phi_loss        | 173.069     |
| PolicyEntropy   | 2.78413     |
| PolicyLoss      | -0.00841541 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0388      |
| _MeanReward     | 2.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.25567     |
| _max_adv        | 3.53        |
| _max_discrew    | 3.68        |
| _max_obs        | 1.47        |
| _mean_act       | -0.172719   |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 2.37        |
| _mean_obs       | 0.0415      |
| _min_adv        | -14.6       |
| _min_discrew    | -0.72       |
| _min_obs        | -1.51       |
| _std_act        | 0.735583    |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.855      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00646414 |
| Phi_loss        | 189.192    |
| PolicyEntropy   | 2.76395    |
| PolicyLoss      | -0.0195565 |
| Steps           | 10000      |
| VarFuncLoss     | 0.21       |
| _MeanReward     | 3.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.39776    |
| _max_adv        | 7.72       |
| _max_discrew    | 3.73       |
| _max_obs        | 1.14       |
| _mean_act       | -0.178374  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.7        |
| _mean_obs       | 0.0416     |
| _min_adv        | -7.66      |
| _min_discrew    | 0.00625    |
| _min_obs        | -1.33      |
| _std_act        | 0.684341   |
| _std_adv        | 1          |
| _std_discrew    | 0.738      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.923       |
| ExplainedVarOld | 0.92        |
| KL              | 0.000838404 |
| Phi_loss        | 200.554     |
| PolicyEntropy   | 2.75533     |
| PolicyLoss      | -0.0108993  |
| Steps           | 10000       |
| VarFuncLoss     | 0.062       |
| _MeanReward     | 3.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.21488     |
| _max_adv        | 11.4        |
| _max_discrew    | 3.84        |
| _max_obs        | 1.27        |
| _mean_act       | -0.173394   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.64        |
| _mean_obs       | 0.0419      |
| _min_adv        | -9.04       |
| _min_discrew    | 0.00732     |
| _min_obs        | -1.38       |
| _std_act        | 0.691733    |
| _std_adv        | 1           |
| _std_discrew    | 0.83        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00200258 |
| Phi_loss        | 180.384    |
| PolicyEntropy   | 2.7573     |
| PolicyLoss      | -0.0206057 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0737     |
| _MeanReward     | 3.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24065    |
| _max_adv        | 15.8       |
| _max_discrew    | 3.75       |
| _max_obs        | 1.17       |
| _mean_act       | -0.183252  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.77       |
| _mean_obs       | 0.0411     |
| _min_adv        | -8.49      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.32      |
| _std_act        | 0.682765   |
| _std_adv        | 1          |
| _std_discrew    | 0.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.94        |
| KL              | 0.00249416  |
| Phi_loss        | 174.151     |
| PolicyEntropy   | 2.73847     |
| PolicyLoss      | -0.00603428 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0471      |
| _MeanReward     | 2.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.06502     |
| _max_adv        | 5.55        |
| _max_discrew    | 3.67        |
| _max_obs        | 1.44        |
| _mean_act       | -0.171245   |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 2.38        |
| _mean_obs       | 0.0415      |
| _min_adv        | -11.3       |
| _min_discrew    | -0.701      |
| _min_obs        | -1.34       |
| _std_act        | 0.731989    |
| _std_adv        | 1           |
| _std_discrew    | 1.2         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.817      |
| ExplainedVarOld | 0.798      |
| KL              | 0.00342078 |
| Phi_loss        | 160.569    |
| PolicyEntropy   | 2.75033    |
| PolicyLoss      | 0.0245796  |
| Steps           | 10000      |
| VarFuncLoss     | 0.228      |
| _MeanReward     | 3.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.04479    |
| _max_adv        | 8.57       |
| _max_discrew    | 3.77       |
| _max_obs        | 1.26       |
| _mean_act       | -0.178576  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 2.72       |
| _mean_obs       | 0.0408     |
| _min_adv        | -5.15      |
| _min_discrew    | 0.00807    |
| _min_obs        | -1.37      |
| _std_act        | 0.686825   |
| _std_adv        | 1          |
| _std_discrew    | 0.716      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.953       |
| ExplainedVarOld | 0.954       |
| KL              | 0.00186029  |
| Phi_loss        | 199.95      |
| PolicyEntropy   | 2.74308     |
| PolicyLoss      | -0.00930875 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0382      |
| _MeanReward     | 3.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94083     |
| _max_adv        | 6.35        |
| _max_discrew    | 3.75        |
| _max_obs        | 1.19        |
| _mean_act       | -0.178912   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0407      |
| _min_adv        | -5.97       |
| _min_discrew    | -0.0476     |
| _min_obs        | -1.3        |
| _std_act        | 0.681766    |
| _std_adv        | 1           |
| _std_discrew    | 0.79        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00227565 |
| Phi_loss        | 177.767    |
| PolicyEntropy   | 2.74831    |
| PolicyLoss      | -0.0232735 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0333     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.21687    |
| _max_adv        | 4.04       |
| _max_discrew    | 3.6        |
| _max_obs        | 1.49       |
| _mean_act       | -0.174239  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.45       |
| _mean_obs       | 0.041      |
| _min_adv        | -14.8      |
| _min_discrew    | -0.67      |
| _min_obs        | -1.16      |
| _std_act        | 0.732489   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.858      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00215    |
| Phi_loss        | 154.351    |
| PolicyEntropy   | 2.72277    |
| PolicyLoss      | -0.0307943 |
| Steps           | 10000      |
| VarFuncLoss     | 0.162      |
| _MeanReward     | 3e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 3.03331    |
| _max_adv        | 6.8        |
| _max_discrew    | 3.92       |
| _max_obs        | 1.45       |
| _mean_act       | -0.173109  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.44       |
| _mean_obs       | 0.0419     |
| _min_adv        | -15.4      |
| _min_discrew    | -0.685     |
| _min_obs        | -1.31      |
| _std_act        | 0.741316   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.871       |
| ExplainedVarOld | 0.866       |
| KL              | 0.00211317  |
| Phi_loss        | 182.906     |
| PolicyEntropy   | 2.71644     |
| PolicyLoss      | 0.000666213 |
| Steps           | 10000       |
| VarFuncLoss     | 0.178       |
| _MeanReward     | 2.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.14228     |
| _max_adv        | 3.95        |
| _max_discrew    | 3.9         |
| _max_obs        | 1.52        |
| _mean_act       | -0.170336   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.42        |
| _mean_obs       | 0.0414      |
| _min_adv        | -16.5       |
| _min_discrew    | -0.742      |
| _min_obs        | -1.24       |
| _std_act        | 0.744518    |
| _std_adv        | 1           |
| _std_discrew    | 1.64        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.9          |
| ExplainedVarOld | 0.89         |
| KL              | 0.00160343   |
| Phi_loss        | 140.901      |
| PolicyEntropy   | 2.71149      |
| PolicyLoss      | -0.000121333 |
| Steps           | 10000        |
| VarFuncLoss     | 0.165        |
| _MeanReward     | 3.03e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.08016      |
| _max_adv        | 6.96         |
| _max_discrew    | 3.67         |
| _max_obs        | 1.47         |
| _mean_act       | -0.176995    |
| _mean_adv       | 0            |
| _mean_discrew   | 2.48         |
| _mean_obs       | 0.0405       |
| _min_adv        | -17.9        |
| _min_discrew    | -0.708       |
| _min_obs        | -1.25        |
| _std_act        | 0.736193     |
| _std_adv        | 1            |
| _std_discrew    | 1.34         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.878      |
| ExplainedVarOld | 0.876      |
| KL              | 0.00115476 |
| Phi_loss        | 178.957    |
| PolicyEntropy   | 2.7101     |
| PolicyLoss      | 0.00688451 |
| Steps           | 10000      |
| VarFuncLoss     | 0.163      |
| _MeanReward     | 2.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10696    |
| _max_adv        | 6.59       |
| _max_discrew    | 3.77       |
| _max_obs        | 1.56       |
| _mean_act       | -0.163014  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.26       |
| _mean_obs       | 0.0423     |
| _min_adv        | -12.6      |
| _min_discrew    | -0.717     |
| _min_obs        | -1.21      |
| _std_act        | 0.758628   |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.834       |
| ExplainedVarOld | 0.823       |
| KL              | 0.00352419  |
| Phi_loss        | 156.538     |
| PolicyEntropy   | 2.71621     |
| PolicyLoss      | -0.00496999 |
| Steps           | 10000       |
| VarFuncLoss     | 0.279       |
| _MeanReward     | 3.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84433     |
| _max_adv        | 11          |
| _max_discrew    | 3.76        |
| _max_obs        | 1.43        |
| _mean_act       | -0.176951   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.58        |
| _mean_obs       | 0.0412      |
| _min_adv        | -11.4       |
| _min_discrew    | -0.539      |
| _min_obs        | -1.46       |
| _std_act        | 0.712684    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.867      |
| ExplainedVarOld | 0.856      |
| KL              | 0.00475353 |
| Phi_loss        | 170.711    |
| PolicyEntropy   | 2.71438    |
| PolicyLoss      | 0.00484113 |
| Steps           | 10000      |
| VarFuncLoss     | 0.137      |
| _MeanReward     | 3.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.98899    |
| _max_adv        | 15.7       |
| _max_discrew    | 3.73       |
| _max_obs        | 1.44       |
| _mean_act       | -0.176988  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.73       |
| _mean_obs       | 0.0412     |
| _min_adv        | -11.8      |
| _min_discrew    | -0.299     |
| _min_obs        | -1.47      |
| _std_act        | 0.704761   |
| _std_adv        | 1          |
| _std_discrew    | 0.943      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.915      |
| KL              | 0.00267362 |
| Phi_loss        | 177.974    |
| PolicyEntropy   | 2.69774    |
| PolicyLoss      | 0.010902   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0669     |
| _MeanReward     | 3.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9487     |
| _max_adv        | 6.57       |
| _max_discrew    | 3.81       |
| _max_obs        | 1.23       |
| _mean_act       | -0.176972  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.76       |
| _mean_obs       | 0.0413     |
| _min_adv        | -9.22      |
| _min_discrew    | -0.00902   |
| _min_obs        | -1.27      |
| _std_act        | 0.689186   |
| _std_adv        | 1          |
| _std_discrew    | 0.764      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.947       |
| ExplainedVarOld | 0.945       |
| KL              | 0.00334228  |
| Phi_loss        | 192.553     |
| PolicyEntropy   | 2.67379     |
| PolicyLoss      | -0.00263376 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0403      |
| _MeanReward     | 3.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93433     |
| _max_adv        | 5.25        |
| _max_discrew    | 3.85        |
| _max_obs        | 1.45        |
| _mean_act       | -0.176374   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.74        |
| _mean_obs       | 0.041       |
| _min_adv        | -16.2       |
| _min_discrew    | -0.471      |
| _min_obs        | -1.14       |
| _std_act        | 0.693528    |
| _std_adv        | 1           |
| _std_discrew    | 0.943       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.907      |
| KL              | 0.00374959 |
| Phi_loss        | 182.298    |
| PolicyEntropy   | 2.65724    |
| PolicyLoss      | 0.00183928 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0856     |
| _MeanReward     | 3.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84622    |
| _max_adv        | 5.59       |
| _max_discrew    | 3.93       |
| _max_obs        | 1.16       |
| _mean_act       | -0.176981  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.7        |
| _mean_obs       | 0.0409     |
| _min_adv        | -9.75      |
| _min_discrew    | 0.00686    |
| _min_obs        | -1.36      |
| _std_act        | 0.691996   |
| _std_adv        | 1          |
| _std_discrew    | 0.892      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.851      |
| ExplainedVarOld | 0.833      |
| KL              | 0.00302838 |
| Phi_loss        | 170.059    |
| PolicyEntropy   | 2.64833    |
| PolicyLoss      | 0.00280163 |
| Steps           | 10000      |
| VarFuncLoss     | 0.133      |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06173    |
| _max_adv        | 7.41       |
| _max_discrew    | 3.82       |
| _max_obs        | 1.48       |
| _mean_act       | -0.176836  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.71       |
| _mean_obs       | 0.0403     |
| _min_adv        | -10.3      |
| _min_discrew    | -0.324     |
| _min_obs        | -1.48      |
| _std_act        | 0.697006   |
| _std_adv        | 1          |
| _std_discrew    | 0.891      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.884      |
| KL              | 0.0102713  |
| Phi_loss        | 204.144    |
| PolicyEntropy   | 2.64755    |
| PolicyLoss      | -0.0545305 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0994     |
| _MeanReward     | 3.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17789    |
| _max_adv        | 9.15       |
| _max_discrew    | 3.85       |
| _max_obs        | 1.31       |
| _mean_act       | -0.178503  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.77       |
| _mean_obs       | 0.0409     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.28      |
| _std_act        | 0.693959   |
| _std_adv        | 1          |
| _std_discrew    | 0.799      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.944      |
| ExplainedVarOld | 0.934      |
| KL              | 0.00288339 |
| Phi_loss        | 210.442    |
| PolicyEntropy   | 2.62132    |
| PolicyLoss      | 0.00301024 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0451     |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09153    |
| _max_adv        | 3.88       |
| _max_discrew    | 3.84       |
| _max_obs        | 1.17       |
| _mean_act       | -0.17634   |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 2.75       |
| _mean_obs       | 0.0409     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.62      |
| _std_act        | 0.69021    |
| _std_adv        | 1          |
| _std_discrew    | 0.796      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.891      |
| ExplainedVarOld | 0.864      |
| KL              | 0.00272086 |
| Phi_loss        | 155.508    |
| PolicyEntropy   | 2.61987    |
| PolicyLoss      | -0.0178104 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0864     |
| _MeanReward     | 3.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.18769    |
| _max_adv        | 12.4       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.2        |
| _mean_act       | -0.183513  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.85       |
| _mean_obs       | 0.0409     |
| _min_adv        | -7.08      |
| _min_discrew    | 0.00763    |
| _min_obs        | -1.35      |
| _std_act        | 0.692788   |
| _std_adv        | 1          |
| _std_discrew    | 0.822      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.956       |
| KL              | 0.00262146  |
| Phi_loss        | 191.156     |
| PolicyEntropy   | 2.59785     |
| PolicyLoss      | -0.00719887 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0356      |
| _MeanReward     | 3.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91154     |
| _max_adv        | 10.9        |
| _max_discrew    | 3.94        |
| _max_obs        | 1.24        |
| _mean_act       | -0.176406   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.83        |
| _mean_obs       | 0.0411      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.00806    |
| _min_obs        | -1.5        |
| _std_act        | 0.68603     |
| _std_adv        | 1           |
| _std_discrew    | 0.814       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00229197 |
| Phi_loss        | 234.373    |
| PolicyEntropy   | 2.58502    |
| PolicyLoss      | -0.0134443 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0259     |
| _MeanReward     | 3.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88999    |
| _max_adv        | 4.39       |
| _max_discrew    | 3.79       |
| _max_obs        | 1.6        |
| _mean_act       | -0.182346  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.0405     |
| _min_adv        | -11.7      |
| _min_discrew    | -0.645     |
| _min_obs        | -1.48      |
| _std_act        | 0.723648   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00312124 |
| Phi_loss        | 165.697    |
| PolicyEntropy   | 2.58811    |
| PolicyLoss      | -0.0166058 |
| Steps           | 10000      |
| VarFuncLoss     | 0.128      |
| _MeanReward     | 3.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76763    |
| _max_adv        | 4.94       |
| _max_discrew    | 3.98       |
| _max_obs        | 1.21       |
| _mean_act       | -0.178059  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.85       |
| _mean_obs       | 0.0416     |
| _min_adv        | -9.42      |
| _min_discrew    | 0.00481    |
| _min_obs        | -1.38      |
| _std_act        | 0.698773   |
| _std_adv        | 1          |
| _std_discrew    | 0.903      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.908     |
| ExplainedVarOld | 0.904     |
| KL              | 0.0036311 |
| Phi_loss        | 199.924   |
| PolicyEntropy   | 2.57592   |
| PolicyLoss      | 0.0111725 |
| Steps           | 10000     |
| VarFuncLoss     | 0.086     |
| _MeanReward     | 3.29e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.75234   |
| _max_adv        | 9.56      |
| _max_discrew    | 4.02      |
| _max_obs        | 1.24      |
| _mean_act       | -0.176167 |
| _mean_adv       | -4.69e-17 |
| _mean_discrew   | 2.72      |
| _mean_obs       | 0.0406    |
| _min_adv        | -9.03     |
| _min_discrew    | 0.0102    |
| _min_obs        | -1.36     |
| _std_act        | 0.697149  |
| _std_adv        | 1         |
| _std_discrew    | 0.722     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.895      |
| ExplainedVarOld | 0.889      |
| KL              | 0.00231291 |
| Phi_loss        | 217.227    |
| PolicyEntropy   | 2.56674    |
| PolicyLoss      | 0.00923299 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0788     |
| _MeanReward     | 3.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95417    |
| _max_adv        | 5.01       |
| _max_discrew    | 4.01       |
| _max_obs        | 1.52       |
| _mean_act       | -0.185683  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.57       |
| _mean_obs       | 0.0394     |
| _min_adv        | -16.8      |
| _min_discrew    | -0.823     |
| _min_obs        | -1.25      |
| _std_act        | 0.740444   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.895      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00230594 |
| Phi_loss        | 224.165    |
| PolicyEntropy   | 2.54845    |
| PolicyLoss      | 0.00616222 |
| Steps           | 10000      |
| VarFuncLoss     | 0.151      |
| _MeanReward     | 3.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75557    |
| _max_adv        | 7.85       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.18       |
| _mean_act       | -0.180253  |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 2.83       |
| _mean_obs       | 0.0405     |
| _min_adv        | -9.76      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.28      |
| _std_act        | 0.693382   |
| _std_adv        | 1          |
| _std_discrew    | 0.777      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.925      |
| KL              | 0.00255854 |
| Phi_loss        | 198.526    |
| PolicyEntropy   | 2.53098    |
| PolicyLoss      | -0.011249  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0595     |
| _MeanReward     | 3.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86618    |
| _max_adv        | 9.8        |
| _max_discrew    | 3.92       |
| _max_obs        | 1.19       |
| _mean_act       | -0.177156  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.79       |
| _mean_obs       | 0.04       |
| _min_adv        | -7.87      |
| _min_discrew    | 0.00936    |
| _min_obs        | -1.23      |
| _std_act        | 0.692513   |
| _std_adv        | 1          |
| _std_discrew    | 0.732      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.886       |
| KL              | 0.00170777  |
| Phi_loss        | 168.219     |
| PolicyEntropy   | 2.52477     |
| PolicyLoss      | -0.00925147 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0658      |
| _MeanReward     | 3.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80471     |
| _max_adv        | 9.6         |
| _max_discrew    | 3.88        |
| _max_obs        | 1.17        |
| _mean_act       | -0.180843   |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 2.86        |
| _mean_obs       | 0.0403      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0102      |
| _min_obs        | -1.45       |
| _std_act        | 0.697008    |
| _std_adv        | 1           |
| _std_discrew    | 0.746       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00214715 |
| Phi_loss        | 216.088    |
| PolicyEntropy   | 2.50927    |
| PolicyLoss      | 0.00563421 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0323     |
| _MeanReward     | 3.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95147    |
| _max_adv        | 4.64       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.23       |
| _mean_act       | -0.179721  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.84       |
| _mean_obs       | 0.0405     |
| _min_adv        | -9.44      |
| _min_discrew    | 0.00033    |
| _min_obs        | -1.51      |
| _std_act        | 0.685632   |
| _std_adv        | 1          |
| _std_discrew    | 0.864      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.951        |
| ExplainedVarOld | 0.936        |
| KL              | 0.00217874   |
| Phi_loss        | 210.878      |
| PolicyEntropy   | 2.50293      |
| PolicyLoss      | -0.000868719 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0424       |
| _MeanReward     | 3.59e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.17593      |
| _max_adv        | 4.93         |
| _max_discrew    | 4            |
| _max_obs        | 1.19         |
| _mean_act       | -0.183202    |
| _mean_adv       | 4.26e-17     |
| _mean_discrew   | 2.97         |
| _mean_obs       | 0.0411       |
| _min_adv        | -10.3        |
| _min_discrew    | 0.0131       |
| _min_obs        | -1.39        |
| _std_act        | 0.69179      |
| _std_adv        | 1            |
| _std_discrew    | 0.871        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.967       |
| KL              | 0.00179068  |
| Phi_loss        | 215.248     |
| PolicyEntropy   | 2.48513     |
| PolicyLoss      | -0.00538119 |
| Steps           | 10000       |
| VarFuncLoss     | 0.028       |
| _MeanReward     | 3.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85256     |
| _max_adv        | 5.76        |
| _max_discrew    | 4.08        |
| _max_obs        | 1.26        |
| _mean_act       | -0.183306   |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 2.92        |
| _mean_obs       | 0.0409      |
| _min_adv        | -10.8       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.39       |
| _std_act        | 0.695315    |
| _std_adv        | 1           |
| _std_discrew    | 0.866       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.949       |
| ExplainedVarOld | 0.948       |
| KL              | 0.00196457  |
| Phi_loss        | 253.592     |
| PolicyEntropy   | 2.45501     |
| PolicyLoss      | -0.00840276 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0445      |
| _MeanReward     | 3.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.16448     |
| _max_adv        | 10.3        |
| _max_discrew    | 4.11        |
| _max_obs        | 1.14        |
| _mean_act       | -0.186264   |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 2.99        |
| _mean_obs       | 0.041       |
| _min_adv        | -6.02       |
| _min_discrew    | 0.00971     |
| _min_obs        | -1.27       |
| _std_act        | 0.694149    |
| _std_adv        | 1           |
| _std_discrew    | 0.883       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00278288 |
| Phi_loss        | 233.839    |
| PolicyEntropy   | 2.43883    |
| PolicyLoss      | -0.02091   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0329     |
| _MeanReward     | 3.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85776    |
| _max_adv        | 5.27       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.14       |
| _mean_act       | -0.182267  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.86       |
| _mean_obs       | 0.0402     |
| _min_adv        | -9.92      |
| _min_discrew    | -0.0759    |
| _min_obs        | -1.35      |
| _std_act        | 0.690023   |
| _std_adv        | 1          |
| _std_discrew    | 0.904      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.905      |
| KL              | 0.00411472 |
| Phi_loss        | 217.957    |
| PolicyEntropy   | 2.43198    |
| PolicyLoss      | -0.0131366 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0822     |
| _MeanReward     | 3.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90637    |
| _max_adv        | 5.74       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.17       |
| _mean_act       | -0.186701  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.04       |
| _min_adv        | -5.07      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.41      |
| _std_act        | 0.695865   |
| _std_adv        | 1          |
| _std_discrew    | 0.795      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.97       |
| KL              | 0.00183657 |
| Phi_loss        | 263.137    |
| PolicyEntropy   | 2.41717    |
| PolicyLoss      | 0.00677668 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0265     |
| _MeanReward     | 3.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87961    |
| _max_adv        | 7.44       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.17       |
| _mean_act       | -0.184364  |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 2.83       |
| _mean_obs       | 0.0397     |
| _min_adv        | -8.68      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.48      |
| _std_act        | 0.693903   |
| _std_adv        | 1          |
| _std_discrew    | 0.82       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.925      |
| ExplainedVarOld | 0.917      |
| KL              | 0.00201003 |
| Phi_loss        | 234.386    |
| PolicyEntropy   | 2.40907    |
| PolicyLoss      | -0.0102755 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0637     |
| _MeanReward     | 3.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95102    |
| _max_adv        | 4.82       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.27       |
| _mean_act       | -0.186073  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.84       |
| _mean_obs       | 0.0397     |
| _min_adv        | -8.97      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.32      |
| _std_act        | 0.694871   |
| _std_adv        | 1          |
| _std_discrew    | 0.836      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.922      |
| KL              | 0.00261016 |
| Phi_loss        | 227.464    |
| PolicyEntropy   | 2.3962     |
| PolicyLoss      | -0.0156662 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0611     |
| _MeanReward     | 3.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77642    |
| _max_adv        | 3.64       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.18       |
| _mean_act       | -0.184557  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.96       |
| _mean_obs       | 0.0412     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.00784    |
| _min_obs        | -1.5       |
| _std_act        | 0.699      |
| _std_adv        | 1          |
| _std_discrew    | 0.983      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.923       |
| ExplainedVarOld | 0.916       |
| KL              | 0.00205814  |
| Phi_loss        | 225.9       |
| PolicyEntropy   | 2.38486     |
| PolicyLoss      | -0.00518989 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0784      |
| _MeanReward     | 3.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.05215     |
| _max_adv        | 2.68        |
| _max_discrew    | 4.13        |
| _max_obs        | 1.61        |
| _mean_act       | -0.199392   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.67        |
| _mean_obs       | 0.0391      |
| _min_adv        | -15.4       |
| _min_discrew    | -0.928      |
| _min_obs        | -1.43       |
| _std_act        | 0.768734    |
| _std_adv        | 1           |
| _std_discrew    | 1.96        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00151467 |
| Phi_loss        | 156.417    |
| PolicyEntropy   | 2.3677     |
| PolicyLoss      | 0.00728899 |
| Steps           | 10000      |
| VarFuncLoss     | 0.167      |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89179    |
| _max_adv        | 4.69       |
| _max_discrew    | 3.9        |
| _max_obs        | 1.52       |
| _mean_act       | -0.200923  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.039      |
| _min_adv        | -17        |
| _min_discrew    | -0.935     |
| _min_obs        | -1.26      |
| _std_act        | 0.766453   |
| _std_adv        | 1          |
| _std_discrew    | 1.93       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.907      |
| ExplainedVarOld | 0.9        |
| KL              | 0.00253724 |
| Phi_loss        | 182.287    |
| PolicyEntropy   | 2.36737    |
| PolicyLoss      | -0.0192099 |
| Steps           | 10000      |
| VarFuncLoss     | 0.18       |
| _MeanReward     | 3.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86418    |
| _max_adv        | 13.6       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.16       |
| _mean_act       | -0.18943   |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0398     |
| _min_adv        | -4.62      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.29      |
| _std_act        | 0.691439   |
| _std_adv        | 1          |
| _std_discrew    | 0.843      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00190093 |
| Phi_loss        | 198.146    |
| PolicyEntropy   | 2.33784    |
| PolicyLoss      | -0.0079706 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0303     |
| _MeanReward     | 3.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01115    |
| _max_adv        | 16.5       |
| _max_discrew    | 3.99       |
| _max_obs        | 1.16       |
| _mean_act       | -0.18912   |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 2.93       |
| _mean_obs       | 0.0399     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.39      |
| _std_act        | 0.700595   |
| _std_adv        | 1          |
| _std_discrew    | 0.904      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.953       |
| ExplainedVarOld | 0.94        |
| KL              | 0.00273639  |
| Phi_loss        | 227.346     |
| PolicyEntropy   | 2.32051     |
| PolicyLoss      | 5.85238e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0442      |
| _MeanReward     | 3.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88552     |
| _max_adv        | 8.41        |
| _max_discrew    | 4.13        |
| _max_obs        | 1.72        |
| _mean_act       | -0.19294    |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3           |
| _mean_obs       | 0.0401      |
| _min_adv        | -13         |
| _min_discrew    | -0.306      |
| _min_obs        | -1.3        |
| _std_act        | 0.707114    |
| _std_adv        | 1           |
| _std_discrew    | 0.941       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00409525 |
| Phi_loss        | 196.57     |
| PolicyEntropy   | 2.32674    |
| PolicyLoss      | -0.0144514 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0411     |
| _MeanReward     | 3.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76738    |
| _max_adv        | 18.7       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.18       |
| _mean_act       | -0.189995  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.94       |
| _mean_obs       | 0.0403     |
| _min_adv        | -9.39      |
| _min_discrew    | -0.0277    |
| _min_obs        | -1.35      |
| _std_act        | 0.69282    |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.907      |
| ExplainedVarOld | 0.904      |
| KL              | 0.00250736 |
| Phi_loss        | 233.223    |
| PolicyEntropy   | 2.31256    |
| PolicyLoss      | -0.0130328 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0949     |
| _MeanReward     | 3.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15226    |
| _max_adv        | 8.71       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.24       |
| _mean_act       | -0.19145   |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.01       |
| _mean_obs       | 0.04       |
| _min_adv        | -11.3      |
| _min_discrew    | 0.00789    |
| _min_obs        | -1.27      |
| _std_act        | 0.699564   |
| _std_adv        | 1          |
| _std_discrew    | 0.929      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00283996 |
| Phi_loss        | 255.048    |
| PolicyEntropy   | 2.29952    |
| PolicyLoss      | -0.0315827 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0316     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88158    |
| _max_adv        | 12         |
| _max_discrew    | 4.14       |
| _max_obs        | 1.17       |
| _mean_act       | -0.190353  |
| _mean_adv       | 5.68e-17   |
| _mean_discrew   | 3.03       |
| _mean_obs       | 0.0402     |
| _min_adv        | -7.12      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.31      |
| _std_act        | 0.693407   |
| _std_adv        | 1          |
| _std_discrew    | 0.898      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00479924 |
| Phi_loss        | 283.846    |
| PolicyEntropy   | 2.28418    |
| PolicyLoss      | -0.0792705 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0309     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70999    |
| _max_adv        | 6.53       |
| _max_discrew    | 4.32       |
| _max_obs        | 1.22       |
| _mean_act       | -0.192097  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.11       |
| _mean_obs       | 0.041      |
| _min_adv        | -4.35      |
| _min_discrew    | 0.00744    |
| _min_obs        | -1.26      |
| _std_act        | 0.696276   |
| _std_adv        | 1          |
| _std_discrew    | 0.962      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.0020528  |
| Phi_loss        | 281.614    |
| PolicyEntropy   | 2.26507    |
| PolicyLoss      | 0.00542631 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84693    |
| _max_adv        | 4.32       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.17       |
| _mean_act       | -0.187584  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.99       |
| _mean_obs       | 0.0397     |
| _min_adv        | -8.18      |
| _min_discrew    | 0.00915    |
| _min_obs        | -1.35      |
| _std_act        | 0.692671   |
| _std_adv        | 1          |
| _std_discrew    | 0.943      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.908      |
| KL              | 0.00492084 |
| Phi_loss        | 254.018    |
| PolicyEntropy   | 2.24445    |
| PolicyLoss      | -0.0180925 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0824     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92382    |
| _max_adv        | 6.25       |
| _max_discrew    | 4.28       |
| _max_obs        | 1.19       |
| _mean_act       | -0.187073  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.0398     |
| _min_adv        | -9.09      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.31      |
| _std_act        | 0.707884   |
| _std_adv        | 1          |
| _std_discrew    | 0.944      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.877      |
| KL              | 0.00190944 |
| Phi_loss        | 263.547    |
| PolicyEntropy   | 2.23738    |
| PolicyLoss      | 0.00309448 |
| Steps           | 10000      |
| VarFuncLoss     | 0.111      |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06982    |
| _max_adv        | 8.64       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.25       |
| _mean_act       | -0.191466  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0397     |
| _min_adv        | -5.06      |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.38      |
| _std_act        | 0.696713   |
| _std_adv        | 1          |
| _std_discrew    | 0.896      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00245276 |
| Phi_loss        | 274.617    |
| PolicyEntropy   | 2.2345     |
| PolicyLoss      | -0.0111445 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0228     |
| _MeanReward     | 3.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92995    |
| _max_adv        | 7.75       |
| _max_discrew    | 4.05       |
| _max_obs        | 1.19       |
| _mean_act       | -0.192888  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.01       |
| _mean_obs       | 0.0399     |
| _min_adv        | -9.56      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.33      |
| _std_act        | 0.701064   |
| _std_adv        | 1          |
| _std_discrew    | 0.913      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.949      |
| KL              | 0.00220082 |
| Phi_loss        | 299.234    |
| PolicyEntropy   | 2.21552    |
| PolicyLoss      | -0.0156702 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0427     |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94274    |
| _max_adv        | 10.7       |
| _max_discrew    | 4.41       |
| _max_obs        | 1.19       |
| _mean_act       | -0.195757  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.09       |
| _mean_obs       | 0.0396     |
| _min_adv        | -4.32      |
| _min_discrew    | 0.00776    |
| _min_obs        | -1.16      |
| _std_act        | 0.700413   |
| _std_adv        | 1          |
| _std_discrew    | 0.991      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.972      |
| KL              | 0.0017789  |
| Phi_loss        | 262.369    |
| PolicyEntropy   | 2.21047    |
| PolicyLoss      | -0.0164843 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0258     |
| _MeanReward     | 3.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70828    |
| _max_adv        | 7.54       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.16       |
| _mean_act       | -0.193082  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0404     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0102     |
| _min_obs        | -1.38      |
| _std_act        | 0.696826   |
| _std_adv        | 1          |
| _std_discrew    | 0.937      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.96        |
| KL              | 0.0021566   |
| Phi_loss        | 292.161     |
| PolicyEntropy   | 2.19634     |
| PolicyLoss      | -0.00969151 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0373      |
| _MeanReward     | 3.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71637     |
| _max_adv        | 6.04        |
| _max_discrew    | 4.3         |
| _max_obs        | 1.13        |
| _mean_act       | -0.197113   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.13        |
| _mean_obs       | 0.0405      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.41       |
| _std_act        | 0.711759    |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.943       |
| KL              | 0.00620212  |
| Phi_loss        | 245.143     |
| PolicyEntropy   | 2.19311     |
| PolicyLoss      | -0.00480884 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0569      |
| _MeanReward     | 3.69e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87108     |
| _max_adv        | 5.66        |
| _max_discrew    | 4.28        |
| _max_obs        | 1.11        |
| _mean_act       | -0.197087   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0406      |
| _min_adv        | -10         |
| _min_discrew    | -0.246      |
| _min_obs        | -1.35       |
| _std_act        | 0.713899    |
| _std_adv        | 1           |
| _std_discrew    | 0.974       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.924      |
| KL              | 0.00162124 |
| Phi_loss        | 261.902    |
| PolicyEntropy   | 2.18597    |
| PolicyLoss      | 0.00609057 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0729     |
| _MeanReward     | 3.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94152    |
| _max_adv        | 7.56       |
| _max_discrew    | 4.28       |
| _max_obs        | 1.18       |
| _mean_act       | -0.19145   |
| _mean_adv       | 1.92e-17   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0407     |
| _min_adv        | -5.01      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.38      |
| _std_act        | 0.709685   |
| _std_adv        | 1          |
| _std_discrew    | 0.994      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00100853 |
| Phi_loss        | 251.223    |
| PolicyEntropy   | 2.17816    |
| PolicyLoss      | -0.0112505 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0285     |
| _MeanReward     | 3.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76712    |
| _max_adv        | 5.93       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.24       |
| _mean_act       | -0.194306  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0404     |
| _min_adv        | -5.55      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.34      |
| _std_act        | 0.706691   |
| _std_adv        | 1          |
| _std_discrew    | 0.924      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00173438 |
| Phi_loss        | 285.726    |
| PolicyEntropy   | 2.16979    |
| PolicyLoss      | -0.0139117 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0267     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68364    |
| _max_adv        | 6.12       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.18       |
| _mean_act       | -0.194016  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0405     |
| _min_adv        | -6.01      |
| _min_discrew    | 0.0071     |
| _min_obs        | -1.43      |
| _std_act        | 0.709343   |
| _std_adv        | 1          |
| _std_discrew    | 0.916      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00182835 |
| Phi_loss        | 269.867    |
| PolicyEntropy   | 2.1617     |
| PolicyLoss      | -0.0206198 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0252     |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73423    |
| _max_adv        | 3.66       |
| _max_discrew    | 4.31       |
| _max_obs        | 1.13       |
| _mean_act       | -0.193674  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.0406     |
| _min_adv        | -9.38      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.46      |
| _std_act        | 0.70915    |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.943       |
| ExplainedVarOld | 0.94        |
| KL              | 0.00291171  |
| Phi_loss        | 282.217     |
| PolicyEntropy   | 2.14311     |
| PolicyLoss      | -0.00985334 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0592      |
| _MeanReward     | 3.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84933     |
| _max_adv        | 3.59        |
| _max_discrew    | 4.2         |
| _max_obs        | 1.15        |
| _mean_act       | -0.195702   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.14        |
| _mean_obs       | 0.04        |
| _min_adv        | -10.7       |
| _min_discrew    | 0.0117      |
| _min_obs        | -1.32       |
| _std_act        | 0.702729    |
| _std_adv        | 1           |
| _std_discrew    | 0.96        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.957      |
| KL              | 0.00190458 |
| Phi_loss        | 260.296    |
| PolicyEntropy   | 2.13637    |
| PolicyLoss      | -0.0328181 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0387     |
| _MeanReward     | 3.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92372    |
| _max_adv        | 5.56       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.13       |
| _mean_act       | -0.194207  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0399     |
| _min_adv        | -8.59      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.26      |
| _std_act        | 0.711349   |
| _std_adv        | 1          |
| _std_discrew    | 0.962      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00174063 |
| Phi_loss        | 281.694    |
| PolicyEntropy   | 2.1156     |
| PolicyLoss      | 0.00153112 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0237     |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78017    |
| _max_adv        | 12         |
| _max_discrew    | 4.41       |
| _max_obs        | 1.15       |
| _mean_act       | -0.194932  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.22       |
| _mean_obs       | 0.0403     |
| _min_adv        | -4.04      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.4       |
| _std_act        | 0.708618   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00162024 |
| Phi_loss        | 289.021    |
| PolicyEntropy   | 2.10145    |
| PolicyLoss      | -0.0198144 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0273     |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58951    |
| _max_adv        | 6.98       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.22       |
| _mean_act       | -0.20042   |
| _mean_adv       | 0          |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.24      |
| _min_discrew    | 0.00753    |
| _min_obs        | -1.4       |
| _std_act        | 0.705513   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00219483 |
| Phi_loss        | 287.78     |
| PolicyEntropy   | 2.06423    |
| PolicyLoss      | 0.0134169  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73699    |
| _max_adv        | 6.51       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.2        |
| _mean_act       | -0.200645  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.0408     |
| _min_adv        | -10.9      |
| _min_discrew    | -0.0608    |
| _min_obs        | -1.28      |
| _std_act        | 0.715267   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00243858 |
| Phi_loss        | 275.583    |
| PolicyEntropy   | 2.04862    |
| PolicyLoss      | -0.0088464 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 3.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74563    |
| _max_adv        | 4.26       |
| _max_discrew    | 4.41       |
| _max_obs        | 1.25       |
| _mean_act       | -0.195562  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.0405     |
| _min_adv        | -12.3      |
| _min_discrew    | 0.012      |
| _min_obs        | -1.29      |
| _std_act        | 0.710692   |
| _std_adv        | 1          |
| _std_discrew    | 0.979      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.943      |
| KL              | 0.00229978 |
| Phi_loss        | 248.584    |
| PolicyEntropy   | 2.04625    |
| PolicyLoss      | 0.00153827 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0504     |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.42498    |
| _max_adv        | 2.25       |
| _max_discrew    | 4.32       |
| _max_obs        | 1.55       |
| _mean_act       | -0.203621  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.97       |
| _mean_obs       | 0.0396     |
| _min_adv        | -13.4      |
| _min_discrew    | -1.15      |
| _min_obs        | -1.28      |
| _std_act        | 0.777355   |
| _std_adv        | 1          |
| _std_discrew    | 1.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.872     |
| ExplainedVarOld | 0.838     |
| KL              | 0.0145011 |
| Phi_loss        | 244.462   |
| PolicyEntropy   | 2.05158   |
| PolicyLoss      | -0.181559 |
| Steps           | 10000     |
| VarFuncLoss     | 0.218     |
| _MeanReward     | 3.81e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.79872   |
| _max_adv        | 11.5      |
| _max_discrew    | 4.3       |
| _max_obs        | 1.22      |
| _mean_act       | -0.201133 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.14      |
| _mean_obs       | 0.0396    |
| _min_adv        | -7.92     |
| _min_discrew    | 0.0104    |
| _min_obs        | -1.45     |
| _std_act        | 0.705063  |
| _std_adv        | 1         |
| _std_discrew    | 0.994     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.951      |
| KL              | 0.00198099 |
| Phi_loss        | 272.748    |
| PolicyEntropy   | 2.05645    |
| PolicyLoss      | -0.0263966 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0472     |
| _MeanReward     | 3.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96948    |
| _max_adv        | 10.9       |
| _max_discrew    | 4.42       |
| _max_obs        | 1.21       |
| _mean_act       | -0.196088  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.0395     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.37      |
| _std_act        | 0.711414   |
| _std_adv        | 1          |
| _std_discrew    | 0.933      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.946      |
| KL              | 0.00124903 |
| Phi_loss        | 283.659    |
| PolicyEntropy   | 2.04165    |
| PolicyLoss      | 0.00588705 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0467     |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.99668    |
| _max_adv        | 10.5       |
| _max_discrew    | 4.53       |
| _max_obs        | 1.23       |
| _mean_act       | -0.196963  |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0395     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0156     |
| _min_obs        | -1.36      |
| _std_act        | 0.708878   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.936      |
| KL              | 0.00242916 |
| Phi_loss        | 284.151    |
| PolicyEntropy   | 2.01092    |
| PolicyLoss      | 0.0075528  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0616     |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.34686    |
| _max_adv        | 3.58       |
| _max_discrew    | 4.42       |
| _max_obs        | 1.59       |
| _mean_act       | -0.200422  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.98       |
| _mean_obs       | 0.0394     |
| _min_adv        | -13.6      |
| _min_discrew    | -1.12      |
| _min_obs        | -1.56      |
| _std_act        | 0.766389   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.878       |
| ExplainedVarOld | 0.851       |
| KL              | 0.0024551   |
| Phi_loss        | 212.563     |
| PolicyEntropy   | 2.00797     |
| PolicyLoss      | -0.00815468 |
| Steps           | 10000       |
| VarFuncLoss     | 0.2         |
| _MeanReward     | 3.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75857     |
| _max_adv        | 18.3        |
| _max_discrew    | 4.39        |
| _max_obs        | 1.14        |
| _mean_act       | -0.201582   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.3         |
| _mean_obs       | 0.04        |
| _min_adv        | -5.32       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.4        |
| _std_act        | 0.707864    |
| _std_adv        | 1           |
| _std_discrew    | 1.07        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00199558 |
| Phi_loss        | 276.845    |
| PolicyEntropy   | 1.99029    |
| PolicyLoss      | 0.00578291 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0414     |
| _MeanReward     | 3.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.0641     |
| _max_adv        | 9.49       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.21       |
| _mean_act       | -0.203558  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.04       |
| _min_adv        | -4.93      |
| _min_discrew    | 0.00857    |
| _min_obs        | -1.48      |
| _std_act        | 0.706967   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.965      |
| KL              | 0.00166106 |
| Phi_loss        | 279.279    |
| PolicyEntropy   | 1.99179    |
| PolicyLoss      | -0.0246929 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0321     |
| _MeanReward     | 3.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.11998    |
| _max_adv        | 11.1       |
| _max_discrew    | 4.24       |
| _max_obs        | 1.12       |
| _mean_act       | -0.201757  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.0393     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.38      |
| _std_act        | 0.7053     |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00188227 |
| Phi_loss        | 296.88     |
| PolicyEntropy   | 1.97859    |
| PolicyLoss      | 0.00270177 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0425     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65896    |
| _max_adv        | 5.1        |
| _max_discrew    | 4.38       |
| _max_obs        | 1.23       |
| _mean_act       | -0.20282   |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.0396     |
| _min_adv        | -6.24      |
| _min_discrew    | 0.015      |
| _min_obs        | -1.27      |
| _std_act        | 0.70577    |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00164422 |
| Phi_loss        | 295.808    |
| PolicyEntropy   | 1.97531    |
| PolicyLoss      | -0.0124112 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0238     |
| _MeanReward     | 3.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90305    |
| _max_adv        | 5.28       |
| _max_discrew    | 4.52       |
| _max_obs        | 1.23       |
| _mean_act       | -0.200554  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0396     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.00986    |
| _min_obs        | -1.2       |
| _std_act        | 0.70741    |
| _std_adv        | 1          |
| _std_discrew    | 0.997      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.919      |
| KL              | 0.00291802 |
| Phi_loss        | 270.024    |
| PolicyEntropy   | 1.95067    |
| PolicyLoss      | 0.00164986 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0747     |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87733    |
| _max_adv        | 10         |
| _max_discrew    | 4.46       |
| _max_obs        | 1.16       |
| _mean_act       | -0.20082   |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0394     |
| _min_adv        | -12.8      |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.28      |
| _std_act        | 0.705227   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.949      |
| KL              | 0.00351875 |
| Phi_loss        | 246.533    |
| PolicyEntropy   | 1.94428    |
| PolicyLoss      | -0.0108707 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0513     |
| _MeanReward     | 3.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.39045    |
| _max_adv        | 4.13       |
| _max_discrew    | 4.38       |
| _max_obs        | 1.62       |
| _mean_act       | -0.206266  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.86       |
| _mean_obs       | 0.038      |
| _min_adv        | -17.4      |
| _min_discrew    | -1.12      |
| _min_obs        | -1.23      |
| _std_act        | 0.782906   |
| _std_adv        | 1          |
| _std_discrew    | 2.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.901      |
| KL              | 0.00354043 |
| Phi_loss        | 304.823    |
| PolicyEntropy   | 1.93846    |
| PolicyLoss      | -0.0143323 |
| Steps           | 10000      |
| VarFuncLoss     | 0.201      |
| _MeanReward     | 3.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61898    |
| _max_adv        | 23.4       |
| _max_discrew    | 4.4        |
| _max_obs        | 1.15       |
| _mean_act       | -0.204246  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0395     |
| _min_adv        | -9.41      |
| _min_discrew    | -0.19      |
| _min_obs        | -1.41      |
| _std_act        | 0.705739   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.964       |
| ExplainedVarOld | 0.96        |
| KL              | 0.00472391  |
| Phi_loss        | 290.642     |
| PolicyEntropy   | 1.9327      |
| PolicyLoss      | -0.00646775 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0438      |
| _MeanReward     | 3.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.24981     |
| _max_adv        | 3.62        |
| _max_discrew    | 4.33        |
| _max_obs        | 1.67        |
| _mean_act       | -0.204843   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.95        |
| _mean_obs       | 0.0391      |
| _min_adv        | -20.1       |
| _min_discrew    | -1.11       |
| _min_obs        | -1.32       |
| _std_act        | 0.787955    |
| _std_adv        | 1           |
| _std_discrew    | 2.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.909       |
| KL              | 0.00303059  |
| Phi_loss        | 343.268     |
| PolicyEntropy   | 1.89915     |
| PolicyLoss      | -0.00867181 |
| Steps           | 10000       |
| VarFuncLoss     | 0.202       |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.98573     |
| _max_adv        | 4.77        |
| _max_discrew    | 4.58        |
| _max_obs        | 1.17        |
| _mean_act       | -0.205299   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.34        |
| _mean_obs       | 0.0394      |
| _min_adv        | -4.41       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.47       |
| _std_act        | 0.707088    |
| _std_adv        | 1           |
| _std_discrew    | 1.05        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00153394 |
| Phi_loss        | 370.815    |
| PolicyEntropy   | 1.88532    |
| PolicyLoss      | 0.0110417  |
| Steps           | 10000      |
| VarFuncLoss     | 0.03       |
| _MeanReward     | 3.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10234    |
| _max_adv        | 13.6       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.14       |
| _mean_act       | -0.202479  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0393     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.00539    |
| _min_obs        | -1.27      |
| _std_act        | 0.706676   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00165589 |
| Phi_loss        | 286.731    |
| PolicyEntropy   | 1.86443    |
| PolicyLoss      | -0.0325153 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0435     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6292     |
| _max_adv        | 4.33       |
| _max_discrew    | 4.4        |
| _max_obs        | 1.11       |
| _mean_act       | -0.204741  |
| _mean_adv       | 3.27e-17   |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0396     |
| _min_adv        | -5.37      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.4       |
| _std_act        | 0.708964   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00202765  |
| Phi_loss        | 366.923     |
| PolicyEntropy   | 1.84882     |
| PolicyLoss      | -0.00348973 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0214      |
| _MeanReward     | 3.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.24179     |
| _max_adv        | 9.56        |
| _max_discrew    | 4.39        |
| _max_obs        | 1.2         |
| _mean_act       | -0.198157   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.19        |
| _mean_obs       | 0.0403      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.43       |
| _std_act        | 0.722478    |
| _std_adv        | 1           |
| _std_discrew    | 1.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.89       |
| ExplainedVarOld | 0.874      |
| KL              | 0.00502455 |
| Phi_loss        | 290.776    |
| PolicyEntropy   | 1.85394    |
| PolicyLoss      | 0.0350551  |
| Steps           | 10000      |
| VarFuncLoss     | 0.129      |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.98848    |
| _max_adv        | 12.3       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.18       |
| _mean_act       | -0.206197  |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0396     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.00273    |
| _min_obs        | -1.32      |
| _std_act        | 0.71149    |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.938       |
| ExplainedVarOld | 0.936       |
| KL              | 0.00248119  |
| Phi_loss        | 280.61      |
| PolicyEntropy   | 1.83876     |
| PolicyLoss      | -0.00399485 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0697      |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59997     |
| _max_adv        | 9.12        |
| _max_discrew    | 4.61        |
| _max_obs        | 1.15        |
| _mean_act       | -0.206175   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0398      |
| _min_adv        | -5          |
| _min_discrew    | 0.0114      |
| _min_obs        | -1.27       |
| _std_act        | 0.710056    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.959      |
| KL              | 0.00171353 |
| Phi_loss        | 282.14     |
| PolicyEntropy   | 1.83116    |
| PolicyLoss      | -0.0185946 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0332     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7581     |
| _max_adv        | 5.96       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.14       |
| _mean_act       | -0.20847   |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.35       |
| _mean_obs       | 0.0392     |
| _min_adv        | -6.57      |
| _min_discrew    | 0.00935    |
| _min_obs        | -1.26      |
| _std_act        | 0.712651   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00194324 |
| Phi_loss        | 343.513    |
| PolicyEntropy   | 1.80765    |
| PolicyLoss      | -0.0317144 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 3.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24851    |
| _max_adv        | 1.48       |
| _max_discrew    | 4.41       |
| _max_obs        | 1.6        |
| _mean_act       | -0.211836  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.89       |
| _mean_obs       | 0.0381     |
| _min_adv        | -17.3      |
| _min_discrew    | -0.981     |
| _min_obs        | -1.37      |
| _std_act        | 0.788361   |
| _std_adv        | 1          |
| _std_discrew    | 2.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.924      |
| KL              | 0.00774919 |
| Phi_loss        | 269.675    |
| PolicyEntropy   | 1.83598    |
| PolicyLoss      | -0.039125  |
| Steps           | 10000      |
| VarFuncLoss     | 0.175      |
| _MeanReward     | 3.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66637    |
| _max_adv        | 14.7       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.26       |
| _mean_act       | -0.202341  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0393     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.0128     |
| _min_obs        | -1.37      |
| _std_act        | 0.714676   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.928       |
| ExplainedVarOld | 0.916       |
| KL              | 0.00202875  |
| Phi_loss        | 239.529     |
| PolicyEntropy   | 1.81932     |
| PolicyLoss      | -0.00740372 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0787      |
| _MeanReward     | 4.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91443     |
| _max_adv        | 20.1        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.19        |
| _mean_act       | -0.209323   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.4         |
| _mean_obs       | 0.0398      |
| _min_adv        | -9.98       |
| _min_discrew    | 0.000786    |
| _min_obs        | -1.31       |
| _std_act        | 0.715454    |
| _std_adv        | 1           |
| _std_discrew    | 1.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00104255 |
| Phi_loss        | 311.264    |
| PolicyEntropy   | 1.80441    |
| PolicyLoss      | 0.0211931  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0472     |
| _MeanReward     | 3.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72299    |
| _max_adv        | 5.49       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.19       |
| _mean_act       | -0.204895  |
| _mean_adv       | -5.68e-17  |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0394     |
| _min_adv        | -11.8      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.39      |
| _std_act        | 0.713044   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.937      |
| ExplainedVarOld | 0.933      |
| KL              | 0.00227506 |
| Phi_loss        | 392.235    |
| PolicyEntropy   | 1.79025    |
| PolicyLoss      | -0.0243641 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0719     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78619    |
| _max_adv        | 6.38       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.13       |
| _mean_act       | -0.207631  |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0392     |
| _min_adv        | -11.5      |
| _min_discrew    | 0.0126     |
| _min_obs        | -1.29      |
| _std_act        | 0.716314   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.948      |
| ExplainedVarOld | 0.946      |
| KL              | 0.00226775 |
| Phi_loss        | 339.189    |
| PolicyEntropy   | 1.76788    |
| PolicyLoss      | 0.0166935  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0595     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88031    |
| _max_adv        | 9.2        |
| _max_discrew    | 4.53       |
| _max_obs        | 1.17       |
| _mean_act       | -0.210323  |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 3.35       |
| _mean_obs       | 0.0387     |
| _min_adv        | -11.4      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.24      |
| _std_act        | 0.710662   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.966       |
| KL              | 0.00248457  |
| Phi_loss        | 334.554     |
| PolicyEntropy   | 1.76522     |
| PolicyLoss      | -0.00818023 |
| Steps           | 10000       |
| VarFuncLoss     | 0.033       |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12012     |
| _max_adv        | 6.37        |
| _max_discrew    | 4.49        |
| _max_obs        | 1.12        |
| _mean_act       | -0.208167   |
| _mean_adv       | 2.42e-17    |
| _mean_discrew   | 3.36        |
| _mean_obs       | 0.0395      |
| _min_adv        | -11.6       |
| _min_discrew    | 0.0145      |
| _min_obs        | -1.25       |
| _std_act        | 0.712267    |
| _std_adv        | 1           |
| _std_discrew    | 1.09        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00191076 |
| Phi_loss        | 356.257    |
| PolicyEntropy   | 1.76018    |
| PolicyLoss      | -0.0296847 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0361     |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10872    |
| _max_adv        | 3.21       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.2        |
| _mean_act       | -0.208164  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0392     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.46      |
| _std_act        | 0.710853   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.944      |
| ExplainedVarOld | 0.939      |
| KL              | 0.00197648 |
| Phi_loss        | 315.702    |
| PolicyEntropy   | 1.74542    |
| PolicyLoss      | -0.0180346 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0592     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69896    |
| _max_adv        | 8.76       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.13       |
| _mean_act       | -0.207286  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0392     |
| _min_adv        | -9.01      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.19      |
| _std_act        | 0.713972   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00219769 |
| Phi_loss        | 329.284    |
| PolicyEntropy   | 1.74004    |
| PolicyLoss      | 0.00600014 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0327     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.75412    |
| _max_adv        | 6.58       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.68       |
| _mean_act       | -0.207032  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.039      |
| _min_adv        | -10.6      |
| _min_discrew    | -0.684     |
| _min_obs        | -1.39      |
| _std_act        | 0.737192   |
| _std_adv        | 1          |
| _std_discrew    | 1.47       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.824      |
| KL              | 0.00589031 |
| Phi_loss        | 204.731    |
| PolicyEntropy   | 1.74403    |
| PolicyLoss      | -0.0140139 |
| Steps           | 10000      |
| VarFuncLoss     | 0.178      |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69482    |
| _max_adv        | 9.17       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.13       |
| _mean_act       | -0.209369  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0389     |
| _min_adv        | -5.74      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.35      |
| _std_act        | 0.709083   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.0020505  |
| Phi_loss        | 340.235    |
| PolicyEntropy   | 1.73505    |
| PolicyLoss      | -0.0116249 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0273     |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73666    |
| _max_adv        | 11.5       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.14       |
| _mean_act       | -0.211671  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.0387     |
| _min_adv        | -4.21      |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.26      |
| _std_act        | 0.709334   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00182503 |
| Phi_loss        | 347.224    |
| PolicyEntropy   | 1.72442    |
| PolicyLoss      | -0.0189301 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0222     |
| _MeanReward     | 4.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93838    |
| _max_adv        | 5.02       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.18       |
| _mean_act       | -0.207633  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.039      |
| _min_adv        | -9.94      |
| _min_discrew    | 0.0107     |
| _min_obs        | -1.33      |
| _std_act        | 0.727693   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.888      |
| KL              | 0.00290818 |
| Phi_loss        | 387.779    |
| PolicyEntropy   | 1.72467    |
| PolicyLoss      | -0.0194406 |
| Steps           | 10000      |
| VarFuncLoss     | 0.122      |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73247    |
| _max_adv        | 9.08       |
| _max_discrew    | 4.64       |
| _max_obs        | 1.2        |
| _mean_act       | -0.210504  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0389     |
| _min_adv        | -4.77      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.36      |
| _std_act        | 0.713678   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00186476 |
| Phi_loss        | 349.356    |
| PolicyEntropy   | 1.7104     |
| PolicyLoss      | 0.0145483  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0263     |
| _MeanReward     | 4.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14909    |
| _max_adv        | 5.15       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.2        |
| _mean_act       | -0.211713  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.5        |
| _mean_obs       | 0.0397     |
| _min_adv        | -3.95      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.37      |
| _std_act        | 0.717535   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.97       |
| KL              | 0.0018433  |
| Phi_loss        | 360.808    |
| PolicyEntropy   | 1.69138    |
| PolicyLoss      | -0.0184909 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0319     |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86696    |
| _max_adv        | 10.3       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.13       |
| _mean_act       | -0.208863  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0393     |
| _min_adv        | -10        |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.34      |
| _std_act        | 0.725233   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00180471  |
| Phi_loss        | 346.223     |
| PolicyEntropy   | 1.67234     |
| PolicyLoss      | -0.00188875 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0299      |
| _MeanReward     | 3.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.21313     |
| _max_adv        | 5.84        |
| _max_discrew    | 4.66        |
| _max_obs        | 1.81        |
| _mean_act       | -0.213476   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.11        |
| _mean_obs       | 0.038       |
| _min_adv        | -18.3       |
| _min_discrew    | -1.02       |
| _min_obs        | -1.44       |
| _std_act        | 0.782114    |
| _std_adv        | 1           |
| _std_discrew    | 2.2         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.892      |
| ExplainedVarOld | 0.874      |
| KL              | 0.00519491 |
| Phi_loss        | 291.061    |
| PolicyEntropy   | 1.67811    |
| PolicyLoss      | -0.0634385 |
| Steps           | 10000      |
| VarFuncLoss     | 0.239      |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6167     |
| _max_adv        | 11.9       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.14       |
| _mean_act       | -0.211464  |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0391     |
| _min_adv        | -7.09      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.44      |
| _std_act        | 0.711809   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00196804 |
| Phi_loss        | 376.849    |
| PolicyEntropy   | 1.66701    |
| PolicyLoss      | -0.019325  |
| Steps           | 10000      |
| VarFuncLoss     | 0.042      |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61767    |
| _max_adv        | 15.8       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.12       |
| _mean_act       | -0.210018  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0393     |
| _min_adv        | -7.92      |
| _min_discrew    | 0.00586    |
| _min_obs        | -1.3       |
| _std_act        | 0.716973   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00197215  |
| Phi_loss        | 340.017     |
| PolicyEntropy   | 1.65301     |
| PolicyLoss      | -0.00333548 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0349      |
| _MeanReward     | 4.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.83609     |
| _max_adv        | 14          |
| _max_discrew    | 4.75        |
| _max_obs        | 1.16        |
| _mean_act       | -0.210033   |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 3.39        |
| _mean_obs       | 0.039       |
| _min_adv        | -10.2       |
| _min_discrew    | 0.013       |
| _min_obs        | -1.31       |
| _std_act        | 0.727315    |
| _std_adv        | 1           |
| _std_discrew    | 1.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.928      |
| KL              | 0.00424268 |
| Phi_loss        | 363.097    |
| PolicyEntropy   | 1.62543    |
| PolicyLoss      | -0.0201411 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0766     |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.77895    |
| _max_adv        | 5.13       |
| _max_discrew    | 4.76       |
| _max_obs        | 1.12       |
| _mean_act       | -0.206814  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0394     |
| _min_adv        | -6.25      |
| _min_discrew    | 0.00879    |
| _min_obs        | -1.33      |
| _std_act        | 0.722954   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.975     |
| ExplainedVarOld | 0.974     |
| KL              | 0.0021551 |
| Phi_loss        | 397.165   |
| PolicyEntropy   | 1.60121   |
| PolicyLoss      | 0.0108531 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0281    |
| _MeanReward     | 4.13e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.06844   |
| _max_adv        | 8.15      |
| _max_discrew    | 4.85      |
| _max_obs        | 1.2       |
| _mean_act       | -0.210022 |
| _mean_adv       | 2.84e-17  |
| _mean_discrew   | 3.42      |
| _mean_obs       | 0.0394    |
| _min_adv        | -9.69     |
| _min_discrew    | 0.014     |
| _min_obs        | -1.39     |
| _std_act        | 0.724533  |
| _std_adv        | 1         |
| _std_discrew    | 1.14      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.951       |
| ExplainedVarOld | 0.95        |
| KL              | 0.00189004  |
| Phi_loss        | 350.699     |
| PolicyEntropy   | 1.59602     |
| PolicyLoss      | -0.00592603 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0567      |
| _MeanReward     | 3.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.29243     |
| _max_adv        | 3.76        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.73        |
| _mean_act       | -0.214066   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0384      |
| _min_adv        | -13.7       |
| _min_discrew    | -1.07       |
| _min_obs        | -1.26       |
| _std_act        | 0.761831    |
| _std_adv        | 1           |
| _std_discrew    | 1.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.878      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00381828 |
| Phi_loss        | 269.24     |
| PolicyEntropy   | 1.57743    |
| PolicyLoss      | -0.0164113 |
| Steps           | 10000      |
| VarFuncLoss     | 0.226      |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71985    |
| _max_adv        | 10.7       |
| _max_discrew    | 4.74       |
| _max_obs        | 1.19       |
| _mean_act       | -0.21096   |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0394     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.3       |
| _std_act        | 0.72302    |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00211207 |
| Phi_loss        | 433.295    |
| PolicyEntropy   | 1.56544    |
| PolicyLoss      | -0.0146503 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0552     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78203    |
| _max_adv        | 17.9       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.13       |
| _mean_act       | -0.212876  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0388     |
| _min_adv        | -9.67      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.27      |
| _std_act        | 0.71966    |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.954      |
| ExplainedVarOld | 0.951      |
| KL              | 0.00196791 |
| Phi_loss        | 370.147    |
| PolicyEntropy   | 1.5597     |
| PolicyLoss      | 0.0127954  |
| Steps           | 10000      |
| VarFuncLoss     | 0.053      |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66895    |
| _max_adv        | 5.45       |
| _max_discrew    | 4.73       |
| _max_obs        | 1.21       |
| _mean_act       | -0.212687  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 3.52       |
| _mean_obs       | 0.0394     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.00717    |
| _min_obs        | -1.22      |
| _std_act        | 0.712761   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00177299 |
| Phi_loss        | 351.98     |
| PolicyEntropy   | 1.56448    |
| PolicyLoss      | 0.0053881  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0504     |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89466    |
| _max_adv        | 12.3       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.14       |
| _mean_act       | -0.214729  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0389     |
| _min_adv        | -8.45      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.32      |
| _std_act        | 0.725704   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.955       |
| KL              | 0.00269283  |
| Phi_loss        | 413.507     |
| PolicyEntropy   | 1.55684     |
| PolicyLoss      | -0.00302529 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0505      |
| _MeanReward     | 4.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62024     |
| _max_adv        | 7.84        |
| _max_discrew    | 4.7         |
| _max_obs        | 1.06        |
| _mean_act       | -0.212928   |
| _mean_adv       | 1.28e-17    |
| _mean_discrew   | 3.5         |
| _mean_obs       | 0.0394      |
| _min_adv        | -4.57       |
| _min_discrew    | 0.0138      |
| _min_obs        | -1.3        |
| _std_act        | 0.72156     |
| _std_adv        | 1           |
| _std_discrew    | 1.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00172168  |
| Phi_loss        | 460.651     |
| PolicyEntropy   | 1.55245     |
| PolicyLoss      | -0.00332848 |
| Steps           | 10000       |
| VarFuncLoss     | 0.017       |
| _MeanReward     | 4.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95527     |
| _max_adv        | 12.3        |
| _max_discrew    | 4.76        |
| _max_obs        | 1.16        |
| _mean_act       | -0.213205   |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0395      |
| _min_adv        | -10.8       |
| _min_discrew    | 0.0142      |
| _min_obs        | -1.26       |
| _std_act        | 0.717672    |
| _std_adv        | 1           |
| _std_discrew    | 1.18        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00193533 |
| Phi_loss        | 383.513    |
| PolicyEntropy   | 1.54193    |
| PolicyLoss      | -0.0170683 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0394     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89994    |
| _max_adv        | 7.75       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.18       |
| _mean_act       | -0.216205  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0396     |
| _min_adv        | -7.43      |
| _min_discrew    | 0.00691    |
| _min_obs        | -1.33      |
| _std_act        | 0.718951   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00235678 |
| Phi_loss        | 416.0      |
| PolicyEntropy   | 1.5346     |
| PolicyLoss      | 0.0063676  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0306     |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05656    |
| _max_adv        | 3.52       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.28       |
| _mean_act       | -0.214499  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0391     |
| _min_adv        | -10.8      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.29      |
| _std_act        | 0.716163   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.978       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00292263  |
| Phi_loss        | 471.472     |
| PolicyEntropy   | 1.51462     |
| PolicyLoss      | -0.00531445 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0271      |
| _MeanReward     | 3.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.90137     |
| _max_adv        | 0.939       |
| _max_discrew    | 4.76        |
| _max_obs        | 2.12        |
| _mean_act       | -0.229653   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.56        |
| _mean_obs       | 0.0357      |
| _min_adv        | -10.8       |
| _min_discrew    | -1.24       |
| _min_obs        | -1.31       |
| _std_act        | 0.883582    |
| _std_adv        | 1           |
| _std_discrew    | 3.8         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.828      |
| ExplainedVarOld | 0.803      |
| KL              | 0.00487941 |
| Phi_loss        | 338.753    |
| PolicyEntropy   | 1.53469    |
| PolicyLoss      | -0.0300694 |
| Steps           | 10000      |
| VarFuncLoss     | 0.675      |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60559    |
| _max_adv        | 9.6        |
| _max_discrew    | 4.67       |
| _max_obs        | 1.1        |
| _mean_act       | -0.213412  |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0395     |
| _min_adv        | -7.91      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.24      |
| _std_act        | 0.712932   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00195715 |
| Phi_loss        | 360.005    |
| PolicyEntropy   | 1.5341     |
| PolicyLoss      | 0.00557747 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0585     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97251    |
| _max_adv        | 14.1       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.12       |
| _mean_act       | -0.210912  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0386     |
| _min_adv        | -7.78      |
| _min_discrew    | 0.00966    |
| _min_obs        | -1.32      |
| _std_act        | 0.715791   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.955      |
| KL              | 0.0017795  |
| Phi_loss        | 346.438    |
| PolicyEntropy   | 1.52989    |
| PolicyLoss      | 0.00149149 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0443     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73821    |
| _max_adv        | 6.65       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.12       |
| _mean_act       | -0.215323  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0394     |
| _min_adv        | -5.56      |
| _min_discrew    | 0.013      |
| _min_obs        | -1.31      |
| _std_act        | 0.713812   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00199438  |
| Phi_loss        | 428.21      |
| PolicyEntropy   | 1.51322     |
| PolicyLoss      | 0.000676754 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0332      |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.24523     |
| _max_adv        | 2.91        |
| _max_discrew    | 4.67        |
| _max_obs        | 1.65        |
| _mean_act       | -0.214638   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.23        |
| _mean_obs       | 0.0375      |
| _min_adv        | -18.4       |
| _min_discrew    | -1.07       |
| _min_obs        | -1.27       |
| _std_act        | 0.759079    |
| _std_adv        | 1           |
| _std_discrew    | 1.91        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.867      |
| ExplainedVarOld | 0.86       |
| KL              | 0.0021487  |
| Phi_loss        | 390.662    |
| PolicyEntropy   | 1.49865    |
| PolicyLoss      | -0.0176347 |
| Steps           | 10000      |
| VarFuncLoss     | 0.262      |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96509    |
| _max_adv        | 10.5       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.09       |
| _mean_act       | -0.209201  |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0387     |
| _min_adv        | -12.4      |
| _min_discrew    | -0.0466    |
| _min_obs        | -1.36      |
| _std_act        | 0.713148   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.921      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00208622 |
| Phi_loss        | 348.763    |
| PolicyEntropy   | 1.49919    |
| PolicyLoss      | 0.00989183 |
| Steps           | 10000      |
| VarFuncLoss     | 0.119      |
| _MeanReward     | 4.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.32107    |
| _max_adv        | 8.35       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.89       |
| _mean_act       | -0.214396  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0381     |
| _min_adv        | -17.7      |
| _min_discrew    | -0.796     |
| _min_obs        | -1.33      |
| _std_act        | 0.734773   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.939     |
| ExplainedVarOld | 0.93      |
| KL              | 0.0075999 |
| Phi_loss        | 331.215   |
| PolicyEntropy   | 1.49459   |
| PolicyLoss      | 0.0358581 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0968    |
| _MeanReward     | 4.22e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.93468   |
| _max_adv        | 8.16      |
| _max_discrew    | 4.75      |
| _max_obs        | 1.15      |
| _mean_act       | -0.21115  |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.5       |
| _mean_obs       | 0.0391    |
| _min_adv        | -10.5     |
| _min_discrew    | 0.0101    |
| _min_obs        | -1.34     |
| _std_act        | 0.71586   |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.926       |
| KL              | 0.00160998  |
| Phi_loss        | 317.534     |
| PolicyEntropy   | 1.48592     |
| PolicyLoss      | -0.00707913 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0773      |
| _MeanReward     | 4.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75852     |
| _max_adv        | 5.41        |
| _max_discrew    | 4.71        |
| _max_obs        | 1.14        |
| _mean_act       | -0.215731   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.59        |
| _mean_obs       | 0.0381      |
| _min_adv        | -3.58       |
| _min_discrew    | 0.0146      |
| _min_obs        | -1.33       |
| _std_act        | 0.704881    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.982        |
| ExplainedVarOld | 0.98         |
| KL              | 0.00113022   |
| Phi_loss        | 384.061      |
| PolicyEntropy   | 1.47573      |
| PolicyLoss      | -0.000334753 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0235       |
| _MeanReward     | 4.39e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.56919      |
| _max_adv        | 25.2         |
| _max_discrew    | 5.01         |
| _max_obs        | 1.15         |
| _mean_act       | -0.216625    |
| _mean_adv       | -3.13e-17    |
| _mean_discrew   | 3.63         |
| _mean_obs       | 0.0391       |
| _min_adv        | -8.9         |
| _min_discrew    | 0.0108       |
| _min_obs        | -1.4         |
| _std_act        | 0.7058       |
| _std_adv        | 1            |
| _std_discrew    | 1.26         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.973     |
| ExplainedVarOld | 0.96      |
| KL              | 0.0139632 |
| Phi_loss        | 286.822   |
| PolicyEntropy   | 1.45839   |
| PolicyLoss      | -0.103463 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0348    |
| _MeanReward     | 4.34e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.51877   |
| _max_adv        | 5.5       |
| _max_discrew    | 4.79      |
| _max_obs        | 1.16      |
| _mean_act       | -0.218363 |
| _mean_adv       | -2.42e-17 |
| _mean_discrew   | 3.59      |
| _mean_obs       | 0.0388    |
| _min_adv        | -3.79     |
| _min_discrew    | 0.0207    |
| _min_obs        | -1.44     |
| _std_act        | 0.705799  |
| _std_adv        | 1         |
| _std_discrew    | 1.26      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00203091  |
| Phi_loss        | 504.935     |
| PolicyEntropy   | 1.44924     |
| PolicyLoss      | -0.00065429 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0218      |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71053     |
| _max_adv        | 5.21        |
| _max_discrew    | 4.84        |
| _max_obs        | 1.15        |
| _mean_act       | -0.216082   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.038       |
| _min_adv        | -6.26       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.52       |
| _std_act        | 0.708526    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00101453  |
| Phi_loss        | 490.595     |
| PolicyEntropy   | 1.4424      |
| PolicyLoss      | -0.00364917 |
| Steps           | 10000       |
| VarFuncLoss     | 0.034       |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5846      |
| _max_adv        | 5.03        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.23        |
| _mean_act       | -0.217243   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.6         |
| _mean_obs       | 0.0382      |
| _min_adv        | -4.39       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.3        |
| _std_act        | 0.703631    |
| _std_adv        | 1           |
| _std_discrew    | 1.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00157984  |
| Phi_loss        | 505.673     |
| PolicyEntropy   | 1.41586     |
| PolicyLoss      | -0.00729544 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0313      |
| _MeanReward     | 4.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.53764     |
| _max_adv        | 3.08        |
| _max_discrew    | 4.78        |
| _max_obs        | 1.16        |
| _mean_act       | -0.215492   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.57        |
| _mean_obs       | 0.0384      |
| _min_adv        | -5.72       |
| _min_discrew    | 0.0171      |
| _min_obs        | -1.36       |
| _std_act        | 0.705338    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00183688  |
| Phi_loss        | 501.041     |
| PolicyEntropy   | 1.39434     |
| PolicyLoss      | 0.000352394 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0337      |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87462     |
| _max_adv        | 4.07        |
| _max_discrew    | 4.74        |
| _max_obs        | 1.11        |
| _mean_act       | -0.213511   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.58        |
| _mean_obs       | 0.0382      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.29       |
| _std_act        | 0.706791    |
| _std_adv        | 1           |
| _std_discrew    | 1.2         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.96       |
| KL              | 0.00211755 |
| Phi_loss        | 467.884    |
| PolicyEntropy   | 1.37784    |
| PolicyLoss      | -0.0195709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0436     |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90925    |
| _max_adv        | 4.26       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.12       |
| _mean_act       | -0.217177  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.06      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.33      |
| _std_act        | 0.706467   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.982        |
| ExplainedVarOld | 0.98         |
| KL              | 0.00174422   |
| Phi_loss        | 476.109      |
| PolicyEntropy   | 1.35542      |
| PolicyLoss      | -0.000610696 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0231       |
| _MeanReward     | 4.36e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.96789      |
| _max_adv        | 4.6          |
| _max_discrew    | 4.87         |
| _max_obs        | 1.15         |
| _mean_act       | -0.218979    |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 3.61         |
| _mean_obs       | 0.0386       |
| _min_adv        | -7.05        |
| _min_discrew    | 0.00253      |
| _min_obs        | -1.43        |
| _std_act        | 0.708772     |
| _std_adv        | 1            |
| _std_discrew    | 1.31         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00233464 |
| Phi_loss        | 525.645    |
| PolicyEntropy   | 1.34446    |
| PolicyLoss      | 0.00829307 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0246     |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87011    |
| _max_adv        | 5.06       |
| _max_discrew    | 5.17       |
| _max_obs        | 1.1        |
| _mean_act       | -0.221103  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0385     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0193     |
| _min_obs        | -1.37      |
| _std_act        | 0.711765   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.936      |
| KL              | 0.0020295  |
| Phi_loss        | 459.912    |
| PolicyEntropy   | 1.32235    |
| PolicyLoss      | -0.0020615 |
| Steps           | 10000      |
| VarFuncLoss     | 0.089      |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.37078    |
| _max_adv        | 7.92       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.67       |
| _mean_act       | -0.214026  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0387     |
| _min_adv        | -11.2      |
| _min_discrew    | -0.312     |
| _min_obs        | -1.31      |
| _std_act        | 0.709439   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.964        |
| ExplainedVarOld | 0.962        |
| KL              | 0.00267785   |
| Phi_loss        | 463.129      |
| PolicyEntropy   | 1.30493      |
| PolicyLoss      | -8.22871e-05 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0492       |
| _MeanReward     | 4.24e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.4584       |
| _max_adv        | 2.89         |
| _max_discrew    | 4.95         |
| _max_obs        | 1.78         |
| _mean_act       | -0.22108     |
| _mean_adv       | -1.42e-17    |
| _mean_discrew   | 3.49         |
| _mean_obs       | 0.0385       |
| _min_adv        | -16.4        |
| _min_discrew    | -1.12        |
| _min_obs        | -1.45        |
| _std_act        | 0.753017     |
| _std_adv        | 1            |
| _std_discrew    | 1.82         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.868      |
| KL              | 0.00318876 |
| Phi_loss        | 418.097    |
| PolicyEntropy   | 1.31162    |
| PolicyLoss      | -0.0334883 |
| Steps           | 10000      |
| VarFuncLoss     | 0.229      |
| _MeanReward     | 4.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17994    |
| _max_adv        | 9.06       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.3        |
| _mean_act       | -0.214672  |
| _mean_adv       | -2.13e-18  |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0385     |
| _min_adv        | -10        |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.38      |
| _std_act        | 0.715995   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.912       |
| ExplainedVarOld | 0.902       |
| KL              | 0.00436614  |
| Phi_loss        | 335.872     |
| PolicyEntropy   | 1.29185     |
| PolicyLoss      | -0.00810695 |
| Steps           | 10000       |
| VarFuncLoss     | 0.116       |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5736      |
| _max_adv        | 18.2        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.14        |
| _mean_act       | -0.220351   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.039       |
| _min_adv        | -8.84       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.49       |
| _std_act        | 0.704657    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.978     |
| ExplainedVarOld | 0.975     |
| KL              | 0.001907  |
| Phi_loss        | 359.824   |
| PolicyEntropy   | 1.2569    |
| PolicyLoss      | 0.0134688 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0303    |
| _MeanReward     | 4.32e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.70347   |
| _max_adv        | 5.76      |
| _max_discrew    | 4.87      |
| _max_obs        | 1.12      |
| _mean_act       | -0.217178 |
| _mean_adv       | 8.53e-18  |
| _mean_discrew   | 3.57      |
| _mean_obs       | 0.0386    |
| _min_adv        | -13.1     |
| _min_discrew    | 0.0123    |
| _min_obs        | -1.5      |
| _std_act        | 0.707748  |
| _std_adv        | 1         |
| _std_discrew    | 1.22      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00221361 |
| Phi_loss        | 437.0      |
| PolicyEntropy   | 1.25037    |
| PolicyLoss      | 0.00337197 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0457     |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84916    |
| _max_adv        | 6.13       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.1        |
| _mean_act       | -0.217848  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0386     |
| _min_adv        | -12.5      |
| _min_discrew    | 0.0202     |
| _min_obs        | -1.39      |
| _std_act        | 0.70827    |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.934       |
| ExplainedVarOld | 0.932       |
| KL              | 0.00457459  |
| Phi_loss        | 612.821     |
| PolicyEntropy   | 1.22186     |
| PolicyLoss      | -0.00410375 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0843      |
| _MeanReward     | 4.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92716     |
| _max_adv        | 8.23        |
| _max_discrew    | 4.81        |
| _max_obs        | 1.18        |
| _mean_act       | -0.21818    |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.7         |
| _mean_obs       | 0.0392      |
| _min_adv        | -6.31       |
| _min_discrew    | 0.0195      |
| _min_obs        | -1.32       |
| _std_act        | 0.705532    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00227063 |
| Phi_loss        | 509.63     |
| PolicyEntropy   | 1.2063     |
| PolicyLoss      | 0.00561576 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0289     |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19088    |
| _max_adv        | 9.44       |
| _max_discrew    | 5.02       |
| _max_obs        | 1.16       |
| _mean_act       | -0.218888  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0389     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0225     |
| _min_obs        | -1.35      |
| _std_act        | 0.716349   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00279998 |
| Phi_loss        | 469.5      |
| PolicyEntropy   | 1.19104    |
| PolicyLoss      | 0.00460372 |
| Steps           | 10000      |
| VarFuncLoss     | 0.091      |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7423     |
| _max_adv        | 5.25       |
| _max_discrew    | 5.04       |
| _max_obs        | 1.13       |
| _mean_act       | -0.218281  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0389     |
| _min_adv        | -8.73      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.48      |
| _std_act        | 0.700516   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00183437 |
| Phi_loss        | 507.319    |
| PolicyEntropy   | 1.18179    |
| PolicyLoss      | -0.0280632 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0349     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.96357    |
| _max_adv        | 3.75       |
| _max_discrew    | 4.94       |
| _max_obs        | 3.4        |
| _mean_act       | -0.226976  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0417     |
| _min_adv        | -16.9      |
| _min_discrew    | -1.66      |
| _min_obs        | -1.2       |
| _std_act        | 0.795604   |
| _std_adv        | 1          |
| _std_discrew    | 2.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.901     |
| ExplainedVarOld | 0.88      |
| KL              | 0.0136609 |
| Phi_loss        | 473.224   |
| PolicyEntropy   | 1.1821    |
| PolicyLoss      | 0.0716983 |
| Steps           | 10000     |
| VarFuncLoss     | 0.225     |
| _MeanReward     | 4.48e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.9698    |
| _max_adv        | 13.2      |
| _max_discrew    | 4.9       |
| _max_obs        | 1.29      |
| _mean_act       | -0.223687 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 3.72      |
| _mean_obs       | 0.0386    |
| _min_adv        | -11.9     |
| _min_discrew    | 0.014     |
| _min_obs        | -1.53     |
| _std_act        | 0.707036  |
| _std_adv        | 1         |
| _std_discrew    | 1.31      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.954      |
| KL              | 0.00716839 |
| Phi_loss        | 473.577    |
| PolicyEntropy   | 1.17427    |
| PolicyLoss      | -0.0126561 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0648     |
| _MeanReward     | 4.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52996    |
| _max_adv        | 26.2       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.12       |
| _mean_act       | -0.220224  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0383     |
| _min_adv        | -5.59      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.42      |
| _std_act        | 0.701729   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
-------------------------------
| Beta            | 1.5       |
| ExplainedVarNew | 0.978     |
| ExplainedVarOld | 0.974     |
| KL              | 0.0148415 |
| Phi_loss        | 510.733   |
| PolicyEntropy   | 1.17534   |
| PolicyLoss      | 0.0232198 |
| Steps           | 10000     |
| VarFuncLoss     | 0.028     |
| _MeanReward     | 4.35e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.98482   |
| _max_adv        | 8.87      |
| _max_discrew    | 4.82      |
| _max_obs        | 1.1       |
| _mean_act       | -0.213726 |
| _mean_adv       | -1.99e-17 |
| _mean_discrew   | 3.59      |
| _mean_obs       | 0.0383    |
| _min_adv        | -10.3     |
| _min_discrew    | 0.0101    |
| _min_obs        | -1.44     |
| _std_act        | 0.705611  |
| _std_adv        | 1         |
| _std_discrew    | 1.34      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
-------------------------------
| Beta            | 2.25      |
| ExplainedVarNew | 0.931     |
| ExplainedVarOld | 0.926     |
| KL              | 0.0352948 |
| Phi_loss        | 602.536   |
| PolicyEntropy   | 1.17573   |
| PolicyLoss      | 0.0785522 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0935    |
| _MeanReward     | 4.44e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.73936   |
| _max_adv        | 8.16      |
| _max_discrew    | 4.9       |
| _max_obs        | 1.21      |
| _mean_act       | -0.219321 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 3.68      |
| _mean_obs       | 0.038     |
| _min_adv        | -6.74     |
| _min_discrew    | 0.0143    |
| _min_obs        | -1.31     |
| _std_act        | 0.687226  |
| _std_adv        | 1         |
| _std_discrew    | 1.29      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
-------------------------------
| Beta            | 3.38      |
| ExplainedVarNew | 0.985     |
| ExplainedVarOld | 0.983     |
| KL              | 0.0292071 |
| Phi_loss        | 571.316   |
| PolicyEntropy   | 1.17578   |
| PolicyLoss      | 0.0948382 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0211    |
| _MeanReward     | 4.33e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.71679   |
| _max_adv        | 3.83      |
| _max_discrew    | 4.74      |
| _max_obs        | 1.23      |
| _mean_act       | -0.212048 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.58      |
| _mean_obs       | 0.0378    |
| _min_adv        | -4.12     |
| _min_discrew    | 0.0105    |
| _min_obs        | -1.44     |
| _std_act        | 0.684853  |
| _std_adv        | 1         |
| _std_discrew    | 1.24      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
-------------------------------
| Beta            | 5.06      |
| ExplainedVarNew | 0.98      |
| ExplainedVarOld | 0.979     |
| KL              | 0.0224037 |
| Phi_loss        | 530.584   |
| PolicyEntropy   | 1.1757    |
| PolicyLoss      | 0.0877549 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0267    |
| _MeanReward     | 4.3e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.54997   |
| _max_adv        | 4.38      |
| _max_discrew    | 4.83      |
| _max_obs        | 1.13      |
| _mean_act       | -0.210066 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 3.51      |
| _mean_obs       | 0.0379    |
| _min_adv        | -4.16     |
| _min_discrew    | 0.0109    |
| _min_obs        | -1.29     |
| _std_act        | 0.68547   |
| _std_adv        | 1         |
| _std_discrew    | 1.26      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
-------------------------------
| Beta            | 7.59      |
| ExplainedVarNew | 0.98      |
| ExplainedVarOld | 0.976     |
| KL              | 0.0194487 |
| Phi_loss        | 488.99    |
| PolicyEntropy   | 1.1756    |
| PolicyLoss      | 0.116578  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0271    |
| _MeanReward     | 4.23e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.38123   |
| _max_adv        | 5.67      |
| _max_discrew    | 4.61      |
| _max_obs        | 1.18      |
| _mean_act       | -0.208238 |
| _mean_adv       | 7.11e-18  |
| _mean_discrew   | 3.51      |
| _mean_obs       | 0.0371    |
| _min_adv        | -10.8     |
| _min_discrew    | 0.0133    |
| _min_obs        | -1.41     |
| _std_act        | 0.687328  |
| _std_adv        | 1         |
| _std_discrew    | 1.19      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
-------------------------------
| Beta            | 11.4      |
| ExplainedVarNew | 0.961     |
| ExplainedVarOld | 0.958     |
| KL              | 0.0147569 |
| Phi_loss        | 605.99    |
| PolicyEntropy   | 1.17549   |
| PolicyLoss      | 0.110173  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0468    |
| _MeanReward     | 4.24e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.59416   |
| _max_adv        | 13.8      |
| _max_discrew    | 4.66      |
| _max_obs        | 1.17      |
| _mean_act       | -0.207356 |
| _mean_adv       | -1.85e-17 |
| _mean_discrew   | 3.5       |
| _mean_obs       | 0.0378    |
| _min_adv        | -4.75     |
| _min_discrew    | 0.0108    |
| _min_obs        | -1.37     |
| _std_act        | 0.684045  |
| _std_adv        | 1         |
| _std_discrew    | 1.23      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
-------------------------------
| Beta            | 17.1      |
| ExplainedVarNew | 0.985     |
| ExplainedVarOld | 0.983     |
| KL              | 0.100007  |
| Phi_loss        | 559.334   |
| PolicyEntropy   | 1.17764   |
| PolicyLoss      | 1.56725   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0189    |
| _MeanReward     | 4.32e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.66337   |
| _max_adv        | 4.38      |
| _max_discrew    | 4.99      |
| _max_obs        | 1.13      |
| _mean_act       | -0.211579 |
| _mean_adv       | -8.53e-18 |
| _mean_discrew   | 3.56      |
| _mean_obs       | 0.0374    |
| _min_adv        | -3.94     |
| _min_discrew    | 0.0213    |
| _min_obs        | -1.22     |
| _std_act        | 0.686158  |
| _std_adv        | 1         |
| _std_discrew    | 1.22      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
-------------------------------
| Beta            | 25.6      |
| ExplainedVarNew | 0.984     |
| ExplainedVarOld | 0.983     |
| KL              | 0.144875  |
| Phi_loss        | 626.771   |
| PolicyEntropy   | 1.17962   |
| PolicyLoss      | 3.39549   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0202    |
| _MeanReward     | 4.07e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.65122   |
| _max_adv        | 3.41      |
| _max_discrew    | 4.99      |
| _max_obs        | 1.77      |
| _mean_act       | -0.220474 |
| _mean_adv       | -8.53e-18 |
| _mean_discrew   | 3.31      |
| _mean_obs       | 0.0375    |
| _min_adv        | -18.1     |
| _min_discrew    | -1.42     |
| _min_obs        | -1.37     |
| _std_act        | 0.793071  |
| _std_adv        | 1         |
| _std_discrew    | 2.64      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.887     |
| ExplainedVarOld | 0.878     |
| KL              | 0.110644  |
| Phi_loss        | 578.516   |
| PolicyEntropy   | 1.18161   |
| PolicyLoss      | 3.37421   |
| Steps           | 10000     |
| VarFuncLoss     | 0.299     |
| _MeanReward     | 4.45e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.63013   |
| _max_adv        | 5.83      |
| _max_discrew    | 4.88      |
| _max_obs        | 1.07      |
| _mean_act       | -0.224969 |
| _mean_adv       | -8.53e-18 |
| _mean_discrew   | 3.68      |
| _mean_obs       | 0.037     |
| _min_adv        | -4.27     |
| _min_discrew    | 0.0174    |
| _min_obs        | -1.2      |
| _std_act        | 0.701431  |
| _std_adv        | 1         |
| _std_discrew    | 1.29      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.98      |
| ExplainedVarOld | 0.979     |
| KL              | 0.09463   |
| Phi_loss        | 553.081   |
| PolicyEntropy   | 1.18315   |
| PolicyLoss      | 3.69542   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0287    |
| _MeanReward     | 4.42e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.50443   |
| _max_adv        | 14.5      |
| _max_discrew    | 4.92      |
| _max_obs        | 1.1       |
| _mean_act       | -0.223766 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.66      |
| _mean_obs       | 0.0367    |
| _min_adv        | -5.49     |
| _min_discrew    | 0.0164    |
| _min_obs        | -1.41     |
| _std_act        | 0.709588  |
| _std_adv        | 1         |
| _std_discrew    | 1.37      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.977     |
| ExplainedVarOld | 0.971     |
| KL              | 0.0757653 |
| Phi_loss        | 586.89    |
| PolicyEntropy   | 1.18391   |
| PolicyLoss      | 2.87923   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0315    |
| _MeanReward     | 4.42e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.48255   |
| _max_adv        | 5.49      |
| _max_discrew    | 5.01      |
| _max_obs        | 1.2       |
| _mean_act       | -0.229827 |
| _mean_adv       | -2.84e-18 |
| _mean_discrew   | 3.66      |
| _mean_obs       | 0.0357    |
| _min_adv        | -12.2     |
| _min_discrew    | 0.0134    |
| _min_obs        | -1.45     |
| _std_act        | 0.717522  |
| _std_adv        | 1         |
| _std_discrew    | 1.33      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.977     |
| ExplainedVarOld | 0.977     |
| KL              | 0.0599335 |
| Phi_loss        | 558.725   |
| PolicyEntropy   | 1.18465   |
| PolicyLoss      | 2.23188   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0303    |
| _MeanReward     | 4.23e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.38248   |
| _max_adv        | 13.9      |
| _max_discrew    | 4.89      |
| _max_obs        | 1.15      |
| _mean_act       | -0.224339 |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 3.5       |
| _mean_obs       | 0.0357    |
| _min_adv        | -10.9     |
| _min_discrew    | 0.0174    |
| _min_obs        | -1.22     |
| _std_act        | 0.74717   |
| _std_adv        | 1         |
| _std_discrew    | 1.36      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.919     |
| ExplainedVarOld | 0.903     |
| KL              | 0.0464862 |
| Phi_loss        | 454.705   |
| PolicyEntropy   | 1.18519   |
| PolicyLoss      | 1.69472   |
| Steps           | 10000     |
| VarFuncLoss     | 0.114     |
| _MeanReward     | 4.29e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.62856   |
| _max_adv        | 8.79      |
| _max_discrew    | 4.89      |
| _max_obs        | 1.16      |
| _mean_act       | -0.228696 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 3.55      |
| _mean_obs       | 0.0346    |
| _min_adv        | -9.14     |
| _min_discrew    | 0.0186    |
| _min_obs        | -1.25     |
| _std_act        | 0.737052  |
| _std_adv        | 1         |
| _std_discrew    | 1.45      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.963     |
| ExplainedVarOld | 0.958     |
| KL              | 0.0371593 |
| Phi_loss        | 508.605   |
| PolicyEntropy   | 1.18544   |
| PolicyLoss      | 1.34263   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0543    |
| _MeanReward     | 4.21e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.11472   |
| _max_adv        | 5.19      |
| _max_discrew    | 4.82      |
| _max_obs        | 1.14      |
| _mean_act       | -0.228196 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.49      |
| _mean_obs       | 0.034     |
| _min_adv        | -13.7     |
| _min_discrew    | 0.00632   |
| _min_obs        | -1.43     |
| _std_act        | 0.747259  |
| _std_adv        | 1         |
| _std_discrew    | 1.29      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.942     |
| ExplainedVarOld | 0.94      |
| KL              | 0.0292427 |
| Phi_loss        | 786.179   |
| PolicyEntropy   | 1.18538   |
| PolicyLoss      | 1.04405   |
| Steps           | 10000     |
| VarFuncLoss     | 0.076     |
| _MeanReward     | 3.66e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.52374   |
| _max_adv        | 3.66      |
| _max_discrew    | 4.65      |
| _max_obs        | 1.77      |
| _mean_act       | -0.214634 |
| _mean_adv       | 0         |
| _mean_discrew   | 3         |
| _mean_obs       | 0.0331    |
| _min_adv        | -8.45     |
| _min_discrew    | -1.13     |
| _min_obs        | -1.37     |
| _std_act        | 0.800047  |
| _std_adv        | 1         |
| _std_discrew    | 1.74      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.845     |
| ExplainedVarOld | 0.765     |
| KL              | 0.0214026 |
| Phi_loss        | 393.013   |
| PolicyEntropy   | 1.185     |
| PolicyLoss      | 0.756367  |
| Steps           | 10000     |
| VarFuncLoss     | 0.299     |
| _MeanReward     | 3.87e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.59673   |
| _max_adv        | 12.4      |
| _max_discrew    | 4.59      |
| _max_obs        | 1.71      |
| _mean_act       | -0.218957 |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 3.16      |
| _mean_obs       | 0.0326    |
| _min_adv        | -7.83     |
| _min_discrew    | -0.17     |
| _min_obs        | -1.21     |
| _std_act        | 0.77102   |
| _std_adv        | 1         |
| _std_discrew    | 1.43      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.9       |
| ExplainedVarOld | 0.896     |
| KL              | 0.0179258 |
| Phi_loss        | 522.477   |
| PolicyEntropy   | 1.18431   |
| PolicyLoss      | 0.636038  |
| Steps           | 10000     |
| VarFuncLoss     | 0.146     |
| _MeanReward     | 3.85e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.37251   |
| _max_adv        | 5.76      |
| _max_discrew    | 4.54      |
| _max_obs        | 1.13      |
| _mean_act       | -0.217922 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.16      |
| _mean_obs       | 0.0321    |
| _min_adv        | -8.8      |
| _min_discrew    | -0.000914 |
| _min_obs        | -1.16     |
| _std_act        | 0.770813  |
| _std_adv        | 1         |
| _std_discrew    | 1.17      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.861     |
| ExplainedVarOld | 0.85      |
| KL              | 0.0143519 |
| Phi_loss        | 564.405   |
| PolicyEntropy   | 1.18319   |
| PolicyLoss      | 0.526282  |
| Steps           | 10000     |
| VarFuncLoss     | 0.162     |
| _MeanReward     | 3.76e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.40693   |
| _max_adv        | 7.37      |
| _max_discrew    | 4.4       |
| _max_obs        | 1.07      |
| _mean_act       | -0.220182 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.1       |
| _mean_obs       | 0.0314    |
| _min_adv        | -9.29     |
| _min_discrew    | -0.00214  |
| _min_obs        | -1.28     |
| _std_act        | 0.77533   |
| _std_adv        | 1         |
| _std_discrew    | 1.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.905     |
| ExplainedVarOld | 0.897     |
| KL              | 0.0712741 |
| Phi_loss        | 552.432   |
| PolicyEntropy   | 1.18716   |
| PolicyLoss      | 2.70185   |
| Steps           | 10000     |
| VarFuncLoss     | 0.107     |
| _MeanReward     | 4.02e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.30338   |
| _max_adv        | 9.36      |
| _max_discrew    | 4.54      |
| _max_obs        | 1.16      |
| _mean_act       | -0.226099 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 3.33      |
| _mean_obs       | 0.0321    |
| _min_adv        | -8.26     |
| _min_discrew    | 0.0133    |
| _min_obs        | -1.29     |
| _std_act        | 0.755825  |
| _std_adv        | 1         |
| _std_discrew    | 1.14      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.945     |
| ExplainedVarOld | 0.942     |
| KL              | 0.113536  |
| Phi_loss        | 536.443   |
| PolicyEntropy   | 1.19158   |
| PolicyLoss      | 4.53771   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0722    |
| _MeanReward     | 4.22e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.51387   |
| _max_adv        | 5.45      |
| _max_discrew    | 5.03      |
| _max_obs        | 1.18      |
| _mean_act       | -0.229619 |
| _mean_adv       | -1.99e-17 |
| _mean_discrew   | 3.5       |
| _mean_obs       | 0.0335    |
| _min_adv        | -4.61     |
| _min_discrew    | 0.0085    |
| _min_obs        | -1.46     |
| _std_act        | 0.742705  |
| _std_adv        | 1         |
| _std_discrew    | 1.23      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.958     |
| ExplainedVarOld | 0.952     |
| KL              | 0.0923012 |
| Phi_loss        | 544.858   |
| PolicyEntropy   | 1.19541   |
| PolicyLoss      | 3.59296   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0555    |
| _MeanReward     | 4.1e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.02218   |
| _max_adv        | 4.55      |
| _max_discrew    | 4.63      |
| _max_obs        | 1.09      |
| _mean_act       | -0.227118 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.37      |
| _mean_obs       | 0.0331    |
| _min_adv        | -8.77     |
| _min_discrew    | -0.0475   |
| _min_obs        | -1.34     |
| _std_act        | 0.736262  |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.921     |
| ExplainedVarOld | 0.918     |
| KL              | 0.0727974 |
| Phi_loss        | 489.384   |
| PolicyEntropy   | 1.19876   |
| PolicyLoss      | 2.75209   |
| Steps           | 10000     |
| VarFuncLoss     | 0.108     |
| _MeanReward     | 3.84e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.58021   |
| _max_adv        | 2.12      |
| _max_discrew    | 4.75      |
| _max_obs        | 1.81      |
| _mean_act       | -0.225137 |
| _mean_adv       | -1.99e-17 |
| _mean_discrew   | 3.12      |
| _mean_obs       | 0.0337    |
| _min_adv        | -14.9     |
| _min_discrew    | -1.33     |
| _min_obs        | -1.38     |
| _std_act        | 0.787277  |
| _std_adv        | 1         |
| _std_discrew    | 2.43      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.872     |
| ExplainedVarOld | 0.859     |
| KL              | 0.055242  |
| Phi_loss        | 540.46    |
| PolicyEntropy   | 1.20183   |
| PolicyLoss      | 2.0592    |
| Steps           | 10000     |
| VarFuncLoss     | 0.31      |
| _MeanReward     | 4.34e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.63539   |
| _max_adv        | 9.21      |
| _max_discrew    | 4.74      |
| _max_obs        | 1.23      |
| _mean_act       | -0.232781 |
| _mean_adv       | 6.54e-17  |
| _mean_discrew   | 3.59      |
| _mean_obs       | 0.0341    |
| _min_adv        | -5.01     |
| _min_discrew    | 0.0124    |
| _min_obs        | -1.31     |
| _std_act        | 0.714986  |
| _std_adv        | 1         |
| _std_discrew    | 1.3       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.97      |
| ExplainedVarOld | 0.967     |
| KL              | 0.0482468 |
| Phi_loss        | 555.807   |
| PolicyEntropy   | 1.20427   |
| PolicyLoss      | 1.76048   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0555    |
| _MeanReward     | 4.39e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.91701   |
| _max_adv        | 9.78      |
| _max_discrew    | 4.82      |
| _max_obs        | 1.13      |
| _mean_act       | -0.231062 |
| _mean_adv       | 1.42e-17  |
| _mean_discrew   | 3.64      |
| _mean_obs       | 0.0345    |
| _min_adv        | -10.9     |
| _min_discrew    | 0.0124    |
| _min_obs        | -1.25     |
| _std_act        | 0.70975   |
| _std_adv        | 1         |
| _std_discrew    | 1.3       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.968     |
| ExplainedVarOld | 0.962     |
| KL              | 0.0381458 |
| Phi_loss        | 526.024   |
| PolicyEntropy   | 1.20632   |
| PolicyLoss      | 1.37643   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0419    |
| _MeanReward     | 4.1e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.45727   |
| _max_adv        | 7.83      |
| _max_discrew    | 4.74      |
| _max_obs        | 1.71      |
| _mean_act       | -0.2225   |
| _mean_adv       | 3.41e-17  |
| _mean_discrew   | 3.38      |
| _mean_obs       | 0.0345    |
| _min_adv        | -13.6     |
| _min_discrew    | -0.687    |
| _min_obs        | -1.3      |
| _std_act        | 0.73028   |
| _std_adv        | 1         |
| _std_discrew    | 1.51      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.909     |
| ExplainedVarOld | 0.9       |
| KL              | 0.0292745 |
| Phi_loss        | 575.779   |
| PolicyEntropy   | 1.20774   |
| PolicyLoss      | 1.04129   |
| Steps           | 10000     |
| VarFuncLoss     | 0.148     |
| _MeanReward     | 4.39e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.62183   |
| _max_adv        | 13        |
| _max_discrew    | 4.86      |
| _max_obs        | 1.1       |
| _mean_act       | -0.229677 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 3.63      |
| _mean_obs       | 0.0349    |
| _min_adv        | -4.55     |
| _min_discrew    | 0.0136    |
| _min_obs        | -1.42     |
| _std_act        | 0.691893  |
| _std_adv        | 1         |
| _std_discrew    | 1.34      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.977     |
| ExplainedVarOld | 0.973     |
| KL              | 0.0242509 |
| Phi_loss        | 458.835   |
| PolicyEntropy   | 1.2089    |
| PolicyLoss      | 0.846681  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0392    |
| _MeanReward     | 4.32e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.95079   |
| _max_adv        | 27.9      |
| _max_discrew    | 4.78      |
| _max_obs        | 1.2       |
| _mean_act       | -0.227057 |
| _mean_adv       | -2.98e-17 |
| _mean_discrew   | 3.58      |
| _mean_obs       | 0.0347    |
| _min_adv        | -8.59     |
| _min_discrew    | 0.0158    |
| _min_obs        | -1.31     |
| _std_act        | 0.690162  |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.977     |
| ExplainedVarOld | 0.972     |
| KL              | 0.01918   |
| Phi_loss        | 326.259   |
| PolicyEntropy   | 1.20967   |
| PolicyLoss      | 0.672871  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0299    |
| _MeanReward     | 4.33e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.73735   |
| _max_adv        | 4.38      |
| _max_discrew    | 4.77      |
| _max_obs        | 1.1       |
| _mean_act       | -0.224621 |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 3.61      |
| _mean_obs       | 0.0344    |
| _min_adv        | -5.12     |
| _min_discrew    | 0.00435   |
| _min_obs        | -1.49     |
| _std_act        | 0.681274  |
| _std_adv        | 1         |
| _std_discrew    | 1.26      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.98      |
| ExplainedVarOld | 0.977     |
| KL              | 0.0153693 |
| Phi_loss        | 509.421   |
| PolicyEntropy   | 1.21002   |
| PolicyLoss      | 0.536971  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0258    |
| _MeanReward     | 4.26e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.94548   |
| _max_adv        | 3.27      |
| _max_discrew    | 4.8       |
| _max_obs        | 1.13      |
| _mean_act       | -0.22139  |
| _mean_adv       | 4.41e-17  |
| _mean_discrew   | 3.54      |
| _mean_obs       | 0.0338    |
| _min_adv        | -9.6      |
| _min_discrew    | 0.0109    |
| _min_obs        | -1.35     |
| _std_act        | 0.67999   |
| _std_adv        | 1         |
| _std_discrew    | 1.17      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.979     |
| ExplainedVarOld | 0.976     |
| KL              | 0.012016  |
| Phi_loss        | 559.962   |
| PolicyEntropy   | 1.20987   |
| PolicyLoss      | 0.433377  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0255    |
| _MeanReward     | 4.3e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.45504   |
| _max_adv        | 3.44      |
| _max_discrew    | 4.78      |
| _max_obs        | 1.13      |
| _mean_act       | -0.222609 |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 3.56      |
| _mean_obs       | 0.0352    |
| _min_adv        | -4.21     |
| _min_discrew    | 0.00748   |
| _min_obs        | -1.27     |
| _std_act        | 0.67906   |
| _std_adv        | 1         |
| _std_discrew    | 1.22      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.981     |
| ExplainedVarOld | 0.981     |
| KL              | 0.0149936 |
| Phi_loss        | 548.76    |
| PolicyEntropy   | 1.21331   |
| PolicyLoss      | 0.522317  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0233    |
| _MeanReward     | 4.21e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.96306   |
| _max_adv        | 10.5      |
| _max_discrew    | 4.76      |
| _max_obs        | 1.15      |
| _mean_act       | -0.219837 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.49      |
| _mean_obs       | 0.0347    |
| _min_adv        | -11.1     |
| _min_discrew    | 0.0135    |
| _min_obs        | -1.25     |
| _std_act        | 0.684218  |
| _std_adv        | 1         |
| _std_discrew    | 1.28      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.952     |
| ExplainedVarOld | 0.944     |
| KL              | 0.0370921 |
| Phi_loss        | 466.118   |
| PolicyEntropy   | 1.21641   |
| PolicyLoss      | 1.33142   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0635    |
| _MeanReward     | 4.28e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.6579    |
| _max_adv        | 6.99      |
| _max_discrew    | 4.72      |
| _max_obs        | 1.09      |
| _mean_act       | -0.226379 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.55      |
| _mean_obs       | 0.0345    |
| _min_adv        | -6.63     |
| _min_discrew    | 0.0138    |
| _min_obs        | -1.25     |
| _std_act        | 0.690215  |
| _std_adv        | 1         |
| _std_discrew    | 1.25      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.98      |
| ExplainedVarOld | 0.979     |
| KL              | 0.0298835 |
| Phi_loss        | 533.918   |
| PolicyEntropy   | 1.21893   |
| PolicyLoss      | 1.08727   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0256    |
| _MeanReward     | 4.28e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.98252   |
| _max_adv        | 7.02      |
| _max_discrew    | 4.88      |
| _max_obs        | 1.1       |
| _mean_act       | -0.224512 |
| _mean_adv       | -3.13e-17 |
| _mean_discrew   | 3.54      |
| _mean_obs       | 0.0345    |
| _min_adv        | -10.5     |
| _min_discrew    | 0.0176    |
| _min_obs        | -1.34     |
| _std_act        | 0.695211  |
| _std_adv        | 1         |
| _std_discrew    | 1.22      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.955     |
| ExplainedVarOld | 0.951     |
| KL              | 0.0238344 |
| Phi_loss        | 456.169   |
| PolicyEntropy   | 1.22124   |
| PolicyLoss      | 0.841555  |
| Steps           | 10000     |
| VarFuncLoss     | 0.055     |
| _MeanReward     | 4.37e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.79261   |
| _max_adv        | 4.08      |
| _max_discrew    | 4.8       |
| _max_obs        | 1.13      |
| _mean_act       | -0.228546 |
| _mean_adv       | -7.11e-19 |
| _mean_discrew   | 3.6       |
| _mean_obs       | 0.0348    |
| _min_adv        | -3.92     |
| _min_discrew    | 0.0197    |
| _min_obs        | -1.41     |
| _std_act        | 0.700858  |
| _std_adv        | 1         |
| _std_discrew    | 1.3       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.981     |
| ExplainedVarOld | 0.978     |
| KL              | 0.0192792 |
| Phi_loss        | 482.965   |
| PolicyEntropy   | 1.22298   |
| PolicyLoss      | 0.675836  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0256    |
| _MeanReward     | 4.33e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.70228   |
| _max_adv        | 4.08      |
| _max_discrew    | 4.92      |
| _max_obs        | 1.08      |
| _mean_act       | -0.229118 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.56      |
| _mean_obs       | 0.035     |
| _min_adv        | -11.5     |
| _min_discrew    | 0.0141    |
| _min_obs        | -1.31     |
| _std_act        | 0.70727   |
| _std_adv        | 1         |
| _std_discrew    | 1.33      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.947     |
| ExplainedVarOld | 0.945     |
| KL              | 0.0151953 |
| Phi_loss        | 528.997   |
| PolicyEntropy   | 1.22445   |
| PolicyLoss      | 0.519171  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0703    |
| _MeanReward     | 4.21e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.45427   |
| _max_adv        | 5.81      |
| _max_discrew    | 4.88      |
| _max_obs        | 1.75      |
| _mean_act       | -0.226118 |
| _mean_adv       | 1.42e-17  |
| _mean_discrew   | 3.49      |
| _mean_obs       | 0.0348    |
| _min_adv        | -14.9     |
| _min_discrew    | -0.855    |
| _min_obs        | -1.19     |
| _std_act        | 0.736064  |
| _std_adv        | 1         |
| _std_discrew    | 1.63      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.893     |
| ExplainedVarOld | 0.885     |
| KL              | 0.0121166 |
| Phi_loss        | 880.024   |
| PolicyEntropy   | 1.23264   |
| PolicyLoss      | 0.429614  |
| Steps           | 10000     |
| VarFuncLoss     | 0.175     |
| _MeanReward     | 4.36e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.24247   |
| _max_adv        | 7.16      |
| _max_discrew    | 4.98      |
| _max_obs        | 1.17      |
| _mean_act       | -0.225132 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.59      |
| _mean_obs       | 0.0363    |
| _min_adv        | -10.2     |
| _min_discrew    | -0.297    |
| _min_obs        | -1.39     |
| _std_act        | 0.714391  |
| _std_adv        | 1         |
| _std_discrew    | 1.46      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.945     |
| ExplainedVarOld | 0.942     |
| KL              | 0.013183  |
| Phi_loss        | 520.332   |
| PolicyEntropy   | 1.23531   |
| PolicyLoss      | 0.473314  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0814    |
| _MeanReward     | 4.3e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 3.26517   |
| _max_adv        | 14.1      |
| _max_discrew    | 5.07      |
| _max_obs        | 1.14      |
| _mean_act       | -0.220798 |
| _mean_adv       | -2.42e-17 |
| _mean_discrew   | 3.57      |
| _mean_obs       | 0.0361    |
| _min_adv        | -9.68     |
| _min_discrew    | 0.0142    |
| _min_obs        | -1.33     |
| _std_act        | 0.71752   |
| _std_adv        | 1         |
| _std_discrew    | 1.38      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
--------------------------------
| Beta            | 23.3       |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00102957 |
| Phi_loss        | 468.414    |
| PolicyEntropy   | 1.23466    |
| PolicyLoss      | 0.0538008  |
| Steps           | 10000      |
| VarFuncLoss     | 0.103      |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86772    |
| _max_adv        | 11.7       |
| _max_discrew    | 5.19       |
| _max_obs        | 1.2        |
| _mean_act       | -0.22465   |
| _mean_adv       | 0          |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0369     |
| _min_adv        | -9.52      |
| _min_discrew    | 0.0206     |
| _min_obs        | -1.29      |
| _std_act        | 0.711598   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
---------------------------------
| Beta            | 15.6        |
| ExplainedVarNew | 0.932       |
| ExplainedVarOld | 0.925       |
| KL              | 3.31954e-05 |
| Phi_loss        | 470.043     |
| PolicyEntropy   | 1.23347     |
| PolicyLoss      | 0.0265668   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0955      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6673      |
| _max_adv        | 5.12        |
| _max_discrew    | 4.86        |
| _max_obs        | 1.19        |
| _mean_act       | -0.227047   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0364      |
| _min_adv        | -6.14       |
| _min_discrew    | 0.0187      |
| _min_obs        | -1.39       |
| _std_act        | 0.708545    |
| _std_adv        | 1           |
| _std_discrew    | 1.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.968       |
| KL              | 3.94433e-06 |
| Phi_loss        | 465.876     |
| PolicyEntropy   | 1.23302     |
| PolicyLoss      | -0.0119828  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0386      |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68893     |
| _max_adv        | 5.58        |
| _max_discrew    | 4.98        |
| _max_obs        | 1.13        |
| _mean_act       | -0.226159   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.7         |
| _mean_obs       | 0.0368      |
| _min_adv        | -9.47       |
| _min_discrew    | 0.0198      |
| _min_obs        | -1.26       |
| _std_act        | 0.705202    |
| _std_adv        | 1           |
| _std_discrew    | 1.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
---------------------------------
| Beta            | 6.91        |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.96        |
| KL              | 1.99032e-06 |
| Phi_loss        | 495.148     |
| PolicyEntropy   | 1.23242     |
| PolicyLoss      | 0.000103862 |
| Steps           | 10000       |
| VarFuncLoss     | 0.049       |
| _MeanReward     | 4.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.07026     |
| _max_adv        | 4.31        |
| _max_discrew    | 5.19        |
| _max_obs        | 1.12        |
| _mean_act       | -0.223474   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0362      |
| _min_adv        | -11.1       |
| _min_discrew    | 0.00662     |
| _min_obs        | -1.38       |
| _std_act        | 0.71319     |
| _std_adv        | 1           |
| _std_discrew    | 1.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.939       |
| KL              | 5.60403e-06 |
| Phi_loss        | 466.939     |
| PolicyEntropy   | 1.23208     |
| PolicyLoss      | -0.0311144  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0782      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08507     |
| _max_adv        | 5.08        |
| _max_discrew    | 5.1         |
| _max_obs        | 1.15        |
| _mean_act       | -0.224517   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0362      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.0163      |
| _min_obs        | -1.43       |
| _std_act        | 0.710922    |
| _std_adv        | 1           |
| _std_discrew    | 1.39        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.96        |
| KL              | 6.97932e-06 |
| Phi_loss        | 514.958     |
| PolicyEntropy   | 1.23163     |
| PolicyLoss      | 0.011857    |
| Steps           | 10000       |
| VarFuncLoss     | 0.0511      |
| _MeanReward     | 4.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.37912     |
| _max_adv        | 4.62        |
| _max_discrew    | 5.15        |
| _max_obs        | 1.88        |
| _mean_act       | -0.219373   |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 3.41        |
| _mean_obs       | 0.0364      |
| _min_adv        | -12.6       |
| _min_discrew    | -1.05       |
| _min_obs        | -1.23       |
| _std_act        | 0.754578    |
| _std_adv        | 1           |
| _std_discrew    | 1.95        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
---------------------------------
| Beta            | 2.05        |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.841       |
| KL              | 3.57656e-05 |
| Phi_loss        | 460.751     |
| PolicyEntropy   | 1.23087     |
| PolicyLoss      | -0.0395041  |
| Steps           | 10000       |
| VarFuncLoss     | 0.229       |
| _MeanReward     | 4.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91186     |
| _max_adv        | 19.6        |
| _max_discrew    | 5.17        |
| _max_obs        | 1.12        |
| _mean_act       | -0.227028   |
| _mean_adv       | -6.82e-17   |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0374      |
| _min_adv        | -8.16       |
| _min_discrew    | 0.0156      |
| _min_obs        | -1.32       |
| _std_act        | 0.707154    |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.951       |
| KL              | 3.71079e-05 |
| Phi_loss        | 362.324     |
| PolicyEntropy   | 1.22923     |
| PolicyLoss      | 0.0359326   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0669      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86983     |
| _max_adv        | 6.14        |
| _max_discrew    | 5.14        |
| _max_obs        | 1.14        |
| _mean_act       | -0.222672   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.62        |
| _mean_obs       | 0.0362      |
| _min_adv        | -11.1       |
| _min_discrew    | 0.0212      |
| _min_obs        | -1.37       |
| _std_act        | 0.709488    |
| _std_adv        | 1           |
| _std_discrew    | 1.4         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.945       |
| ExplainedVarOld | 0.942       |
| KL              | 6.1251e-05  |
| Phi_loss        | 476.552     |
| PolicyEntropy   | 1.22666     |
| PolicyLoss      | -0.00957442 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0804      |
| _MeanReward     | 4.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.11964     |
| _max_adv        | 5.81        |
| _max_discrew    | 4.93        |
| _max_obs        | 1.14        |
| _mean_act       | -0.219074   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.55        |
| _mean_obs       | 0.0361      |
| _min_adv        | -10.5       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.48       |
| _std_act        | 0.716878    |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.915       |
| KL              | 9.75119e-05 |
| Phi_loss        | 493.994     |
| PolicyEntropy   | 1.22387     |
| PolicyLoss      | 0.0201527   |
| Steps           | 10000       |
| VarFuncLoss     | 0.115       |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.33315     |
| _max_adv        | 4.88        |
| _max_discrew    | 4.86        |
| _max_obs        | 1.79        |
| _mean_act       | -0.229345   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0369      |
| _min_adv        | -14.8       |
| _min_discrew    | -0.754      |
| _min_obs        | -1.32       |
| _std_act        | 0.735375    |
| _std_adv        | 1           |
| _std_discrew    | 1.64        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
---------------------------------
| Beta            | 0.405       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.917       |
| KL              | 0.000383897 |
| Phi_loss        | 631.685     |
| PolicyEntropy   | 1.21417     |
| PolicyLoss      | -0.0137281  |
| Steps           | 10000       |
| VarFuncLoss     | 0.129       |
| _MeanReward     | 4.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.052       |
| _max_adv        | 12.6        |
| _max_discrew    | 4.99        |
| _max_obs        | 1.11        |
| _mean_act       | -0.226976   |
| _mean_adv       | -4.26e-18   |
| _mean_discrew   | 3.74        |
| _mean_obs       | 0.0371      |
| _min_adv        | -12.3       |
| _min_discrew    | 0.0116      |
| _min_obs        | -1.45       |
| _std_act        | 0.712072    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.972       |
| KL              | 0.000358769 |
| Phi_loss        | 478.685     |
| PolicyEntropy   | 1.18692     |
| PolicyLoss      | -0.00227302 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0347      |
| _MeanReward     | 4.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80555     |
| _max_adv        | 4.97        |
| _max_discrew    | 4.97        |
| _max_obs        | 1.17        |
| _mean_act       | -0.225713   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.7         |
| _mean_obs       | 0.0364      |
| _min_adv        | -10.8       |
| _min_discrew    | 0.00503     |
| _min_obs        | -1.38       |
| _std_act        | 0.710811    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.953       |
| KL              | 0.000247643 |
| Phi_loss        | 458.693     |
| PolicyEntropy   | 1.17562     |
| PolicyLoss      | 0.0104577   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0497      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7907      |
| _max_adv        | 7.14        |
| _max_discrew    | 5.23        |
| _max_obs        | 1.16        |
| _mean_act       | -0.223829   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0362      |
| _min_adv        | -12.4       |
| _min_discrew    | 0.0178      |
| _min_obs        | -1.32       |
| _std_act        | 0.715771    |
| _std_adv        | 1           |
| _std_discrew    | 1.35        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.922      |
| KL              | 0.00069761 |
| Phi_loss        | 405.232    |
| PolicyEntropy   | 1.16596    |
| PolicyLoss      | -0.0493461 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0981     |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.33697    |
| _max_adv        | 6.82       |
| _max_discrew    | 5.11       |
| _max_obs        | 1.15       |
| _mean_act       | -0.22102   |
| _mean_adv       | 0          |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0364     |
| _min_adv        | -7.64      |
| _min_discrew    | -0.263     |
| _min_obs        | -1.31      |
| _std_act        | 0.721287   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.898       |
| ExplainedVarOld | 0.889       |
| KL              | 0.000887069 |
| Phi_loss        | 426.564     |
| PolicyEntropy   | 1.14533     |
| PolicyLoss      | -0.0134085  |
| Steps           | 10000       |
| VarFuncLoss     | 0.155       |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.47937     |
| _max_adv        | 5.61        |
| _max_discrew    | 5.12        |
| _max_obs        | 1.79        |
| _mean_act       | -0.225177   |
| _mean_adv       | 4.97e-18    |
| _mean_discrew   | 3.3         |
| _mean_obs       | 0.0364      |
| _min_adv        | -14.7       |
| _min_discrew    | -1.29       |
| _min_obs        | -1.35       |
| _std_act        | 0.790029    |
| _std_adv        | 1           |
| _std_discrew    | 2.78        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.887      |
| ExplainedVarOld | 0.872      |
| KL              | 0.00217269 |
| Phi_loss        | 459.833    |
| PolicyEntropy   | 1.14842    |
| PolicyLoss      | -0.0346925 |
| Steps           | 10000      |
| VarFuncLoss     | 0.313      |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.7923     |
| _max_adv        | 6.9        |
| _max_discrew    | 5.21       |
| _max_obs        | 1.11       |
| _mean_act       | -0.224431  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0366     |
| _min_adv        | -4.88      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.57      |
| _std_act        | 0.712061   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.969       |
| KL              | 0.000909106 |
| Phi_loss        | 510.256     |
| PolicyEntropy   | 1.12363     |
| PolicyLoss      | 0.00521971  |
| Steps           | 10000       |
| VarFuncLoss     | 0.049       |
| _MeanReward     | 4.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.65819     |
| _max_adv        | 5.86        |
| _max_discrew    | 5.08        |
| _max_obs        | 1.15        |
| _mean_act       | -0.225731   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0356      |
| _min_adv        | -6.88       |
| _min_discrew    | 0.00906     |
| _min_obs        | -1.55       |
| _std_act        | 0.704736    |
| _std_adv        | 1           |
| _std_discrew    | 1.39        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
----------------------------------
| Beta            | 0.0355       |
| ExplainedVarNew | 0.972        |
| ExplainedVarOld | 0.969        |
| KL              | 0.001185     |
| Phi_loss        | 493.69       |
| PolicyEntropy   | 1.0922       |
| PolicyLoss      | -0.000635754 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0385       |
| _MeanReward     | 4.47e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.61845      |
| _max_adv        | 20.5         |
| _max_discrew    | 5.34         |
| _max_obs        | 1.18         |
| _mean_act       | -0.2231      |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 3.7          |
| _mean_obs       | 0.037        |
| _min_adv        | -9.57        |
| _min_discrew    | 0.0146       |
| _min_obs        | -1.43        |
| _std_act        | 0.710204     |
| _std_adv        | 1            |
| _std_discrew    | 1.41         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00131433 |
| Phi_loss        | 364.508    |
| PolicyEntropy   | 1.06668    |
| PolicyLoss      | -0.0209931 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0497     |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.75809    |
| _max_adv        | 2.33       |
| _max_discrew    | 4.94       |
| _max_obs        | 1.82       |
| _mean_act       | -0.227384  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0363     |
| _min_adv        | -15.2      |
| _min_discrew    | -1.36      |
| _min_obs        | -1.33      |
| _std_act        | 0.805492   |
| _std_adv        | 1          |
| _std_discrew    | 3.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
-------------------------------
| Beta            | 0.0429    |
| ExplainedVarNew | 0.908     |
| ExplainedVarOld | 0.879     |
| KL              | 0.0127747 |
| Phi_loss        | 364.324   |
| PolicyEntropy   | 1.02553   |
| PolicyLoss      | 0.242652  |
| Steps           | 10000     |
| VarFuncLoss     | 0.286     |
| _MeanReward     | 4.25e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.41559   |
| _max_adv        | 4.18      |
| _max_discrew    | 4.95      |
| _max_obs        | 1.14      |
| _mean_act       | -0.218424 |
| _mean_adv       | -2.27e-17 |
| _mean_discrew   | 3.49      |
| _mean_obs       | 0.0364    |
| _min_adv        | -8.65     |
| _min_discrew    | 0.018     |
| _min_obs        | -1.29     |
| _std_act        | 0.723944  |
| _std_adv        | 1         |
| _std_discrew    | 1.41      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.881      |
| ExplainedVarOld | 0.868      |
| KL              | 0.00160851 |
| Phi_loss        | 596.409    |
| PolicyEntropy   | 0.996659   |
| PolicyLoss      | 0.00802491 |
| Steps           | 10000      |
| VarFuncLoss     | 0.172      |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73048    |
| _max_adv        | 9.42       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.13       |
| _mean_act       | -0.221579  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0354     |
| _min_adv        | -12.3      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.21      |
| _std_act        | 0.702157   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.951      |
| KL              | 0.00109675 |
| Phi_loss        | 492.363    |
| PolicyEntropy   | 0.976652   |
| PolicyLoss      | 0.00230567 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0577     |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60583    |
| _max_adv        | 10.3       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.17       |
| _mean_act       | -0.223469  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0368     |
| _min_adv        | -5.93      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.36      |
| _std_act        | 0.695199   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00214776 |
| Phi_loss        | 480.472    |
| PolicyEntropy   | 0.958338   |
| PolicyLoss      | -0.0232842 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0558     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00435    |
| _max_adv        | 11         |
| _max_discrew    | 5.01       |
| _max_obs        | 1.14       |
| _mean_act       | -0.221233  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.0364     |
| _min_adv        | -10        |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.32      |
| _std_act        | 0.707554   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00153166 |
| Phi_loss        | 595.223    |
| PolicyEntropy   | 0.944729   |
| PolicyLoss      | 0.00430305 |
| Steps           | 10000      |
| VarFuncLoss     | 0.06       |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89295    |
| _max_adv        | 10.1       |
| _max_discrew    | 5.17       |
| _max_obs        | 1.08       |
| _mean_act       | -0.221479  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0365     |
| _min_adv        | -9.48      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.39      |
| _std_act        | 0.712946   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.903      |
| KL              | 0.00188904 |
| Phi_loss        | 592.764    |
| PolicyEntropy   | 0.912519   |
| PolicyLoss      | 0.020451   |
| Steps           | 10000      |
| VarFuncLoss     | 0.139      |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69596    |
| _max_adv        | 6.55       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.12       |
| _mean_act       | -0.231314  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0365     |
| _min_adv        | -11.9      |
| _min_discrew    | 0.0132     |
| _min_obs        | -1.34      |
| _std_act        | 0.706138   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.962       |
| KL              | 0.00198783  |
| Phi_loss        | 684.845     |
| PolicyEntropy   | 0.890739    |
| PolicyLoss      | -0.00712894 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0531      |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51926     |
| _max_adv        | 5.05        |
| _max_discrew    | 5.07        |
| _max_obs        | 1.19        |
| _mean_act       | -0.233442   |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | 3.82        |
| _mean_obs       | 0.0364      |
| _min_adv        | -4.31       |
| _min_discrew    | 0.0168      |
| _min_obs        | -1.16       |
| _std_act        | 0.698837    |
| _std_adv        | 1           |
| _std_discrew    | 1.35        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.975       |
| KL              | 0.000945129 |
| Phi_loss        | 563.553     |
| PolicyEntropy   | 0.881272    |
| PolicyLoss      | -0.0193326  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0327      |
| _MeanReward     | 4.53e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01776     |
| _max_adv        | 8.29        |
| _max_discrew    | 5.1         |
| _max_obs        | 1.14        |
| _mean_act       | -0.224673   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0369      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.0151      |
| _min_obs        | -1.37       |
| _std_act        | 0.704154    |
| _std_adv        | 1           |
| _std_discrew    | 1.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00177675 |
| Phi_loss        | 615.517    |
| PolicyEntropy   | 0.864695   |
| PolicyLoss      | -0.0113116 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0402     |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13715    |
| _max_adv        | 5.34       |
| _max_discrew    | 5.07       |
| _max_obs        | 1.19       |
| _mean_act       | -0.220519  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.037      |
| _min_adv        | -9.03      |
| _min_discrew    | -0.0828    |
| _min_obs        | -1.33      |
| _std_act        | 0.712615   |
| _std_adv        | 1          |
| _std_discrew    | 1.62       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00226516 |
| Phi_loss        | 514.398    |
| PolicyEntropy   | 0.827675   |
| PolicyLoss      | 0.0188559  |
| Steps           | 10000      |
| VarFuncLoss     | 0.1        |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90662    |
| _max_adv        | 9.45       |
| _max_discrew    | 5.1        |
| _max_obs        | 1.15       |
| _mean_act       | -0.224112  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0368     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0179     |
| _min_obs        | -1.25      |
| _std_act        | 0.706288   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00207783  |
| Phi_loss        | 507.756     |
| PolicyEntropy   | 0.798426    |
| PolicyLoss      | 0.000677548 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0304      |
| _MeanReward     | 4.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.85464     |
| _max_adv        | 5.57        |
| _max_discrew    | 5.07        |
| _max_obs        | 1.15        |
| _mean_act       | -0.226612   |
| _mean_adv       | 5.12e-17    |
| _mean_discrew   | 3.83        |
| _mean_obs       | 0.0374      |
| _min_adv        | -6.35       |
| _min_discrew    | 0.00581     |
| _min_obs        | -1.27       |
| _std_act        | 0.704702    |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00232925 |
| Phi_loss        | 523.196    |
| PolicyEntropy   | 0.778734   |
| PolicyLoss      | -0.0237708 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0417     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97889    |
| _max_adv        | 5.33       |
| _max_discrew    | 5.35       |
| _max_obs        | 1.13       |
| _mean_act       | -0.228291  |
| _mean_adv       | 1.07e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0366     |
| _min_adv        | -9.13      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.38      |
| _std_act        | 0.704436   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.96        |
| KL              | 0.000530701 |
| Phi_loss        | 621.249     |
| PolicyEntropy   | 0.762443    |
| PolicyLoss      | 0.0216824   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0544      |
| _MeanReward     | 4.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94164     |
| _max_adv        | 2.59        |
| _max_discrew    | 5.12        |
| _max_obs        | 1.14        |
| _mean_act       | -0.225548   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.77        |
| _mean_obs       | 0.0373      |
| _min_adv        | -12.6       |
| _min_discrew    | 0.0134      |
| _min_obs        | -1.34       |
| _std_act        | 0.708913    |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.956       |
| ExplainedVarOld | 0.954       |
| KL              | 0.00272753  |
| Phi_loss        | 619.179     |
| PolicyEntropy   | 0.747773    |
| PolicyLoss      | -0.00159725 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0622      |
| _MeanReward     | 4.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55257     |
| _max_adv        | 6.31        |
| _max_discrew    | 5.28        |
| _max_obs        | 1.08        |
| _mean_act       | -0.225274   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0375      |
| _min_adv        | -8.08       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.37       |
| _std_act        | 0.700652    |
| _std_adv        | 1           |
| _std_discrew    | 1.46        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00178828 |
| Phi_loss        | 636.459    |
| PolicyEntropy   | 0.749592   |
| PolicyLoss      | 0.00828882 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.74134    |
| _max_adv        | 10.2       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.12       |
| _mean_act       | -0.225596  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0366     |
| _min_adv        | -9.29      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.22      |
| _std_act        | 0.702155   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.967      |
| KL              | 0.00144646 |
| Phi_loss        | 651.095    |
| PolicyEntropy   | 0.750147   |
| PolicyLoss      | 0.00107434 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0414     |
| _MeanReward     | 4.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.37901    |
| _max_adv        | 4.57       |
| _max_discrew    | 5.25       |
| _max_obs        | 2.04       |
| _mean_act       | -0.228397  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0363     |
| _min_adv        | -17.6      |
| _min_discrew    | -1.26      |
| _min_obs        | -1.58      |
| _std_act        | 0.772977   |
| _std_adv        | 1          |
| _std_discrew    | 2.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.89       |
| KL              | 0.00489979 |
| Phi_loss        | 423.006    |
| PolicyEntropy   | 0.76236    |
| PolicyLoss      | 0.00728223 |
| Steps           | 10000      |
| VarFuncLoss     | 0.26       |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88156    |
| _max_adv        | 5.93       |
| _max_discrew    | 5.21       |
| _max_obs        | 1.12       |
| _mean_act       | -0.229621  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0368     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.35      |
| _std_act        | 0.700019   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.954       |
| ExplainedVarOld | 0.944       |
| KL              | 0.00272823  |
| Phi_loss        | 467.325     |
| PolicyEntropy   | 0.768309    |
| PolicyLoss      | -0.00742441 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0694      |
| _MeanReward     | 4.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.30329     |
| _max_adv        | 7.64        |
| _max_discrew    | 5.32        |
| _max_obs        | 1.23        |
| _mean_act       | -0.226597   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.81        |
| _mean_obs       | 0.037       |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0171      |
| _min_obs        | -1.26       |
| _std_act        | 0.706283    |
| _std_adv        | 1           |
| _std_discrew    | 1.47        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00218466 |
| Phi_loss        | 551.593    |
| PolicyEntropy   | 0.761059   |
| PolicyLoss      | -0.018692  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0409     |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1985     |
| _max_adv        | 15.7       |
| _max_discrew    | 5.07       |
| _max_obs        | 1.12       |
| _mean_act       | -0.219241  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0372     |
| _min_adv        | -9.32      |
| _min_discrew    | -0.258     |
| _min_obs        | -1.4       |
| _std_act        | 0.717067   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.924      |
| KL              | 0.0020061  |
| Phi_loss        | 453.356    |
| PolicyEntropy   | 0.759188   |
| PolicyLoss      | -0.0403403 |
| Steps           | 10000      |
| VarFuncLoss     | 0.111      |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.6587     |
| _max_adv        | 3.44       |
| _max_discrew    | 5.1        |
| _max_obs        | 2.37       |
| _mean_act       | -0.222001  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0381     |
| _min_adv        | -17.2      |
| _min_discrew    | -1.11      |
| _min_obs        | -1.33      |
| _std_act        | 0.764305   |
| _std_adv        | 1          |
| _std_discrew    | 2.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.882      |
| ExplainedVarOld | 0.874      |
| KL              | 0.00373132 |
| Phi_loss        | 886.954    |
| PolicyEntropy   | 0.755756   |
| PolicyLoss      | -0.067218  |
| Steps           | 10000      |
| VarFuncLoss     | 0.251      |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.3905     |
| _max_adv        | 4.69       |
| _max_discrew    | 5.1        |
| _max_obs        | 2.18       |
| _mean_act       | -0.221017  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.038      |
| _min_adv        | -16.3      |
| _min_discrew    | -1.04      |
| _min_obs        | -1.33      |
| _std_act        | 0.760487   |
| _std_adv        | 1          |
| _std_discrew    | 2.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.896      |
| KL              | 0.00202597 |
| Phi_loss        | 564.383    |
| PolicyEntropy   | 0.751815   |
| PolicyLoss      | 0.00160697 |
| Steps           | 10000      |
| VarFuncLoss     | 0.201      |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.0004     |
| _max_adv        | 18.5       |
| _max_discrew    | 5.08       |
| _max_obs        | 1.12       |
| _mean_act       | -0.223656  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0376     |
| _min_adv        | -11        |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.34      |
| _std_act        | 0.719788   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.953      |
| KL              | 0.0015586  |
| Phi_loss        | 350.184    |
| PolicyEntropy   | 0.730687   |
| PolicyLoss      | -0.0176686 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0533     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.95832    |
| _max_adv        | 11.6       |
| _max_discrew    | 5.13       |
| _max_obs        | 1.2        |
| _mean_act       | -0.224497  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0371     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.39      |
| _std_act        | 0.725939   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.929      |
| KL              | 0.00129945 |
| Phi_loss        | 497.267    |
| PolicyEntropy   | 0.710316   |
| PolicyLoss      | -0.022951  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0807     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73178    |
| _max_adv        | 15.7       |
| _max_discrew    | 5.14       |
| _max_obs        | 1.19       |
| _mean_act       | -0.226375  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0378     |
| _min_adv        | -12.8      |
| _min_discrew    | 0.0171     |
| _min_obs        | -1.35      |
| _std_act        | 0.714101   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.968       |
| ExplainedVarOld | 0.966       |
| KL              | 0.0014536   |
| Phi_loss        | 632.87      |
| PolicyEntropy   | 0.695169    |
| PolicyLoss      | -0.00360387 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0455      |
| _MeanReward     | 4.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77004     |
| _max_adv        | 4.97        |
| _max_discrew    | 5.18        |
| _max_obs        | 1.13        |
| _mean_act       | -0.22888    |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.84        |
| _mean_obs       | 0.0374      |
| _min_adv        | -10.8       |
| _min_discrew    | 0.0163      |
| _min_obs        | -1.37       |
| _std_act        | 0.720394    |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00193229 |
| Phi_loss        | 569.757    |
| PolicyEntropy   | 0.682146   |
| PolicyLoss      | 0.00733114 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0543     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.41442    |
| _max_adv        | 3.49       |
| _max_discrew    | 5.07       |
| _max_obs        | 2.04       |
| _mean_act       | -0.229258  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.41       |
| _mean_obs       | 0.0375     |
| _min_adv        | -14.9      |
| _min_discrew    | -1.27      |
| _min_obs        | -1.38      |
| _std_act        | 0.8082     |
| _std_adv        | 1          |
| _std_discrew    | 2.91       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
-------------------------------
| Beta            | 0.0286    |
| ExplainedVarNew | 0.87      |
| ExplainedVarOld | 0.852     |
| KL              | 0.0048771 |
| Phi_loss        | 535.837   |
| PolicyEntropy   | 0.657867  |
| PolicyLoss      | 0.0324422 |
| Steps           | 10000     |
| VarFuncLoss     | 0.386     |
| _MeanReward     | 4.46e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.90821   |
| _max_adv        | 4.53      |
| _max_discrew    | 5.1       |
| _max_obs        | 1.1       |
| _mean_act       | -0.224946 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.68      |
| _mean_obs       | 0.0364    |
| _min_adv        | -10.2     |
| _min_discrew    | -0.208    |
| _min_obs        | -1.32     |
| _std_act        | 0.715929  |
| _std_adv        | 1         |
| _std_discrew    | 1.53      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.929      |
| ExplainedVarOld | 0.923      |
| KL              | 0.00154783 |
| Phi_loss        | 604.699    |
| PolicyEntropy   | 0.637223   |
| PolicyLoss      | 0.0179513  |
| Steps           | 10000      |
| VarFuncLoss     | 0.109      |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82106    |
| _max_adv        | 7.42       |
| _max_discrew    | 5.51       |
| _max_obs        | 1.1        |
| _mean_act       | -0.227095  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.037      |
| _min_adv        | -8.88      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.39      |
| _std_act        | 0.713823   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00233397 |
| Phi_loss        | 574.635    |
| PolicyEntropy   | 0.629453   |
| PolicyLoss      | 0.0198729  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0806     |
| _MeanReward     | 4.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77382    |
| _max_adv        | 8.33       |
| _max_discrew    | 5.34       |
| _max_obs        | 1.14       |
| _mean_act       | -0.232515  |
| _mean_adv       | 3.84e-17   |
| _mean_discrew   | 3.95       |
| _mean_obs       | 0.0377     |
| _min_adv        | -7.16      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.37      |
| _std_act        | 0.704931   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00276527 |
| Phi_loss        | 601.937    |
| PolicyEntropy   | 0.617713   |
| PolicyLoss      | -0.0191585 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0418     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9043     |
| _max_adv        | 22.2       |
| _max_discrew    | 5.17       |
| _max_obs        | 1.18       |
| _mean_act       | -0.225769  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0365     |
| _min_adv        | -10        |
| _min_discrew    | 0.0132     |
| _min_obs        | -1.34      |
| _std_act        | 0.7072     |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.956       |
| ExplainedVarOld | 0.949       |
| KL              | 0.00207998  |
| Phi_loss        | 623.88      |
| PolicyEntropy   | 0.596889    |
| PolicyLoss      | 0.000974438 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0689      |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.98744     |
| _max_adv        | 4.46        |
| _max_discrew    | 5.27        |
| _max_obs        | 1.21        |
| _mean_act       | -0.225943   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.82        |
| _mean_obs       | 0.0373      |
| _min_adv        | -12         |
| _min_discrew    | 0.0168      |
| _min_obs        | -1.39       |
| _std_act        | 0.714515    |
| _std_adv        | 1           |
| _std_discrew    | 1.47        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.916      |
| KL              | 0.00117533 |
| Phi_loss        | 624.263    |
| PolicyEntropy   | 0.567745   |
| PolicyLoss      | -0.0011898 |
| Steps           | 10000      |
| VarFuncLoss     | 0.107      |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55008    |
| _max_adv        | 3.38       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.09       |
| _mean_act       | -0.226394  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0373     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.43      |
| _std_act        | 0.713988   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.957      |
| KL              | 0.00233057 |
| Phi_loss        | 695.235    |
| PolicyEntropy   | 0.553241   |
| PolicyLoss      | 0.00394548 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0622     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74493    |
| _max_adv        | 4.8        |
| _max_discrew    | 5.02       |
| _max_obs        | 1.09       |
| _mean_act       | -0.22565   |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0363     |
| _min_adv        | -6.31      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.33      |
| _std_act        | 0.70714    |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.978       |
| KL              | 0.00237345  |
| Phi_loss        | 632.106     |
| PolicyEntropy   | 0.556896    |
| PolicyLoss      | -0.00306299 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0289      |
| _MeanReward     | 4.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55599     |
| _max_adv        | 7.3         |
| _max_discrew    | 5.36        |
| _max_obs        | 1.15        |
| _mean_act       | -0.224991   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.95        |
| _mean_obs       | 0.0377      |
| _min_adv        | -9.25       |
| _min_discrew    | 0.0137      |
| _min_obs        | -1.46       |
| _std_act        | 0.706374    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00400495  |
| Phi_loss        | 703.16      |
| PolicyEntropy   | 0.558276    |
| PolicyLoss      | -0.00852282 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0594      |
| _MeanReward     | 4.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.26615     |
| _max_adv        | 4.16        |
| _max_discrew    | 5.17        |
| _max_obs        | 1.96        |
| _mean_act       | -0.219099   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.47        |
| _mean_obs       | 0.0369      |
| _min_adv        | -15.2       |
| _min_discrew    | -1.23       |
| _min_obs        | -1.28       |
| _std_act        | 0.77008     |
| _std_adv        | 1           |
| _std_discrew    | 2.47        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.872      |
| ExplainedVarOld | 0.858      |
| KL              | 0.00344633 |
| Phi_loss        | 631.253    |
| PolicyEntropy   | 0.562464   |
| PolicyLoss      | 0.0228437  |
| Steps           | 10000      |
| VarFuncLoss     | 0.328      |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79601    |
| _max_adv        | 21.2       |
| _max_discrew    | 5.3        |
| _max_obs        | 1.18       |
| _mean_act       | -0.22464   |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.038      |
| _min_adv        | -9.84      |
| _min_discrew    | 0.0188     |
| _min_obs        | -1.33      |
| _std_act        | 0.701285   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00203549 |
| Phi_loss        | 396.29     |
| PolicyEntropy   | 0.563426   |
| PolicyLoss      | 0.00274343 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0555     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6891     |
| _max_adv        | 10.6       |
| _max_discrew    | 5.31       |
| _max_obs        | 1.16       |
| _mean_act       | -0.225189  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.87       |
| _mean_obs       | 0.0367     |
| _min_adv        | -5.89      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.27      |
| _std_act        | 0.690797   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00296285 |
| Phi_loss        | 607.41     |
| PolicyEntropy   | 0.55006    |
| PolicyLoss      | 0.0210818  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0554     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79758    |
| _max_adv        | 3.96       |
| _max_discrew    | 5.31       |
| _max_obs        | 1.17       |
| _mean_act       | -0.219972  |
| _mean_adv       | -3.69e-17  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0363     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.32      |
| _std_act        | 0.694465   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.944       |
| ExplainedVarOld | 0.939       |
| KL              | 0.00203496  |
| Phi_loss        | 812.241     |
| PolicyEntropy   | 0.519298    |
| PolicyLoss      | -0.00455678 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0774      |
| _MeanReward     | 4.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85566     |
| _max_adv        | 6.56        |
| _max_discrew    | 5.3         |
| _max_obs        | 1.18        |
| _mean_act       | -0.22332    |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.9         |
| _mean_obs       | 0.0374      |
| _min_adv        | -9.28       |
| _min_discrew    | 0.0161      |
| _min_obs        | -1.37       |
| _std_act        | 0.689936    |
| _std_adv        | 1           |
| _std_discrew    | 1.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00357746 |
| Phi_loss        | 680.696    |
| PolicyEntropy   | 0.487782   |
| PolicyLoss      | -0.0107079 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0674     |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.90399    |
| _max_adv        | 4.61       |
| _max_discrew    | 5.25       |
| _max_obs        | 1.26       |
| _mean_act       | -0.220953  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0366     |
| _min_adv        | -9.4       |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.35      |
| _std_act        | 0.690944   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.951      |
| KL              | 0.00302478 |
| Phi_loss        | 684.35     |
| PolicyEntropy   | 0.470063   |
| PolicyLoss      | -0.0145236 |
| Steps           | 10000      |
| VarFuncLoss     | 0.07       |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90897    |
| _max_adv        | 4.31       |
| _max_discrew    | 5.4        |
| _max_obs        | 1.23       |
| _mean_act       | -0.224141  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.037      |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0105     |
| _min_obs        | -1.3       |
| _std_act        | 0.697275   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.959       |
| ExplainedVarOld | 0.958       |
| KL              | 0.00196576  |
| Phi_loss        | 714.977     |
| PolicyEntropy   | 0.466727    |
| PolicyLoss      | -0.00482592 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0613      |
| _MeanReward     | 4.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91451     |
| _max_adv        | 6.82        |
| _max_discrew    | 5.48        |
| _max_obs        | 1.19        |
| _mean_act       | -0.227674   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.97        |
| _mean_obs       | 0.0377      |
| _min_adv        | -5.53       |
| _min_discrew    | 0.0144      |
| _min_obs        | -1.29       |
| _std_act        | 0.680791    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.97        |
| KL              | 0.00380138  |
| Phi_loss        | 732.974     |
| PolicyEntropy   | 0.459756    |
| PolicyLoss      | -0.00203374 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0438      |
| _MeanReward     | 4.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.48011     |
| _max_adv        | 2.75        |
| _max_discrew    | 5.4         |
| _max_obs        | 1.97        |
| _mean_act       | -0.223057   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.037       |
| _min_adv        | -13.9       |
| _min_discrew    | -1.15       |
| _min_obs        | -1.31       |
| _std_act        | 0.74352     |
| _std_adv        | 1           |
| _std_discrew    | 2.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.872      |
| ExplainedVarOld | 0.855      |
| KL              | 0.00318866 |
| Phi_loss        | 607.963    |
| PolicyEntropy   | 0.452748   |
| PolicyLoss      | -0.0136852 |
| Steps           | 10000      |
| VarFuncLoss     | 0.314      |
| _MeanReward     | 4.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13107    |
| _max_adv        | 8.67       |
| _max_discrew    | 5.21       |
| _max_obs        | 1.15       |
| _mean_act       | -0.223876  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.93       |
| _mean_obs       | 0.0383     |
| _min_adv        | -11.5      |
| _min_discrew    | -0.00447   |
| _min_obs        | -1.27      |
| _std_act        | 0.696819   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.937      |
| ExplainedVarOld | 0.932      |
| KL              | 0.00382321 |
| Phi_loss        | 748.496    |
| PolicyEntropy   | 0.429591   |
| PolicyLoss      | 0.00694107 |
| Steps           | 10000      |
| VarFuncLoss     | 0.109      |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73449    |
| _max_adv        | 11.6       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.11       |
| _mean_act       | -0.220842  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0378     |
| _min_adv        | -11        |
| _min_discrew    | -0.014     |
| _min_obs        | -1.43      |
| _std_act        | 0.69692    |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.927      |
| KL              | 0.00296994 |
| Phi_loss        | 645.895    |
| PolicyEntropy   | 0.401105   |
| PolicyLoss      | -0.0107573 |
| Steps           | 10000      |
| VarFuncLoss     | 0.113      |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79928    |
| _max_adv        | 13.2       |
| _max_discrew    | 5.52       |
| _max_obs        | 1.05       |
| _mean_act       | -0.221817  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0382     |
| _min_adv        | -9.44      |
| _min_discrew    | -0.0173    |
| _min_obs        | -1.4       |
| _std_act        | 0.698285   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00315141 |
| Phi_loss        | 683.188    |
| PolicyEntropy   | 0.371572   |
| PolicyLoss      | 0.0212743  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0632     |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79171    |
| _max_adv        | 12.4       |
| _max_discrew    | 5.15       |
| _max_obs        | 1.16       |
| _mean_act       | -0.218904  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0367     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.49      |
| _std_act        | 0.694814   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.951      |
| KL              | 0.00334023 |
| Phi_loss        | 774.468    |
| PolicyEntropy   | 0.355654   |
| PolicyLoss      | -0.0250999 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0687     |
| _MeanReward     | 4.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61911    |
| _max_adv        | 6.53       |
| _max_discrew    | 5.27       |
| _max_obs        | 1.12       |
| _mean_act       | -0.22733   |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.037      |
| _min_adv        | -6.14      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.39      |
| _std_act        | 0.689987   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00332528 |
| Phi_loss        | 799.494    |
| PolicyEntropy   | 0.335196   |
| PolicyLoss      | 0.0135315  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0272     |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82364    |
| _max_adv        | 12.5       |
| _max_discrew    | 5.57       |
| _max_obs        | 1.11       |
| _mean_act       | -0.22654   |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0373     |
| _min_adv        | -11.5      |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.37      |
| _std_act        | 0.689725   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00240585 |
| Phi_loss        | 606.567    |
| PolicyEntropy   | 0.312491   |
| PolicyLoss      | 0.0074703  |
| Steps           | 10000      |
| VarFuncLoss     | 0.125      |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.25122    |
| _max_adv        | 10         |
| _max_discrew    | 5.23       |
| _max_obs        | 1.83       |
| _mean_act       | -0.222557  |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0372     |
| _min_adv        | -17.3      |
| _min_discrew    | -1.27      |
| _min_obs        | -1.29      |
| _std_act        | 0.752942   |
| _std_adv        | 1          |
| _std_discrew    | 2.83       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.882      |
| ExplainedVarOld | 0.866      |
| KL              | 0.00887332 |
| Phi_loss        | 641.325    |
| PolicyEntropy   | 0.310979   |
| PolicyLoss      | 0.0561346  |
| Steps           | 10000      |
| VarFuncLoss     | 0.336      |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94102    |
| _max_adv        | 4.61       |
| _max_discrew    | 5.43       |
| _max_obs        | 1.09       |
| _mean_act       | -0.224806  |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0368     |
| _min_adv        | -10.6      |
| _min_discrew    | -0.448     |
| _min_obs        | -1.38      |
| _std_act        | 0.678991   |
| _std_adv        | 1          |
| _std_discrew    | 1.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.938       |
| ExplainedVarOld | 0.927       |
| KL              | 0.00265042  |
| Phi_loss        | 555.189     |
| PolicyEntropy   | 0.314384    |
| PolicyLoss      | -0.00688454 |
| Steps           | 10000       |
| VarFuncLoss     | 0.117       |
| _MeanReward     | 4.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.49809     |
| _max_adv        | 9.42        |
| _max_discrew    | 5.35        |
| _max_obs        | 1.12        |
| _mean_act       | -0.222355   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.95        |
| _mean_obs       | 0.0374      |
| _min_adv        | -4.71       |
| _min_discrew    | 0.0116      |
| _min_obs        | -1.46       |
| _std_act        | 0.673648    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.969       |
| KL              | 0.00419676  |
| Phi_loss        | 708.203     |
| PolicyEntropy   | 0.299338    |
| PolicyLoss      | -0.00638714 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0393      |
| _MeanReward     | 4.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87926     |
| _max_adv        | 13.9        |
| _max_discrew    | 5.41        |
| _max_obs        | 1.09        |
| _mean_act       | -0.230843   |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 3.95        |
| _mean_obs       | 0.0371      |
| _min_adv        | -9.28       |
| _min_discrew    | 0.0199      |
| _min_obs        | -1.42       |
| _std_act        | 0.677814    |
| _std_adv        | 1           |
| _std_discrew    | 1.54        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.965       |
| KL              | 0.00250992  |
| Phi_loss        | 614.845     |
| PolicyEntropy   | 0.277702    |
| PolicyLoss      | -0.00906296 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0465      |
| _MeanReward     | 4.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.44725     |
| _max_adv        | 3.38        |
| _max_discrew    | 5.28        |
| _max_obs        | 2.12        |
| _mean_act       | -0.227491   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.43        |
| _mean_obs       | 0.0371      |
| _min_adv        | -16.4       |
| _min_discrew    | -1.29       |
| _min_obs        | -1.33       |
| _std_act        | 0.777541    |
| _std_adv        | 1           |
| _std_discrew    | 3.18        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
-------------------------------
| Beta            | 0.0643    |
| ExplainedVarNew | 0.896     |
| ExplainedVarOld | 0.886     |
| KL              | 0.0114388 |
| Phi_loss        | 766.157   |
| PolicyEntropy   | 0.288957  |
| PolicyLoss      | 0.0180821 |
| Steps           | 10000     |
| VarFuncLoss     | 0.342     |
| _MeanReward     | 4.74e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.75438   |
| _max_adv        | 17.9      |
| _max_discrew    | 5.3       |
| _max_obs        | 1.1       |
| _mean_act       | -0.231606 |
| _mean_adv       | -1.42e-18 |
| _mean_discrew   | 3.94      |
| _mean_obs       | 0.0368    |
| _min_adv        | -11.9     |
| _min_discrew    | 0.0154    |
| _min_obs        | -1.32     |
| _std_act        | 0.687291  |
| _std_adv        | 1         |
| _std_discrew    | 1.61      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00331496 |
| Phi_loss        | 735.502    |
| PolicyEntropy   | 0.287254   |
| PolicyLoss      | -0.0121242 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0656     |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.33981    |
| _max_adv        | 17.1       |
| _max_discrew    | 5.18       |
| _max_obs        | 1.94       |
| _mean_act       | -0.225942  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0366     |
| _min_adv        | -16        |
| _min_discrew    | -0.928     |
| _min_obs        | -1.29      |
| _std_act        | 0.724337   |
| _std_adv        | 1          |
| _std_discrew    | 2.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.89       |
| KL              | 0.00255785 |
| Phi_loss        | 670.727    |
| PolicyEntropy   | 0.288308   |
| PolicyLoss      | 0.00643567 |
| Steps           | 10000      |
| VarFuncLoss     | 0.222      |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.54565    |
| _max_adv        | 13.2       |
| _max_discrew    | 5.23       |
| _max_obs        | 2.35       |
| _mean_act       | -0.230881  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.0364     |
| _min_adv        | -10.4      |
| _min_discrew    | -0.0738    |
| _min_obs        | -1.55      |
| _std_act        | 0.69353    |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00358544 |
| Phi_loss        | 774.944    |
| PolicyEntropy   | 0.295292   |
| PolicyLoss      | -0.0268559 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0645     |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.23524    |
| _max_adv        | 5.37       |
| _max_discrew    | 5.39       |
| _max_obs        | 1.08       |
| _mean_act       | -0.227671  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.0365     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.33      |
| _std_act        | 0.688976   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.946      |
| ExplainedVarOld | 0.938      |
| KL              | 0.00532864 |
| Phi_loss        | 665.963    |
| PolicyEntropy   | 0.29937    |
| PolicyLoss      | 0.00606529 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0812     |
| _MeanReward     | 4.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50422    |
| _max_adv        | 8.97       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.1        |
| _mean_act       | -0.234746  |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 4          |
| _mean_obs       | 0.0364     |
| _min_adv        | -7.71      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.5       |
| _std_act        | 0.680221   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00250559 |
| Phi_loss        | 727.611    |
| PolicyEntropy   | 0.28578    |
| PolicyLoss      | 0.00460546 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0356     |
| _MeanReward     | 4.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83933    |
| _max_adv        | 19.3       |
| _max_discrew    | 5.3        |
| _max_obs        | 1.15       |
| _mean_act       | -0.232572  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.93       |
| _mean_obs       | 0.0364     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.43      |
| _std_act        | 0.682702   |
| _std_adv        | 1          |
| _std_discrew    | 1.5        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.967       |
| KL              | 0.0033602   |
| Phi_loss        | 586.21      |
| PolicyEntropy   | 0.267143    |
| PolicyLoss      | -0.00391143 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0453      |
| _MeanReward     | 4.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.13031     |
| _max_adv        | 8.33        |
| _max_discrew    | 5.16        |
| _max_obs        | 1.08        |
| _mean_act       | -0.236591   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.96        |
| _mean_obs       | 0.0362      |
| _min_adv        | -13.3       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.22       |
| _std_act        | 0.680636    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00220026 |
| Phi_loss        | 685.184    |
| PolicyEntropy   | 0.253381   |
| PolicyLoss      | -0.0221879 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0421     |
| _MeanReward     | 4.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.20676    |
| _max_adv        | 16.4       |
| _max_discrew    | 5.46       |
| _max_obs        | 1.87       |
| _mean_act       | -0.231968  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.94       |
| _mean_obs       | 0.0366     |
| _min_adv        | -11.9      |
| _min_discrew    | -0.161     |
| _min_obs        | -1.53      |
| _std_act        | 0.680659   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00306127 |
| Phi_loss        | 435.985    |
| PolicyEntropy   | 0.259567   |
| PolicyLoss      | 0.0312566  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0418     |
| _MeanReward     | 4.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63756    |
| _max_adv        | 4.46       |
| _max_discrew    | 5.31       |
| _max_obs        | 1.12       |
| _mean_act       | -0.231285  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.036      |
| _min_adv        | -8.29      |
| _min_discrew    | -0.183     |
| _min_obs        | -1.45      |
| _std_act        | 0.683769   |
| _std_adv        | 1          |
| _std_discrew    | 1.62       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00347112 |
| Phi_loss        | 708.439    |
| PolicyEntropy   | 0.246377   |
| PolicyLoss      | -0.0224418 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0472     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.20897    |
| _max_adv        | 2.56       |
| _max_discrew    | 5.25       |
| _max_obs        | 1.97       |
| _mean_act       | -0.230217  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0361     |
| _min_adv        | -17.6      |
| _min_discrew    | -1.01      |
| _min_obs        | -1.31      |
| _std_act        | 0.714109   |
| _std_adv        | 1          |
| _std_discrew    | 2.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.902      |
| KL              | 0.00826602 |
| Phi_loss        | 651.294    |
| PolicyEntropy   | 0.236376   |
| PolicyLoss      | -0.0371036 |
| Steps           | 10000      |
| VarFuncLoss     | 0.196      |
| _MeanReward     | 4.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85543    |
| _max_adv        | 9.59       |
| _max_discrew    | 5.55       |
| _max_obs        | 1.18       |
| _mean_act       | -0.233607  |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 3.95       |
| _mean_obs       | 0.0368     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.39      |
| _std_act        | 0.692811   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.918      |
| KL              | 0.00209773 |
| Phi_loss        | 776.843    |
| PolicyEntropy   | 0.216208   |
| PolicyLoss      | 0.013218   |
| Steps           | 10000      |
| VarFuncLoss     | 0.124      |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.31103    |
| _max_adv        | 4.75       |
| _max_discrew    | 5.45       |
| _max_obs        | 1.88       |
| _mean_act       | -0.233096  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0359     |
| _min_adv        | -18.9      |
| _min_discrew    | -1.09      |
| _min_obs        | -1.3       |
| _std_act        | 0.729967   |
| _std_adv        | 1          |
| _std_discrew    | 2.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.892       |
| ExplainedVarOld | 0.89        |
| KL              | 0.00432685  |
| Phi_loss        | 1005.04     |
| PolicyEntropy   | 0.180683    |
| PolicyLoss      | -0.00231016 |
| Steps           | 10000       |
| VarFuncLoss     | 0.257       |
| _MeanReward     | 4.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.04879     |
| _max_adv        | 16.9        |
| _max_discrew    | 5.23        |
| _max_obs        | 1.11        |
| _mean_act       | -0.235919   |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 3.98        |
| _mean_obs       | 0.0363      |
| _min_adv        | -9.99       |
| _min_discrew    | 0.00209     |
| _min_obs        | -1.36       |
| _std_act        | 0.69554     |
| _std_adv        | 1           |
| _std_discrew    | 1.53        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.954      |
| ExplainedVarOld | 0.94       |
| KL              | 0.00188989 |
| Phi_loss        | 579.974    |
| PolicyEntropy   | 0.16787    |
| PolicyLoss      | 0.0095148  |
| Steps           | 10000      |
| VarFuncLoss     | 0.075      |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83719    |
| _max_adv        | 3.99       |
| _max_discrew    | 5.09       |
| _max_obs        | 1.16       |
| _mean_act       | -0.233492  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0358     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.44      |
| _std_act        | 0.69594    |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.948      |
| KL              | 0.00345171 |
| Phi_loss        | 803.616    |
| PolicyEntropy   | 0.155786   |
| PolicyLoss      | -0.0171187 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0847     |
| _MeanReward     | 4.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61267    |
| _max_adv        | 10.8       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.06       |
| _mean_act       | -0.236036  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.0361     |
| _min_adv        | -11.8      |
| _min_discrew    | -0.042     |
| _min_obs        | -1.46      |
| _std_act        | 0.690603   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.975       |
| KL              | 0.0045143   |
| Phi_loss        | 845.005     |
| PolicyEntropy   | 0.141429    |
| PolicyLoss      | -0.00760249 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0368      |
| _MeanReward     | 4.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09074     |
| _max_adv        | 6.23        |
| _max_discrew    | 5.46        |
| _max_obs        | 1.12        |
| _mean_act       | -0.233295   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.97        |
| _mean_obs       | 0.0362      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0142      |
| _min_obs        | -1.25       |
| _std_act        | 0.690664    |
| _std_adv        | 1           |
| _std_discrew    | 1.69        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00272339 |
| Phi_loss        | 685.643    |
| PolicyEntropy   | 0.126687   |
| PolicyLoss      | 0.0225099  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0596     |
| _MeanReward     | 4.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.47847    |
| _max_adv        | 9.01       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.11       |
| _mean_act       | -0.232301  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4          |
| _mean_obs       | 0.0358     |
| _min_adv        | -5.94      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.38      |
| _std_act        | 0.680192   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00312273 |
| Phi_loss        | 827.169    |
| PolicyEntropy   | 0.102077   |
| PolicyLoss      | 0.016842   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0233     |
| _MeanReward     | 4.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4753     |
| _max_adv        | 7.81       |
| _max_discrew    | 5.38       |
| _max_obs        | 1.13       |
| _mean_act       | -0.233623  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0361     |
| _min_adv        | -5.56      |
| _min_discrew    | 0.0141     |
| _min_obs        | -1.27      |
| _std_act        | 0.676682   |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00303198 |
| Phi_loss        | 858.644    |
| PolicyEntropy   | 0.0845156  |
| PolicyLoss      | -0.0206013 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.19278    |
| _max_adv        | 6.63       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.13       |
| _mean_act       | -0.228991  |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.0359     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0184     |
| _min_obs        | -1.39      |
| _std_act        | 0.696012   |
| _std_adv        | 1          |
| _std_discrew    | 1.5        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
----------------------------------
| Beta            | 0.0643       |
| ExplainedVarNew | 0.935        |
| ExplainedVarOld | 0.933        |
| KL              | 0.00144242   |
| Phi_loss        | 811.618      |
| PolicyEntropy   | 0.0803041    |
| PolicyLoss      | -0.000906944 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0981       |
| _MeanReward     | 4.82e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.71586      |
| _max_adv        | 11           |
| _max_discrew    | 5.36         |
| _max_obs        | 1.15         |
| _mean_act       | -0.231147    |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 4.01         |
| _mean_obs       | 0.0364       |
| _min_adv        | -4.78        |
| _min_discrew    | 0.0217       |
| _min_obs        | -1.43        |
| _std_act        | 0.690813     |
| _std_adv        | 1            |
| _std_discrew    | 1.5          |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00215906 |
| Phi_loss        | 835.289    |
| PolicyEntropy   | 0.0487204  |
| PolicyLoss      | 0.00513156 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 4.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94819    |
| _max_adv        | 2.91       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.09       |
| _mean_act       | -0.22752   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.95       |
| _mean_obs       | 0.0364     |
| _min_adv        | -13.3      |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.42      |
| _std_act        | 0.691562   |
| _std_adv        | 1          |
| _std_discrew    | 1.53       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.953       |
| KL              | 0.0033189   |
| Phi_loss        | 744.108     |
| PolicyEntropy   | 0.0407896   |
| PolicyLoss      | -0.00621942 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0658      |
| _MeanReward     | 4.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79827     |
| _max_adv        | 19.7        |
| _max_discrew    | 5.23        |
| _max_obs        | 1.11        |
| _mean_act       | -0.226832   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 4.03        |
| _mean_obs       | 0.0372      |
| _min_adv        | -9.33       |
| _min_discrew    | 0.0164      |
| _min_obs        | -1.63       |
| _std_act        | 0.684832    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00533556 |
| Phi_loss        | 799.622    |
| PolicyEntropy   | 0.0265913  |
| PolicyLoss      | 0.0393102  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0229     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.27037    |
| _max_adv        | 3.38       |
| _max_discrew    | 5.38       |
| _max_obs        | 1.98       |
| _mean_act       | -0.222105  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0385     |
| _min_adv        | -11.5      |
| _min_discrew    | -1.23      |
| _min_obs        | -1.35      |
| _std_act        | 0.812206   |
| _std_adv        | 1          |
| _std_discrew    | 4.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.857      |
| ExplainedVarOld | 0.798      |
| KL              | 0.012159   |
| Phi_loss        | 844.558    |
| PolicyEntropy   | 0.0150909  |
| PolicyLoss      | 0.00291821 |
| Steps           | 10000      |
| VarFuncLoss     | 0.609      |
| _MeanReward     | 4.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71621    |
| _max_adv        | 16.5       |
| _max_discrew    | 5.36       |
| _max_obs        | 1.13       |
| _mean_act       | -0.21951   |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 4.01       |
| _mean_obs       | 0.0377     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.48      |
| _std_act        | 0.687634   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.946       |
| ExplainedVarOld | 0.942       |
| KL              | 0.00618312  |
| Phi_loss        | 784.565     |
| PolicyEntropy   | -0.013979   |
| PolicyLoss      | -0.00602137 |
| Steps           | 10000       |
| VarFuncLoss     | 0.095       |
| _MeanReward     | 4.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67471     |
| _max_adv        | 18.2        |
| _max_discrew    | 5.31        |
| _max_obs        | 1.22        |
| _mean_act       | -0.218877   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 3.99        |
| _mean_obs       | 0.0378      |
| _min_adv        | -11.5       |
| _min_discrew    | 0.0132      |
| _min_obs        | -1.34       |
| _std_act        | 0.688472    |
| _std_adv        | 1           |
| _std_discrew    | 1.56        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00313907 |
| Phi_loss        | 797.852    |
| PolicyEntropy   | -0.020627  |
| PolicyLoss      | 0.017907   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0392     |
| _MeanReward     | 4.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51877    |
| _max_adv        | 16.4       |
| _max_discrew    | 5.35       |
| _max_obs        | 1.1        |
| _mean_act       | -0.21842   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.99       |
| _mean_obs       | 0.0377     |
| _min_adv        | -7.62      |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.28      |
| _std_act        | 0.687968   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00218848 |
| Phi_loss        | 916.143    |
| PolicyEntropy   | -0.021554  |
| PolicyLoss      | -0.0209115 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0447     |
| _MeanReward     | 4.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92575    |
| _max_adv        | 4.89       |
| _max_discrew    | 5.47       |
| _max_obs        | 1.16       |
| _mean_act       | -0.217745  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.97       |
| _mean_obs       | 0.0381     |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0201     |
| _min_obs        | -1.5       |
| _std_act        | 0.692817   |
| _std_adv        | 1          |
| _std_discrew    | 1.78       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.943      |
| ExplainedVarOld | 0.935      |
| KL              | 0.00287016 |
| Phi_loss        | 768.159    |
| PolicyEntropy   | -0.0238295 |
| PolicyLoss      | -0.039416  |
| Steps           | 10000      |
| VarFuncLoss     | 0.102      |
| _MeanReward     | 4.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74354    |
| _max_adv        | 7.17       |
| _max_discrew    | 5.46       |
| _max_obs        | 1.15       |
| _mean_act       | -0.221235  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.04       |
| _mean_obs       | 0.0381     |
| _min_adv        | -13.1      |
| _min_discrew    | 0.0185     |
| _min_obs        | -1.28      |
| _std_act        | 0.696311   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.951       |
| ExplainedVarOld | 0.947       |
| KL              | 0.00118181  |
| Phi_loss        | 853.175     |
| PolicyEntropy   | -0.0288877  |
| PolicyLoss      | -0.00426826 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0783      |
| _MeanReward     | 4.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.67355     |
| _max_adv        | 5.47        |
| _max_discrew    | 5.6         |
| _max_obs        | 4.15        |
| _mean_act       | -0.221155   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.91        |
| _mean_obs       | 0.0412      |
| _min_adv        | -17.2       |
| _min_discrew    | -1.05       |
| _min_obs        | -1.35       |
| _std_act        | 0.73003     |
| _std_adv        | 1           |
| _std_discrew    | 2.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.912      |
| KL              | 0.0101241  |
| Phi_loss        | 687.398    |
| PolicyEntropy   | -0.0200634 |
| PolicyLoss      | -0.0103118 |
| Steps           | 10000      |
| VarFuncLoss     | 0.18       |
| _MeanReward     | 4.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7558     |
| _max_adv        | 22.2       |
| _max_discrew    | 5.49       |
| _max_obs        | 1.1        |
| _mean_act       | -0.22157   |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0381     |
| _min_adv        | -6.54      |
| _min_discrew    | -0.00369   |
| _min_obs        | -1.28      |
| _std_act        | 0.692101   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.976       |
| KL              | 0.00368413  |
| Phi_loss        | 994.422     |
| PolicyEntropy   | -0.0167446  |
| PolicyLoss      | -0.00326376 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0358      |
| _MeanReward     | 4.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75451     |
| _max_adv        | 10.8        |
| _max_discrew    | 5.42        |
| _max_obs        | 1.2         |
| _mean_act       | -0.223427   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 4.07        |
| _mean_obs       | 0.0377      |
| _min_adv        | -12.5       |
| _min_discrew    | -0.00271    |
| _min_obs        | -1.29       |
| _std_act        | 0.694432    |
| _std_adv        | 1           |
| _std_discrew    | 1.68        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00290054 |
| Phi_loss        | 1135.74    |
| PolicyEntropy   | -0.0238819 |
| PolicyLoss      | 0.0237843  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0533     |
| _MeanReward     | 4.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89604    |
| _max_adv        | 14.7       |
| _max_discrew    | 5.42       |
| _max_obs        | 1.12       |
| _mean_act       | -0.22426   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.04       |
| _mean_obs       | 0.0376     |
| _min_adv        | -13.6      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.39      |
| _std_act        | 0.692453   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.953       |
| ExplainedVarOld | 0.948       |
| KL              | 0.00235866  |
| Phi_loss        | 731.816     |
| PolicyEntropy   | -0.0340071  |
| PolicyLoss      | -0.00182332 |
| Steps           | 10000       |
| VarFuncLoss     | 0.075       |
| _MeanReward     | 4.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.13969     |
| _max_adv        | 6.17        |
| _max_discrew    | 5.35        |
| _max_obs        | 1.07        |
| _mean_act       | -0.217546   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.94        |
| _mean_obs       | 0.0374      |
| _min_adv        | -10.8       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.54       |
| _std_act        | 0.698923    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.905       |
| ExplainedVarOld | 0.898       |
| KL              | 0.00279998  |
| Phi_loss        | 872.708     |
| PolicyEntropy   | -0.0344982  |
| PolicyLoss      | -0.00784916 |
| Steps           | 10000       |
| VarFuncLoss     | 0.152       |
| _MeanReward     | 4.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.11972     |
| _max_adv        | 16.7        |
| _max_discrew    | 5.6         |
| _max_obs        | 1.18        |
| _mean_act       | -0.218012   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.96        |
| _mean_obs       | 0.0375      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.0109      |
| _min_obs        | -1.4        |
| _std_act        | 0.693392    |
| _std_adv        | 1           |
| _std_discrew    | 1.56        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.943       |
| ExplainedVarOld | 0.939       |
| KL              | 0.00233735  |
| Phi_loss        | 927.174     |
| PolicyEntropy   | -0.0350447  |
| PolicyLoss      | -0.00780297 |
| Steps           | 10000       |
| VarFuncLoss     | 0.089       |
| _MeanReward     | 4.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9264      |
| _max_adv        | 11.5        |
| _max_discrew    | 5.54        |
| _max_obs        | 1.29        |
| _mean_act       | -0.222421   |
| _mean_adv       | -4.12e-17   |
| _mean_discrew   | 4.13        |
| _mean_obs       | 0.0385      |
| _min_adv        | -7.37       |
| _min_discrew    | -0.0426     |
| _min_obs        | -1.47       |
| _std_act        | 0.692659    |
| _std_adv        | 1           |
| _std_discrew    | 1.7         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.976      |
| KL              | 0.0022873  |
| Phi_loss        | 896.06     |
| PolicyEntropy   | -0.0563478 |
| PolicyLoss      | -0.0185592 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0385     |
| _MeanReward     | 4.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14209    |
| _max_adv        | 5.51       |
| _max_discrew    | 5.51       |
| _max_obs        | 1.13       |
| _mean_act       | -0.222378  |
| _mean_adv       | 0          |
| _mean_discrew   | 4          |
| _mean_obs       | 0.0373     |
| _min_adv        | -13.6      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.41      |
| _std_act        | 0.693887   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00262362  |
| Phi_loss        | 976.06      |
| PolicyEntropy   | -0.0665121  |
| PolicyLoss      | -0.00936182 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0474      |
| _MeanReward     | 4.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.95731     |
| _max_adv        | 6.61        |
| _max_discrew    | 5.57        |
| _max_obs        | 3.63        |
| _mean_act       | -0.225205   |
| _mean_adv       | -4.83e-17   |
| _mean_discrew   | 4.06        |
| _mean_obs       | 0.0375      |
| _min_adv        | -17.1       |
| _min_discrew    | 0.00289     |
| _min_obs        | -1.37       |
| _std_act        | 0.699658    |
| _std_adv        | 1           |
| _std_discrew    | 1.7         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.962       |
| ExplainedVarOld | 0.957       |
| KL              | 0.00190429  |
| Phi_loss        | 881.257     |
| PolicyEntropy   | -0.0695648  |
| PolicyLoss      | -0.00550271 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0649      |
| _MeanReward     | 4.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.73389     |
| _max_adv        | 3.59        |
| _max_discrew    | 5.28        |
| _max_obs        | 2.84        |
| _mean_act       | -0.219998   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.82        |
| _mean_obs       | 0.0388      |
| _min_adv        | -15.8       |
| _min_discrew    | -1.3        |
| _min_obs        | -1.41       |
| _std_act        | 0.743842    |
| _std_adv        | 1           |
| _std_discrew    | 2.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.868      |
| KL              | 0.00865661 |
| Phi_loss        | 1092.33    |
| PolicyEntropy   | -0.0906477 |
| PolicyLoss      | -0.0223487 |
| Steps           | 10000      |
| VarFuncLoss     | 0.282      |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.6689     |
| _max_adv        | 7.59       |
| _max_discrew    | 5.39       |
| _max_obs        | 1.96       |
| _mean_act       | -0.221578  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0371     |
| _min_adv        | -16.5      |
| _min_discrew    | -1.07      |
| _min_obs        | -1.32      |
| _std_act        | 0.734434   |
| _std_adv        | 1          |
| _std_discrew    | 2.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.881      |
| ExplainedVarOld | 0.876      |
| KL              | 0.00281717 |
| Phi_loss        | 1010.11    |
| PolicyEntropy   | -0.0993357 |
| PolicyLoss      | 0.011494   |
| Steps           | 10000      |
| VarFuncLoss     | 0.279      |
| _MeanReward     | 4.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.45932    |
| _max_adv        | 13.5       |
| _max_discrew    | 5.48       |
| _max_obs        | 1.1        |
| _mean_act       | -0.226057  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0368     |
| _min_adv        | -7.44      |
| _min_discrew    | 0.0172     |
| _min_obs        | -1.4       |
| _std_act        | 0.686188   |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.967       |
| KL              | 0.00151704  |
| Phi_loss        | 839.965     |
| PolicyEntropy   | -0.10637    |
| PolicyLoss      | -0.00425018 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0471      |
| _MeanReward     | 4.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96547     |
| _max_adv        | 16.7        |
| _max_discrew    | 5.49        |
| _max_obs        | 1.2         |
| _mean_act       | -0.228528   |
| _mean_adv       | 0           |
| _mean_discrew   | 4.04        |
| _mean_obs       | 0.0366      |
| _min_adv        | -8.89       |
| _min_discrew    | 0.0151      |
| _min_obs        | -1.38       |
| _std_act        | 0.692812    |
| _std_adv        | 1           |
| _std_discrew    | 1.62        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.963      |
| KL              | 0.0015051  |
| Phi_loss        | 972.18     |
| PolicyEntropy   | -0.109498  |
| PolicyLoss      | -0.0230675 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0535     |
| _MeanReward     | 4.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.04535    |
| _max_adv        | 4.65       |
| _max_discrew    | 5.59       |
| _max_obs        | 1.15       |
| _mean_act       | -0.230101  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 4.08       |
| _mean_obs       | 0.036      |
| _min_adv        | -7.57      |
| _min_discrew    | 0.0209     |
| _min_obs        | -1.53      |
| _std_act        | 0.688186   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00118459  |
| Phi_loss        | 1045.68     |
| PolicyEntropy   | -0.121474   |
| PolicyLoss      | -0.00876656 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0405      |
| _MeanReward     | 4.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60528     |
| _max_adv        | 6.68        |
| _max_discrew    | 5.47        |
| _max_obs        | 1.07        |
| _mean_act       | -0.23413    |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 4.09        |
| _mean_obs       | 0.0363      |
| _min_adv        | -6.28       |
| _min_discrew    | 0.0136      |
| _min_obs        | -1.44       |
| _std_act        | 0.68617     |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00146522 |
| Phi_loss        | 1065.28    |
| PolicyEntropy   | -0.130942  |
| PolicyLoss      | -0.0340956 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0289     |
| _MeanReward     | 4.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87574    |
| _max_adv        | 23.6       |
| _max_discrew    | 5.48       |
| _max_obs        | 1.1        |
| _mean_act       | -0.234558  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.13       |
| _mean_obs       | 0.0364     |
| _min_adv        | -7.65      |
| _min_discrew    | 0.0103     |
| _min_obs        | -1.53      |
| _std_act        | 0.690404   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00635014 |
| Phi_loss        | 993.671    |
| PolicyEntropy   | -0.13726   |
| PolicyLoss      | -0.0243746 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0368     |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49586    |
| _max_adv        | 3.22       |
| _max_discrew    | 5.49       |
| _max_obs        | 1.13       |
| _mean_act       | -0.232725  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0361     |
| _min_adv        | -5.85      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.48      |
| _std_act        | 0.693979   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00240354 |
| Phi_loss        | 1034.02    |
| PolicyEntropy   | -0.142861  |
| PolicyLoss      | 0.0222274  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0343     |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55926    |
| _max_adv        | 3.79       |
| _max_discrew    | 5.49       |
| _max_obs        | 1.1        |
| _mean_act       | -0.231895  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.08       |
| _mean_obs       | 0.036      |
| _min_adv        | -7.25      |
| _min_discrew    | 0.015      |
| _min_obs        | -1.37      |
| _std_act        | 0.68711    |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 477
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00367463  |
| Phi_loss        | 1110.49     |
| PolicyEntropy   | -0.159608   |
| PolicyLoss      | -0.00557324 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 4.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.44676     |
| _max_adv        | 3.65        |
| _max_discrew    | 5.44        |
| _max_obs        | 2.1         |
| _mean_act       | -0.229566   |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.73        |
| _mean_obs       | 0.037       |
| _min_adv        | -16.5       |
| _min_discrew    | -1.27       |
| _min_obs        | -1.36       |
| _std_act        | 0.771255    |
| _std_adv        | 1           |
| _std_discrew    | 3.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 478
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.881      |
| KL              | 0.00486588 |
| Phi_loss        | 663.684    |
| PolicyEntropy   | -0.161883  |
| PolicyLoss      | 0.053441   |
| Steps           | 10000      |
| VarFuncLoss     | 0.298      |
| _MeanReward     | 4.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72398    |
| _max_adv        | 15.8       |
| _max_discrew    | 5.48       |
| _max_obs        | 1.13       |
| _mean_act       | -0.234651  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.13       |
| _mean_obs       | 0.0366     |
| _min_adv        | -8.05      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.3       |
| _std_act        | 0.693432   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 479
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00320711 |
| Phi_loss        | 952.746    |
| PolicyEntropy   | -0.164306  |
| PolicyLoss      | -0.0176384 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0475     |
| _MeanReward     | 4.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.63226    |
| _max_adv        | 13.4       |
| _max_discrew    | 5.45       |
| _max_obs        | 2.73       |
| _mean_act       | -0.230424  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.0377     |
| _min_adv        | -18.5      |
| _min_discrew    | -1.06      |
| _min_obs        | -1.5       |
| _std_act        | 0.731666   |
| _std_adv        | 1          |
| _std_discrew    | 2.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 480
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.899      |
| KL              | 0.00759979 |
| Phi_loss        | 1120.89    |
| PolicyEntropy   | -0.186234  |
| PolicyLoss      | -0.0801271 |
| Steps           | 10000      |
| VarFuncLoss     | 0.207      |
| _MeanReward     | 4.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09698    |
| _max_adv        | 2.44       |
| _max_discrew    | 5.55       |
| _max_obs        | 1.13       |
| _mean_act       | -0.229997  |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 4.03       |
| _mean_obs       | 0.0367     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.00935    |
| _min_obs        | -1.43      |
| _std_act        | 0.702927   |
| _std_adv        | 1          |
| _std_discrew    | 1.85       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 481
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.928       |
| ExplainedVarOld | 0.906       |
| KL              | 0.0016421   |
| Phi_loss        | 625.224     |
| PolicyEntropy   | -0.198532   |
| PolicyLoss      | -0.00782979 |
| Steps           | 10000       |
| VarFuncLoss     | 0.135       |
| _MeanReward     | 4.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.14678     |
| _max_adv        | 7.99        |
| _max_discrew    | 5.4         |
| _max_obs        | 1.16        |
| _mean_act       | -0.229627   |
| _mean_adv       | 0           |
| _mean_discrew   | 4.02        |
| _mean_obs       | 0.0362      |
| _min_adv        | -11.3       |
| _min_discrew    | 0.0174      |
| _min_obs        | -1.43       |
| _std_act        | 0.701164    |
| _std_adv        | 1           |
| _std_discrew    | 1.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 482
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.929      |
| KL              | 0.00247518 |
| Phi_loss        | 904.009    |
| PolicyEntropy   | -0.218366  |
| PolicyLoss      | -0.0270555 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0861     |
| _MeanReward     | 4.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.36778    |
| _max_adv        | 9.76       |
| _max_discrew    | 5.45       |
| _max_obs        | 2.15       |
| _mean_act       | -0.232193  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0369     |
| _min_adv        | -13.5      |
| _min_discrew    | -0.0602    |
| _min_obs        | -1.43      |
| _std_act        | 0.697197   |
| _std_adv        | 1          |
| _std_discrew    | 1.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 483
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00187257 |
| Phi_loss        | 820.991    |
| PolicyEntropy   | -0.235719  |
| PolicyLoss      | 0.0311363  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0369     |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.66011    |
| _max_adv        | 5.19       |
| _max_discrew    | 5.61       |
| _max_obs        | 1.87       |
| _mean_act       | -0.224624  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0377     |
| _min_adv        | -15.2      |
| _min_discrew    | -1.2       |
| _min_obs        | -1.37      |
| _std_act        | 0.772586   |
| _std_adv        | 1          |
| _std_discrew    | 3.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 484
Draw Samples..
----------------------------------
| Beta            | 0.217        |
| ExplainedVarNew | 0.864        |
| ExplainedVarOld | 0.846        |
| KL              | 0.00538673   |
| Phi_loss        | 1137.9       |
| PolicyEntropy   | -0.257874    |
| PolicyLoss      | -0.000333985 |
| Steps           | 10000        |
| VarFuncLoss     | 0.424        |
| _MeanReward     | 4.9e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 3.42717      |
| _max_adv        | 15.7         |
| _max_discrew    | 5.53         |
| _max_obs        | 1.86         |
| _mean_act       | -0.231916    |
| _mean_adv       | 0            |
| _mean_discrew   | 4.08         |
| _mean_obs       | 0.037        |
| _min_adv        | -10.9        |
| _min_discrew    | -0.383       |
| _min_obs        | -1.42        |
| _std_act        | 0.712111     |
| _std_adv        | 1            |
| _std_discrew    | 1.9          |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 485
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.956      |
| ExplainedVarOld | 0.952      |
| KL              | 0.00220284 |
| Phi_loss        | 837.718    |
| PolicyEntropy   | -0.261533  |
| PolicyLoss      | -0.022638  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0842     |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62192    |
| _max_adv        | 24.1       |
| _max_discrew    | 5.54       |
| _max_obs        | 1.11       |
| _mean_act       | -0.232196  |
| _mean_adv       | 4.09e-17   |
| _mean_discrew   | 4.1        |
| _mean_obs       | 0.0356     |
| _min_adv        | -5.86      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.45      |
| _std_act        | 0.695717   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 486
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00134313 |
| Phi_loss        | 958.443    |
| PolicyEntropy   | -0.265431  |
| PolicyLoss      | 0.0164374  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0414     |
| _MeanReward     | 4.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65755    |
| _max_adv        | 17.3       |
| _max_discrew    | 5.47       |
| _max_obs        | 1.19       |
| _mean_act       | -0.236804  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0357     |
| _min_adv        | -5.67      |
| _min_discrew    | 0.0171     |
| _min_obs        | -1.31      |
| _std_act        | 0.693975   |
| _std_adv        | 1          |
| _std_discrew    | 1.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 487
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00231901 |
| Phi_loss        | 1106.41    |
| PolicyEntropy   | -0.271949  |
| PolicyLoss      | -0.0173683 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0267     |
| _MeanReward     | 4.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14699    |
| _max_adv        | 7.61       |
| _max_discrew    | 5.35       |
| _max_obs        | 1.09       |
| _mean_act       | -0.234392  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.07       |
| _mean_obs       | 0.0359     |
| _min_adv        | -15.7      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.35      |
| _std_act        | 0.691485   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 488
Draw Samples..
----------------------------------
| Beta            | 0.145        |
| ExplainedVarNew | 0.963        |
| ExplainedVarOld | 0.958        |
| KL              | 0.00256023   |
| Phi_loss        | 924.955      |
| PolicyEntropy   | -0.289783    |
| PolicyLoss      | -0.000648091 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0614       |
| _MeanReward     | 4.99e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.58698      |
| _max_adv        | 18.1         |
| _max_discrew    | 5.57         |
| _max_obs        | 1.12         |
| _mean_act       | -0.238522    |
| _mean_adv       | 3.27e-17     |
| _mean_discrew   | 4.16         |
| _mean_obs       | 0.0363       |
| _min_adv        | -9.99        |
| _min_discrew    | 0.0162       |
| _min_obs        | -1.32        |
| _std_act        | 0.697217     |
| _std_adv        | 1            |
| _std_discrew    | 1.65         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 489
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00247463 |
| Phi_loss        | 1026.88    |
| PolicyEntropy   | -0.303157  |
| PolicyLoss      | 0.0186952  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0336     |
| _MeanReward     | 4.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60692    |
| _max_adv        | 4.69       |
| _max_discrew    | 5.41       |
| _max_obs        | 1.14       |
| _mean_act       | -0.235097  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0358     |
| _min_adv        | -11.9      |
| _min_discrew    | 0.0179     |
| _min_obs        | -1.51      |
| _std_act        | 0.694185   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 490
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.958       |
| KL              | 0.00265597  |
| Phi_loss        | 1061.2      |
| PolicyEntropy   | -0.301002   |
| PolicyLoss      | -0.00399858 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0635      |
| _MeanReward     | 4.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90616     |
| _max_adv        | 4.56        |
| _max_discrew    | 5.57        |
| _max_obs        | 1.1         |
| _mean_act       | -0.2344     |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 4.13        |
| _mean_obs       | 0.0366      |
| _min_adv        | -13.2       |
| _min_discrew    | 0.0139      |
| _min_obs        | -1.39       |
| _std_act        | 0.688872    |
| _std_adv        | 1           |
| _std_discrew    | 1.76        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 491
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00265021 |
| Phi_loss        | 856.559    |
| PolicyEntropy   | -0.322986  |
| PolicyLoss      | 0.0128726  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0592     |
| _MeanReward     | 4.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03344    |
| _max_adv        | 25.9       |
| _max_discrew    | 5.49       |
| _max_obs        | 1.11       |
| _mean_act       | -0.22978   |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0356     |
| _min_adv        | -11        |
| _min_discrew    | 0.0207     |
| _min_obs        | -1.39      |
| _std_act        | 0.686661   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 492
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00667262 |
| Phi_loss        | 1018.89    |
| PolicyEntropy   | -0.342823  |
| PolicyLoss      | 0.0591553  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0593     |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.55619    |
| _max_adv        | 3.04       |
| _max_discrew    | 5.39       |
| _max_obs        | 2.12       |
| _mean_act       | -0.223789  |
| _mean_adv       | -4.41e-17  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.036      |
| _min_adv        | -17.1      |
| _min_discrew    | -1.29      |
| _min_obs        | -1.49      |
| _std_act        | 0.776577   |
| _std_adv        | 1          |
| _std_discrew    | 3.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 493
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00576736 |
| Phi_loss        | 1112.37    |
| PolicyEntropy   | -0.379683  |
| PolicyLoss      | -0.0122827 |
| Steps           | 10000      |
| VarFuncLoss     | 0.373      |
| _MeanReward     | 5.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56142    |
| _max_adv        | 17.7       |
| _max_discrew    | 5.59       |
| _max_obs        | 1.06       |
| _mean_act       | -0.236935  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.036      |
| _min_adv        | -4.17      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.28      |
| _std_act        | 0.673523   |
| _std_adv        | 1          |
| _std_discrew    | 1.63       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 494
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00165188 |
| Phi_loss        | 1022.8     |
| PolicyEntropy   | -0.406009  |
| PolicyLoss      | 0.0449411  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0552     |
| _MeanReward     | 4.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51659    |
| _max_adv        | 9.77       |
| _max_discrew    | 5.45       |
| _max_obs        | 1.07       |
| _mean_act       | -0.236611  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.13       |
| _mean_obs       | 0.0355     |
| _min_adv        | -5.34      |
| _min_discrew    | 0.0203     |
| _min_obs        | -1.33      |
| _std_act        | 0.67337    |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 495
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00157525 |
| Phi_loss        | 1087.0     |
| PolicyEntropy   | -0.414472  |
| PolicyLoss      | 0.0123831  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0276     |
| _MeanReward     | 5.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78857    |
| _max_adv        | 20.4       |
| _max_discrew    | 5.5        |
| _max_obs        | 1.13       |
| _mean_act       | -0.237529  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.15       |
| _mean_obs       | 0.036      |
| _min_adv        | -11.1      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.28      |
| _std_act        | 0.6737     |
| _std_adv        | 1          |
| _std_discrew    | 1.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 496
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00125709 |
| Phi_loss        | 1134.91    |
| PolicyEntropy   | -0.430186  |
| PolicyLoss      | -0.0032278 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0552     |
| _MeanReward     | 5.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71464    |
| _max_adv        | 8.9        |
| _max_discrew    | 5.51       |
| _max_obs        | 1.09       |
| _mean_act       | -0.232385  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.0365     |
| _min_adv        | -8.51      |
| _min_discrew    | 0.0192     |
| _min_obs        | -1.36      |
| _std_act        | 0.676432   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 497
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00336378 |
| Phi_loss        | 1272.73    |
| PolicyEntropy   | -0.449224  |
| PolicyLoss      | -0.0226664 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0336     |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9674     |
| _max_adv        | 4.94       |
| _max_discrew    | 5.64       |
| _max_obs        | 1.12       |
| _mean_act       | -0.229093  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0366     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0214     |
| _min_obs        | -1.33      |
| _std_act        | 0.678537   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 498
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.963      |
| KL              | 0.0030472  |
| Phi_loss        | 1351.37    |
| PolicyEntropy   | -0.471169  |
| PolicyLoss      | 0.00180231 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0579     |
| _MeanReward     | 4.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.38408    |
| _max_adv        | 1.5        |
| _max_discrew    | 5.58       |
| _max_obs        | 1.98       |
| _mean_act       | -0.229188  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0374     |
| _min_adv        | -16        |
| _min_discrew    | -1.27      |
| _min_obs        | -1.33      |
| _std_act        | 0.75589    |
| _std_adv        | 1          |
| _std_discrew    | 3.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 499
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.871      |
| KL              | 0.00533146 |
| Phi_loss        | 874.88     |
| PolicyEntropy   | -0.485616  |
| PolicyLoss      | -0.0109636 |
| Steps           | 10000      |
| VarFuncLoss     | 0.333      |
| _MeanReward     | 5.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90575    |
| _max_adv        | 10.6       |
| _max_discrew    | 5.52       |
| _max_obs        | 1.11       |
| _mean_act       | -0.235773  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.0362     |
| _min_adv        | -11.8      |
| _min_discrew    | 0.00957    |
| _min_obs        | -1.4       |
| _std_act        | 0.675393   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 500
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00429732 |
| Phi_loss        | 1145.11    |
| PolicyEntropy   | -0.487122  |
| PolicyLoss      | 0.0084391  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0583     |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57446    |
| _max_adv        | 16.7       |
| _max_discrew    | 5.38       |
| _max_obs        | 1.07       |
| _mean_act       | -0.235082  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.15       |
| _mean_obs       | 0.036      |
| _min_adv        | -4.92      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.43      |
| _std_act        | 0.679911   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 501
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00280949 |
| Phi_loss        | 1026.01    |
| PolicyEntropy   | -0.488755  |
| PolicyLoss      | 0.00203552 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0244     |
| _MeanReward     | 5.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.12228    |
| _max_adv        | 15.5       |
| _max_discrew    | 5.67       |
| _max_obs        | 1.09       |
| _mean_act       | -0.232829  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.16       |
| _mean_obs       | 0.0362     |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.34      |
| _std_act        | 0.67734    |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 502
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.956       |
| KL              | 0.00414534  |
| Phi_loss        | 1175.89     |
| PolicyEntropy   | -0.515189   |
| PolicyLoss      | -0.00744686 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0632      |
| _MeanReward     | 5.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.28818     |
| _max_adv        | 7.43        |
| _max_discrew    | 5.65        |
| _max_obs        | 1.11        |
| _mean_act       | -0.236287   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 4.25        |
| _mean_obs       | 0.0368      |
| _min_adv        | -6.01       |
| _min_discrew    | 0.0161      |
| _min_obs        | -1.37       |
| _std_act        | 0.673124    |
| _std_adv        | 1           |
| _std_discrew    | 1.73        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 503
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00239299 |
| Phi_loss        | 1219.77    |
| PolicyEntropy   | -0.545907  |
| PolicyLoss      | -0.0220636 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0308     |
| _MeanReward     | 5.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.38318    |
| _max_adv        | 6.26       |
| _max_discrew    | 5.38       |
| _max_obs        | 1.11       |
| _mean_act       | -0.233663  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0363     |
| _min_adv        | -7.22      |
| _min_discrew    | 0.0225     |
| _min_obs        | -1.23      |
| _std_act        | 0.674665   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 504
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00332132 |
| Phi_loss        | 1314.2     |
| PolicyEntropy   | -0.566058  |
| PolicyLoss      | 0.0378744  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0312     |
| _MeanReward     | 5.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48966    |
| _max_adv        | 17.4       |
| _max_discrew    | 5.59       |
| _max_obs        | 1.13       |
| _mean_act       | -0.234625  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 4.19       |
| _mean_obs       | 0.036      |
| _min_adv        | -7.3       |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.42      |
| _std_act        | 0.671455   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 505
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00273765 |
| Phi_loss        | 1589.8     |
| PolicyEntropy   | -0.597285  |
| PolicyLoss      | -0.0205898 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0278     |
| _MeanReward     | 5.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66268    |
| _max_adv        | 15.1       |
| _max_discrew    | 5.54       |
| _max_obs        | 1.1        |
| _mean_act       | -0.234242  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 4.24       |
| _mean_obs       | 0.037      |
| _min_adv        | -10.5      |
| _min_discrew    | 0.0191     |
| _min_obs        | -1.39      |
| _std_act        | 0.675818   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 506
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00390591 |
| Phi_loss        | 1348.28    |
| PolicyEntropy   | -0.615103  |
| PolicyLoss      | 0.00649042 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0349     |
| _MeanReward     | 5.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03679    |
| _max_adv        | 6.46       |
| _max_discrew    | 5.82       |
| _max_obs        | 1.12       |
| _mean_act       | -0.235263  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.0365     |
| _min_adv        | -7.96      |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.48      |
| _std_act        | 0.674568   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 507
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00274534 |
| Phi_loss        | 1444.75    |
| PolicyEntropy   | -0.643314  |
| PolicyLoss      | -0.0102289 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0349     |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06477    |
| _max_adv        | 4.51       |
| _max_discrew    | 5.76       |
| _max_obs        | 1.04       |
| _mean_act       | -0.233225  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0368     |
| _min_adv        | -14.3      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.46      |
| _std_act        | 0.679459   |
| _std_adv        | 1          |
| _std_discrew    | 1.78       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 508
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.969      |
| KL              | 0.00335173 |
| Phi_loss        | 1308.56    |
| PolicyEntropy   | -0.668515  |
| PolicyLoss      | 0.0426619  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0525     |
| _MeanReward     | 5.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.41971    |
| _max_adv        | 4.73       |
| _max_discrew    | 5.69       |
| _max_obs        | 1.09       |
| _mean_act       | -0.233595  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 4.32       |
| _mean_obs       | 0.0379     |
| _min_adv        | -4.48      |
| _min_discrew    | 0.0201     |
| _min_obs        | -1.42      |
| _std_act        | 0.669872   |
| _std_adv        | 1          |
| _std_discrew    | 1.79       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 509
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00422015  |
| Phi_loss        | 1413.45     |
| PolicyEntropy   | -0.67692    |
| PolicyLoss      | -0.00142081 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0299      |
| _MeanReward     | 5.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67371     |
| _max_adv        | 4.17        |
| _max_discrew    | 5.54        |
| _max_obs        | 1.08        |
| _mean_act       | -0.234353   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.24        |
| _mean_obs       | 0.0373      |
| _min_adv        | -4.41       |
| _min_discrew    | 0.0188      |
| _min_obs        | -1.28       |
| _std_act        | 0.675315    |
| _std_adv        | 1           |
| _std_discrew    | 1.77        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 510
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.0046275   |
| Phi_loss        | 1499.77     |
| PolicyEntropy   | -0.679542   |
| PolicyLoss      | -0.00474781 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0348      |
| _MeanReward     | 4.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.4044      |
| _max_adv        | 5.04        |
| _max_discrew    | 5.74        |
| _max_obs        | 1.93        |
| _mean_act       | -0.227182   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 4.02        |
| _mean_obs       | 0.0383      |
| _min_adv        | -16         |
| _min_discrew    | -1.15       |
| _min_obs        | -1.29       |
| _std_act        | 0.732102    |
| _std_adv        | 1           |
| _std_discrew    | 2.71        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 511
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.885      |
| ExplainedVarOld | 0.862      |
| KL              | 0.00319944 |
| Phi_loss        | 1201.99    |
| PolicyEntropy   | -0.690389  |
| PolicyLoss      | 0.0463906  |
| Steps           | 10000      |
| VarFuncLoss     | 0.313      |
| _MeanReward     | 5.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60874    |
| _max_adv        | 29         |
| _max_discrew    | 5.6        |
| _max_obs        | 1.12       |
| _mean_act       | -0.232494  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 4.19       |
| _mean_obs       | 0.0364     |
| _min_adv        | -7.24      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.51      |
| _std_act        | 0.675455   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 512
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00749775 |
| Phi_loss        | 975.21     |
| PolicyEntropy   | -0.683974  |
| PolicyLoss      | 0.0623918  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0379     |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.04983    |
| _max_adv        | 15.1       |
| _max_discrew    | 5.87       |
| _max_obs        | 1.13       |
| _mean_act       | -0.228328  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0377     |
| _min_adv        | -13.1      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.45      |
| _std_act        | 0.676009   |
| _std_adv        | 1          |
| _std_discrew    | 1.84       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 513
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.95       |
| KL              | 0.00367248 |
| Phi_loss        | 1271.08    |
| PolicyEntropy   | -0.673245  |
| PolicyLoss      | -0.0105154 |
| Steps           | 10000      |
| VarFuncLoss     | 0.078      |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.25837    |
| _max_adv        | 2          |
| _max_discrew    | 5.5        |
| _max_obs        | 1.89       |
| _mean_act       | -0.220816  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.0378     |
| _min_adv        | -18.7      |
| _min_discrew    | -1.26      |
| _min_obs        | -1.32      |
| _std_act        | 0.750289   |
| _std_adv        | 1          |
| _std_discrew    | 3.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 514
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.902      |
| KL              | 0.00565744 |
| Phi_loss        | 1385.97    |
| PolicyEntropy   | -0.663299  |
| PolicyLoss      | 0.098757   |
| Steps           | 10000      |
| VarFuncLoss     | 0.316      |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.40551    |
| _max_adv        | 12.8       |
| _max_discrew    | 5.56       |
| _max_obs        | 1.9        |
| _mean_act       | -0.221908  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0371     |
| _min_adv        | -18.6      |
| _min_discrew    | -1.18      |
| _min_obs        | -1.46      |
| _std_act        | 0.736175   |
| _std_adv        | 1          |
| _std_discrew    | 3.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 515
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.891      |
| ExplainedVarOld | 0.887      |
| KL              | 0.00238359 |
| Phi_loss        | 1356.82    |
| PolicyEntropy   | -0.666973  |
| PolicyLoss      | 0.0163635  |
| Steps           | 10000      |
| VarFuncLoss     | 0.34       |
| _MeanReward     | 5.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37776    |
| _max_adv        | 26.2       |
| _max_discrew    | 5.57       |
| _max_obs        | 1.15       |
| _mean_act       | -0.229038  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0368     |
| _min_adv        | -6.43      |
| _min_discrew    | 0.0232     |
| _min_obs        | -1.34      |
| _std_act        | 0.664601   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 516
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00250202 |
| Phi_loss        | 1080.82    |
| PolicyEntropy   | -0.670683  |
| PolicyLoss      | 0.0239575  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0289     |
| _MeanReward     | 4.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24077    |
| _max_adv        | 4.47       |
| _max_discrew    | 5.53       |
| _max_obs        | 1.89       |
| _mean_act       | -0.226031  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.0375     |
| _min_adv        | -20.3      |
| _min_discrew    | -1.1       |
| _min_obs        | -1.29      |
| _std_act        | 0.714506   |
| _std_adv        | 1          |
| _std_discrew    | 2.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 517
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.889      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00760396 |
| Phi_loss        | 1854.14    |
| PolicyEntropy   | -0.650867  |
| PolicyLoss      | 0.0565002  |
| Steps           | 10000      |
| VarFuncLoss     | 0.304      |
| _MeanReward     | 5.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06807    |
| _max_adv        | 18.4       |
| _max_discrew    | 5.64       |
| _max_obs        | 1.15       |
| _mean_act       | -0.22805   |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 4.16       |
| _mean_obs       | 0.0365     |
| _min_adv        | -13.9      |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.34      |
| _std_act        | 0.670214   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 518
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00169863 |
| Phi_loss        | 1174.03    |
| PolicyEntropy   | -0.660409  |
| PolicyLoss      | 0.0104447  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0618     |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.11149    |
| _max_adv        | 12         |
| _max_discrew    | 5.47       |
| _max_obs        | 1.09       |
| _mean_act       | -0.228035  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.0371     |
| _min_adv        | -12.3      |
| _min_discrew    | 0.0186     |
| _min_obs        | -1.29      |
| _std_act        | 0.667451   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 519
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.966       |
| KL              | 0.000940031 |
| Phi_loss        | 1158.67     |
| PolicyEntropy   | -0.671817   |
| PolicyLoss      | 0.0286534   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0485      |
| _MeanReward     | 5.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83065     |
| _max_adv        | 8.28        |
| _max_discrew    | 5.57        |
| _max_obs        | 1.05        |
| _mean_act       | -0.226992   |
| _mean_adv       | 0           |
| _mean_discrew   | 4.18        |
| _mean_obs       | 0.036       |
| _min_adv        | -16.2       |
| _min_discrew    | 0.0187      |
| _min_obs        | -1.38       |
| _std_act        | 0.66444     |
| _std_adv        | 1           |
| _std_discrew    | 1.67        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 520
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.97        |
| KL              | 0.00285319  |
| Phi_loss        | 1154.05     |
| PolicyEntropy   | -0.695531   |
| PolicyLoss      | -0.00513297 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0462      |
| _MeanReward     | 5.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54121     |
| _max_adv        | 14.6        |
| _max_discrew    | 5.73        |
| _max_obs        | 1.1         |
| _mean_act       | -0.23155    |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 4.25        |
| _mean_obs       | 0.0371      |
| _min_adv        | -6.63       |
| _min_discrew    | 0.0086      |
| _min_obs        | -1.21       |
| _std_act        | 0.664086    |
| _std_adv        | 1           |
| _std_discrew    | 1.82        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 521
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.982      |
| KL              | 0.0013206  |
| Phi_loss        | 1296.47    |
| PolicyEntropy   | -0.70222   |
| PolicyLoss      | -0.0237327 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 5.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52624    |
| _max_adv        | 10.5       |
| _max_discrew    | 5.57       |
| _max_obs        | 1.11       |
| _mean_act       | -0.229036  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.0367     |
| _min_adv        | -5.07      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.29      |
| _std_act        | 0.665935   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 522
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00308768 |
| Phi_loss        | 1534.25    |
| PolicyEntropy   | -0.706093  |
| PolicyLoss      | 0.00425089 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0355     |
| _MeanReward     | 5.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37542    |
| _max_adv        | 5.01       |
| _max_discrew    | 5.66       |
| _max_obs        | 1.12       |
| _mean_act       | -0.230247  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.31       |
| _mean_obs       | 0.0373     |
| _min_adv        | -5.9       |
| _min_discrew    | 0.0196     |
| _min_obs        | -1.37      |
| _std_act        | 0.663903   |
| _std_adv        | 1          |
| _std_discrew    | 1.82       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 523
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00368292 |
| Phi_loss        | 1475.98    |
| PolicyEntropy   | -0.693227  |
| PolicyLoss      | -0.0118069 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0338     |
| _MeanReward     | 5.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39992    |
| _max_adv        | 4.23       |
| _max_discrew    | 5.61       |
| _max_obs        | 1.12       |
| _mean_act       | -0.22971   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.2        |
| _mean_obs       | 0.0367     |
| _min_adv        | -6.78      |
| _min_discrew    | 0.0194     |
| _min_obs        | -1.4       |
| _std_act        | 0.662768   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 524
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00329968 |
| Phi_loss        | 1629.62    |
| PolicyEntropy   | -0.686975  |
| PolicyLoss      | -0.0129709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0253     |
| _MeanReward     | 5.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.7277     |
| _max_adv        | 9          |
| _max_discrew    | 5.48       |
| _max_obs        | 1.11       |
| _mean_act       | -0.231551  |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 4.24       |
| _mean_obs       | 0.0372     |
| _min_adv        | -16.5      |
| _min_discrew    | -0.00747   |
| _min_obs        | -1.28      |
| _std_act        | 0.669888   |
| _std_adv        | 1          |
| _std_discrew    | 1.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 525
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00441665 |
| Phi_loss        | 1339.58    |
| PolicyEntropy   | -0.683345  |
| PolicyLoss      | 0.0104624  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0208     |
| _MeanReward     | 5.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63837    |
| _max_adv        | 3.55       |
| _max_discrew    | 5.5        |
| _max_obs        | 1.08       |
| _mean_act       | -0.2318    |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.037      |
| _min_adv        | -9.33      |
| _min_discrew    | -0.0266    |
| _min_obs        | -1.43      |
| _std_act        | 0.665533   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 526
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00347856 |
| Phi_loss        | 1428.96    |
| PolicyEntropy   | -0.689738  |
| PolicyLoss      | 0.0122494  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0308     |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85563    |
| _max_adv        | 6.71       |
| _max_discrew    | 5.59       |
| _max_obs        | 1.13       |
| _mean_act       | -0.23081   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0371     |
| _min_adv        | -7.04      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.35      |
| _std_act        | 0.665377   |
| _std_adv        | 1          |
| _std_discrew    | 1.83       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 527
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00348217 |
| Phi_loss        | 1492.49    |
| PolicyEntropy   | -0.712224  |
| PolicyLoss      | -0.0154064 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0481     |
| _MeanReward     | 4.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.61066    |
| _max_adv        | 4.98       |
| _max_discrew    | 5.64       |
| _max_obs        | 2.13       |
| _mean_act       | -0.225101  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.0383     |
| _min_adv        | -16.8      |
| _min_discrew    | -1.05      |
| _min_obs        | -1.39      |
| _std_act        | 0.720911   |
| _std_adv        | 1          |
| _std_discrew    | 2.97       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 528
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.879      |
| KL              | 0.00585999 |
| Phi_loss        | 1486.79    |
| PolicyEntropy   | -0.728169  |
| PolicyLoss      | 0.0418909  |
| Steps           | 10000      |
| VarFuncLoss     | 0.337      |
| _MeanReward     | 5.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.41506    |
| _max_adv        | 8.45       |
| _max_discrew    | 5.66       |
| _max_obs        | 1.12       |
| _mean_act       | -0.232943  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.25       |
| _mean_obs       | 0.0374     |
| _min_adv        | -6.73      |
| _min_discrew    | 0.0189     |
| _min_obs        | -1.43      |
| _std_act        | 0.66218    |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 529
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00200903 |
| Phi_loss        | 1383.38    |
| PolicyEntropy   | -0.730876  |
| PolicyLoss      | 0.00506029 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0565     |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.22876    |
| _max_adv        | 6.83       |
| _max_discrew    | 5.58       |
| _max_obs        | 1.93       |
| _mean_act       | -0.223851  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0374     |
| _min_adv        | -18.1      |
| _min_discrew    | -1.11      |
| _min_obs        | -1.38      |
| _std_act        | 0.72302    |
| _std_adv        | 1          |
| _std_discrew    | 3.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 530
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.903      |
| ExplainedVarOld | 0.892      |
| KL              | 0.00280641 |
| Phi_loss        | 1832.3     |
| PolicyEntropy   | -0.739775  |
| PolicyLoss      | 0.0221429  |
| Steps           | 10000      |
| VarFuncLoss     | 0.313      |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09679    |
| _max_adv        | 19.1       |
| _max_discrew    | 5.56       |
| _max_obs        | 1.19       |
| _mean_act       | -0.225699  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 4.16       |
| _mean_obs       | 0.0363     |
| _min_adv        | -8.57      |
| _min_discrew    | 0.0188     |
| _min_obs        | -1.49      |
| _std_act        | 0.660949   |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 531
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00916515 |
| Phi_loss        | 1500.08    |
| PolicyEntropy   | -0.734934  |
| PolicyLoss      | -0.0462645 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0674     |
| _MeanReward     | 5.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06215    |
| _max_adv        | 17.1       |
| _max_discrew    | 5.55       |
| _max_obs        | 1.07       |
| _mean_act       | -0.226689  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.16       |
| _mean_obs       | 0.0371     |
| _min_adv        | -8.67      |
| _min_discrew    | -0.0704    |
| _min_obs        | -1.35      |
| _std_act        | 0.670804   |
| _std_adv        | 1          |
| _std_discrew    | 1.92       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 532
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00688454 |
| Phi_loss        | 1074.71    |
| PolicyEntropy   | -0.742351  |
| PolicyLoss      | -0.0141963 |
| Steps           | 10000      |
| VarFuncLoss     | 0.126      |
| _MeanReward     | 5.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14672    |
| _max_adv        | 8.58       |
| _max_discrew    | 5.83       |
| _max_obs        | 1.12       |
| _mean_act       | -0.229666  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0364     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0215     |
| _min_obs        | -1.31      |
| _std_act        | 0.664436   |
| _std_adv        | 1          |
| _std_discrew    | 1.83       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 533
Draw Samples..
