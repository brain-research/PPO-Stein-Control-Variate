Logging to halfcheetah_unbiased--state-only_256
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
------------------------------
| Steps         | 10000      |
| _MeanReward   | -365       |
| _max_act      | 2.87769    |
| _max_adv      | 3.7        |
| _max_discrew  | 0.105      |
| _max_obs      | 1.57       |
| _mean_act     | 0.00301008 |
| _mean_adv     | 2.34e-17   |
| _mean_discrew | -0.292     |
| _mean_obs     | -0.00139   |
| _min_adv      | -2.7       |
| _min_discrew  | -0.685     |
| _min_obs      | -1.72      |
| _std_act      | 0.40199    |
| _std_adv      | 1          |
| _std_discrew  | 0.0193     |
------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.231       |
| ExplainedVarOld | -4.26       |
| KL              | 0.000224599 |
| Phi_loss        | 0.934912    |
| PolicyEntropy   | 5.515       |
| PolicyLoss      | -0.00160998 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0148      |
| _MeanReward     | -363        |
| _lr_multiplier  | 1           |
| _max_act        | 3.41345     |
| _max_adv        | 4.23        |
| _max_discrew    | 0.0403      |
| _max_obs        | 1.37        |
| _mean_act       | -0.0792924  |
| _mean_adv       | -9.09e-17   |
| _mean_discrew   | -0.307      |
| _mean_obs       | 0.0249      |
| _min_adv        | -6.07       |
| _min_discrew    | -0.792      |
| _min_obs        | -1.2        |
| _std_act        | 0.412223    |
| _std_adv        | 1           |
| _std_discrew    | 0.0247      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.136       |
| ExplainedVarOld | -0.236      |
| KL              | 0.00170434  |
| Phi_loss        | 17.3037     |
| PolicyEntropy   | 5.52165     |
| PolicyLoss      | -0.00343158 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0213      |
| _MeanReward     | -281        |
| _lr_multiplier  | 1           |
| _max_act        | 2.78049     |
| _max_adv        | 3.98        |
| _max_discrew    | 0.125       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0792003  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | -0.229      |
| _mean_obs       | 0.0308      |
| _min_adv        | -4.34       |
| _min_discrew    | -0.539      |
| _min_obs        | -1.22       |
| _std_act        | 0.410676    |
| _std_adv        | 1           |
| _std_discrew    | 0.0184      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.243       |
| ExplainedVarOld | 0.198       |
| KL              | 0.000639116 |
| Phi_loss        | 21.9067     |
| PolicyEntropy   | 5.5112      |
| PolicyLoss      | 0.00866945  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0153      |
| _MeanReward     | -296        |
| _lr_multiplier  | 1           |
| _max_act        | 2.84315     |
| _max_adv        | 4.27        |
| _max_discrew    | 0.12        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0816152  |
| _mean_adv       | 0           |
| _mean_discrew   | -0.242      |
| _mean_obs       | 0.0301      |
| _min_adv        | -5.01       |
| _min_discrew    | -0.558      |
| _min_obs        | -1.3        |
| _std_act        | 0.411824    |
| _std_adv        | 1           |
| _std_discrew    | 0.0173      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.405      |
| ExplainedVarOld | 0.227      |
| KL              | 0.00119005 |
| Phi_loss        | 17.2256    |
| PolicyEntropy   | 5.50947    |
| PolicyLoss      | 0.0031759  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0103     |
| _MeanReward     | -283       |
| _lr_multiplier  | 1          |
| _max_act        | 2.55632    |
| _max_adv        | 3.41       |
| _max_discrew    | 0.0515     |
| _max_obs        | 1.29       |
| _mean_act       | -0.0691383 |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | -0.224     |
| _mean_obs       | 0.0287     |
| _min_adv        | -3.96      |
| _min_discrew    | -0.609     |
| _min_obs        | -1.37      |
| _std_act        | 0.409145   |
| _std_adv        | 1          |
| _std_discrew    | 0.0179     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.428       |
| ExplainedVarOld | 0.379       |
| KL              | 0.00273516  |
| Phi_loss        | 19.7121     |
| PolicyEntropy   | 5.49463     |
| PolicyLoss      | 0.000848859 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0103      |
| _MeanReward     | -231        |
| _lr_multiplier  | 1           |
| _max_act        | 2.89792     |
| _max_adv        | 4.17        |
| _max_discrew    | 0.0465      |
| _max_obs        | 1.36        |
| _mean_act       | -0.0730216  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | -0.189      |
| _mean_obs       | 0.0379      |
| _min_adv        | -3.6        |
| _min_discrew    | -0.481      |
| _min_obs        | -1.27       |
| _std_act        | 0.41257     |
| _std_adv        | 1           |
| _std_discrew    | 0.0121      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.111      |
| ExplainedVarOld | -0.00255   |
| KL              | 0.00307974 |
| Phi_loss        | 17.8511    |
| PolicyEntropy   | 5.48087    |
| PolicyLoss      | 0.00561864 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0111     |
| _MeanReward     | -228       |
| _lr_multiplier  | 1          |
| _max_act        | 2.41468    |
| _max_adv        | 3.83       |
| _max_discrew    | 0.0483     |
| _max_obs        | 1.27       |
| _mean_act       | -0.0725201 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.181     |
| _mean_obs       | 0.036      |
| _min_adv        | -3.91      |
| _min_discrew    | -0.475     |
| _min_obs        | -1.4       |
| _std_act        | 0.408232   |
| _std_adv        | 1          |
| _std_discrew    | 0.0106     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.198      |
| ExplainedVarOld | 0.0476     |
| KL              | 0.00272519 |
| Phi_loss        | 16.983     |
| PolicyEntropy   | 5.47506    |
| PolicyLoss      | 0.00212164 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00856    |
| _MeanReward     | -202       |
| _lr_multiplier  | 1          |
| _max_act        | 2.89866    |
| _max_adv        | 4.48       |
| _max_discrew    | 0.0266     |
| _max_obs        | 1.24       |
| _mean_act       | -0.0749131 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.171     |
| _mean_obs       | 0.0366     |
| _min_adv        | -4.21      |
| _min_discrew    | -0.46      |
| _min_obs        | -1.28      |
| _std_act        | 0.409949   |
| _std_adv        | 1          |
| _std_discrew    | 0.0109     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.204      |
| ExplainedVarOld | 0.182      |
| KL              | 0.00269239 |
| Phi_loss        | 19.1684    |
| PolicyEntropy   | 5.45874    |
| PolicyLoss      | 0.00400381 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00866    |
| _MeanReward     | -215       |
| _lr_multiplier  | 1          |
| _max_act        | 2.4675     |
| _max_adv        | 3.8        |
| _max_discrew    | 0.118      |
| _max_obs        | 1.25       |
| _mean_act       | -0.0680109 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.172     |
| _mean_obs       | 0.0374     |
| _min_adv        | -3.84      |
| _min_discrew    | -0.509     |
| _min_obs        | -1.39      |
| _std_act        | 0.408543   |
| _std_adv        | 1          |
| _std_discrew    | 0.0149     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.331      |
| ExplainedVarOld | 0.271      |
| KL              | 0.00239429 |
| Phi_loss        | 19.1274    |
| PolicyEntropy   | 5.44659    |
| PolicyLoss      | 0.00251724 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00997    |
| _MeanReward     | -175       |
| _lr_multiplier  | 1          |
| _max_act        | 2.83437    |
| _max_adv        | 3.28       |
| _max_discrew    | 0.113      |
| _max_obs        | 1.22       |
| _mean_act       | -0.0653862 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | -0.132     |
| _mean_obs       | 0.0377     |
| _min_adv        | -4.27      |
| _min_discrew    | -0.419     |
| _min_obs        | -1.49      |
| _std_act        | 0.402892   |
| _std_adv        | 1          |
| _std_discrew    | 0.00914    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.16       |
| ExplainedVarOld | 0.112      |
| KL              | 0.00301023 |
| Phi_loss        | 19.9277    |
| PolicyEntropy   | 5.4185     |
| PolicyLoss      | 0.00767682 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00793    |
| _MeanReward     | -160       |
| _lr_multiplier  | 1          |
| _max_act        | 2.70772    |
| _max_adv        | 4.43       |
| _max_discrew    | 0.136      |
| _max_obs        | 1.32       |
| _mean_act       | -0.075286  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.126     |
| _mean_obs       | 0.0428     |
| _min_adv        | -4.33      |
| _min_discrew    | -0.437     |
| _min_obs        | -1.27      |
| _std_act        | 0.402993   |
| _std_adv        | 1          |
| _std_discrew    | 0.0101     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.244      |
| ExplainedVarOld | 0.171      |
| KL              | 0.00264877 |
| Phi_loss        | 19.267     |
| PolicyEntropy   | 5.41591    |
| PolicyLoss      | 0.0011619  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00769    |
| _MeanReward     | -151       |
| _lr_multiplier  | 1          |
| _max_act        | 2.73464    |
| _max_adv        | 4.02       |
| _max_discrew    | 0.111      |
| _max_obs        | 1.38       |
| _mean_act       | -0.0715589 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | -0.129     |
| _mean_obs       | 0.0401     |
| _min_adv        | -4.51      |
| _min_discrew    | -0.4       |
| _min_obs        | -1.28      |
| _std_act        | 0.406137   |
| _std_adv        | 1          |
| _std_discrew    | 0.00953    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.34       |
| ExplainedVarOld | 0.282      |
| KL              | 0.00302866 |
| Phi_loss        | 18.3498    |
| PolicyEntropy   | 5.40209    |
| PolicyLoss      | 0.00322236 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00629    |
| _MeanReward     | -146       |
| _lr_multiplier  | 1          |
| _max_act        | 2.68487    |
| _max_adv        | 4.29       |
| _max_discrew    | 0.142      |
| _max_obs        | 1.5        |
| _mean_act       | -0.0832932 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.134     |
| _mean_obs       | 0.0417     |
| _min_adv        | -3.49      |
| _min_discrew    | -0.41      |
| _min_obs        | -1.17      |
| _std_act        | 0.409298   |
| _std_adv        | 1          |
| _std_discrew    | 0.0101     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.482       |
| ExplainedVarOld | 0.297       |
| KL              | 0.00246838  |
| Phi_loss        | 16.2299     |
| PolicyEntropy   | 5.39927     |
| PolicyLoss      | 0.000988479 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00523     |
| _MeanReward     | -138        |
| _lr_multiplier  | 1           |
| _max_act        | 2.7997      |
| _max_adv        | 4.04        |
| _max_discrew    | 0.0918      |
| _max_obs        | 1.36        |
| _mean_act       | -0.0755578  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.112      |
| _mean_obs       | 0.0389      |
| _min_adv        | -4.07       |
| _min_discrew    | -0.39       |
| _min_obs        | -1.51       |
| _std_act        | 0.402016    |
| _std_adv        | 1           |
| _std_discrew    | 0.00783     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.288      |
| ExplainedVarOld | 0.188      |
| KL              | 0.0042466  |
| Phi_loss        | 18.031     |
| PolicyEntropy   | 5.38066    |
| PolicyLoss      | 0.00340187 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0056     |
| _MeanReward     | -116       |
| _lr_multiplier  | 1          |
| _max_act        | 2.6366     |
| _max_adv        | 4.87       |
| _max_discrew    | 0.219      |
| _max_obs        | 1.36       |
| _mean_act       | -0.0705962 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | -0.0968    |
| _mean_obs       | 0.0385     |
| _min_adv        | -3.58      |
| _min_discrew    | -0.289     |
| _min_obs        | -1.29      |
| _std_act        | 0.403603   |
| _std_adv        | 1          |
| _std_discrew    | 0.00755    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.332      |
| ExplainedVarOld | 0.307      |
| KL              | 0.00466333 |
| Phi_loss        | 20.0968    |
| PolicyEntropy   | 5.36933    |
| PolicyLoss      | 0.00208634 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00506    |
| _MeanReward     | -110       |
| _lr_multiplier  | 1          |
| _max_act        | 2.61082    |
| _max_adv        | 3.86       |
| _max_discrew    | 0.0962     |
| _max_obs        | 1.33       |
| _mean_act       | -0.0680149 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.09      |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.61      |
| _min_discrew    | -0.313     |
| _min_obs        | -1.24      |
| _std_act        | 0.398753   |
| _std_adv        | 1          |
| _std_discrew    | 0.00592    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.0528     |
| ExplainedVarOld | -0.0416    |
| KL              | 0.00287657 |
| Phi_loss        | 21.2008    |
| PolicyEntropy   | 5.33273    |
| PolicyLoss      | 0.00731408 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0056     |
| _MeanReward     | -57.3      |
| _lr_multiplier  | 1          |
| _max_act        | 2.45555    |
| _max_adv        | 4.67       |
| _max_discrew    | 0.136      |
| _max_obs        | 1.46       |
| _mean_act       | -0.0678498 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | -0.0522    |
| _mean_obs       | 0.0439     |
| _min_adv        | -4.76      |
| _min_discrew    | -0.28      |
| _min_obs        | -1.35      |
| _std_act        | 0.391807   |
| _std_adv        | 1          |
| _std_discrew    | 0.0045     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.147      |
| ExplainedVarOld | 0.0419     |
| KL              | 0.00319297 |
| Phi_loss        | 20.8326    |
| PolicyEntropy   | 5.3135     |
| PolicyLoss      | 0.00516467 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00409    |
| _MeanReward     | -87.3      |
| _lr_multiplier  | 1          |
| _max_act        | 2.60496    |
| _max_adv        | 3.54       |
| _max_discrew    | 0.181      |
| _max_obs        | 1.25       |
| _mean_act       | -0.0626554 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | -0.076     |
| _mean_obs       | 0.0399     |
| _min_adv        | -4.13      |
| _min_discrew    | -0.378     |
| _min_obs        | -1.26      |
| _std_act        | 0.395232   |
| _std_adv        | 1          |
| _std_discrew    | 0.00991    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.181      |
| ExplainedVarOld | 0.153      |
| KL              | 0.00440591 |
| Phi_loss        | 22.9024    |
| PolicyEntropy   | 5.2992     |
| PolicyLoss      | 0.00578974 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00837    |
| _MeanReward     | -59.5      |
| _lr_multiplier  | 1          |
| _max_act        | 2.86528    |
| _max_adv        | 4.35       |
| _max_discrew    | 0.149      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0675846 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | -0.0419    |
| _mean_obs       | 0.0413     |
| _min_adv        | -3.92      |
| _min_discrew    | -0.258     |
| _min_obs        | -1.22      |
| _std_act        | 0.388986   |
| _std_adv        | 1          |
| _std_discrew    | 0.00359    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.131       |
| ExplainedVarOld | 0.116       |
| KL              | 0.00361178  |
| Phi_loss        | 21.232      |
| PolicyEntropy   | 5.29303     |
| PolicyLoss      | -0.00222344 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00341     |
| _MeanReward     | -25.3       |
| _lr_multiplier  | 1           |
| _max_act        | 2.79626     |
| _max_adv        | 4.86        |
| _max_discrew    | 0.175       |
| _max_obs        | 1.54        |
| _mean_act       | -0.0715379  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.0263     |
| _mean_obs       | 0.0423      |
| _min_adv        | -4.14       |
| _min_discrew    | -0.265      |
| _min_obs        | -1.27       |
| _std_act        | 0.3888      |
| _std_adv        | 1           |
| _std_discrew    | 0.0049      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.11       |
| ExplainedVarOld | 0.0823     |
| KL              | 0.00231567 |
| Phi_loss        | 21.4935    |
| PolicyEntropy   | 5.27119    |
| PolicyLoss      | 0.00296994 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00438    |
| _MeanReward     | -46.9      |
| _lr_multiplier  | 1          |
| _max_act        | 2.89773    |
| _max_adv        | 3.94       |
| _max_discrew    | 0.211      |
| _max_obs        | 1.46       |
| _mean_act       | -0.0707161 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | -0.0367    |
| _mean_obs       | 0.0364     |
| _min_adv        | -4.1       |
| _min_discrew    | -0.311     |
| _min_obs        | -1.47      |
| _std_act        | 0.394795   |
| _std_adv        | 1          |
| _std_discrew    | 0.00529    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.0635      |
| ExplainedVarOld | -0.0102     |
| KL              | 0.0036254   |
| Phi_loss        | 21.947      |
| PolicyEntropy   | 5.27108     |
| PolicyLoss      | -0.00549449 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00498     |
| _MeanReward     | -2.95       |
| _lr_multiplier  | 1           |
| _max_act        | 2.84942     |
| _max_adv        | 4.59        |
| _max_discrew    | 0.212       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0671417  |
| _mean_adv       | -4.83e-17   |
| _mean_discrew   | -0.00701    |
| _mean_obs       | 0.0439      |
| _min_adv        | -4.21       |
| _min_discrew    | -0.241      |
| _min_obs        | -1.35       |
| _std_act        | 0.392027    |
| _std_adv        | 1           |
| _std_discrew    | 0.00472     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.0896      |
| ExplainedVarOld | 0.0666      |
| KL              | 0.00372433  |
| Phi_loss        | 23.3998     |
| PolicyEntropy   | 5.25692     |
| PolicyLoss      | -0.00163466 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0046      |
| _MeanReward     | -14.9       |
| _lr_multiplier  | 1           |
| _max_act        | 2.68087     |
| _max_adv        | 5.63        |
| _max_discrew    | 0.246       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0732147  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | -0.0114     |
| _mean_obs       | 0.0415      |
| _min_adv        | -4          |
| _min_discrew    | -0.272      |
| _min_obs        | -1.25       |
| _std_act        | 0.398715    |
| _std_adv        | 1           |
| _std_discrew    | 0.00456     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.0737      |
| ExplainedVarOld | 0.0502      |
| KL              | 0.00375284  |
| Phi_loss        | 21.8609     |
| PolicyEntropy   | 5.26363     |
| PolicyLoss      | -0.00493644 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00423     |
| _MeanReward     | 5.11        |
| _lr_multiplier  | 1           |
| _max_act        | 3.09841     |
| _max_adv        | 4.49        |
| _max_discrew    | 0.263       |
| _max_obs        | 1.6         |
| _mean_act       | -0.0683985  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | -0.000199   |
| _mean_obs       | 0.0413      |
| _min_adv        | -4.29       |
| _min_discrew    | -0.182      |
| _min_obs        | -1.37       |
| _std_act        | 0.400786    |
| _std_adv        | 1           |
| _std_discrew    | 0.00474     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.138      |
| ExplainedVarOld | 0.0877     |
| KL              | 0.00357112 |
| Phi_loss        | 22.3959    |
| PolicyEntropy   | 5.23212    |
| PolicyLoss      | 0.00411877 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0041     |
| _MeanReward     | -37.4      |
| _lr_multiplier  | 1          |
| _max_act        | 2.54908    |
| _max_adv        | 4.59       |
| _max_discrew    | 0.28       |
| _max_obs        | 1.78       |
| _mean_act       | -0.0941802 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | -0.0364    |
| _mean_obs       | 0.0353     |
| _min_adv        | -3.96      |
| _min_discrew    | -0.429     |
| _min_obs        | -1.22      |
| _std_act        | 0.40663    |
| _std_adv        | 1          |
| _std_discrew    | 0.0165     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.645        |
| ExplainedVarOld | 0.482        |
| KL              | 0.00436218   |
| Phi_loss        | 19.7065      |
| PolicyEntropy   | 5.21846      |
| PolicyLoss      | -0.000801297 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00586      |
| _MeanReward     | 22.8         |
| _lr_multiplier  | 1            |
| _max_act        | 2.95478      |
| _max_adv        | 4.98         |
| _max_discrew    | 0.379        |
| _max_obs        | 1.42         |
| _mean_act       | -0.0620792   |
| _mean_adv       | -8.53e-18    |
| _mean_discrew   | 0.00734      |
| _mean_obs       | 0.0395       |
| _min_adv        | -4.02        |
| _min_discrew    | -0.294       |
| _min_obs        | -1.27        |
| _std_act        | 0.399495     |
| _std_adv        | 1            |
| _std_discrew    | 0.007        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.21       |
| ExplainedVarOld | 0.126      |
| KL              | 0.00297769 |
| Phi_loss        | 24.2047    |
| PolicyEntropy   | 5.18472    |
| PolicyLoss      | 0.00374214 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00555    |
| _MeanReward     | 37.5       |
| _lr_multiplier  | 1          |
| _max_act        | 2.82423    |
| _max_adv        | 4.23       |
| _max_discrew    | 0.28       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0664066 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 0.0384     |
| _mean_obs       | 0.0403     |
| _min_adv        | -6.38      |
| _min_discrew    | -0.293     |
| _min_obs        | -1.33      |
| _std_act        | 0.400533   |
| _std_adv        | 1          |
| _std_discrew    | 0.00496    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.15       |
| ExplainedVarOld | 0.054      |
| KL              | 0.00423924 |
| Phi_loss        | 26.1935    |
| PolicyEntropy   | 5.14923    |
| PolicyLoss      | 0.00703564 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00441    |
| _MeanReward     | 39.4       |
| _lr_multiplier  | 1          |
| _max_act        | 2.73876    |
| _max_adv        | 3.81       |
| _max_discrew    | 0.283      |
| _max_obs        | 1.37       |
| _mean_act       | -0.0662221 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.0281     |
| _mean_obs       | 0.0352     |
| _min_adv        | -4.34      |
| _min_discrew    | -0.173     |
| _min_obs        | -1.47      |
| _std_act        | 0.403349   |
| _std_adv        | 1          |
| _std_discrew    | 0.00568    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.148      |
| ExplainedVarOld | 0.141      |
| KL              | 0.00337193 |
| Phi_loss        | 27.4943    |
| PolicyEntropy   | 5.12118    |
| PolicyLoss      | 0.00344302 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00489    |
| _MeanReward     | 69.8       |
| _lr_multiplier  | 1          |
| _max_act        | 2.54235    |
| _max_adv        | 4.29       |
| _max_discrew    | 0.279      |
| _max_obs        | 1.42       |
| _mean_act       | -0.0707328 |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 0.0552     |
| _mean_obs       | 0.0388     |
| _min_adv        | -4.81      |
| _min_discrew    | -0.202     |
| _min_obs        | -1.29      |
| _std_act        | 0.394016   |
| _std_adv        | 1          |
| _std_discrew    | 0.0051     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.108      |
| ExplainedVarOld | 0.114      |
| KL              | 0.00353073 |
| Phi_loss        | 28.5265    |
| PolicyEntropy   | 5.10779    |
| PolicyLoss      | 0.00253593 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00464    |
| _MeanReward     | 105        |
| _lr_multiplier  | 1          |
| _max_act        | 2.77718    |
| _max_adv        | 4.33       |
| _max_discrew    | 0.323      |
| _max_obs        | 1.67       |
| _mean_act       | -0.0645751 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.0906     |
| _mean_obs       | 0.0379     |
| _min_adv        | -5.39      |
| _min_discrew    | -0.103     |
| _min_obs        | -1.25      |
| _std_act        | 0.389186   |
| _std_adv        | 1          |
| _std_discrew    | 0.00506    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.182      |
| ExplainedVarOld | 0.13       |
| KL              | 0.0028362  |
| Phi_loss        | 26.8066    |
| PolicyEntropy   | 5.08273    |
| PolicyLoss      | 0.0035086  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0043     |
| _MeanReward     | 111        |
| _lr_multiplier  | 1          |
| _max_act        | 3.17563    |
| _max_adv        | 4.66       |
| _max_discrew    | 0.293      |
| _max_obs        | 1.57       |
| _mean_act       | -0.0611689 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.0871     |
| _mean_obs       | 0.0387     |
| _min_adv        | -3.51      |
| _min_discrew    | -0.161     |
| _min_obs        | -1.31      |
| _std_act        | 0.392853   |
| _std_adv        | 1          |
| _std_discrew    | 0.00799    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.189       |
| ExplainedVarOld | 0.146       |
| KL              | 0.00364577  |
| Phi_loss        | 28.7372     |
| PolicyEntropy   | 5.05987     |
| PolicyLoss      | -0.00083354 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0065      |
| _MeanReward     | 122         |
| _lr_multiplier  | 1           |
| _max_act        | 3.05579     |
| _max_adv        | 5.11        |
| _max_discrew    | 0.411       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0697304  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.0863      |
| _mean_obs       | 0.0368      |
| _min_adv        | -4.49       |
| _min_discrew    | -0.372      |
| _min_obs        | -1.48       |
| _std_act        | 0.4006      |
| _std_adv        | 1           |
| _std_discrew    | 0.014       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.534      |
| ExplainedVarOld | 0.428      |
| KL              | 0.00357316 |
| Phi_loss        | 25.0916    |
| PolicyEntropy   | 5.02673    |
| PolicyLoss      | 0.00957981 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00654    |
| _MeanReward     | 120        |
| _lr_multiplier  | 1          |
| _max_act        | 2.75156    |
| _max_adv        | 5.04       |
| _max_discrew    | 0.434      |
| _max_obs        | 1.62       |
| _mean_act       | -0.0672593 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 0.0947     |
| _mean_obs       | 0.0374     |
| _min_adv        | -3.82      |
| _min_discrew    | -0.177     |
| _min_obs        | -1.54      |
| _std_act        | 0.396418   |
| _std_adv        | 1          |
| _std_discrew    | 0.00844    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.175      |
| ExplainedVarOld | 0.144      |
| KL              | 0.00281336 |
| Phi_loss        | 30.7894    |
| PolicyEntropy   | 4.99306    |
| PolicyLoss      | 0.00612587 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00697    |
| _MeanReward     | 142        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8788     |
| _max_adv        | 4.77       |
| _max_discrew    | 0.348      |
| _max_obs        | 1.57       |
| _mean_act       | -0.0655298 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.117      |
| _mean_obs       | 0.0385     |
| _min_adv        | -4.1       |
| _min_discrew    | -0.21      |
| _min_obs        | -1.37      |
| _std_act        | 0.390086   |
| _std_adv        | 1          |
| _std_discrew    | 0.00652    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.241       |
| ExplainedVarOld | 0.21        |
| KL              | 0.00327807  |
| Phi_loss        | 29.0856     |
| PolicyEntropy   | 4.98039     |
| PolicyLoss      | -0.00473175 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00514     |
| _MeanReward     | 151         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83532     |
| _max_adv        | 4.58        |
| _max_discrew    | 0.321       |
| _max_obs        | 1.66        |
| _mean_act       | -0.0592258  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.119       |
| _mean_obs       | 0.0367      |
| _min_adv        | -4.98       |
| _min_discrew    | -0.269      |
| _min_obs        | -1.36       |
| _std_act        | 0.395118    |
| _std_adv        | 1           |
| _std_discrew    | 0.00843     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.305      |
| ExplainedVarOld | 0.277      |
| KL              | 0.00249374 |
| Phi_loss        | 31.9783    |
| PolicyEntropy   | 4.94643    |
| PolicyLoss      | 0.00637379 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00586    |
| _MeanReward     | 174        |
| _lr_multiplier  | 1          |
| _max_act        | 2.61023    |
| _max_adv        | 4.13       |
| _max_discrew    | 0.445      |
| _max_obs        | 1.57       |
| _mean_act       | -0.0594182 |
| _mean_adv       | 5.97e-17   |
| _mean_discrew   | 0.143      |
| _mean_obs       | 0.0374     |
| _min_adv        | -5.09      |
| _min_discrew    | -0.0888    |
| _min_obs        | -1.36      |
| _std_act        | 0.392553   |
| _std_adv        | 1          |
| _std_discrew    | 0.00749    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.292       |
| ExplainedVarOld | 0.284       |
| KL              | 0.00282694  |
| Phi_loss        | 32.0099     |
| PolicyEntropy   | 4.92948     |
| PolicyLoss      | -0.00457427 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00555     |
| _MeanReward     | 210         |
| _lr_multiplier  | 1           |
| _max_act        | 3.00442     |
| _max_adv        | 4.9         |
| _max_discrew    | 0.489       |
| _max_obs        | 1.47        |
| _mean_act       | -0.0540703  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.166       |
| _mean_obs       | 0.0388      |
| _min_adv        | -4.54       |
| _min_discrew    | -0.0817     |
| _min_obs        | -1.53       |
| _std_act        | 0.397226    |
| _std_adv        | 1           |
| _std_discrew    | 0.00933     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.395       |
| ExplainedVarOld | 0.369       |
| KL              | 0.00299469  |
| Phi_loss        | 29.436      |
| PolicyEntropy   | 4.92056     |
| PolicyLoss      | -0.00205469 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0057      |
| _MeanReward     | 171         |
| _lr_multiplier  | 1           |
| _max_act        | 2.77008     |
| _max_adv        | 3.25        |
| _max_discrew    | 0.434       |
| _max_obs        | 1.45        |
| _mean_act       | -0.0563774  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.142       |
| _mean_obs       | 0.0325      |
| _min_adv        | -3.62       |
| _min_discrew    | -0.0968     |
| _min_obs        | -1.33       |
| _std_act        | 0.401865    |
| _std_adv        | 1           |
| _std_discrew    | 0.00977     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.233      |
| ExplainedVarOld | 0.217      |
| KL              | 0.00284746 |
| Phi_loss        | 32.9006    |
| PolicyEntropy   | 4.90864    |
| PolicyLoss      | 0.00115522 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00762    |
| _MeanReward     | 208        |
| _lr_multiplier  | 1          |
| _max_act        | 3.19126    |
| _max_adv        | 3.61       |
| _max_discrew    | 0.5        |
| _max_obs        | 1.59       |
| _mean_act       | -0.0544665 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.165      |
| _mean_obs       | 0.0307     |
| _min_adv        | -3.67      |
| _min_discrew    | -0.263     |
| _min_obs        | -1.29      |
| _std_act        | 0.402875   |
| _std_adv        | 1          |
| _std_discrew    | 0.0137     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.267       |
| ExplainedVarOld | 0.246       |
| KL              | 0.00336234  |
| Phi_loss        | 33.5332     |
| PolicyEntropy   | 4.88779     |
| PolicyLoss      | -0.00549984 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0102      |
| _MeanReward     | 216         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90961     |
| _max_adv        | 3.85        |
| _max_discrew    | 0.478       |
| _max_obs        | 1.6         |
| _mean_act       | -0.0608086  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.176       |
| _mean_obs       | 0.0334      |
| _min_adv        | -3.48       |
| _min_discrew    | -0.134      |
| _min_obs        | -1.29       |
| _std_act        | 0.407146    |
| _std_adv        | 1           |
| _std_discrew    | 0.0122      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.321      |
| ExplainedVarOld | 0.311      |
| KL              | 0.00310115 |
| Phi_loss        | 34.1413    |
| PolicyEntropy   | 4.90691    |
| PolicyLoss      | -0.0123171 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00829    |
| _MeanReward     | 206        |
| _lr_multiplier  | 1          |
| _max_act        | 3.03148    |
| _max_adv        | 3.59       |
| _max_discrew    | 0.426      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0692203 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.154      |
| _mean_obs       | 0.0333     |
| _min_adv        | -4.2       |
| _min_discrew    | -0.0912    |
| _min_obs        | -1.35      |
| _std_act        | 0.410733   |
| _std_adv        | 1          |
| _std_discrew    | 0.00985    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.433       |
| ExplainedVarOld | 0.379       |
| KL              | 0.00260174  |
| Phi_loss        | 33.2786     |
| PolicyEntropy   | 4.89264     |
| PolicyLoss      | -0.00194584 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00564     |
| _MeanReward     | 156         |
| _lr_multiplier  | 1           |
| _max_act        | 3.10598     |
| _max_adv        | 3.3         |
| _max_discrew    | 0.457       |
| _max_obs        | 1.46        |
| _mean_act       | -0.0931699  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.123       |
| _mean_obs       | 0.0339      |
| _min_adv        | -3.71       |
| _min_discrew    | -0.495      |
| _min_obs        | -1.38       |
| _std_act        | 0.418318    |
| _std_adv        | 1           |
| _std_discrew    | 0.0339      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.805      |
| ExplainedVarOld | 0.475      |
| KL              | 0.00332513 |
| Phi_loss        | 26.0917    |
| PolicyEntropy   | 4.87812    |
| PolicyLoss      | 0.00269372 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00665    |
| _MeanReward     | 265        |
| _lr_multiplier  | 1          |
| _max_act        | 2.95621    |
| _max_adv        | 4.09       |
| _max_discrew    | 0.492      |
| _max_obs        | 1.72       |
| _mean_act       | -0.0624172 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.201      |
| _mean_obs       | 0.0364     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.0701    |
| _min_obs        | -1.39      |
| _std_act        | 0.411429   |
| _std_adv        | 1          |
| _std_discrew    | 0.0102     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.374       |
| ExplainedVarOld | 0.362       |
| KL              | 0.00263325  |
| Phi_loss        | 31.447      |
| PolicyEntropy   | 4.87132     |
| PolicyLoss      | -0.00111238 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00653     |
| _MeanReward     | 233         |
| _lr_multiplier  | 1           |
| _max_act        | 3.32944     |
| _max_adv        | 4.12        |
| _max_discrew    | 0.456       |
| _max_obs        | 1.5         |
| _mean_act       | -0.0663881  |
| _mean_adv       | -2.13e-17   |
| _mean_discrew   | 0.193       |
| _mean_obs       | 0.0362      |
| _min_adv        | -4.76       |
| _min_discrew    | -0.114      |
| _min_obs        | -1.46       |
| _std_act        | 0.410292    |
| _std_adv        | 1           |
| _std_discrew    | 0.0122      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.428       |
| ExplainedVarOld | 0.414       |
| KL              | 0.00365157  |
| Phi_loss        | 35.8281     |
| PolicyEntropy   | 4.87919     |
| PolicyLoss      | -0.00768287 |
| Steps           | 10000       |
| VarFuncLoss     | 0.007       |
| _MeanReward     | 253         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24717     |
| _max_adv        | 3.7         |
| _max_discrew    | 0.571       |
| _max_obs        | 1.58        |
| _mean_act       | -0.06667    |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.202       |
| _mean_obs       | 0.0359      |
| _min_adv        | -3.59       |
| _min_discrew    | -0.0695     |
| _min_obs        | -1.41       |
| _std_act        | 0.416217    |
| _std_adv        | 1           |
| _std_discrew    | 0.0114      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.363       |
| ExplainedVarOld | 0.339       |
| KL              | 0.00229639  |
| Phi_loss        | 34.8172     |
| PolicyEntropy   | 4.89165     |
| PolicyLoss      | -0.00947022 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00729     |
| _MeanReward     | 250         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03409     |
| _max_adv        | 3.86        |
| _max_discrew    | 0.542       |
| _max_obs        | 1.91        |
| _mean_act       | -0.063363   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.201       |
| _mean_obs       | 0.0337      |
| _min_adv        | -3.5        |
| _min_discrew    | -0.0636     |
| _min_obs        | -1.32       |
| _std_act        | 0.42142     |
| _std_adv        | 1           |
| _std_discrew    | 0.0101      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.326      |
| ExplainedVarOld | 0.307      |
| KL              | 0.00310268 |
| Phi_loss        | 33.5484    |
| PolicyEntropy   | 4.87956    |
| PolicyLoss      | 0.00027544 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00677    |
| _MeanReward     | 276        |
| _lr_multiplier  | 1          |
| _max_act        | 3.93695    |
| _max_adv        | 3.11       |
| _max_discrew    | 0.519      |
| _max_obs        | 1.57       |
| _mean_act       | -0.0629069 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.223      |
| _mean_obs       | 0.0357     |
| _min_adv        | -5.41      |
| _min_discrew    | -0.14      |
| _min_obs        | -1.52      |
| _std_act        | 0.425304   |
| _std_adv        | 1          |
| _std_discrew    | 0.0138     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.412      |
| ExplainedVarOld | 0.378      |
| KL              | 0.00236398 |
| Phi_loss        | 33.312     |
| PolicyEntropy   | 4.86899    |
| PolicyLoss      | 0.00284011 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0082     |
| _MeanReward     | 268        |
| _lr_multiplier  | 1          |
| _max_act        | 2.94646    |
| _max_adv        | 3.12       |
| _max_discrew    | 0.483      |
| _max_obs        | 1.69       |
| _mean_act       | -0.0558372 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.213      |
| _mean_obs       | 0.0322     |
| _min_adv        | -5.18      |
| _min_discrew    | -0.188     |
| _min_obs        | -1.51      |
| _std_act        | 0.422619   |
| _std_adv        | 1          |
| _std_discrew    | 0.0109     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.424        |
| ExplainedVarOld | 0.412        |
| KL              | 0.00284562   |
| Phi_loss        | 36.1585      |
| PolicyEntropy   | 4.8454       |
| PolicyLoss      | -4.51104e-05 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00627      |
| _MeanReward     | 280          |
| _lr_multiplier  | 1            |
| _max_act        | 3.11524      |
| _max_adv        | 3.84         |
| _max_discrew    | 0.667        |
| _max_obs        | 1.58         |
| _mean_act       | -0.0562175   |
| _mean_adv       | -5.12e-17    |
| _mean_discrew   | 0.226        |
| _mean_obs       | 0.0321       |
| _min_adv        | -3.73        |
| _min_discrew    | -0.0447      |
| _min_obs        | -1.5         |
| _std_act        | 0.422752     |
| _std_adv        | 1            |
| _std_discrew    | 0.0136       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.301       |
| ExplainedVarOld | 0.23        |
| KL              | 0.00311652  |
| Phi_loss        | 32.1145     |
| PolicyEntropy   | 4.83812     |
| PolicyLoss      | -0.00683818 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00951     |
| _MeanReward     | 207         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03844     |
| _max_adv        | 2.6         |
| _max_discrew    | 0.586       |
| _max_obs        | 1.62        |
| _mean_act       | -0.0981703  |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 0.151       |
| _mean_obs       | 0.0294      |
| _min_adv        | -3.12       |
| _min_discrew    | -0.507      |
| _min_obs        | -1.43       |
| _std_act        | 0.439469    |
| _std_adv        | 1           |
| _std_discrew    | 0.0642      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.741       |
| ExplainedVarOld | 0.364       |
| KL              | 0.00279444  |
| Phi_loss        | 22.2069     |
| PolicyEntropy   | 4.83951     |
| PolicyLoss      | -0.00585291 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 309         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13652     |
| _max_adv        | 3.37        |
| _max_discrew    | 0.571       |
| _max_obs        | 1.52        |
| _mean_act       | -0.0598236  |
| _mean_adv       | -6.39e-18   |
| _mean_discrew   | 0.249       |
| _mean_obs       | 0.0334      |
| _min_adv        | -4.5        |
| _min_discrew    | -0.0631     |
| _min_obs        | -1.4        |
| _std_act        | 0.433676    |
| _std_adv        | 1           |
| _std_discrew    | 0.0171      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.327      |
| ExplainedVarOld | 0.3        |
| KL              | 0.00296645 |
| Phi_loss        | 36.848     |
| PolicyEntropy   | 4.80289    |
| PolicyLoss      | 0.00638603 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0116     |
| _MeanReward     | 313        |
| _lr_multiplier  | 1          |
| _max_act        | 3.3879     |
| _max_adv        | 3.54       |
| _max_discrew    | 0.549      |
| _max_obs        | 1.59       |
| _mean_act       | -0.0645746 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 0.245      |
| _mean_obs       | 0.0345     |
| _min_adv        | -3.76      |
| _min_discrew    | -0.0321    |
| _min_obs        | -1.42      |
| _std_act        | 0.423281   |
| _std_adv        | 1          |
| _std_discrew    | 0.0172     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.463       |
| ExplainedVarOld | 0.435       |
| KL              | 0.00226772  |
| Phi_loss        | 35.4485     |
| PolicyEntropy   | 4.79654     |
| PolicyLoss      | -0.00710371 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00926     |
| _MeanReward     | 338         |
| _lr_multiplier  | 1           |
| _max_act        | 3.56593     |
| _max_adv        | 3.67        |
| _max_discrew    | 0.618       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0650295  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.268       |
| _mean_obs       | 0.0331      |
| _min_adv        | -3.95       |
| _min_discrew    | -0.116      |
| _min_obs        | -1.38       |
| _std_act        | 0.438964    |
| _std_adv        | 1           |
| _std_discrew    | 0.0189      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.447       |
| ExplainedVarOld | 0.377       |
| KL              | 0.00360195  |
| Phi_loss        | 38.3269     |
| PolicyEntropy   | 4.76987     |
| PolicyLoss      | 0.000968643 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0105      |
| _MeanReward     | 354         |
| _lr_multiplier  | 1           |
| _max_act        | 3.33721     |
| _max_adv        | 3.7         |
| _max_discrew    | 0.718       |
| _max_obs        | 1.75        |
| _mean_act       | -0.0798205  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.275       |
| _mean_obs       | 0.0321      |
| _min_adv        | -4.94       |
| _min_discrew    | -0.528      |
| _min_obs        | -1.36       |
| _std_act        | 0.438091    |
| _std_adv        | 1           |
| _std_discrew    | 0.0544      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.745      |
| ExplainedVarOld | 0.595      |
| KL              | 0.00396467 |
| Phi_loss        | 33.3576    |
| PolicyEntropy   | 4.77018    |
| PolicyLoss      | -0.0101558 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 367        |
| _lr_multiplier  | 1          |
| _max_act        | 3.21526    |
| _max_adv        | 3.71       |
| _max_discrew    | 0.642      |
| _max_obs        | 1.54       |
| _mean_act       | -0.0671147 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.306      |
| _mean_obs       | 0.0343     |
| _min_adv        | -3.81      |
| _min_discrew    | -0.0754    |
| _min_obs        | -1.48      |
| _std_act        | 0.432229   |
| _std_adv        | 1          |
| _std_discrew    | 0.0179     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.611       |
| ExplainedVarOld | 0.575       |
| KL              | 0.00281778  |
| Phi_loss        | 38.5164     |
| PolicyEntropy   | 4.76852     |
| PolicyLoss      | -0.00679295 |
| Steps           | 10000       |
| VarFuncLoss     | 0.007       |
| _MeanReward     | 352         |
| _lr_multiplier  | 1           |
| _max_act        | 3.29657     |
| _max_adv        | 2.92        |
| _max_discrew    | 0.666       |
| _max_obs        | 1.68        |
| _mean_act       | -0.0642853  |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.278       |
| _mean_obs       | 0.0311      |
| _min_adv        | -4.17       |
| _min_discrew    | -0.115      |
| _min_obs        | -1.39       |
| _std_act        | 0.444545    |
| _std_adv        | 1           |
| _std_discrew    | 0.0235      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.357      |
| ExplainedVarOld | 0.302      |
| KL              | 0.00334605 |
| Phi_loss        | 35.9499    |
| PolicyEntropy   | 4.75198    |
| PolicyLoss      | 0.00088391 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0154     |
| _MeanReward     | 382        |
| _lr_multiplier  | 1          |
| _max_act        | 3.13845    |
| _max_adv        | 3.43       |
| _max_discrew    | 0.648      |
| _max_obs        | 1.49       |
| _mean_act       | -0.070801  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.314      |
| _mean_obs       | 0.034      |
| _min_adv        | -5.15      |
| _min_discrew    | -0.0654    |
| _min_obs        | -1.35      |
| _std_act        | 0.431358   |
| _std_adv        | 1          |
| _std_discrew    | 0.0189     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.451       |
| ExplainedVarOld | 0.436       |
| KL              | 0.00315881  |
| Phi_loss        | 39.0299     |
| PolicyEntropy   | 4.74152     |
| PolicyLoss      | -0.00462776 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0105      |
| _MeanReward     | 403         |
| _lr_multiplier  | 1           |
| _max_act        | 3.26363     |
| _max_adv        | 4.06        |
| _max_discrew    | 0.803       |
| _max_obs        | 1.66        |
| _mean_act       | -0.0631416  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 0.311       |
| _mean_obs       | 0.033       |
| _min_adv        | -4.29       |
| _min_discrew    | -0.243      |
| _min_obs        | -1.32       |
| _std_act        | 0.441926    |
| _std_adv        | 1           |
| _std_discrew    | 0.0325      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.652      |
| ExplainedVarOld | 0.547      |
| KL              | 0.00270183 |
| Phi_loss        | 38.0271    |
| PolicyEntropy   | 4.75018    |
| PolicyLoss      | -0.0125098 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 385        |
| _lr_multiplier  | 1          |
| _max_act        | 3.21056    |
| _max_adv        | 3.74       |
| _max_discrew    | 0.788      |
| _max_obs        | 1.54       |
| _mean_act       | -0.0647905 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.313      |
| _mean_obs       | 0.0308     |
| _min_adv        | -3.79      |
| _min_discrew    | -0.0776    |
| _min_obs        | -1.31      |
| _std_act        | 0.442999   |
| _std_adv        | 1          |
| _std_discrew    | 0.0254     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.524        |
| ExplainedVarOld | 0.527        |
| KL              | 0.00272099   |
| Phi_loss        | 42.1454      |
| PolicyEntropy   | 4.7221       |
| PolicyLoss      | -0.000215708 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0121       |
| _MeanReward     | 436          |
| _lr_multiplier  | 1            |
| _max_act        | 3.20908      |
| _max_adv        | 3.48         |
| _max_discrew    | 0.689        |
| _max_obs        | 1.54         |
| _mean_act       | -0.0630052   |
| _mean_adv       | -2.27e-17    |
| _mean_discrew   | 0.346        |
| _mean_obs       | 0.035        |
| _min_adv        | -4.07        |
| _min_discrew    | -0.0988      |
| _min_obs        | -1.36        |
| _std_act        | 0.448568     |
| _std_adv        | 1            |
| _std_discrew    | 0.0258       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.644      |
| ExplainedVarOld | 0.635      |
| KL              | 0.00260125 |
| Phi_loss        | 42.6106    |
| PolicyEntropy   | 4.69869    |
| PolicyLoss      | 0.00126873 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00942    |
| _MeanReward     | 397        |
| _lr_multiplier  | 1          |
| _max_act        | 3.47118    |
| _max_adv        | 3.47       |
| _max_discrew    | 0.759      |
| _max_obs        | 1.61       |
| _mean_act       | -0.0705935 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.319      |
| _mean_obs       | 0.0292     |
| _min_adv        | -4.53      |
| _min_discrew    | -0.0711    |
| _min_obs        | -1.64      |
| _std_act        | 0.440478   |
| _std_adv        | 1          |
| _std_discrew    | 0.0284     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.361      |
| ExplainedVarOld | 0.313      |
| KL              | 0.00354823 |
| Phi_loss        | 42.0423    |
| PolicyEntropy   | 4.69194    |
| PolicyLoss      | -0.01279   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 389        |
| _lr_multiplier  | 1          |
| _max_act        | 3.34415    |
| _max_adv        | 4.5        |
| _max_discrew    | 0.785      |
| _max_obs        | 1.58       |
| _mean_act       | -0.0700196 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.305      |
| _mean_obs       | 0.0295     |
| _min_adv        | -4.06      |
| _min_discrew    | -0.0539    |
| _min_obs        | -1.61      |
| _std_act        | 0.45096    |
| _std_adv        | 1          |
| _std_discrew    | 0.0239     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.482       |
| ExplainedVarOld | 0.456       |
| KL              | 0.00274839  |
| Phi_loss        | 41.5475     |
| PolicyEntropy   | 4.6971      |
| PolicyLoss      | -0.00440822 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0125      |
| _MeanReward     | 422         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02999     |
| _max_adv        | 3.28        |
| _max_discrew    | 0.802       |
| _max_obs        | 1.81        |
| _mean_act       | -0.0757671  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.348       |
| _mean_obs       | 0.0345      |
| _min_adv        | -3.84       |
| _min_discrew    | -0.126      |
| _min_obs        | -1.33       |
| _std_act        | 0.448076    |
| _std_adv        | 1           |
| _std_discrew    | 0.0324      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.535       |
| ExplainedVarOld | 0.472       |
| KL              | 0.00255183  |
| Phi_loss        | 38.1143     |
| PolicyEntropy   | 4.69735     |
| PolicyLoss      | -0.00999652 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0159      |
| _MeanReward     | 445         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90883     |
| _max_adv        | 3.62        |
| _max_discrew    | 0.782       |
| _max_obs        | 1.59        |
| _mean_act       | -0.0759538  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.363       |
| _mean_obs       | 0.0324      |
| _min_adv        | -3.47       |
| _min_discrew    | -0.121      |
| _min_obs        | -1.49       |
| _std_act        | 0.453496    |
| _std_adv        | 1           |
| _std_discrew    | 0.0281      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.613       |
| ExplainedVarOld | 0.597       |
| KL              | 0.0029579   |
| Phi_loss        | 40.9919     |
| PolicyEntropy   | 4.68233     |
| PolicyLoss      | -0.00552678 |
| Steps           | 10000       |
| VarFuncLoss     | 0.011       |
| _MeanReward     | 464         |
| _lr_multiplier  | 1           |
| _max_act        | 3.28072     |
| _max_adv        | 3.52        |
| _max_discrew    | 0.767       |
| _max_obs        | 1.56        |
| _mean_act       | -0.0762775  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.382       |
| _mean_obs       | 0.0328      |
| _min_adv        | -3.76       |
| _min_discrew    | -0.0844     |
| _min_obs        | -1.56       |
| _std_act        | 0.461558    |
| _std_adv        | 1           |
| _std_discrew    | 0.027       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.617      |
| ExplainedVarOld | 0.6        |
| KL              | 0.00336112 |
| Phi_loss        | 43.4988    |
| PolicyEntropy   | 4.65924    |
| PolicyLoss      | 0.00329073 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0105     |
| _MeanReward     | 495        |
| _lr_multiplier  | 1          |
| _max_act        | 3.61069    |
| _max_adv        | 3.47       |
| _max_discrew    | 0.74       |
| _max_obs        | 1.53       |
| _mean_act       | -0.0739134 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.402      |
| _mean_obs       | 0.0343     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.0123    |
| _min_obs        | -1.53      |
| _std_act        | 0.454957   |
| _std_adv        | 1          |
| _std_discrew    | 0.0217     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.634       |
| ExplainedVarOld | 0.596       |
| KL              | 0.00325426  |
| Phi_loss        | 40.7271     |
| PolicyEntropy   | 4.66503     |
| PolicyLoss      | -0.00811709 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00806     |
| _MeanReward     | 515         |
| _lr_multiplier  | 1           |
| _max_act        | 3.08086     |
| _max_adv        | 3.55        |
| _max_discrew    | 0.853       |
| _max_obs        | 1.63        |
| _mean_act       | -0.0693779  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.411       |
| _mean_obs       | 0.0313      |
| _min_adv        | -4.83       |
| _min_discrew    | -0.0523     |
| _min_obs        | -1.52       |
| _std_act        | 0.456935    |
| _std_adv        | 1           |
| _std_discrew    | 0.0331      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.622       |
| ExplainedVarOld | 0.598       |
| KL              | 0.00321963  |
| Phi_loss        | 41.1192     |
| PolicyEntropy   | 4.65999     |
| PolicyLoss      | -0.00689831 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0125      |
| _MeanReward     | 494         |
| _lr_multiplier  | 1           |
| _max_act        | 3.28692     |
| _max_adv        | 3.66        |
| _max_discrew    | 1           |
| _max_obs        | 1.58        |
| _mean_act       | -0.073804   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.394       |
| _mean_obs       | 0.0314      |
| _min_adv        | -6.21       |
| _min_discrew    | -0.411      |
| _min_obs        | -1.36       |
| _std_act        | 0.47398     |
| _std_adv        | 1           |
| _std_discrew    | 0.043       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.592       |
| ExplainedVarOld | 0.543       |
| KL              | 0.00266468  |
| Phi_loss        | 38.1399     |
| PolicyEntropy   | 4.6409      |
| PolicyLoss      | -0.00387074 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0176      |
| _MeanReward     | 510         |
| _lr_multiplier  | 1           |
| _max_act        | 3.32366     |
| _max_adv        | 3.23        |
| _max_discrew    | 0.916       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0749067  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.415       |
| _mean_obs       | 0.0314      |
| _min_adv        | -3.84       |
| _min_discrew    | -0.0346     |
| _min_obs        | -1.53       |
| _std_act        | 0.462547    |
| _std_adv        | 1           |
| _std_discrew    | 0.0369      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.565      |
| ExplainedVarOld | 0.557      |
| KL              | 0.00377208 |
| Phi_loss        | 40.3797    |
| PolicyEntropy   | 4.65065    |
| PolicyLoss      | -0.013691  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0161     |
| _MeanReward     | 475        |
| _lr_multiplier  | 1          |
| _max_act        | 3.48231    |
| _max_adv        | 3.21       |
| _max_discrew    | 0.788      |
| _max_obs        | 1.45       |
| _mean_act       | -0.0818367 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.376      |
| _mean_obs       | 0.0295     |
| _min_adv        | -6.25      |
| _min_discrew    | -0.407     |
| _min_obs        | -1.35      |
| _std_act        | 0.475888   |
| _std_adv        | 1          |
| _std_discrew    | 0.0397     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.651      |
| ExplainedVarOld | 0.641      |
| KL              | 0.00325971 |
| Phi_loss        | 41.7767    |
| PolicyEntropy   | 4.63115    |
| PolicyLoss      | 0.00803617 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0139     |
| _MeanReward     | 467        |
| _lr_multiplier  | 1          |
| _max_act        | 3.27019    |
| _max_adv        | 2.54       |
| _max_discrew    | 0.875      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0897362 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.373      |
| _mean_obs       | 0.0279     |
| _min_adv        | -7.89      |
| _min_discrew    | -0.681     |
| _min_obs        | -1.36      |
| _std_act        | 0.481334   |
| _std_adv        | 1          |
| _std_discrew    | 0.0902     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.737       |
| ExplainedVarOld | 0.683       |
| KL              | 0.00258076  |
| Phi_loss        | 34.8063     |
| PolicyEntropy   | 4.61804     |
| PolicyLoss      | -0.00484143 |
| Steps           | 10000       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 541         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18507     |
| _max_adv        | 3.87        |
| _max_discrew    | 0.853       |
| _max_obs        | 1.6         |
| _mean_act       | -0.072566   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.435       |
| _mean_obs       | 0.0316      |
| _min_adv        | -3.89       |
| _min_discrew    | -0.0298     |
| _min_obs        | -1.4        |
| _std_act        | 0.470066    |
| _std_adv        | 1           |
| _std_discrew    | 0.0343      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.637      |
| ExplainedVarOld | 0.627      |
| KL              | 0.00344169 |
| Phi_loss        | 43.1393    |
| PolicyEntropy   | 4.59854    |
| PolicyLoss      | -0.0022746 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 556        |
| _lr_multiplier  | 1          |
| _max_act        | 3.36841    |
| _max_adv        | 3.93       |
| _max_discrew    | 0.902      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0720566 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.457      |
| _mean_obs       | 0.031      |
| _min_adv        | -4.41      |
| _min_discrew    | -0.0279    |
| _min_obs        | -1.33      |
| _std_act        | 0.468636   |
| _std_adv        | 1          |
| _std_discrew    | 0.0407     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.649       |
| ExplainedVarOld | 0.607       |
| KL              | 0.00290352  |
| Phi_loss        | 43.3305     |
| PolicyEntropy   | 4.59151     |
| PolicyLoss      | -0.00415239 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 512         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13826     |
| _max_adv        | 3.55        |
| _max_discrew    | 0.786       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0716889  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.414       |
| _mean_obs       | 0.0309      |
| _min_adv        | -3.95       |
| _min_discrew    | -0.128      |
| _min_obs        | -1.51       |
| _std_act        | 0.471382    |
| _std_adv        | 1           |
| _std_discrew    | 0.0282      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.708       |
| ExplainedVarOld | 0.693       |
| KL              | 0.00239456  |
| Phi_loss        | 43.1189     |
| PolicyEntropy   | 4.5867      |
| PolicyLoss      | -0.00187346 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00873     |
| _MeanReward     | 558         |
| _lr_multiplier  | 1           |
| _max_act        | 3.2601      |
| _max_adv        | 3.31        |
| _max_discrew    | 0.825       |
| _max_obs        | 1.45        |
| _mean_act       | -0.0684706  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.456       |
| _mean_obs       | 0.0313      |
| _min_adv        | -4.17       |
| _min_discrew    | -0.0607     |
| _min_obs        | -1.49       |
| _std_act        | 0.478855    |
| _std_adv        | 1           |
| _std_discrew    | 0.0318      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.647       |
| ExplainedVarOld | 0.63        |
| KL              | 0.00280073  |
| Phi_loss        | 46.1871     |
| PolicyEntropy   | 4.55441     |
| PolicyLoss      | -0.00122375 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0118      |
| _MeanReward     | 479         |
| _lr_multiplier  | 1           |
| _max_act        | 3.75847     |
| _max_adv        | 2.98        |
| _max_discrew    | 0.929       |
| _max_obs        | 1.72        |
| _mean_act       | -0.0997648  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.389       |
| _mean_obs       | 0.0285      |
| _min_adv        | -9.47       |
| _min_discrew    | -0.64       |
| _min_obs        | -1.35       |
| _std_act        | 0.49356     |
| _std_adv        | 1           |
| _std_discrew    | 0.115       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.832       |
| ExplainedVarOld | 0.78        |
| KL              | 0.00379906  |
| Phi_loss        | 34.9508     |
| PolicyEntropy   | 4.54461     |
| PolicyLoss      | -0.00719324 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0196      |
| _MeanReward     | 597         |
| _lr_multiplier  | 1           |
| _max_act        | 3.62571     |
| _max_adv        | 4.41        |
| _max_discrew    | 0.993       |
| _max_obs        | 1.57        |
| _mean_act       | -0.0644572  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.485       |
| _mean_obs       | 0.0305      |
| _min_adv        | -4.06       |
| _min_discrew    | -0.0726     |
| _min_obs        | -1.47       |
| _std_act        | 0.484023    |
| _std_adv        | 1           |
| _std_discrew    | 0.0387      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.604       |
| ExplainedVarOld | 0.602       |
| KL              | 0.00334687  |
| Phi_loss        | 50.1327     |
| PolicyEntropy   | 4.50952     |
| PolicyLoss      | -0.00459856 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0154      |
| _MeanReward     | 613         |
| _lr_multiplier  | 1           |
| _max_act        | 3.11374     |
| _max_adv        | 3.95        |
| _max_discrew    | 0.905       |
| _max_obs        | 1.62        |
| _mean_act       | -0.0633881  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 0.504       |
| _mean_obs       | 0.0314      |
| _min_adv        | -3.75       |
| _min_discrew    | -0.0425     |
| _min_obs        | -1.27       |
| _std_act        | 0.478562    |
| _std_adv        | 1           |
| _std_discrew    | 0.036       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.588      |
| ExplainedVarOld | 0.561      |
| KL              | 0.00299779 |
| Phi_loss        | 46.2944    |
| PolicyEntropy   | 4.48681    |
| PolicyLoss      | -0.0031805 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0148     |
| _MeanReward     | 703        |
| _lr_multiplier  | 1          |
| _max_act        | 3.07202    |
| _max_adv        | 3.08       |
| _max_discrew    | 1.11       |
| _max_obs        | 1.49       |
| _mean_act       | -0.0635691 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 0.564      |
| _mean_obs       | 0.033      |
| _min_adv        | -3.8       |
| _min_discrew    | -0.0011    |
| _min_obs        | -1.43      |
| _std_act        | 0.481468   |
| _std_adv        | 1          |
| _std_discrew    | 0.0509     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.673      |
| ExplainedVarOld | 0.626      |
| KL              | 0.00269406 |
| Phi_loss        | 46.0321    |
| PolicyEntropy   | 4.4446     |
| PolicyLoss      | 0.00880972 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0175     |
| _MeanReward     | 685        |
| _lr_multiplier  | 1          |
| _max_act        | 3.66554    |
| _max_adv        | 3.66       |
| _max_discrew    | 1.05       |
| _max_obs        | 1.63       |
| _mean_act       | -0.0639373 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 0.549      |
| _mean_obs       | 0.0323     |
| _min_adv        | -4.38      |
| _min_discrew    | -0.0134    |
| _min_obs        | -1.39      |
| _std_act        | 0.477953   |
| _std_adv        | 1          |
| _std_discrew    | 0.0466     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.685      |
| ExplainedVarOld | 0.63       |
| KL              | 0.00350597 |
| Phi_loss        | 44.3416    |
| PolicyEntropy   | 4.43644    |
| PolicyLoss      | 0.00177889 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 680        |
| _lr_multiplier  | 1          |
| _max_act        | 3.40646    |
| _max_adv        | 3.39       |
| _max_discrew    | 1          |
| _max_obs        | 1.53       |
| _mean_act       | -0.0669829 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.539      |
| _mean_obs       | 0.0319     |
| _min_adv        | -3.1       |
| _min_discrew    | -0.0229    |
| _min_obs        | -1.36      |
| _std_act        | 0.481904   |
| _std_adv        | 1          |
| _std_discrew    | 0.0482     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.713       |
| ExplainedVarOld | 0.693       |
| KL              | 0.00303898  |
| Phi_loss        | 49.2565     |
| PolicyEntropy   | 4.41188     |
| PolicyLoss      | 0.000214424 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0139      |
| _MeanReward     | 713         |
| _lr_multiplier  | 1           |
| _max_act        | 3.25996     |
| _max_adv        | 3.82        |
| _max_discrew    | 1.02        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0670053  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.58        |
| _mean_obs       | 0.0328      |
| _min_adv        | -3.94       |
| _min_discrew    | -0.00463    |
| _min_obs        | -1.57       |
| _std_act        | 0.47518     |
| _std_adv        | 1           |
| _std_discrew    | 0.0466      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.727       |
| ExplainedVarOld | 0.692       |
| KL              | 0.00300664  |
| Phi_loss        | 47.1555     |
| PolicyEntropy   | 4.38998     |
| PolicyLoss      | -0.00265954 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0129      |
| _MeanReward     | 617         |
| _lr_multiplier  | 1           |
| _max_act        | 3.21271     |
| _max_adv        | 2.98        |
| _max_discrew    | 1.08        |
| _max_obs        | 1.6         |
| _mean_act       | -0.0874417  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.475       |
| _mean_obs       | 0.03        |
| _min_adv        | -7.24       |
| _min_discrew    | -0.679      |
| _min_obs        | -1.32       |
| _std_act        | 0.499946    |
| _std_adv        | 1           |
| _std_discrew    | 0.136       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.788      |
| ExplainedVarOld | 0.694      |
| KL              | 0.00465563 |
| Phi_loss        | 40.6082    |
| PolicyEntropy   | 4.36983    |
| PolicyLoss      | -0.0127723 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0291     |
| _MeanReward     | 647        |
| _lr_multiplier  | 1          |
| _max_act        | 3.39403    |
| _max_adv        | 4.24       |
| _max_discrew    | 0.994      |
| _max_obs        | 1.71       |
| _mean_act       | -0.0709889 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.529      |
| _mean_obs       | 0.0306     |
| _min_adv        | -3.34      |
| _min_discrew    | -0.011     |
| _min_obs        | -1.42      |
| _std_act        | 0.483401   |
| _std_adv        | 1          |
| _std_discrew    | 0.0411     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.616       |
| ExplainedVarOld | 0.59        |
| KL              | 0.00311064  |
| Phi_loss        | 50.2223     |
| PolicyEntropy   | 4.36185     |
| PolicyLoss      | -0.00176585 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0159      |
| _MeanReward     | 724         |
| _lr_multiplier  | 1           |
| _max_act        | 3.43877     |
| _max_adv        | 4.71        |
| _max_discrew    | 1.1         |
| _max_obs        | 1.6         |
| _mean_act       | -0.0619791  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.586       |
| _mean_obs       | 0.031       |
| _min_adv        | -4.17       |
| _min_discrew    | -0.0218     |
| _min_obs        | -1.41       |
| _std_act        | 0.482348    |
| _std_adv        | 1           |
| _std_discrew    | 0.0529      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.674       |
| ExplainedVarOld | 0.643       |
| KL              | 0.00263334  |
| Phi_loss        | 49.0721     |
| PolicyEntropy   | 4.35583     |
| PolicyLoss      | -0.00898592 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0181      |
| _MeanReward     | 706         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18004     |
| _max_adv        | 3.25        |
| _max_discrew    | 0.982       |
| _max_obs        | 1.62        |
| _mean_act       | -0.0685907  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.588       |
| _mean_obs       | 0.0292      |
| _min_adv        | -3.4        |
| _min_discrew    | -0.0206     |
| _min_obs        | -1.35       |
| _std_act        | 0.485152    |
| _std_adv        | 1           |
| _std_discrew    | 0.0499      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.65        |
| ExplainedVarOld | 0.631       |
| KL              | 0.00359491  |
| Phi_loss        | 49.6328     |
| PolicyEntropy   | 4.3527      |
| PolicyLoss      | -0.00913572 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0175      |
| _MeanReward     | 766         |
| _lr_multiplier  | 1           |
| _max_act        | 3.32535     |
| _max_adv        | 3.44        |
| _max_discrew    | 1.24        |
| _max_obs        | 1.62        |
| _mean_act       | -0.0634616  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 0.622       |
| _mean_obs       | 0.034       |
| _min_adv        | -3.84       |
| _min_discrew    | -0.0463     |
| _min_obs        | -1.5        |
| _std_act        | 0.494401    |
| _std_adv        | 1           |
| _std_discrew    | 0.0513      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.748      |
| ExplainedVarOld | 0.74       |
| KL              | 0.00304786 |
| Phi_loss        | 52.4815    |
| PolicyEntropy   | 4.32121    |
| PolicyLoss      | 0.00688587 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0133     |
| _MeanReward     | 774        |
| _lr_multiplier  | 1          |
| _max_act        | 3.27986    |
| _max_adv        | 3.53       |
| _max_discrew    | 1.21       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0585014 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 0.622      |
| _mean_obs       | 0.032      |
| _min_adv        | -3.7       |
| _min_discrew    | -0.00989   |
| _min_obs        | -1.73      |
| _std_act        | 0.484461   |
| _std_adv        | 1          |
| _std_discrew    | 0.0667     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.768      |
| ExplainedVarOld | 0.736      |
| KL              | 0.00344705 |
| Phi_loss        | 52.8737    |
| PolicyEntropy   | 4.30338    |
| PolicyLoss      | -0.0119243 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0155     |
| _MeanReward     | 661        |
| _lr_multiplier  | 1          |
| _max_act        | 3.18558    |
| _max_adv        | 2.9        |
| _max_discrew    | 1.1        |
| _max_obs        | 1.71       |
| _mean_act       | -0.0829928 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.531      |
| _mean_obs       | 0.0276     |
| _min_adv        | -8.54      |
| _min_discrew    | -0.623     |
| _min_obs        | -1.62      |
| _std_act        | 0.501275   |
| _std_adv        | 1          |
| _std_discrew    | 0.105      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.708       |
| ExplainedVarOld | 0.684       |
| KL              | 0.0026932   |
| Phi_loss        | 49.6654     |
| PolicyEntropy   | 4.29095     |
| PolicyLoss      | -0.00232328 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0313      |
| _MeanReward     | 711         |
| _lr_multiplier  | 1           |
| _max_act        | 3.38842     |
| _max_adv        | 3.79        |
| _max_discrew    | 1.1         |
| _max_obs        | 1.51        |
| _mean_act       | -0.0702162  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.568       |
| _mean_obs       | 0.031       |
| _min_adv        | -3.32       |
| _min_discrew    | -0.0506     |
| _min_obs        | -1.37       |
| _std_act        | 0.49549     |
| _std_adv        | 1           |
| _std_discrew    | 0.0525      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.693       |
| ExplainedVarOld | 0.673       |
| KL              | 0.00335523  |
| Phi_loss        | 52.7819     |
| PolicyEntropy   | 4.24957     |
| PolicyLoss      | 0.000245254 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0163      |
| _MeanReward     | 812         |
| _lr_multiplier  | 1           |
| _max_act        | 3.22431     |
| _max_adv        | 6.18        |
| _max_discrew    | 1.18        |
| _max_obs        | 1.45        |
| _mean_act       | -0.0633665  |
| _mean_adv       | 1.49e-17    |
| _mean_discrew   | 0.663       |
| _mean_obs       | 0.0324      |
| _min_adv        | -3.99       |
| _min_discrew    | -0.0292     |
| _min_obs        | -1.55       |
| _std_act        | 0.493327    |
| _std_adv        | 1           |
| _std_discrew    | 0.0658      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.753       |
| ExplainedVarOld | 0.742       |
| KL              | 0.0039079   |
| Phi_loss        | 55.6383     |
| PolicyEntropy   | 4.24231     |
| PolicyLoss      | -0.00503547 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0178      |
| _MeanReward     | 768         |
| _lr_multiplier  | 1           |
| _max_act        | 3.35682     |
| _max_adv        | 3.61        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.76        |
| _mean_act       | -0.0647086  |
| _mean_adv       | -2.7e-17    |
| _mean_discrew   | 0.596       |
| _mean_obs       | 0.0339      |
| _min_adv        | -4.05       |
| _min_discrew    | -0.0176     |
| _min_obs        | -1.37       |
| _std_act        | 0.500134    |
| _std_adv        | 1           |
| _std_discrew    | 0.0749      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.787       |
| ExplainedVarOld | 0.763       |
| KL              | 0.00263943  |
| Phi_loss        | 55.0454     |
| PolicyEntropy   | 4.2268      |
| PolicyLoss      | 0.000476657 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0171      |
| _MeanReward     | 745         |
| _lr_multiplier  | 1           |
| _max_act        | 4.03803     |
| _max_adv        | 3.61        |
| _max_discrew    | 1.3         |
| _max_obs        | 1.51        |
| _mean_act       | -0.0913342  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.585       |
| _mean_obs       | 0.0299      |
| _min_adv        | -8.12       |
| _min_discrew    | -0.703      |
| _min_obs        | -1.64       |
| _std_act        | 0.513956    |
| _std_adv        | 1           |
| _std_discrew    | 0.162       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.782      |
| ExplainedVarOld | 0.737      |
| KL              | 0.00673633 |
| Phi_loss        | 49.2437    |
| PolicyEntropy   | 4.22793    |
| PolicyLoss      | -0.0268922 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0355     |
| _MeanReward     | 816        |
| _lr_multiplier  | 1          |
| _max_act        | 3.01338    |
| _max_adv        | 3.9        |
| _max_discrew    | 1.21       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0619242 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.647      |
| _mean_obs       | 0.0347     |
| _min_adv        | -3.42      |
| _min_discrew    | -0.0103    |
| _min_obs        | -1.41      |
| _std_act        | 0.494821   |
| _std_adv        | 1          |
| _std_discrew    | 0.0698     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.837       |
| ExplainedVarOld | 0.826       |
| KL              | 0.00157357  |
| Phi_loss        | 57.6147     |
| PolicyEntropy   | 4.21127     |
| PolicyLoss      | -0.00521452 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0114      |
| _MeanReward     | 830         |
| _lr_multiplier  | 1           |
| _max_act        | 3.07901     |
| _max_adv        | 3.93        |
| _max_discrew    | 1.33        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0607755  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.66        |
| _mean_obs       | 0.0319      |
| _min_adv        | -3.13       |
| _min_discrew    | -0.052      |
| _min_obs        | -1.5        |
| _std_act        | 0.496061    |
| _std_adv        | 1           |
| _std_discrew    | 0.0693      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.701       |
| ExplainedVarOld | 0.687       |
| KL              | 0.00183526  |
| Phi_loss        | 60.6069     |
| PolicyEntropy   | 4.18962     |
| PolicyLoss      | -0.00187758 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0208      |
| _MeanReward     | 808         |
| _lr_multiplier  | 1           |
| _max_act        | 3.50103     |
| _max_adv        | 3           |
| _max_discrew    | 1.19        |
| _max_obs        | 1.45        |
| _mean_act       | -0.0642911  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.669       |
| _mean_obs       | 0.032       |
| _min_adv        | -3.38       |
| _min_discrew    | -0.00746    |
| _min_obs        | -1.58       |
| _std_act        | 0.500828    |
| _std_adv        | 1           |
| _std_discrew    | 0.0731      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.689       |
| ExplainedVarOld | 0.619       |
| KL              | 0.00119239  |
| Phi_loss        | 51.8603     |
| PolicyEntropy   | 4.17936     |
| PolicyLoss      | -0.00474489 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0227      |
| _MeanReward     | 726         |
| _lr_multiplier  | 1           |
| _max_act        | 3.59888     |
| _max_adv        | 2.81        |
| _max_discrew    | 1.29        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0929904  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.582       |
| _mean_obs       | 0.0293      |
| _min_adv        | -10.2       |
| _min_discrew    | -0.734      |
| _min_obs        | -1.38       |
| _std_act        | 0.524923    |
| _std_adv        | 1           |
| _std_discrew    | 0.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.771       |
| ExplainedVarOld | 0.729       |
| KL              | 0.00394442  |
| Phi_loss        | 53.5882     |
| PolicyEntropy   | 4.15654     |
| PolicyLoss      | -0.00592645 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0368      |
| _MeanReward     | 825         |
| _lr_multiplier  | 1           |
| _max_act        | 3.09009     |
| _max_adv        | 7.67        |
| _max_discrew    | 1.21        |
| _max_obs        | 1.94        |
| _mean_act       | -0.067433   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.671       |
| _mean_obs       | 0.0327      |
| _min_adv        | -5.23       |
| _min_discrew    | -0.0437     |
| _min_obs        | -1.53       |
| _std_act        | 0.497885    |
| _std_adv        | 1           |
| _std_discrew    | 0.0558      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.689        |
| ExplainedVarOld | 0.633        |
| KL              | 0.00378065   |
| Phi_loss        | 51.1548      |
| PolicyEntropy   | 4.13153      |
| PolicyLoss      | -0.000520944 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0176       |
| _MeanReward     | 874          |
| _lr_multiplier  | 1            |
| _max_act        | 3.22982      |
| _max_adv        | 3.54         |
| _max_discrew    | 1.2          |
| _max_obs        | 1.72         |
| _mean_act       | -0.0660234   |
| _mean_adv       | -1.71e-17    |
| _mean_discrew   | 0.716        |
| _mean_obs       | 0.0333       |
| _min_adv        | -3.72        |
| _min_discrew    | -0.03        |
| _min_obs        | -1.47        |
| _std_act        | 0.499091     |
| _std_adv        | 1            |
| _std_discrew    | 0.0667       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.753       |
| ExplainedVarOld | 0.736       |
| KL              | 0.00254641  |
| Phi_loss        | 59.1672     |
| PolicyEntropy   | 4.13158     |
| PolicyLoss      | -0.00573147 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0168      |
| _MeanReward     | 832         |
| _lr_multiplier  | 1           |
| _max_act        | 3.52216     |
| _max_adv        | 3.61        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.71        |
| _mean_act       | -0.0593381  |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.669       |
| _mean_obs       | 0.0324      |
| _min_adv        | -4.18       |
| _min_discrew    | -0.109      |
| _min_obs        | -1.46       |
| _std_act        | 0.503435    |
| _std_adv        | 1           |
| _std_discrew    | 0.0622      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.734       |
| ExplainedVarOld | 0.723       |
| KL              | 0.00258336  |
| Phi_loss        | 64.7683     |
| PolicyEntropy   | 4.10381     |
| PolicyLoss      | -0.00552737 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0168      |
| _MeanReward     | 870         |
| _lr_multiplier  | 1           |
| _max_act        | 3.36168     |
| _max_adv        | 3.41        |
| _max_discrew    | 1.19        |
| _max_obs        | 1.52        |
| _mean_act       | -0.0646883  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.7         |
| _mean_obs       | 0.0332      |
| _min_adv        | -4.32       |
| _min_discrew    | -0.0226     |
| _min_obs        | -1.43       |
| _std_act        | 0.496496    |
| _std_adv        | 1           |
| _std_discrew    | 0.0735      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.797      |
| ExplainedVarOld | 0.778      |
| KL              | 0.00221457 |
| Phi_loss        | 60.5784    |
| PolicyEntropy   | 4.06882    |
| PolicyLoss      | 0.00793134 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0151     |
| _MeanReward     | 947        |
| _lr_multiplier  | 1          |
| _max_act        | 3.05676    |
| _max_adv        | 3.41       |
| _max_discrew    | 1.46       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0511613 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 0.765      |
| _mean_obs       | 0.0344     |
| _min_adv        | -3.43      |
| _min_discrew    | -0.00853   |
| _min_obs        | -1.34      |
| _std_act        | 0.50587    |
| _std_adv        | 1          |
| _std_discrew    | 0.0833     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.753      |
| ExplainedVarOld | 0.74       |
| KL              | 0.00288535 |
| Phi_loss        | 67.2574    |
| PolicyEntropy   | 4.02833    |
| PolicyLoss      | 0.00269104 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 903        |
| _lr_multiplier  | 1          |
| _max_act        | 3.20653    |
| _max_adv        | 3.32       |
| _max_discrew    | 1.37       |
| _max_obs        | 1.65       |
| _mean_act       | -0.0607385 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.729      |
| _mean_obs       | 0.0346     |
| _min_adv        | -3.78      |
| _min_discrew    | -0.0146    |
| _min_obs        | -1.47      |
| _std_act        | 0.498213   |
| _std_adv        | 1          |
| _std_discrew    | 0.0736     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.772       |
| ExplainedVarOld | 0.765       |
| KL              | 0.00246399  |
| Phi_loss        | 63.7376     |
| PolicyEntropy   | 4.00331     |
| PolicyLoss      | 0.000509804 |
| Steps           | 10000       |
| VarFuncLoss     | 0.017       |
| _MeanReward     | 900         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18881     |
| _max_adv        | 3.36        |
| _max_discrew    | 1.32        |
| _max_obs        | 1.53        |
| _mean_act       | -0.0612407  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.738       |
| _mean_obs       | 0.0326      |
| _min_adv        | -4.05       |
| _min_discrew    | -0.0181     |
| _min_obs        | -1.4        |
| _std_act        | 0.502034    |
| _std_adv        | 1           |
| _std_discrew    | 0.083       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.695       |
| ExplainedVarOld | 0.676       |
| KL              | 0.00236258  |
| Phi_loss        | 66.2905     |
| PolicyEntropy   | 3.99763     |
| PolicyLoss      | -0.00609371 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0253      |
| _MeanReward     | 867         |
| _lr_multiplier  | 1           |
| _max_act        | 3.28039     |
| _max_adv        | 3.55        |
| _max_discrew    | 1.31        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0656542  |
| _mean_adv       | -1.28e-17   |
| _mean_discrew   | 0.692       |
| _mean_obs       | 0.0337      |
| _min_adv        | -3.59       |
| _min_discrew    | -0.0546     |
| _min_obs        | -1.32       |
| _std_act        | 0.507221    |
| _std_adv        | 1           |
| _std_discrew    | 0.0864      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.775       |
| ExplainedVarOld | 0.76        |
| KL              | 0.00280661  |
| Phi_loss        | 66.995      |
| PolicyEntropy   | 3.99051     |
| PolicyLoss      | -0.00299736 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0197      |
| _MeanReward     | 952         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02288     |
| _max_adv        | 3.27        |
| _max_discrew    | 1.41        |
| _max_obs        | 1.51        |
| _mean_act       | -0.0615304  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.782       |
| _mean_obs       | 0.0339      |
| _min_adv        | -3.18       |
| _min_discrew    | -0.0256     |
| _min_obs        | -1.54       |
| _std_act        | 0.496429    |
| _std_adv        | 1           |
| _std_discrew    | 0.0934      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.764       |
| ExplainedVarOld | 0.751       |
| KL              | 0.00275935  |
| Phi_loss        | 63.5494     |
| PolicyEntropy   | 3.991       |
| PolicyLoss      | -0.00756085 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0238      |
| _MeanReward     | 950         |
| _lr_multiplier  | 1           |
| _max_act        | 3.2903      |
| _max_adv        | 3.08        |
| _max_discrew    | 1.3         |
| _max_obs        | 1.44        |
| _mean_act       | -0.058169   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.765       |
| _mean_obs       | 0.0358      |
| _min_adv        | -3.29       |
| _min_discrew    | -0.0263     |
| _min_obs        | -1.52       |
| _std_act        | 0.503189    |
| _std_adv        | 1           |
| _std_discrew    | 0.0863      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.785       |
| ExplainedVarOld | 0.782       |
| KL              | 0.00338228  |
| Phi_loss        | 68.6271     |
| PolicyEntropy   | 3.97851     |
| PolicyLoss      | -0.00994471 |
| Steps           | 10000       |
| VarFuncLoss     | 0.019       |
| _MeanReward     | 980         |
| _lr_multiplier  | 1           |
| _max_act        | 3.25868     |
| _max_adv        | 3.27        |
| _max_discrew    | 1.44        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0682489  |
| _mean_adv       | 9.95e-18    |
| _mean_discrew   | 0.778       |
| _mean_obs       | 0.0347      |
| _min_adv        | -6.99       |
| _min_discrew    | -0.503      |
| _min_obs        | -1.35       |
| _std_act        | 0.516939    |
| _std_adv        | 1           |
| _std_discrew    | 0.134       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.818       |
| ExplainedVarOld | 0.778       |
| KL              | 0.00277268  |
| Phi_loss        | 60.5702     |
| PolicyEntropy   | 3.96301     |
| PolicyLoss      | 0.000642101 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0244      |
| _MeanReward     | 1e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 3.171       |
| _max_adv        | 3.34        |
| _max_discrew    | 1.45        |
| _max_obs        | 1.61        |
| _mean_act       | -0.0539347  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.822       |
| _mean_obs       | 0.0345      |
| _min_adv        | -3.79       |
| _min_discrew    | -0.00438    |
| _min_obs        | -1.46       |
| _std_act        | 0.504304    |
| _std_adv        | 1           |
| _std_discrew    | 0.0976      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.786       |
| ExplainedVarOld | 0.779       |
| KL              | 0.00310957  |
| Phi_loss        | 72.6935     |
| PolicyEntropy   | 3.94631     |
| PolicyLoss      | -0.00632712 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0209      |
| _MeanReward     | 1.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.39176     |
| _max_adv        | 3.25        |
| _max_discrew    | 1.54        |
| _max_obs        | 1.65        |
| _mean_act       | -0.050898   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.832       |
| _mean_obs       | 0.0347      |
| _min_adv        | -3.4        |
| _min_discrew    | -0.0159     |
| _min_obs        | -1.52       |
| _std_act        | 0.511398    |
| _std_adv        | 1           |
| _std_discrew    | 0.113       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.726      |
| ExplainedVarOld | 0.719      |
| KL              | 0.00308455 |
| Phi_loss        | 71.5241    |
| PolicyEntropy   | 3.9132     |
| PolicyLoss      | -0.0056808 |
| Steps           | 10000      |
| VarFuncLoss     | 0.031      |
| _MeanReward     | 1.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87209    |
| _max_adv        | 3.2        |
| _max_discrew    | 1.44       |
| _max_obs        | 1.53       |
| _mean_act       | -0.0547655 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 0.82       |
| _mean_obs       | 0.0357     |
| _min_adv        | -3.11      |
| _min_discrew    | -0.00157   |
| _min_obs        | -1.58      |
| _std_act        | 0.515247   |
| _std_adv        | 1          |
| _std_discrew    | 0.079      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.766      |
| ExplainedVarOld | 0.748      |
| KL              | 0.00226764 |
| Phi_loss        | 70.6391    |
| PolicyEntropy   | 3.91158    |
| PolicyLoss      | -0.0147679 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 1.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05595    |
| _max_adv        | 3.83       |
| _max_discrew    | 1.46       |
| _max_obs        | 1.63       |
| _mean_act       | -0.0541113 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.831      |
| _mean_obs       | 0.0353     |
| _min_adv        | -3.56      |
| _min_discrew    | -0.0139    |
| _min_obs        | -1.44      |
| _std_act        | 0.513631   |
| _std_adv        | 1          |
| _std_discrew    | 0.0987     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.792       |
| ExplainedVarOld | 0.786       |
| KL              | 0.00325089  |
| Phi_loss        | 70.622      |
| PolicyEntropy   | 3.86701     |
| PolicyLoss      | -0.00146146 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0206      |
| _MeanReward     | 1.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08908     |
| _max_adv        | 2.59        |
| _max_discrew    | 1.48        |
| _max_obs        | 1.46        |
| _mean_act       | -0.0692494  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.819       |
| _mean_obs       | 0.0336      |
| _min_adv        | -12         |
| _min_discrew    | -0.685      |
| _min_obs        | -1.45       |
| _std_act        | 0.539973    |
| _std_adv        | 1           |
| _std_discrew    | 0.179       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.751      |
| ExplainedVarOld | 0.733      |
| KL              | 0.00558962 |
| Phi_loss        | 66.1411    |
| PolicyEntropy   | 3.87137    |
| PolicyLoss      | -0.0201323 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0447     |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06385    |
| _max_adv        | 5.05       |
| _max_discrew    | 1.47       |
| _max_obs        | 1.54       |
| _mean_act       | -0.0551791 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 0.872      |
| _mean_obs       | 0.0352     |
| _min_adv        | -3.44      |
| _min_discrew    | -0.0418    |
| _min_obs        | -1.45      |
| _std_act        | 0.524249   |
| _std_adv        | 1          |
| _std_discrew    | 0.0891     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.817       |
| ExplainedVarOld | 0.806       |
| KL              | 0.00255337  |
| Phi_loss        | 68.4925     |
| PolicyEntropy   | 3.84456     |
| PolicyLoss      | -0.00280864 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0163      |
| _MeanReward     | 1.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.32282     |
| _max_adv        | 5.86        |
| _max_discrew    | 1.36        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0481986  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.839       |
| _mean_obs       | 0.0357      |
| _min_adv        | -3.71       |
| _min_discrew    | -0.00616    |
| _min_obs        | -1.39       |
| _std_act        | 0.524072    |
| _std_adv        | 1           |
| _std_discrew    | 0.089       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.799       |
| ExplainedVarOld | 0.781       |
| KL              | 0.00300017  |
| Phi_loss        | 67.3564     |
| PolicyEntropy   | 3.82825     |
| PolicyLoss      | -0.00985884 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0182      |
| _MeanReward     | 1.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.30539     |
| _max_adv        | 3.2         |
| _max_discrew    | 1.59        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0503204  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.858       |
| _mean_obs       | 0.0351      |
| _min_adv        | -3.26       |
| _min_discrew    | 0.000147    |
| _min_obs        | -1.5        |
| _std_act        | 0.528716    |
| _std_adv        | 1           |
| _std_discrew    | 0.0983      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.707      |
| ExplainedVarOld | 0.692      |
| KL              | 0.00301815 |
| Phi_loss        | 75.0401    |
| PolicyEntropy   | 3.81399    |
| PolicyLoss      | -0.0010107 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 1.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.26215    |
| _max_adv        | 3.66       |
| _max_discrew    | 1.5        |
| _max_obs        | 1.44       |
| _mean_act       | -0.0460052 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.93       |
| _mean_obs       | 0.0356     |
| _min_adv        | -3.86      |
| _min_discrew    | -0.00608   |
| _min_obs        | -1.5       |
| _std_act        | 0.527349   |
| _std_adv        | 1          |
| _std_discrew    | 0.101      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.783      |
| ExplainedVarOld | 0.776      |
| KL              | 0.00231058 |
| Phi_loss        | 74.696     |
| PolicyEntropy   | 3.79058    |
| PolicyLoss      | -0.0102333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0228     |
| _MeanReward     | 1.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.12841    |
| _max_adv        | 3.32       |
| _max_discrew    | 1.39       |
| _max_obs        | 1.57       |
| _mean_act       | -0.0493324 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.907      |
| _mean_obs       | 0.0346     |
| _min_adv        | -3.74      |
| _min_discrew    | -0.00292   |
| _min_obs        | -1.59      |
| _std_act        | 0.528069   |
| _std_adv        | 1          |
| _std_discrew    | 0.0937     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.763      |
| ExplainedVarOld | 0.746      |
| KL              | 0.00378447 |
| Phi_loss        | 79.8039    |
| PolicyEntropy   | 3.79714    |
| PolicyLoss      | -0.0189357 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0224     |
| _MeanReward     | 1.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24856    |
| _max_adv        | 3.39       |
| _max_discrew    | 1.69       |
| _max_obs        | 1.53       |
| _mean_act       | -0.0475637 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.953      |
| _mean_obs       | 0.0366     |
| _min_adv        | -3.57      |
| _min_discrew    | -0.0195    |
| _min_obs        | -1.64      |
| _std_act        | 0.534397   |
| _std_adv        | 1          |
| _std_discrew    | 0.118      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.773      |
| ExplainedVarOld | 0.761      |
| KL              | 0.00359263 |
| Phi_loss        | 72.9078    |
| PolicyEntropy   | 3.77164    |
| PolicyLoss      | 0.00273182 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0273     |
| _MeanReward     | 1.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1846     |
| _max_adv        | 3.02       |
| _max_discrew    | 1.67       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0551552 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.984      |
| _mean_obs       | 0.0371     |
| _min_adv        | -4.13      |
| _min_discrew    | -0.0263    |
| _min_obs        | -1.61      |
| _std_act        | 0.545388   |
| _std_adv        | 1          |
| _std_discrew    | 0.132      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.813       |
| ExplainedVarOld | 0.789       |
| KL              | 0.00229999  |
| Phi_loss        | 69.919      |
| PolicyEntropy   | 3.7546      |
| PolicyLoss      | -0.00499561 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0252      |
| _MeanReward     | 1.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.10634     |
| _max_adv        | 3.44        |
| _max_discrew    | 1.62        |
| _max_obs        | 1.46        |
| _mean_act       | -0.0623464  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.946       |
| _mean_obs       | 0.0346      |
| _min_adv        | -3.72       |
| _min_discrew    | -0.131      |
| _min_obs        | -1.5        |
| _std_act        | 0.538372    |
| _std_adv        | 1           |
| _std_discrew    | 0.127       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.835       |
| KL              | 0.00365244  |
| Phi_loss        | 76.7906     |
| PolicyEntropy   | 3.7222      |
| PolicyLoss      | 0.000130692 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0192      |
| _MeanReward     | 1.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.27173     |
| _max_adv        | 3.58        |
| _max_discrew    | 1.8         |
| _max_obs        | 1.78        |
| _mean_act       | -0.0573367  |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 1.09        |
| _mean_obs       | 0.0377      |
| _min_adv        | -3.86       |
| _min_discrew    | -0.0179     |
| _min_obs        | -1.42       |
| _std_act        | 0.551538    |
| _std_adv        | 1           |
| _std_discrew    | 0.163       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.832      |
| ExplainedVarOld | 0.821      |
| KL              | 0.00336801 |
| Phi_loss        | 75.8398    |
| PolicyEntropy   | 3.71382    |
| PolicyLoss      | -0.0124851 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0321     |
| _MeanReward     | 1.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.20898    |
| _max_adv        | 3.22       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0583508 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.995      |
| _mean_obs       | 0.0343     |
| _min_adv        | -3.98      |
| _min_discrew    | -0.00662   |
| _min_obs        | -1.69      |
| _std_act        | 0.541334   |
| _std_adv        | 1          |
| _std_discrew    | 0.109      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.815       |
| ExplainedVarOld | 0.803       |
| KL              | 0.004239    |
| Phi_loss        | 79.2924     |
| PolicyEntropy   | 3.67984     |
| PolicyLoss      | -0.00368924 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0216      |
| _MeanReward     | 1.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.70073     |
| _max_adv        | 2.28        |
| _max_discrew    | 1.95        |
| _max_obs        | 1.54        |
| _mean_act       | -0.10509    |
| _mean_adv       | 0           |
| _mean_discrew   | 0.894       |
| _mean_obs       | 0.0315      |
| _min_adv        | -9.53       |
| _min_discrew    | -0.714      |
| _min_obs        | -1.48       |
| _std_act        | 0.577806    |
| _std_adv        | 1           |
| _std_discrew    | 0.383       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.766      |
| ExplainedVarOld | 0.734      |
| KL              | 0.00397297 |
| Phi_loss        | 65.3848    |
| PolicyEntropy   | 3.65473    |
| PolicyLoss      | -0.0125936 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0896     |
| _MeanReward     | 1.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03161    |
| _max_adv        | 5.61       |
| _max_discrew    | 1.76       |
| _max_obs        | 1.56       |
| _mean_act       | -0.0542164 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0363     |
| _min_adv        | -3.94      |
| _min_discrew    | -0.091     |
| _min_obs        | -1.51      |
| _std_act        | 0.542823   |
| _std_adv        | 1          |
| _std_discrew    | 0.179      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.873      |
| ExplainedVarOld | 0.821      |
| KL              | 0.00353631 |
| Phi_loss        | 74.8001    |
| PolicyEntropy   | 3.63128    |
| PolicyLoss      | 0.00136886 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0234     |
| _MeanReward     | 1.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.54808    |
| _max_adv        | 6.39       |
| _max_discrew    | 1.9        |
| _max_obs        | 1.41       |
| _mean_act       | -0.0570921 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0343     |
| _min_adv        | -4.19      |
| _min_discrew    | -0.0144    |
| _min_obs        | -1.42      |
| _std_act        | 0.539641   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.737       |
| ExplainedVarOld | 0.73        |
| KL              | 0.00344288  |
| Phi_loss        | 80.1949     |
| PolicyEntropy   | 3.60462     |
| PolicyLoss      | -0.00427387 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0409      |
| _MeanReward     | 1.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.89601     |
| _max_adv        | 2.69        |
| _max_discrew    | 1.8         |
| _max_obs        | 1.48        |
| _mean_act       | -0.055414   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.08        |
| _mean_obs       | 0.0353      |
| _min_adv        | -3.58       |
| _min_discrew    | -0.0066     |
| _min_obs        | -1.44       |
| _std_act        | 0.542099    |
| _std_adv        | 1           |
| _std_discrew    | 0.167       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.8         |
| ExplainedVarOld | 0.787       |
| KL              | 0.00326247  |
| Phi_loss        | 85.0647     |
| PolicyEntropy   | 3.58572     |
| PolicyLoss      | -0.00312445 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0338      |
| _MeanReward     | 1.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.25909     |
| _max_adv        | 3.63        |
| _max_discrew    | 2           |
| _max_obs        | 1.65        |
| _mean_act       | -0.05376    |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0371      |
| _min_adv        | -3.32       |
| _min_discrew    | -0.013      |
| _min_obs        | -1.46       |
| _std_act        | 0.549736    |
| _std_adv        | 1           |
| _std_discrew    | 0.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.782      |
| ExplainedVarOld | 0.773      |
| KL              | 0.00302263 |
| Phi_loss        | 80.6384    |
| PolicyEntropy   | 3.592      |
| PolicyLoss      | 0.00358953 |
| Steps           | 10000      |
| VarFuncLoss     | 0.035      |
| _MeanReward     | 1.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.018      |
| _max_adv        | 3.81       |
| _max_discrew    | 1.88       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0534918 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.0367     |
| _min_adv        | -4.24      |
| _min_discrew    | -0.00372   |
| _min_obs        | -1.35      |
| _std_act        | 0.549157   |
| _std_adv        | 1          |
| _std_discrew    | 0.158      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.806      |
| ExplainedVarOld | 0.804      |
| KL              | 0.00315591 |
| Phi_loss        | 86.9176    |
| PolicyEntropy   | 3.56911    |
| PolicyLoss      | -0.0138089 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0307     |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.31944    |
| _max_adv        | 3.44       |
| _max_discrew    | 1.9        |
| _max_obs        | 1.48       |
| _mean_act       | -0.0656711 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0348     |
| _min_adv        | -4.94      |
| _min_discrew    | -0.355     |
| _min_obs        | -1.52      |
| _std_act        | 0.554988   |
| _std_adv        | 1          |
| _std_discrew    | 0.196      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.809      |
| ExplainedVarOld | 0.788      |
| KL              | 0.00358626 |
| Phi_loss        | 80.7599    |
| PolicyEntropy   | 3.55195    |
| PolicyLoss      | -0.0178637 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0374     |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.45638    |
| _max_adv        | 2.88       |
| _max_discrew    | 2.02       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0620449 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0366     |
| _min_adv        | -3.75      |
| _min_discrew    | -6.78e-05  |
| _min_obs        | -1.51      |
| _std_act        | 0.559831   |
| _std_adv        | 1          |
| _std_discrew    | 0.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.756       |
| ExplainedVarOld | 0.751       |
| KL              | 0.00333551  |
| Phi_loss        | 89.7826     |
| PolicyEntropy   | 3.5404      |
| PolicyLoss      | 0.000501265 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0447      |
| _MeanReward     | 1.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94198     |
| _max_adv        | 4.49        |
| _max_discrew    | 1.83        |
| _max_obs        | 1.56        |
| _mean_act       | -0.0644652  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.07        |
| _mean_obs       | 0.0358      |
| _min_adv        | -6.65       |
| _min_discrew    | -0.413      |
| _min_obs        | -1.41       |
| _std_act        | 0.564114    |
| _std_adv        | 1           |
| _std_discrew    | 0.197       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.778      |
| ExplainedVarOld | 0.773      |
| KL              | 0.00320483 |
| Phi_loss        | 78.4108    |
| PolicyEntropy   | 3.52849    |
| PolicyLoss      | -0.0121825 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0447     |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03044    |
| _max_adv        | 3.23       |
| _max_discrew    | 1.84       |
| _max_obs        | 1.51       |
| _mean_act       | -0.0533666 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.037      |
| _min_adv        | -5.2       |
| _min_discrew    | -0.00866   |
| _min_obs        | -1.5       |
| _std_act        | 0.562303   |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.798       |
| ExplainedVarOld | 0.791       |
| KL              | 0.00330989  |
| Phi_loss        | 90.607      |
| PolicyEntropy   | 3.50763     |
| PolicyLoss      | -0.00027548 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0312      |
| _MeanReward     | 1.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.23365     |
| _max_adv        | 2.66        |
| _max_discrew    | 2.03        |
| _max_obs        | 1.46        |
| _mean_act       | -0.0780694  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.985       |
| _mean_obs       | 0.0341      |
| _min_adv        | -10.2       |
| _min_discrew    | -0.672      |
| _min_obs        | -1.42       |
| _std_act        | 0.58652     |
| _std_adv        | 1           |
| _std_discrew    | 0.316       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.784      |
| ExplainedVarOld | 0.756      |
| KL              | 0.00650949 |
| Phi_loss        | 75.8174    |
| PolicyEntropy   | 3.51793    |
| PolicyLoss      | 0.0143794  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0682     |
| _MeanReward     | 1.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.0936     |
| _max_adv        | 5.24       |
| _max_discrew    | 2.24       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0515987 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.21       |
| _mean_obs       | 0.0368     |
| _min_adv        | -3.41      |
| _min_discrew    | -0.00744   |
| _min_obs        | -1.45      |
| _std_act        | 0.551489   |
| _std_adv        | 1          |
| _std_discrew    | 0.207      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.795      |
| ExplainedVarOld | 0.766      |
| KL              | 0.00157856 |
| Phi_loss        | 89.1704    |
| PolicyEntropy   | 3.49715    |
| PolicyLoss      | 0.00756079 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0455     |
| _MeanReward     | 1.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.30386    |
| _max_adv        | 4.33       |
| _max_discrew    | 1.83       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0531646 |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0368     |
| _min_adv        | -4.87      |
| _min_discrew    | -0.00485   |
| _min_obs        | -1.55      |
| _std_act        | 0.559011   |
| _std_adv        | 1          |
| _std_discrew    | 0.159      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.825      |
| ExplainedVarOld | 0.799      |
| KL              | 0.00167909 |
| Phi_loss        | 85.6453    |
| PolicyEntropy   | 3.46253    |
| PolicyLoss      | 0.00732605 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0289     |
| _MeanReward     | 1.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13523    |
| _max_adv        | 3.96       |
| _max_discrew    | 1.99       |
| _max_obs        | 1.66       |
| _mean_act       | -0.0537681 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.22       |
| _mean_obs       | 0.0364     |
| _min_adv        | -4.71      |
| _min_discrew    | 0.00276    |
| _min_obs        | -1.38      |
| _std_act        | 0.556087   |
| _std_adv        | 1          |
| _std_discrew    | 0.167      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.837      |
| ExplainedVarOld | 0.83       |
| KL              | 0.00181825 |
| Phi_loss        | 94.5909    |
| PolicyEntropy   | 3.458      |
| PolicyLoss      | 0.00343152 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0281     |
| _MeanReward     | 1.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.26784    |
| _max_adv        | 3.39       |
| _max_discrew    | 1.87       |
| _max_obs        | 1.4        |
| _mean_act       | -0.051535  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 1.17       |
| _mean_obs       | 0.0371     |
| _min_adv        | -3.67      |
| _min_discrew    | -0.00259   |
| _min_obs        | -1.26      |
| _std_act        | 0.56153    |
| _std_adv        | 1          |
| _std_discrew    | 0.168      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.796       |
| ExplainedVarOld | 0.791       |
| KL              | 0.00188353  |
| Phi_loss        | 94.2318     |
| PolicyEntropy   | 3.43676     |
| PolicyLoss      | -0.00292559 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0345      |
| _MeanReward     | 1.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.48455     |
| _max_adv        | 3           |
| _max_discrew    | 2.04        |
| _max_obs        | 1.7         |
| _mean_act       | -0.0718074  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0346      |
| _min_adv        | -8.11       |
| _min_discrew    | -0.501      |
| _min_obs        | -1.49       |
| _std_act        | 0.572802    |
| _std_adv        | 1           |
| _std_discrew    | 0.275       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.752       |
| ExplainedVarOld | 0.725       |
| KL              | 0.00174552  |
| Phi_loss        | 82.6845     |
| PolicyEntropy   | 3.4158      |
| PolicyLoss      | -0.00434775 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0687      |
| _MeanReward     | 1.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03611     |
| _max_adv        | 4.66        |
| _max_discrew    | 1.99        |
| _max_obs        | 1.44        |
| _mean_act       | -0.0521574  |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 1.21        |
| _mean_obs       | 0.036       |
| _min_adv        | -3.55       |
| _min_discrew    | -0.00157    |
| _min_obs        | -1.43       |
| _std_act        | 0.553731    |
| _std_adv        | 1           |
| _std_discrew    | 0.191       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.78       |
| ExplainedVarOld | 0.774      |
| KL              | 0.00167866 |
| Phi_loss        | 96.3648    |
| PolicyEntropy   | 3.41807    |
| PolicyLoss      | 0.00713298 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0436     |
| _MeanReward     | 1.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.68964    |
| _max_adv        | 3.8        |
| _max_discrew    | 2.05       |
| _max_obs        | 1.53       |
| _mean_act       | -0.053144  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0371     |
| _min_adv        | -3.98      |
| _min_discrew    | -0.000688  |
| _min_obs        | -1.35      |
| _std_act        | 0.555091   |
| _std_adv        | 1          |
| _std_discrew    | 0.188      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.798      |
| ExplainedVarOld | 0.793      |
| KL              | 0.00183853 |
| Phi_loss        | 94.1976    |
| PolicyEntropy   | 3.41452    |
| PolicyLoss      | 0.00546501 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0379     |
| _MeanReward     | 1.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.44668    |
| _max_adv        | 3.1        |
| _max_discrew    | 1.89       |
| _max_obs        | 1.51       |
| _mean_act       | -0.0510836 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 1.18       |
| _mean_obs       | 0.0362     |
| _min_adv        | -4.08      |
| _min_discrew    | -0.00072   |
| _min_obs        | -1.57      |
| _std_act        | 0.556586   |
| _std_adv        | 1          |
| _std_discrew    | 0.179      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.868       |
| ExplainedVarOld | 0.858       |
| KL              | 0.00154754  |
| Phi_loss        | 97.0029     |
| PolicyEntropy   | 3.40034     |
| PolicyLoss      | -0.00444751 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0238      |
| _MeanReward     | 1.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.35961     |
| _max_adv        | 2.97        |
| _max_discrew    | 2.1         |
| _max_obs        | 1.4         |
| _mean_act       | -0.0560727  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.24        |
| _mean_obs       | 0.0361      |
| _min_adv        | -3.8        |
| _min_discrew    | 0.000202    |
| _min_obs        | -1.52       |
| _std_act        | 0.558022    |
| _std_adv        | 1           |
| _std_discrew    | 0.188       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.827      |
| ExplainedVarOld | 0.824      |
| KL              | 0.00177909 |
| Phi_loss        | 100.13     |
| PolicyEntropy   | 3.37988    |
| PolicyLoss      | -0.0200867 |
| Steps           | 10000      |
| VarFuncLoss     | 0.033      |
| _MeanReward     | 1.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85569    |
| _max_adv        | 3.49       |
| _max_discrew    | 1.95       |
| _max_obs        | 1.49       |
| _mean_act       | -0.0540175 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0365     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.0106    |
| _min_obs        | -1.35      |
| _std_act        | 0.551529   |
| _std_adv        | 1          |
| _std_discrew    | 0.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.857       |
| ExplainedVarOld | 0.847       |
| KL              | 0.00140857  |
| Phi_loss        | 96.6844     |
| PolicyEntropy   | 3.36953     |
| PolicyLoss      | -0.00673944 |
| Steps           | 10000       |
| VarFuncLoss     | 0.028       |
| _MeanReward     | 1.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03757     |
| _max_adv        | 3.5         |
| _max_discrew    | 2.23        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0559634  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.31        |
| _mean_obs       | 0.0368      |
| _min_adv        | -2.92       |
| _min_discrew    | 0.00274     |
| _min_obs        | -1.55       |
| _std_act        | 0.56133     |
| _std_adv        | 1           |
| _std_discrew    | 0.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.836       |
| ExplainedVarOld | 0.828       |
| KL              | 0.00337275  |
| Phi_loss        | 99.3485     |
| PolicyEntropy   | 3.34593     |
| PolicyLoss      | -0.00670713 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0366      |
| _MeanReward     | 1.53e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.14024     |
| _max_adv        | 3.12        |
| _max_discrew    | 2.03        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0534697  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.24        |
| _mean_obs       | 0.0368      |
| _min_adv        | -3.2        |
| _min_discrew    | 0.000337    |
| _min_obs        | -1.56       |
| _std_act        | 0.563227    |
| _std_adv        | 1           |
| _std_discrew    | 0.186       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.789      |
| ExplainedVarOld | 0.763      |
| KL              | 0.00371291 |
| Phi_loss        | 93.8223    |
| PolicyEntropy   | 3.32667    |
| PolicyLoss      | -0.0296897 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0397     |
| _MeanReward     | 1.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06393    |
| _max_adv        | 2.92       |
| _max_discrew    | 2.09       |
| _max_obs        | 1.59       |
| _mean_act       | -0.0547777 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.27       |
| _mean_obs       | 0.0367     |
| _min_adv        | -3.77      |
| _min_discrew    | 0.00416    |
| _min_obs        | -1.51      |
| _std_act        | 0.571047   |
| _std_adv        | 1          |
| _std_discrew    | 0.203      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.841      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00386916 |
| Phi_loss        | 104.552    |
| PolicyEntropy   | 3.29562    |
| PolicyLoss      | 0.0039064  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0325     |
| _MeanReward     | 1.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.46347    |
| _max_adv        | 3.47       |
| _max_discrew    | 1.99       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0560572 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.23       |
| _mean_obs       | 0.0375     |
| _min_adv        | -3.39      |
| _min_discrew    | -0.0094    |
| _min_obs        | -1.5       |
| _std_act        | 0.574904   |
| _std_adv        | 1          |
| _std_discrew    | 0.177      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.826       |
| ExplainedVarOld | 0.824       |
| KL              | 0.00284931  |
| Phi_loss        | 103.923     |
| PolicyEntropy   | 3.26873     |
| PolicyLoss      | -0.00799399 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0311      |
| _MeanReward     | 1.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.93716     |
| _max_adv        | 2.82        |
| _max_discrew    | 2.23        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0593228  |
| _mean_adv       | -6.25e-17   |
| _mean_discrew   | 1.39        |
| _mean_obs       | 0.0364      |
| _min_adv        | -3.81       |
| _min_discrew    | 0.00538     |
| _min_obs        | -1.46       |
| _std_act        | 0.560936    |
| _std_adv        | 1           |
| _std_discrew    | 0.224       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.848       |
| ExplainedVarOld | 0.836       |
| KL              | 0.0035745   |
| Phi_loss        | 102.155     |
| PolicyEntropy   | 3.24961     |
| PolicyLoss      | -0.00454462 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0388      |
| _MeanReward     | 1.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06164     |
| _max_adv        | 2.93        |
| _max_discrew    | 2.18        |
| _max_obs        | 1.54        |
| _mean_act       | -0.059344   |
| _mean_adv       | 3.55e-18    |
| _mean_discrew   | 1.35        |
| _mean_obs       | 0.0379      |
| _min_adv        | -3.22       |
| _min_discrew    | 0.00253     |
| _min_obs        | -1.45       |
| _std_act        | 0.574003    |
| _std_adv        | 1           |
| _std_discrew    | 0.218       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.841       |
| ExplainedVarOld | 0.828       |
| KL              | 0.00440288  |
| Phi_loss        | 103.59      |
| PolicyEntropy   | 3.21177     |
| PolicyLoss      | -0.00828049 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0354      |
| _MeanReward     | 1.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.09014     |
| _max_adv        | 4.13        |
| _max_discrew    | 2.37        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0637104  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.39        |
| _mean_obs       | 0.0378      |
| _min_adv        | -2.95       |
| _min_discrew    | -0.00793    |
| _min_obs        | -1.43       |
| _std_act        | 0.575639    |
| _std_adv        | 1           |
| _std_discrew    | 0.267       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.832       |
| ExplainedVarOld | 0.82        |
| KL              | 0.00352068  |
| Phi_loss        | 108.374     |
| PolicyEntropy   | 3.17478     |
| PolicyLoss      | -0.00861846 |
| Steps           | 10000       |
| VarFuncLoss     | 0.046       |
| _MeanReward     | 1.72e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.49514     |
| _max_adv        | 3.04        |
| _max_discrew    | 2.24        |
| _max_obs        | 1.62        |
| _mean_act       | -0.0597177  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.42        |
| _mean_obs       | 0.0389      |
| _min_adv        | -3.3        |
| _min_discrew    | 0.000586    |
| _min_obs        | -1.5        |
| _std_act        | 0.581696    |
| _std_adv        | 1           |
| _std_discrew    | 0.231       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.814       |
| ExplainedVarOld | 0.808       |
| KL              | 0.00410535  |
| Phi_loss        | 111.458     |
| PolicyEntropy   | 3.13567     |
| PolicyLoss      | -0.00634463 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0432      |
| _MeanReward     | 1.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.02461     |
| _max_adv        | 3.13        |
| _max_discrew    | 2.24        |
| _max_obs        | 1.49        |
| _mean_act       | -0.087337   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 1.2         |
| _mean_obs       | 0.0357      |
| _min_adv        | -9.39       |
| _min_discrew    | -0.657      |
| _min_obs        | -1.47       |
| _std_act        | 0.611139    |
| _std_adv        | 1           |
| _std_discrew    | 0.456       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.857      |
| ExplainedVarOld | 0.829      |
| KL              | 0.00378631 |
| Phi_loss        | 91.1471    |
| PolicyEntropy   | 3.1088     |
| PolicyLoss      | 0.00200131 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0668     |
| _MeanReward     | 1.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.38741    |
| _max_adv        | 4.75       |
| _max_discrew    | 2.36       |
| _max_obs        | 1.49       |
| _mean_act       | -0.0671031 |
| _mean_adv       | -2.7e-17   |
| _mean_discrew   | 1.45       |
| _mean_obs       | 0.0384     |
| _min_adv        | -3.47      |
| _min_discrew    | -0.000999  |
| _min_obs        | -1.44      |
| _std_act        | 0.576132   |
| _std_adv        | 1          |
| _std_discrew    | 0.274      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.852       |
| ExplainedVarOld | 0.845       |
| KL              | 0.00340464  |
| Phi_loss        | 107.706     |
| PolicyEntropy   | 3.09794     |
| PolicyLoss      | -0.00543928 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0428      |
| _MeanReward     | 1.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.23529     |
| _max_adv        | 5.11        |
| _max_discrew    | 2.39        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0614875  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.5         |
| _mean_obs       | 0.0382      |
| _min_adv        | -3.11       |
| _min_discrew    | -0.00535    |
| _min_obs        | -1.45       |
| _std_act        | 0.58282     |
| _std_adv        | 1           |
| _std_discrew    | 0.267       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.858      |
| ExplainedVarOld | 0.842      |
| KL              | 0.00281095 |
| Phi_loss        | 109.208    |
| PolicyEntropy   | 3.08592    |
| PolicyLoss      | -0.0109456 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0384     |
| _MeanReward     | 1.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19208    |
| _max_adv        | 2.54       |
| _max_discrew    | 2.27       |
| _max_obs        | 1.63       |
| _mean_act       | -0.0849169 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.35       |
| _mean_obs       | 0.0362     |
| _min_adv        | -11.5      |
| _min_discrew    | -0.594     |
| _min_obs        | -1.39      |
| _std_act        | 0.611229   |
| _std_adv        | 1          |
| _std_discrew    | 0.454      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.809      |
| ExplainedVarOld | 0.786      |
| KL              | 0.00608733 |
| Phi_loss        | 95.5154    |
| PolicyEntropy   | 3.09013    |
| PolicyLoss      | -0.0167018 |
| Steps           | 10000      |
| VarFuncLoss     | 0.087      |
| _MeanReward     | 1.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24052    |
| _max_adv        | 4.11       |
| _max_discrew    | 2.41       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0632026 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.49       |
| _mean_obs       | 0.0377     |
| _min_adv        | -3.79      |
| _min_discrew    | 0.00264    |
| _min_obs        | -1.36      |
| _std_act        | 0.58678    |
| _std_adv        | 1          |
| _std_discrew    | 0.307      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.829      |
| ExplainedVarOld | 0.787      |
| KL              | 0.0019204  |
| Phi_loss        | 109.386    |
| PolicyEntropy   | 3.07555    |
| PolicyLoss      | -0.0199856 |
| Steps           | 10000      |
| VarFuncLoss     | 0.053      |
| _MeanReward     | 1.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05302    |
| _max_adv        | 8.05       |
| _max_discrew    | 2.22       |
| _max_obs        | 1.43       |
| _mean_act       | -0.060091  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 1.45       |
| _mean_obs       | 0.0389     |
| _min_adv        | -4.58      |
| _min_discrew    | 0.000643   |
| _min_obs        | -1.46      |
| _std_act        | 0.593933   |
| _std_adv        | 1          |
| _std_discrew    | 0.253      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.836      |
| ExplainedVarOld | 0.827      |
| KL              | 0.00229271 |
| Phi_loss        | 112.473    |
| PolicyEntropy   | 3.06798    |
| PolicyLoss      | -0.0136706 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0421     |
| _MeanReward     | 1.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.25237    |
| _max_adv        | 3.22       |
| _max_discrew    | 2.34       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0611208 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.46       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.41      |
| _min_discrew    | 0.000623   |
| _min_obs        | -1.36      |
| _std_act        | 0.591874   |
| _std_adv        | 1          |
| _std_discrew    | 0.268      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.847        |
| ExplainedVarOld | 0.842        |
| KL              | 0.00208588   |
| Phi_loss        | 126.779      |
| PolicyEntropy   | 3.05604      |
| PolicyLoss      | -0.000370614 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0411       |
| _MeanReward     | 1.9e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 3.13586      |
| _max_adv        | 3.13         |
| _max_discrew    | 2.45         |
| _max_obs        | 1.59         |
| _mean_act       | -0.0611192   |
| _mean_adv       | -4.55e-17    |
| _mean_discrew   | 1.54         |
| _mean_obs       | 0.0371       |
| _min_adv        | -4.3         |
| _min_discrew    | -0.00234     |
| _min_obs        | -1.39        |
| _std_act        | 0.582812     |
| _std_adv        | 1            |
| _std_discrew    | 0.314        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.862       |
| ExplainedVarOld | 0.843       |
| KL              | 0.0017865   |
| Phi_loss        | 123.131     |
| PolicyEntropy   | 3.04316     |
| PolicyLoss      | -0.00315393 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0448      |
| _MeanReward     | 1.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.08525     |
| _max_adv        | 6.57        |
| _max_discrew    | 2.46        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0583725  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 1.53        |
| _mean_obs       | 0.0378      |
| _min_adv        | -3.55       |
| _min_discrew    | -0.00897    |
| _min_obs        | -1.51       |
| _std_act        | 0.588333    |
| _std_adv        | 1           |
| _std_discrew    | 0.297       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.817       |
| ExplainedVarOld | 0.798       |
| KL              | 0.00221873  |
| Phi_loss        | 118.576     |
| PolicyEntropy   | 3.04416     |
| PolicyLoss      | -0.00844526 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0544      |
| _MeanReward     | 1.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.16538     |
| _max_adv        | 3.46        |
| _max_discrew    | 2.61        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0691337  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.59        |
| _mean_obs       | 0.0383      |
| _min_adv        | -3.67       |
| _min_discrew    | -0.0189     |
| _min_obs        | -1.36       |
| _std_act        | 0.592845    |
| _std_adv        | 1           |
| _std_discrew    | 0.403       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.854      |
| ExplainedVarOld | 0.839      |
| KL              | 0.00218979 |
| Phi_loss        | 120.437    |
| PolicyEntropy   | 3.03398    |
| PolicyLoss      | 0.0127142  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0591     |
| _MeanReward     | 1.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1412     |
| _max_adv        | 2.92       |
| _max_discrew    | 2.3        |
| _max_obs        | 1.43       |
| _mean_act       | -0.0620731 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.55       |
| _mean_obs       | 0.0365     |
| _min_adv        | -4.79      |
| _min_discrew    | -0.0267    |
| _min_obs        | -1.47      |
| _std_act        | 0.581758   |
| _std_adv        | 1          |
| _std_discrew    | 0.265      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.83         |
| ExplainedVarOld | 0.818        |
| KL              | 0.00204519   |
| Phi_loss        | 111.153      |
| PolicyEntropy   | 3.02206      |
| PolicyLoss      | -0.000707107 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0452       |
| _MeanReward     | 1.87e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.29625      |
| _max_adv        | 3.38         |
| _max_discrew    | 2.46         |
| _max_obs        | 1.37         |
| _mean_act       | -0.0646498   |
| _mean_adv       | -8.53e-18    |
| _mean_discrew   | 1.51         |
| _mean_obs       | 0.0371       |
| _min_adv        | -4.48        |
| _min_discrew    | 0.00174      |
| _min_obs        | -1.44        |
| _std_act        | 0.593683     |
| _std_adv        | 1            |
| _std_discrew    | 0.305        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.843       |
| ExplainedVarOld | 0.838       |
| KL              | 0.00173624  |
| Phi_loss        | 118.995     |
| PolicyEntropy   | 3.00807     |
| PolicyLoss      | -0.00432036 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0485      |
| _MeanReward     | 1.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.1114      |
| _max_adv        | 2.75        |
| _max_discrew    | 2.64        |
| _max_obs        | 1.48        |
| _mean_act       | -0.065014   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.64        |
| _mean_obs       | 0.0377      |
| _min_adv        | -4.49       |
| _min_discrew    | 0.00399     |
| _min_obs        | -1.41       |
| _std_act        | 0.589648    |
| _std_adv        | 1           |
| _std_discrew    | 0.304       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.868      |
| ExplainedVarOld | 0.86       |
| KL              | 0.00194583 |
| Phi_loss        | 129.114    |
| PolicyEntropy   | 2.98651    |
| PolicyLoss      | 0.00501124 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0433     |
| _MeanReward     | 1.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.21376    |
| _max_adv        | 2.76       |
| _max_discrew    | 2.47       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0617909 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 1.57       |
| _mean_obs       | 0.0378     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.00241   |
| _min_obs        | -1.38      |
| _std_act        | 0.588675   |
| _std_adv        | 1          |
| _std_discrew    | 0.307      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.856       |
| ExplainedVarOld | 0.853       |
| KL              | 0.00228821  |
| Phi_loss        | 129.007     |
| PolicyEntropy   | 2.96845     |
| PolicyLoss      | -0.00151735 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0448      |
| _MeanReward     | 1.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01244     |
| _max_adv        | 2.82        |
| _max_discrew    | 2.51        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0644145  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.61        |
| _mean_obs       | 0.0373      |
| _min_adv        | -3.98       |
| _min_discrew    | -0.00442    |
| _min_obs        | -1.48       |
| _std_act        | 0.591396    |
| _std_adv        | 1           |
| _std_discrew    | 0.299       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.829       |
| ExplainedVarOld | 0.824       |
| KL              | 0.00196075  |
| Phi_loss        | 130.804     |
| PolicyEntropy   | 2.95124     |
| PolicyLoss      | -0.00768734 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0519      |
| _MeanReward     | 1.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00141     |
| _max_adv        | 3.04        |
| _max_discrew    | 2.53        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0618848  |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 1.61        |
| _mean_obs       | 0.0361      |
| _min_adv        | -4.02       |
| _min_discrew    | 0.000392    |
| _min_obs        | -1.32       |
| _std_act        | 0.580743    |
| _std_adv        | 1           |
| _std_discrew    | 0.308       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.834      |
| ExplainedVarOld | 0.826      |
| KL              | 0.0018699  |
| Phi_loss        | 129.297    |
| PolicyEntropy   | 2.93439    |
| PolicyLoss      | -0.004122  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0512     |
| _MeanReward     | 1.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15813    |
| _max_adv        | 3.05       |
| _max_discrew    | 2.44       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0625888 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.62       |
| _mean_obs       | 0.0365     |
| _min_adv        | -3.86      |
| _min_discrew    | -0.00409   |
| _min_obs        | -1.39      |
| _std_act        | 0.580479   |
| _std_adv        | 1          |
| _std_discrew    | 0.271      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.846       |
| ExplainedVarOld | 0.838       |
| KL              | 0.00194096  |
| Phi_loss        | 133.801     |
| PolicyEntropy   | 2.93685     |
| PolicyLoss      | -0.00838279 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0418      |
| _MeanReward     | 2.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.42987     |
| _max_adv        | 3.19        |
| _max_discrew    | 2.57        |
| _max_obs        | 1.43        |
| _mean_act       | -0.065783   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 1.67        |
| _mean_obs       | 0.0373      |
| _min_adv        | -3.61       |
| _min_discrew    | -0.00228    |
| _min_obs        | -1.55       |
| _std_act        | 0.588976    |
| _std_adv        | 1           |
| _std_discrew    | 0.391       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.889      |
| ExplainedVarOld | 0.871      |
| KL              | 0.00198276 |
| Phi_loss        | 128.626    |
| PolicyEntropy   | 2.9182     |
| PolicyLoss      | -0.0013357 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0436     |
| _MeanReward     | 2.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91505    |
| _max_adv        | 2.9        |
| _max_discrew    | 2.66       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0716922 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.73       |
| _mean_obs       | 0.0364     |
| _min_adv        | -3.24      |
| _min_discrew    | 0.000478   |
| _min_obs        | -1.36      |
| _std_act        | 0.583768   |
| _std_adv        | 1          |
| _std_discrew    | 0.352      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.826     |
| ExplainedVarOld | 0.826     |
| KL              | 0.0018319 |
| Phi_loss        | 131.001   |
| PolicyEntropy   | 2.89152   |
| PolicyLoss      | 0.0132051 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0617    |
| _MeanReward     | 2.05e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.15386   |
| _max_adv        | 3.13      |
| _max_discrew    | 2.75      |
| _max_obs        | 1.52      |
| _mean_act       | -0.077484 |
| _mean_adv       | 8.53e-18  |
| _mean_discrew   | 1.7       |
| _mean_obs       | 0.0363    |
| _min_adv        | -4.81     |
| _min_discrew    | -0.348    |
| _min_obs        | -1.5      |
| _std_act        | 0.589259  |
| _std_adv        | 1         |
| _std_discrew    | 0.416     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.866       |
| ExplainedVarOld | 0.843       |
| KL              | 0.00192479  |
| Phi_loss        | 126.683     |
| PolicyEntropy   | 2.87932     |
| PolicyLoss      | -0.00672336 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0559      |
| _MeanReward     | 1.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.44092     |
| _max_adv        | 2.67        |
| _max_discrew    | 2.5         |
| _max_obs        | 1.54        |
| _mean_act       | -0.0800625  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.63        |
| _mean_obs       | 0.0356      |
| _min_adv        | -9.28       |
| _min_discrew    | -0.46       |
| _min_obs        | -1.32       |
| _std_act        | 0.592794    |
| _std_adv        | 1           |
| _std_discrew    | 0.429       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.83       |
| ExplainedVarOld | 0.823      |
| KL              | 0.00182567 |
| Phi_loss        | 124.691    |
| PolicyEntropy   | 2.87195    |
| PolicyLoss      | -0.0151116 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0736     |
| _MeanReward     | 2.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.24454    |
| _max_adv        | 4.08       |
| _max_discrew    | 2.82       |
| _max_obs        | 1.28       |
| _mean_act       | -0.073379  |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 1.79       |
| _mean_obs       | 0.0362     |
| _min_adv        | -4.12      |
| _min_discrew    | 0.00167    |
| _min_obs        | -1.43      |
| _std_act        | 0.582541   |
| _std_adv        | 1          |
| _std_discrew    | 0.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.886       |
| ExplainedVarOld | 0.875       |
| KL              | 0.00181369  |
| Phi_loss        | 127.072     |
| PolicyEntropy   | 2.86554     |
| PolicyLoss      | -0.00119879 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0442      |
| _MeanReward     | 2.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91518     |
| _max_adv        | 4.08        |
| _max_discrew    | 2.81        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0682237  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 1.69        |
| _mean_obs       | 0.0372      |
| _min_adv        | -3.34       |
| _min_discrew    | 0.00144     |
| _min_obs        | -1.55       |
| _std_act        | 0.58316     |
| _std_adv        | 1           |
| _std_discrew    | 0.331       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.853       |
| ExplainedVarOld | 0.839       |
| KL              | 0.0020972   |
| Phi_loss        | 134.452     |
| PolicyEntropy   | 2.85044     |
| PolicyLoss      | -0.00802127 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0508      |
| _MeanReward     | 2.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03919     |
| _max_adv        | 3.2         |
| _max_discrew    | 2.63        |
| _max_obs        | 1.27        |
| _mean_act       | -0.0658329  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.75        |
| _mean_obs       | 0.0364      |
| _min_adv        | -4.19       |
| _min_discrew    | -0.0407     |
| _min_obs        | -1.37       |
| _std_act        | 0.580431    |
| _std_adv        | 1           |
| _std_discrew    | 0.346       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.89        |
| ExplainedVarOld | 0.888       |
| KL              | 0.00185278  |
| Phi_loss        | 145.242     |
| PolicyEntropy   | 2.83471     |
| PolicyLoss      | -0.00466814 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0382      |
| _MeanReward     | 2.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03261     |
| _max_adv        | 3.75        |
| _max_discrew    | 2.55        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0699928  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.7         |
| _mean_obs       | 0.0354      |
| _min_adv        | -4.46       |
| _min_discrew    | 0.00444     |
| _min_obs        | -1.53       |
| _std_act        | 0.578804    |
| _std_adv        | 1           |
| _std_discrew    | 0.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.814       |
| ExplainedVarOld | 0.78        |
| KL              | 0.00188364  |
| Phi_loss        | 132.933     |
| PolicyEntropy   | 2.82845     |
| PolicyLoss      | -0.00190221 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0524      |
| _MeanReward     | 2.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.4257      |
| _max_adv        | 3.28        |
| _max_discrew    | 2.5         |
| _max_obs        | 1.41        |
| _mean_act       | -0.0717588  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.67        |
| _mean_obs       | 0.0363      |
| _min_adv        | -3.36       |
| _min_discrew    | 0.00101     |
| _min_obs        | -1.33       |
| _std_act        | 0.585419    |
| _std_adv        | 1           |
| _std_discrew    | 0.321       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.82       |
| ExplainedVarOld | 0.814      |
| KL              | 0.00216821 |
| Phi_loss        | 138.358    |
| PolicyEntropy   | 2.80988    |
| PolicyLoss      | 0.00721713 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0579     |
| _MeanReward     | 2.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19071    |
| _max_adv        | 3.09       |
| _max_discrew    | 2.74       |
| _max_obs        | 1.3        |
| _mean_act       | -0.066877  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.79       |
| _mean_obs       | 0.0366     |
| _min_adv        | -3.47      |
| _min_discrew    | 0.00491    |
| _min_obs        | -1.62      |
| _std_act        | 0.581382   |
| _std_adv        | 1          |
| _std_discrew    | 0.394      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.848      |
| ExplainedVarOld | 0.822      |
| KL              | 0.00211254 |
| Phi_loss        | 139.978    |
| PolicyEntropy   | 2.79975    |
| PolicyLoss      | 0.00567104 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0629     |
| _MeanReward     | 2.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.08948    |
| _max_adv        | 2.99       |
| _max_discrew    | 2.84       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0698497 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 1.85       |
| _mean_obs       | 0.0363     |
| _min_adv        | -4.35      |
| _min_discrew    | -0.00153   |
| _min_obs        | -1.47      |
| _std_act        | 0.578146   |
| _std_adv        | 1          |
| _std_discrew    | 0.381      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.845      |
| ExplainedVarOld | 0.839      |
| KL              | 0.00212006 |
| Phi_loss        | 141.887    |
| PolicyEntropy   | 2.79175    |
| PolicyLoss      | -0.0217481 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0593     |
| _MeanReward     | 2.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.16821    |
| _max_adv        | 3.39       |
| _max_discrew    | 2.78       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0709616 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.77       |
| _mean_obs       | 0.036      |
| _min_adv        | -3.83      |
| _min_discrew    | 0.00259    |
| _min_obs        | -1.28      |
| _std_act        | 0.584347   |
| _std_adv        | 1          |
| _std_discrew    | 0.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.85       |
| ExplainedVarOld | 0.839      |
| KL              | 0.00158941 |
| Phi_loss        | 146.543    |
| PolicyEntropy   | 2.78364    |
| PolicyLoss      | -0.0109674 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0563     |
| _MeanReward     | 2.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.17745    |
| _max_adv        | 3.21       |
| _max_discrew    | 2.87       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0727517 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.86       |
| _mean_obs       | 0.0356     |
| _min_adv        | -4.08      |
| _min_discrew    | 0.00113    |
| _min_obs        | -1.44      |
| _std_act        | 0.576888   |
| _std_adv        | 1          |
| _std_discrew    | 0.388      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.857       |
| ExplainedVarOld | 0.852       |
| KL              | 0.0020958   |
| Phi_loss        | 153.504     |
| PolicyEntropy   | 2.76708     |
| PolicyLoss      | -0.00246508 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0576      |
| _MeanReward     | 2.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02884     |
| _max_adv        | 2.85        |
| _max_discrew    | 2.71        |
| _max_obs        | 1.27        |
| _mean_act       | -0.0675417  |
| _mean_adv       | 2.98e-17    |
| _mean_discrew   | 1.82        |
| _mean_obs       | 0.0364      |
| _min_adv        | -5.02       |
| _min_discrew    | 0.0033      |
| _min_obs        | -1.36       |
| _std_act        | 0.582677    |
| _std_adv        | 1           |
| _std_discrew    | 0.374       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.864      |
| ExplainedVarOld | 0.861      |
| KL              | 0.00215062 |
| Phi_loss        | 155.265    |
| PolicyEntropy   | 2.75332    |
| PolicyLoss      | -0.0175348 |
| Steps           | 10000      |
| VarFuncLoss     | 0.051      |
| _MeanReward     | 2.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.58134    |
| _max_adv        | 2.83       |
| _max_discrew    | 2.72       |
| _max_obs        | 1.55       |
| _mean_act       | -0.0963519 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.67       |
| _mean_obs       | 0.0345     |
| _min_adv        | -9.77      |
| _min_discrew    | -0.644     |
| _min_obs        | -1.35      |
| _std_act        | 0.620982   |
| _std_adv        | 1          |
| _std_discrew    | 0.743      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.842       |
| ExplainedVarOld | 0.816       |
| KL              | 0.00201921  |
| Phi_loss        | 129.986     |
| PolicyEntropy   | 2.72129     |
| PolicyLoss      | -0.00693375 |
| Steps           | 10000       |
| VarFuncLoss     | 0.118       |
| _MeanReward     | 2.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9534      |
| _max_adv        | 3.7         |
| _max_discrew    | 2.92        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0761951  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.91        |
| _mean_obs       | 0.0361      |
| _min_adv        | -3.42       |
| _min_discrew    | 0.000267    |
| _min_obs        | -1.58       |
| _std_act        | 0.583754    |
| _std_adv        | 1           |
| _std_discrew    | 0.421       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.872       |
| ExplainedVarOld | 0.868       |
| KL              | 0.00194091  |
| Phi_loss        | 146.603     |
| PolicyEntropy   | 2.69412     |
| PolicyLoss      | -0.00533093 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0565      |
| _MeanReward     | 2.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.12513     |
| _max_adv        | 5.95        |
| _max_discrew    | 3.04        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0800553  |
| _mean_adv       | 7.11e-18    |
| _mean_discrew   | 1.88        |
| _mean_obs       | 0.0356      |
| _min_adv        | -4.62       |
| _min_discrew    | -0.0111     |
| _min_obs        | -1.42       |
| _std_act        | 0.584854    |
| _std_adv        | 1           |
| _std_discrew    | 0.454       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.878      |
| ExplainedVarOld | 0.859      |
| KL              | 0.00221378 |
| Phi_loss        | 147.345    |
| PolicyEntropy   | 2.66183    |
| PolicyLoss      | 0.00418731 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0556     |
| _MeanReward     | 2.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.28874    |
| _max_adv        | 3.46       |
| _max_discrew    | 2.82       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0768253 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.89       |
| _mean_obs       | 0.0357     |
| _min_adv        | -4.06      |
| _min_discrew    | 0.00362    |
| _min_obs        | -1.4       |
| _std_act        | 0.584382   |
| _std_adv        | 1          |
| _std_discrew    | 0.417      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.894      |
| ExplainedVarOld | 0.892      |
| KL              | 0.00211521 |
| Phi_loss        | 169.03     |
| PolicyEntropy   | 2.64614    |
| PolicyLoss      | -0.0115216 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0445     |
| _MeanReward     | 2.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90329    |
| _max_adv        | 3          |
| _max_discrew    | 2.77       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0758714 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.89       |
| _mean_obs       | 0.0349     |
| _min_adv        | -3.82      |
| _min_discrew    | 0.00695    |
| _min_obs        | -1.29      |
| _std_act        | 0.576996   |
| _std_adv        | 1          |
| _std_discrew    | 0.369      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.869      |
| KL              | 0.00186229 |
| Phi_loss        | 159.202    |
| PolicyEntropy   | 2.6425     |
| PolicyLoss      | -0.0144479 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0455     |
| _MeanReward     | 2.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13444    |
| _max_adv        | 3.28       |
| _max_discrew    | 3.07       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0747893 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 1.97       |
| _mean_obs       | 0.0363     |
| _min_adv        | -3.76      |
| _min_discrew    | -0.00281   |
| _min_obs        | -1.5       |
| _std_act        | 0.58534    |
| _std_adv        | 1          |
| _std_discrew    | 0.483      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.872      |
| ExplainedVarOld | 0.868      |
| KL              | 0.00172979 |
| Phi_loss        | 155.622    |
| PolicyEntropy   | 2.62454    |
| PolicyLoss      | -0.012283  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0623     |
| _MeanReward     | 2.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.07217    |
| _max_adv        | 2.82       |
| _max_discrew    | 2.91       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0779749 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.99       |
| _mean_obs       | 0.0359     |
| _min_adv        | -4.34      |
| _min_discrew    | 0.0053     |
| _min_obs        | -1.51      |
| _std_act        | 0.582996   |
| _std_adv        | 1          |
| _std_discrew    | 0.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.909      |
| KL              | 0.00199921 |
| Phi_loss        | 157.291    |
| PolicyEntropy   | 2.62386    |
| PolicyLoss      | -0.0196815 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0337     |
| _MeanReward     | 2.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15278    |
| _max_adv        | 3.15       |
| _max_discrew    | 3.01       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0841672 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.07       |
| _mean_obs       | 0.0347     |
| _min_adv        | -5.07      |
| _min_discrew    | -0.00098   |
| _min_obs        | -1.47      |
| _std_act        | 0.58036    |
| _std_adv        | 1          |
| _std_discrew    | 0.434      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.886       |
| ExplainedVarOld | 0.878       |
| KL              | 0.00235934  |
| Phi_loss        | 155.63      |
| PolicyEntropy   | 2.60287     |
| PolicyLoss      | -0.00414536 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0518      |
| _MeanReward     | 2.29e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94236     |
| _max_adv        | 2.29        |
| _max_discrew    | 3.11        |
| _max_obs        | 1.56        |
| _mean_act       | -0.0995683  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 1.88        |
| _mean_obs       | 0.0343      |
| _min_adv        | -13.4       |
| _min_discrew    | -0.636      |
| _min_obs        | -1.31       |
| _std_act        | 0.615597    |
| _std_adv        | 1           |
| _std_discrew    | 0.771       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.87       |
| ExplainedVarOld | 0.841      |
| KL              | 0.00431142 |
| Phi_loss        | 127.202    |
| PolicyEntropy   | 2.61309    |
| PolicyLoss      | 0.0049386  |
| Steps           | 10000      |
| VarFuncLoss     | 0.1        |
| _MeanReward     | 2.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06127    |
| _max_adv        | 4.01       |
| _max_discrew    | 3.03       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0768179 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.03       |
| _mean_obs       | 0.0345     |
| _min_adv        | -3.73      |
| _min_discrew    | 0.00498    |
| _min_obs        | -1.4       |
| _std_act        | 0.579483   |
| _std_adv        | 1          |
| _std_discrew    | 0.429      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.883      |
| KL              | 0.00204092 |
| Phi_loss        | 167.37     |
| PolicyEntropy   | 2.6131     |
| PolicyLoss      | -0.0149648 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0482     |
| _MeanReward     | 2.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.42645    |
| _max_adv        | 12.2       |
| _max_discrew    | 3.04       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0835304 |
| _mean_adv       | -2.91e-17  |
| _mean_discrew   | 2.03       |
| _mean_obs       | 0.0345     |
| _min_adv        | -4.23      |
| _min_discrew    | 0.00339    |
| _min_obs        | -1.49      |
| _std_act        | 0.579256   |
| _std_adv        | 1          |
| _std_discrew    | 0.437      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.878       |
| ExplainedVarOld | 0.854       |
| KL              | 0.00228884  |
| Phi_loss        | 149.827     |
| PolicyEntropy   | 2.60912     |
| PolicyLoss      | -0.00493732 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0535      |
| _MeanReward     | 2.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06977     |
| _max_adv        | 2.94        |
| _max_discrew    | 3.22        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0833704  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.12        |
| _mean_obs       | 0.0352      |
| _min_adv        | -4.74       |
| _min_discrew    | 0.0074      |
| _min_obs        | -1.38       |
| _std_act        | 0.579961    |
| _std_adv        | 1           |
| _std_discrew    | 0.516       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.902      |
| KL              | 0.00199354 |
| Phi_loss        | 169.749    |
| PolicyEntropy   | 2.58899    |
| PolicyLoss      | 0.00684809 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0482     |
| _MeanReward     | 2.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91385    |
| _max_adv        | 3.65       |
| _max_discrew    | 3.05       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0845491 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.12       |
| _mean_obs       | 0.035      |
| _min_adv        | -4.89      |
| _min_discrew    | 0.000495   |
| _min_obs        | -1.57      |
| _std_act        | 0.584832   |
| _std_adv        | 1          |
| _std_discrew    | 0.495      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.914      |
| KL              | 0.00176293 |
| Phi_loss        | 166.42     |
| PolicyEntropy   | 2.57733    |
| PolicyLoss      | -0.010341  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0397     |
| _MeanReward     | 2.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.27507    |
| _max_adv        | 2.27       |
| _max_discrew    | 2.98       |
| _max_obs        | 1.57       |
| _mean_act       | -0.0825309 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.05       |
| _mean_obs       | 0.0341     |
| _min_adv        | -8.64      |
| _min_discrew    | -0.329     |
| _min_obs        | -1.49      |
| _std_act        | 0.585072   |
| _std_adv        | 1          |
| _std_discrew    | 0.523      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.863        |
| ExplainedVarOld | 0.858        |
| KL              | 0.00235522   |
| Phi_loss        | 169.423      |
| PolicyEntropy   | 2.56637      |
| PolicyLoss      | -0.000616167 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0719       |
| _MeanReward     | 2.53e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.95386      |
| _max_adv        | 3.23         |
| _max_discrew    | 3.02         |
| _max_obs        | 1.37         |
| _mean_act       | -0.0807946   |
| _mean_adv       | 2.84e-18     |
| _mean_discrew   | 2.1          |
| _mean_obs       | 0.0333       |
| _min_adv        | -6.24        |
| _min_discrew    | 0.00239      |
| _min_obs        | -1.41        |
| _std_act        | 0.577444     |
| _std_adv        | 1            |
| _std_discrew    | 0.536        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.91        |
| KL              | 0.00264462  |
| Phi_loss        | 158.271     |
| PolicyEntropy   | 2.54122     |
| PolicyLoss      | -0.00696751 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0419      |
| _MeanReward     | 2.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.39951     |
| _max_adv        | 4.75        |
| _max_discrew    | 2.91        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0793308  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.03        |
| _mean_obs       | 0.0338      |
| _min_adv        | -5.08       |
| _min_discrew    | 0.00288     |
| _min_obs        | -1.41       |
| _std_act        | 0.584214    |
| _std_adv        | 1           |
| _std_discrew    | 0.447       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.886      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00251074 |
| Phi_loss        | 174.15     |
| PolicyEntropy   | 2.52789    |
| PolicyLoss      | -0.0096229 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0536     |
| _MeanReward     | 2.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.4614     |
| _max_adv        | 3.22       |
| _max_discrew    | 3.14       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0865246 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.12       |
| _mean_obs       | 0.0335     |
| _min_adv        | -4.53      |
| _min_discrew    | -0.00208   |
| _min_obs        | -1.45      |
| _std_act        | 0.58162    |
| _std_adv        | 1          |
| _std_discrew    | 0.544      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.912       |
| KL              | 0.00226095  |
| Phi_loss        | 168.825     |
| PolicyEntropy   | 2.53036     |
| PolicyLoss      | -0.00907156 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0483      |
| _MeanReward     | 2.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02055     |
| _max_adv        | 3.13        |
| _max_discrew    | 3.04        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0824312  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.16        |
| _mean_obs       | 0.0334      |
| _min_adv        | -4.66       |
| _min_discrew    | 0.00588     |
| _min_obs        | -1.26       |
| _std_act        | 0.585166    |
| _std_adv        | 1           |
| _std_discrew    | 0.511       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.917       |
| KL              | 0.00202981  |
| Phi_loss        | 183.271     |
| PolicyEntropy   | 2.50949     |
| PolicyLoss      | -0.00898523 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0375      |
| _MeanReward     | 2.65e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.53618     |
| _max_adv        | 2.92        |
| _max_discrew    | 3.18        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0841083  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.19        |
| _mean_obs       | 0.0353      |
| _min_adv        | -4.57       |
| _min_discrew    | 0.00429     |
| _min_obs        | -1.5        |
| _std_act        | 0.591707    |
| _std_adv        | 1           |
| _std_discrew    | 0.524       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.921      |
| KL              | 0.00214705 |
| Phi_loss        | 176.04     |
| PolicyEntropy   | 2.50155    |
| PolicyLoss      | -0.0209886 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0403     |
| _MeanReward     | 2.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.28046    |
| _max_adv        | 3.34       |
| _max_discrew    | 3.03       |
| _max_obs        | 1.25       |
| _mean_act       | -0.084223  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 2.2        |
| _mean_obs       | 0.034      |
| _min_adv        | -4.64      |
| _min_discrew    | -0.00657   |
| _min_obs        | -1.38      |
| _std_act        | 0.5877     |
| _std_adv        | 1          |
| _std_discrew    | 0.498      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.925      |
| KL              | 0.00226849 |
| Phi_loss        | 174.605    |
| PolicyEntropy   | 2.47254    |
| PolicyLoss      | -0.0110178 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0361     |
| _MeanReward     | 2.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.05996    |
| _max_adv        | 3.74       |
| _max_discrew    | 3.29       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0834589 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 2.29       |
| _mean_obs       | 0.0351     |
| _min_adv        | -5.49      |
| _min_discrew    | 0.00858    |
| _min_obs        | -1.38      |
| _std_act        | 0.587363   |
| _std_adv        | 1          |
| _std_discrew    | 0.537      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00192073 |
| Phi_loss        | 167.193    |
| PolicyEntropy   | 2.46398    |
| PolicyLoss      | -0.0203608 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0424     |
| _MeanReward     | 2.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1204     |
| _max_adv        | 2.74       |
| _max_discrew    | 3.27       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0850225 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.21       |
| _mean_obs       | 0.0348     |
| _min_adv        | -4.35      |
| _min_discrew    | 0.00645    |
| _min_obs        | -1.44      |
| _std_act        | 0.598462   |
| _std_adv        | 1          |
| _std_discrew    | 0.544      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.896       |
| ExplainedVarOld | 0.894       |
| KL              | 0.00235205  |
| Phi_loss        | 178.014     |
| PolicyEntropy   | 2.44711     |
| PolicyLoss      | -0.00300841 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0571      |
| _MeanReward     | 2.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0284      |
| _max_adv        | 3.1         |
| _max_discrew    | 3.19        |
| _max_obs        | 1.18        |
| _mean_act       | -0.085074   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.29        |
| _mean_obs       | 0.0347      |
| _min_adv        | -5.42       |
| _min_discrew    | -0.00783    |
| _min_obs        | -1.54       |
| _std_act        | 0.589006    |
| _std_adv        | 1           |
| _std_discrew    | 0.605       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.925       |
| KL              | 0.0021685   |
| Phi_loss        | 183.133     |
| PolicyEntropy   | 2.43132     |
| PolicyLoss      | 0.000388757 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0451      |
| _MeanReward     | 2.82e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96705     |
| _max_adv        | 3.5         |
| _max_discrew    | 3.25        |
| _max_obs        | 1.27        |
| _mean_act       | -0.086279   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.32        |
| _mean_obs       | 0.0344      |
| _min_adv        | -4.96       |
| _min_discrew    | -0.00167    |
| _min_obs        | -1.31       |
| _std_act        | 0.586505    |
| _std_adv        | 1           |
| _std_discrew    | 0.577       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.95        |
| ExplainedVarOld | 0.948       |
| KL              | 0.00219657  |
| Phi_loss        | 193.491     |
| PolicyEntropy   | 2.41371     |
| PolicyLoss      | -0.00773786 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0291      |
| _MeanReward     | 2.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.38607     |
| _max_adv        | 2.74        |
| _max_discrew    | 3.17        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0877479  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.29        |
| _mean_obs       | 0.033       |
| _min_adv        | -5.21       |
| _min_discrew    | 0.00822     |
| _min_obs        | -1.47       |
| _std_act        | 0.582707    |
| _std_adv        | 1           |
| _std_discrew    | 0.505       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.922      |
| KL              | 0.00259215 |
| Phi_loss        | 175.918    |
| PolicyEntropy   | 2.41604    |
| PolicyLoss      | -0.0153277 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0364     |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.20743    |
| _max_adv        | 3.25       |
| _max_discrew    | 3.15       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0841489 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.24       |
| _mean_obs       | 0.034      |
| _min_adv        | -4.62      |
| _min_discrew    | -0.00103   |
| _min_obs        | -1.23      |
| _std_act        | 0.586614   |
| _std_adv        | 1          |
| _std_discrew    | 0.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.911       |
| KL              | 0.0028205   |
| Phi_loss        | 190.611     |
| PolicyEntropy   | 2.38283     |
| PolicyLoss      | -0.00877397 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0491      |
| _MeanReward     | 2.82e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87845     |
| _max_adv        | 3.44        |
| _max_discrew    | 3.29        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0859106  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.33        |
| _mean_obs       | 0.0338      |
| _min_adv        | -6.98       |
| _min_discrew    | 0.00436     |
| _min_obs        | -1.48       |
| _std_act        | 0.592417    |
| _std_adv        | 1           |
| _std_discrew    | 0.578       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.93       |
| ExplainedVarOld | 0.928      |
| KL              | 0.00266434 |
| Phi_loss        | 209.11     |
| PolicyEntropy   | 2.34524    |
| PolicyLoss      | 0.00257336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0422     |
| _MeanReward     | 2.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80381    |
| _max_adv        | 3.86       |
| _max_discrew    | 3.42       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0865246 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.37       |
| _mean_obs       | 0.035      |
| _min_adv        | -4.4       |
| _min_discrew    | 0.00446    |
| _min_obs        | -1.39      |
| _std_act        | 0.590432   |
| _std_adv        | 1          |
| _std_discrew    | 0.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.924      |
| KL              | 0.00237915 |
| Phi_loss        | 209.472    |
| PolicyEntropy   | 2.32439    |
| PolicyLoss      | 0.0010879  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0406     |
| _MeanReward     | 2.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.04369    |
| _max_adv        | 5.1        |
| _max_discrew    | 3.25       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0869606 |
| _mean_adv       | -2.13e-18  |
| _mean_discrew   | 2.4        |
| _mean_obs       | 0.0349     |
| _min_adv        | -5.06      |
| _min_discrew    | 0.00575    |
| _min_obs        | -1.45      |
| _std_act        | 0.598635   |
| _std_adv        | 1          |
| _std_discrew    | 0.646      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.943      |
| KL              | 0.00320133 |
| Phi_loss        | 187.539    |
| PolicyEntropy   | 2.31494    |
| PolicyLoss      | -0.023256  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0321     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71765    |
| _max_adv        | 4.44       |
| _max_discrew    | 3.38       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0903205 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0348     |
| _min_adv        | -6.81      |
| _min_discrew    | 0.00186    |
| _min_obs        | -1.43      |
| _std_act        | 0.589739   |
| _std_adv        | 1          |
| _std_discrew    | 0.595      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.939      |
| KL              | 0.00238537 |
| Phi_loss        | 207.8      |
| PolicyEntropy   | 2.29891    |
| PolicyLoss      | -0.0229119 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0361     |
| _MeanReward     | 2.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.19642    |
| _max_adv        | 3.58       |
| _max_discrew    | 3.29       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0895933 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0339     |
| _min_adv        | -5.9       |
| _min_discrew    | 0.00567    |
| _min_obs        | -1.33      |
| _std_act        | 0.591612   |
| _std_adv        | 1          |
| _std_discrew    | 0.608      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.956      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00197322 |
| Phi_loss        | 173.986    |
| PolicyEntropy   | 2.30302    |
| PolicyLoss      | -0.037974  |
| Steps           | 10000      |
| VarFuncLoss     | 0.027      |
| _MeanReward     | 3.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.1408     |
| _max_adv        | 3.71       |
| _max_discrew    | 3.42       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0923909 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.51       |
| _mean_obs       | 0.0337     |
| _min_adv        | -5.72      |
| _min_discrew    | 0.00596    |
| _min_obs        | -1.41      |
| _std_act        | 0.597016   |
| _std_adv        | 1          |
| _std_discrew    | 0.609      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.944      |
| KL              | 0.00309168 |
| Phi_loss        | 206.098    |
| PolicyEntropy   | 2.29041    |
| PolicyLoss      | -0.0150409 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0337     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.73317    |
| _max_adv        | 6.44       |
| _max_discrew    | 3.4        |
| _max_obs        | 1.26       |
| _mean_act       | -0.0914192 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.47       |
| _mean_obs       | 0.0333     |
| _min_adv        | -5.51      |
| _min_discrew    | 0.0099     |
| _min_obs        | -1.48      |
| _std_act        | 0.59405    |
| _std_adv        | 1          |
| _std_discrew    | 0.592      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00229009 |
| Phi_loss        | 193.962    |
| PolicyEntropy   | 2.27636    |
| PolicyLoss      | -0.0141429 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8965     |
| _max_adv        | 2.79       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0894716 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 2.45       |
| _mean_obs       | 0.0341     |
| _min_adv        | -6.58      |
| _min_discrew    | 0.00707    |
| _min_obs        | -1.36      |
| _std_act        | 0.60041    |
| _std_adv        | 1          |
| _std_discrew    | 0.619      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.937      |
| KL              | 0.0022328  |
| Phi_loss        | 194.0      |
| PolicyEntropy   | 2.26722    |
| PolicyLoss      | -0.0130233 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0357     |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.99244    |
| _max_adv        | 3.05       |
| _max_discrew    | 3.32       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0899328 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.0335     |
| _min_adv        | -6.01      |
| _min_discrew    | 0.00671    |
| _min_obs        | -1.46      |
| _std_act        | 0.598059   |
| _std_adv        | 1          |
| _std_discrew    | 0.622      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.961       |
| KL              | 0.00222168  |
| Phi_loss        | 215.316     |
| PolicyEntropy   | 2.25564     |
| PolicyLoss      | -0.00173469 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 3.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.27071     |
| _max_adv        | 3.6         |
| _max_discrew    | 3.46        |
| _max_obs        | 1.62        |
| _mean_act       | -0.0935929  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 2.51        |
| _mean_obs       | 0.0341      |
| _min_adv        | -6.93       |
| _min_discrew    | -0.0634     |
| _min_obs        | -1.48       |
| _std_act        | 0.608592    |
| _std_adv        | 1           |
| _std_discrew    | 0.686       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.957      |
| KL              | 0.00258873 |
| Phi_loss        | 199.419    |
| PolicyEntropy   | 2.23514    |
| PolicyLoss      | -0.0096003 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0274     |
| _MeanReward     | 2.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89661    |
| _max_adv        | 2.55       |
| _max_discrew    | 3.48       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0886484 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0341     |
| _min_adv        | -6.68      |
| _min_discrew    | 0.00359    |
| _min_obs        | -1.45      |
| _std_act        | 0.608525   |
| _std_adv        | 1          |
| _std_discrew    | 0.632      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.9         |
| KL              | 0.00277716  |
| Phi_loss        | 184.803     |
| PolicyEntropy   | 2.22839     |
| PolicyLoss      | -0.00728893 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0544      |
| _MeanReward     | 3.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.41653     |
| _max_adv        | 3.81        |
| _max_discrew    | 3.42        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0869316  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.55        |
| _mean_obs       | 0.0345      |
| _min_adv        | -7.73       |
| _min_discrew    | 0.00645     |
| _min_obs        | -1.44       |
| _std_act        | 0.605116    |
| _std_adv        | 1           |
| _std_discrew    | 0.664       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.958      |
| KL              | 0.0022051  |
| Phi_loss        | 210.307    |
| PolicyEntropy   | 2.20352    |
| PolicyLoss      | -0.0118232 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0291     |
| _MeanReward     | 3.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01563    |
| _max_adv        | 5.81       |
| _max_discrew    | 3.53       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0924037 |
| _mean_adv       | 2.7e-17    |
| _mean_discrew   | 2.61       |
| _mean_obs       | 0.0339     |
| _min_adv        | -6.55      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.54      |
| _std_act        | 0.601993   |
| _std_adv        | 1          |
| _std_discrew    | 0.682      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.97       |
| KL              | 0.0026662  |
| Phi_loss        | 215.34     |
| PolicyEntropy   | 2.19046    |
| PolicyLoss      | -0.0173469 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0194     |
| _MeanReward     | 3.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66639    |
| _max_adv        | 3.85       |
| _max_discrew    | 3.48       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0921563 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.6        |
| _mean_obs       | 0.0336     |
| _min_adv        | -7.9       |
| _min_discrew    | 0.00698    |
| _min_obs        | -1.57      |
| _std_act        | 0.600636   |
| _std_adv        | 1          |
| _std_discrew    | 0.662      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.959       |
| ExplainedVarOld | 0.958       |
| KL              | 0.00258711  |
| Phi_loss        | 226.668     |
| PolicyEntropy   | 2.18001     |
| PolicyLoss      | -0.00279701 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0273      |
| _MeanReward     | 3.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88632     |
| _max_adv        | 4.71        |
| _max_discrew    | 3.58        |
| _max_obs        | 1.15        |
| _mean_act       | -0.0964652  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 2.63        |
| _mean_obs       | 0.0333      |
| _min_adv        | -6.65       |
| _min_discrew    | 0.00392     |
| _min_obs        | -1.36       |
| _std_act        | 0.60103     |
| _std_adv        | 1           |
| _std_discrew    | 0.683       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.00269399 |
| Phi_loss        | 211.784    |
| PolicyEntropy   | 2.15555    |
| PolicyLoss      | -0.0192618 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0207     |
| _MeanReward     | 3.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09732    |
| _max_adv        | 4.47       |
| _max_discrew    | 3.66       |
| _max_obs        | 1.23       |
| _mean_act       | -0.091861  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.64       |
| _mean_obs       | 0.0342     |
| _min_adv        | -6.02      |
| _min_discrew    | 0.01       |
| _min_obs        | -1.41      |
| _std_act        | 0.610967   |
| _std_adv        | 1          |
| _std_discrew    | 0.697      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.966       |
| KL              | 0.0024755   |
| Phi_loss        | 241.976     |
| PolicyEntropy   | 2.13795     |
| PolicyLoss      | -0.00964191 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0229      |
| _MeanReward     | 3.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76126     |
| _max_adv        | 4.01        |
| _max_discrew    | 3.56        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0962993  |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 2.66        |
| _mean_obs       | 0.0332      |
| _min_adv        | -6.83       |
| _min_discrew    | 0.00481     |
| _min_obs        | -1.34       |
| _std_act        | 0.598343    |
| _std_adv        | 1           |
| _std_discrew    | 0.693       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00200628 |
| Phi_loss        | 253.465    |
| PolicyEntropy   | 2.11802    |
| PolicyLoss      | -0.0112182 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0197     |
| _MeanReward     | 2.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.38177    |
| _max_adv        | 2.16       |
| _max_discrew    | 3.6        |
| _max_obs        | 1.66       |
| _mean_act       | -0.113542  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.41       |
| _mean_obs       | 0.0325     |
| _min_adv        | -14.1      |
| _min_discrew    | -0.608     |
| _min_obs        | -1.42      |
| _std_act        | 0.647057   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
----------------------------------
| Beta            | 0.667        |
| ExplainedVarNew | 0.904        |
| ExplainedVarOld | 0.878        |
| KL              | 0.00808927   |
| Phi_loss        | 159.213      |
| PolicyEntropy   | 2.1186       |
| PolicyLoss      | -0.000885697 |
| Steps           | 10000        |
| VarFuncLoss     | 0.131        |
| _MeanReward     | 3.26e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.98052      |
| _max_adv        | 16.3         |
| _max_discrew    | 3.62         |
| _max_obs        | 1.11         |
| _mean_act       | -0.09955     |
| _mean_adv       | -2.13e-18    |
| _mean_discrew   | 2.67         |
| _mean_obs       | 0.0338       |
| _min_adv        | -7.65        |
| _min_discrew    | 0.00596      |
| _min_obs        | -1.52        |
| _std_act        | 0.608892     |
| _std_adv        | 1            |
| _std_discrew    | 0.709        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00153026 |
| Phi_loss        | 216.876    |
| PolicyEntropy   | 2.10717    |
| PolicyLoss      | -0.0067529 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0171     |
| _MeanReward     | 3.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97581    |
| _max_adv        | 8.91       |
| _max_discrew    | 3.62       |
| _max_obs        | 1.21       |
| _mean_act       | -0.093699  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.7        |
| _mean_obs       | 0.0345     |
| _min_adv        | -6.78      |
| _min_discrew    | 0.00629    |
| _min_obs        | -1.52      |
| _std_act        | 0.607311   |
| _std_adv        | 1          |
| _std_discrew    | 0.713      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.96       |
| KL              | 0.00127644 |
| Phi_loss        | 208.879    |
| PolicyEntropy   | 2.10005    |
| PolicyLoss      | -0.0186045 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0275     |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.26581    |
| _max_adv        | 6.34       |
| _max_discrew    | 3.79       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0988218 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.72       |
| _mean_obs       | 0.0333     |
| _min_adv        | -6.85      |
| _min_discrew    | 0.00806    |
| _min_obs        | -1.44      |
| _std_act        | 0.609615   |
| _std_adv        | 1          |
| _std_discrew    | 0.722      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.0020628  |
| Phi_loss        | 250.518    |
| PolicyEntropy   | 2.08449    |
| PolicyLoss      | -0.0185901 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0191     |
| _MeanReward     | 3.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81349    |
| _max_adv        | 4.3        |
| _max_discrew    | 3.54       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0951872 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.64       |
| _mean_obs       | 0.0334     |
| _min_adv        | -9.44      |
| _min_discrew    | 0.00939    |
| _min_obs        | -1.36      |
| _std_act        | 0.613586   |
| _std_adv        | 1          |
| _std_discrew    | 0.685      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00194227 |
| Phi_loss        | 231.328    |
| PolicyEntropy   | 2.07618    |
| PolicyLoss      | 0.00484615 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0235     |
| _MeanReward     | 3.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70364    |
| _max_adv        | 4.56       |
| _max_discrew    | 3.63       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0950043 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.73       |
| _mean_obs       | 0.0338     |
| _min_adv        | -6.38      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.56      |
| _std_act        | 0.61379    |
| _std_adv        | 1          |
| _std_discrew    | 0.727      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00196916 |
| Phi_loss        | 249.965    |
| PolicyEntropy   | 2.06097    |
| PolicyLoss      | -0.0282361 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0164     |
| _MeanReward     | 3.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00051    |
| _max_adv        | 5.46       |
| _max_discrew    | 3.66       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0998301 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.0335     |
| _min_adv        | -9.05      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.45      |
| _std_act        | 0.614787   |
| _std_adv        | 1          |
| _std_discrew    | 0.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.959      |
| KL              | 0.00220165 |
| Phi_loss        | 234.474    |
| PolicyEntropy   | 2.05125    |
| PolicyLoss      | -0.0197355 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 3.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.07687    |
| _max_adv        | 4.41       |
| _max_discrew    | 3.68       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0948125 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.78       |
| _mean_obs       | 0.0347     |
| _min_adv        | -9.77      |
| _min_discrew    | 2.75e-05   |
| _min_obs        | -1.4       |
| _std_act        | 0.619098   |
| _std_adv        | 1          |
| _std_discrew    | 0.757      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00279038 |
| Phi_loss        | 258.803    |
| PolicyEntropy   | 2.03015    |
| PolicyLoss      | -0.0229213 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0186     |
| _MeanReward     | 3.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.51281    |
| _max_adv        | 6.7        |
| _max_discrew    | 3.61       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0966533 |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 2.74       |
| _mean_obs       | 0.0339     |
| _min_adv        | -5.83      |
| _min_discrew    | 0.00553    |
| _min_obs        | -1.59      |
| _std_act        | 0.617803   |
| _std_adv        | 1          |
| _std_discrew    | 0.718      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00263406 |
| Phi_loss        | 244.87     |
| PolicyEntropy   | 2.01212    |
| PolicyLoss      | -0.0201182 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 3.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.0672     |
| _max_adv        | 3.4        |
| _max_discrew    | 3.73       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0931691 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.72       |
| _mean_obs       | 0.0346     |
| _min_adv        | -6.03      |
| _min_discrew    | 0.0092     |
| _min_obs        | -1.41      |
| _std_act        | 0.627667   |
| _std_adv        | 1          |
| _std_discrew    | 0.769      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.966       |
| ExplainedVarOld | 0.964       |
| KL              | 0.00219349  |
| Phi_loss        | 232.439     |
| PolicyEntropy   | 2.014       |
| PolicyLoss      | -0.00917826 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0264      |
| _MeanReward     | 3.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9506      |
| _max_adv        | 3.12        |
| _max_discrew    | 3.72        |
| _max_obs        | 1.23        |
| _mean_act       | -0.0949186  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.75        |
| _mean_obs       | 0.0343      |
| _min_adv        | -6.06       |
| _min_discrew    | 0.012       |
| _min_obs        | -1.38       |
| _std_act        | 0.622449    |
| _std_adv        | 1           |
| _std_discrew    | 0.751       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.964       |
| ExplainedVarOld | 0.962       |
| KL              | 0.00226631  |
| Phi_loss        | 264.902     |
| PolicyEntropy   | 1.98963     |
| PolicyLoss      | -0.00741792 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0274      |
| _MeanReward     | 3.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77576     |
| _max_adv        | 5.77        |
| _max_discrew    | 3.71        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0907679  |
| _mean_adv       | 0           |
| _mean_discrew   | 2.78        |
| _mean_obs       | 0.0344      |
| _min_adv        | -8.08       |
| _min_discrew    | 0.00922     |
| _min_obs        | -1.43       |
| _std_act        | 0.62056     |
| _std_adv        | 1           |
| _std_discrew    | 0.767       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00223509 |
| Phi_loss        | 230.934    |
| PolicyEntropy   | 1.98587    |
| PolicyLoss      | -0.0348391 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.99529    |
| _max_adv        | 2.83       |
| _max_discrew    | 3.78       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0945685 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.82       |
| _mean_obs       | 0.0348     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.33      |
| _std_act        | 0.624351   |
| _std_adv        | 1          |
| _std_discrew    | 0.775      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00265928 |
| Phi_loss        | 211.889    |
| PolicyEntropy   | 1.9807     |
| PolicyLoss      | -0.0155124 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 3.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92205    |
| _max_adv        | 4.31       |
| _max_discrew    | 3.8        |
| _max_obs        | 1.23       |
| _mean_act       | -0.0958549 |
| _mean_adv       | -5.26e-17  |
| _mean_discrew   | 2.86       |
| _mean_obs       | 0.0345     |
| _min_adv        | -6.22      |
| _min_discrew    | 0.00885    |
| _min_obs        | -1.46      |
| _std_act        | 0.631752   |
| _std_adv        | 1          |
| _std_discrew    | 0.811      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.0021604  |
| Phi_loss        | 246.196    |
| PolicyEntropy   | 1.95379    |
| PolicyLoss      | -0.0145759 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0138     |
| _MeanReward     | 3.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86049    |
| _max_adv        | 5.33       |
| _max_discrew    | 3.81       |
| _max_obs        | 1.66       |
| _mean_act       | -0.0991157 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.76       |
| _mean_obs       | 0.034      |
| _min_adv        | -7.06      |
| _min_discrew    | -0.0639    |
| _min_obs        | -1.33      |
| _std_act        | 0.631871   |
| _std_adv        | 1          |
| _std_discrew    | 0.807      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00320632 |
| Phi_loss        | 241.73     |
| PolicyEntropy   | 1.9293     |
| PolicyLoss      | -0.0205367 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0297     |
| _MeanReward     | 3.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.27112    |
| _max_adv        | 6.63       |
| _max_discrew    | 3.82       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0990124 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.83       |
| _mean_obs       | 0.0347     |
| _min_adv        | -7.01      |
| _min_discrew    | 0.00745    |
| _min_obs        | -1.5       |
| _std_act        | 0.634793   |
| _std_adv        | 1          |
| _std_discrew    | 0.772      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00211437 |
| Phi_loss        | 255.561    |
| PolicyEntropy   | 1.90558    |
| PolicyLoss      | -0.0120387 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 3.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74868    |
| _max_adv        | 4.1        |
| _max_discrew    | 3.8        |
| _max_obs        | 1.12       |
| _mean_act       | -0.0999732 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 2.8        |
| _mean_obs       | 0.0346     |
| _min_adv        | -9.42      |
| _min_discrew    | 0.00957    |
| _min_obs        | -1.37      |
| _std_act        | 0.635166   |
| _std_adv        | 1          |
| _std_discrew    | 0.807      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00253878 |
| Phi_loss        | 244.998    |
| PolicyEntropy   | 1.89314    |
| PolicyLoss      | -0.0216296 |
| Steps           | 10000      |
| VarFuncLoss     | 0.017      |
| _MeanReward     | 3.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63738    |
| _max_adv        | 4.65       |
| _max_discrew    | 3.74       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0968934 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.84       |
| _mean_obs       | 0.0334     |
| _min_adv        | -7.89      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.31      |
| _std_act        | 0.622945   |
| _std_adv        | 1          |
| _std_discrew    | 0.784      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.981       |
| KL              | 0.00253173  |
| Phi_loss        | 265.92      |
| PolicyEntropy   | 1.87593     |
| PolicyLoss      | -0.00225292 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0152      |
| _MeanReward     | 3.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.0036      |
| _max_adv        | 4.28        |
| _max_discrew    | 3.9         |
| _max_obs        | 1.15        |
| _mean_act       | -0.095937   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.87        |
| _mean_obs       | 0.0338      |
| _min_adv        | -6.69       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.58       |
| _std_act        | 0.627072    |
| _std_adv        | 1           |
| _std_discrew    | 0.785       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00217672 |
| Phi_loss        | 273.226    |
| PolicyEntropy   | 1.85516    |
| PolicyLoss      | -0.0382158 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 3.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79148    |
| _max_adv        | 3.24       |
| _max_discrew    | 3.9        |
| _max_obs        | 1.12       |
| _mean_act       | -0.0987638 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.85       |
| _mean_obs       | 0.0338     |
| _min_adv        | -7.63      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.37      |
| _std_act        | 0.633344   |
| _std_adv        | 1          |
| _std_discrew    | 0.792      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00262578 |
| Phi_loss        | 288.457    |
| PolicyEntropy   | 1.84439    |
| PolicyLoss      | 0.0128477  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0255     |
| _MeanReward     | 3.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.42284    |
| _max_adv        | 4.59       |
| _max_discrew    | 3.88       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0966113 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.86       |
| _mean_obs       | 0.0339     |
| _min_adv        | -6.88      |
| _min_discrew    | 0.0094     |
| _min_obs        | -1.36      |
| _std_act        | 0.632007   |
| _std_adv        | 1          |
| _std_discrew    | 0.797      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00206789 |
| Phi_loss        | 300.698    |
| PolicyEntropy   | 1.81964    |
| PolicyLoss      | -0.0162981 |
| Steps           | 10000      |
| VarFuncLoss     | 0.019      |
| _MeanReward     | 3.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73212    |
| _max_adv        | 4.31       |
| _max_discrew    | 3.86       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0994872 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 2.91       |
| _mean_obs       | 0.0343     |
| _min_adv        | -6.59      |
| _min_discrew    | 0.00708    |
| _min_obs        | -1.36      |
| _std_act        | 0.635072   |
| _std_adv        | 1          |
| _std_discrew    | 0.835      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00198439 |
| Phi_loss        | 302.157    |
| PolicyEntropy   | 1.81074    |
| PolicyLoss      | -0.0232962 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0152     |
| _MeanReward     | 3.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.96381    |
| _max_adv        | 3.74       |
| _max_discrew    | 3.78       |
| _max_obs        | 1.25       |
| _mean_act       | -0.101071  |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 2.88       |
| _mean_obs       | 0.0342     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.00899    |
| _min_obs        | -1.33      |
| _std_act        | 0.636774   |
| _std_adv        | 1          |
| _std_discrew    | 0.835      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00243987 |
| Phi_loss        | 223.77     |
| PolicyEntropy   | 1.79507    |
| PolicyLoss      | 0.0122628  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97012    |
| _max_adv        | 8.25       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0971747 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.0343     |
| _min_adv        | -7.48      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.5       |
| _std_act        | 0.637093   |
| _std_adv        | 1          |
| _std_discrew    | 0.837      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00365479 |
| Phi_loss        | 268.523    |
| PolicyEntropy   | 1.75292    |
| PolicyLoss      | -0.012629  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00996    |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96348    |
| _max_adv        | 5.87       |
| _max_discrew    | 3.88       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0952389 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.94       |
| _mean_obs       | 0.0353     |
| _min_adv        | -6.99      |
| _min_discrew    | 0.00357    |
| _min_obs        | -1.43      |
| _std_act        | 0.641385   |
| _std_adv        | 1          |
| _std_discrew    | 0.858      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00243146 |
| Phi_loss        | 272.55     |
| PolicyEntropy   | 1.73953    |
| PolicyLoss      | -0.0210067 |
| Steps           | 10000      |
| VarFuncLoss     | 0.014      |
| _MeanReward     | 3.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72745    |
| _max_adv        | 4.64       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.14       |
| _mean_act       | -0.094941  |
| _mean_adv       | -5.97e-17  |
| _mean_discrew   | 2.97       |
| _mean_obs       | 0.035      |
| _min_adv        | -6.67      |
| _min_discrew    | 0.0131     |
| _min_obs        | -1.31      |
| _std_act        | 0.641774   |
| _std_adv        | 1          |
| _std_discrew    | 0.87       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0021773  |
| Phi_loss        | 301.627    |
| PolicyEntropy   | 1.73212    |
| PolicyLoss      | -0.0243477 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88667    |
| _max_adv        | 3.26       |
| _max_discrew    | 3.97       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0965522 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.97       |
| _mean_obs       | 0.0347     |
| _min_adv        | -7.71      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.41      |
| _std_act        | 0.641613   |
| _std_adv        | 1          |
| _std_discrew    | 0.861      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.0023724  |
| Phi_loss        | 318.542    |
| PolicyEntropy   | 1.71303    |
| PolicyLoss      | -0.0156117 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00991    |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75319    |
| _max_adv        | 5.35       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0964953 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 2.99       |
| _mean_obs       | 0.034      |
| _min_adv        | -9.42      |
| _min_discrew    | 0.00675    |
| _min_obs        | -1.4       |
| _std_act        | 0.64345    |
| _std_adv        | 1          |
| _std_discrew    | 0.881      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0018083  |
| Phi_loss        | 264.446    |
| PolicyEntropy   | 1.70574    |
| PolicyLoss      | -0.0165488 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0104     |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6239     |
| _max_adv        | 4.89       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.18       |
| _mean_act       | -0.096539  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.99       |
| _mean_obs       | 0.0343     |
| _min_adv        | -4.85      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.48      |
| _std_act        | 0.638387   |
| _std_adv        | 1          |
| _std_discrew    | 0.851      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00248082  |
| Phi_loss        | 290.534     |
| PolicyEntropy   | 1.69522     |
| PolicyLoss      | -0.00308452 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00792     |
| _MeanReward     | 3.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03608     |
| _max_adv        | 3.35        |
| _max_discrew    | 3.87        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0984574  |
| _mean_adv       | 0           |
| _mean_discrew   | 2.99        |
| _mean_obs       | 0.0346      |
| _min_adv        | -8.06       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.42       |
| _std_act        | 0.641826    |
| _std_adv        | 1           |
| _std_discrew    | 0.879       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00247811 |
| Phi_loss        | 346.715    |
| PolicyEntropy   | 1.67015    |
| PolicyLoss      | -0.0216556 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0166     |
| _MeanReward     | 3.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.06324    |
| _max_adv        | 4.36       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.16       |
| _mean_act       | -0.09451   |
| _mean_adv       | 5.12e-17   |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0358     |
| _min_adv        | -7.95      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.55      |
| _std_act        | 0.651574   |
| _std_adv        | 1          |
| _std_discrew    | 0.904      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00234985 |
| Phi_loss        | 322.743    |
| PolicyEntropy   | 1.65369    |
| PolicyLoss      | -0.0153794 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 3.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.981      |
| _max_adv        | 3.03       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0932517 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.99       |
| _mean_obs       | 0.0354     |
| _min_adv        | -7.43      |
| _min_discrew    | 0.00662    |
| _min_obs        | -1.56      |
| _std_act        | 0.645547   |
| _std_adv        | 1          |
| _std_discrew    | 0.931      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00281292 |
| Phi_loss        | 332.309    |
| PolicyEntropy   | 1.63348    |
| PolicyLoss      | -0.0118689 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0161     |
| _MeanReward     | 3.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94497    |
| _max_adv        | 3.53       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0988384 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.06       |
| _mean_obs       | 0.0353     |
| _min_adv        | -8.26      |
| _min_discrew    | 0.00987    |
| _min_obs        | -1.33      |
| _std_act        | 0.653144   |
| _std_adv        | 1          |
| _std_discrew    | 0.913      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00208094 |
| Phi_loss        | 362.264    |
| PolicyEntropy   | 1.61244    |
| PolicyLoss      | -0.0114755 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0109     |
| _MeanReward     | 3.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.70398    |
| _max_adv        | 3.39       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0938953 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.035      |
| _min_adv        | -6.15      |
| _min_discrew    | 0.0132     |
| _min_obs        | -1.43      |
| _std_act        | 0.646803   |
| _std_adv        | 1          |
| _std_discrew    | 0.886      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00234966 |
| Phi_loss        | 322.52     |
| PolicyEntropy   | 1.58854    |
| PolicyLoss      | -0.0405986 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 3.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83705    |
| _max_adv        | 3.36       |
| _max_discrew    | 4.07       |
| _max_obs        | 1.16       |
| _mean_act       | -0.098996  |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 3.08       |
| _mean_obs       | 0.0353     |
| _min_adv        | -9.83      |
| _min_discrew    | 0.00586    |
| _min_obs        | -1.33      |
| _std_act        | 0.661368   |
| _std_adv        | 1          |
| _std_discrew    | 0.919      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00234484 |
| Phi_loss        | 315.365    |
| PolicyEntropy   | 1.56103    |
| PolicyLoss      | 0.012      |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68169    |
| _max_adv        | 3.64       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0972941 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.09       |
| _mean_obs       | 0.0354     |
| _min_adv        | -3.96      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.48      |
| _std_act        | 0.654167   |
| _std_adv        | 1          |
| _std_discrew    | 0.894      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00237564 |
| Phi_loss        | 351.074    |
| PolicyEntropy   | 1.52401    |
| PolicyLoss      | -0.0150564 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00991    |
| _MeanReward     | 3.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91679    |
| _max_adv        | 4.1        |
| _max_discrew    | 4          |
| _max_obs        | 1.16       |
| _mean_act       | -0.0943541 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0351     |
| _min_adv        | -7.34      |
| _min_discrew    | 0.00843    |
| _min_obs        | -1.49      |
| _std_act        | 0.65444    |
| _std_adv        | 1          |
| _std_discrew    | 0.888      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00274165 |
| Phi_loss        | 405.257    |
| PolicyEntropy   | 1.51523    |
| PolicyLoss      | -0.0146522 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0101     |
| _MeanReward     | 3.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06356    |
| _max_adv        | 3.19       |
| _max_discrew    | 4.1        |
| _max_obs        | 1.14       |
| _mean_act       | -0.096743  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.036      |
| _min_adv        | -5.71      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.39      |
| _std_act        | 0.658403   |
| _std_adv        | 1          |
| _std_discrew    | 0.928      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00288437 |
| Phi_loss        | 365.614    |
| PolicyEntropy   | 1.50216    |
| PolicyLoss      | -0.0124909 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00949    |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8965     |
| _max_adv        | 2.93       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.17       |
| _mean_act       | -0.096856  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.1        |
| _mean_obs       | 0.0353     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.34      |
| _std_act        | 0.655488   |
| _std_adv        | 1          |
| _std_discrew    | 0.939      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00357916 |
| Phi_loss        | 278.915    |
| PolicyEntropy   | 1.48726    |
| PolicyLoss      | -0.0054069 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0157     |
| _MeanReward     | 3.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83202    |
| _max_adv        | 7.21       |
| _max_discrew    | 4.18       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0956376 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.036      |
| _min_adv        | -10.1      |
| _min_discrew    | 0.00984    |
| _min_obs        | -1.46      |
| _std_act        | 0.660666   |
| _std_adv        | 1          |
| _std_discrew    | 0.942      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00260949 |
| Phi_loss        | 376.191    |
| PolicyEntropy   | 1.46007    |
| PolicyLoss      | 0.00380646 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74329    |
| _max_adv        | 6.09       |
| _max_discrew    | 4.15       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0995524 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0359     |
| _min_adv        | -8.15      |
| _min_discrew    | 0.00974    |
| _min_obs        | -1.52      |
| _std_act        | 0.658292   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0024555  |
| Phi_loss        | 361.837    |
| PolicyEntropy   | 1.43273    |
| PolicyLoss      | -0.0198271 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0124     |
| _MeanReward     | 3.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6119     |
| _max_adv        | 5.32       |
| _max_discrew    | 4.11       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0983454 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0351     |
| _min_adv        | -3.61      |
| _min_discrew    | 0.0132     |
| _min_obs        | -1.41      |
| _std_act        | 0.657291   |
| _std_adv        | 1          |
| _std_discrew    | 0.952      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00278426 |
| Phi_loss        | 404.188    |
| PolicyEntropy   | 1.40876    |
| PolicyLoss      | -0.0141482 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00826    |
| _MeanReward     | 3.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63467    |
| _max_adv        | 4.52       |
| _max_discrew    | 4.15       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0958107 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.0362     |
| _min_adv        | -6.87      |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.51      |
| _std_act        | 0.661079   |
| _std_adv        | 1          |
| _std_discrew    | 0.957      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00225046 |
| Phi_loss        | 406.465    |
| PolicyEntropy   | 1.39002    |
| PolicyLoss      | -0.0202275 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0153     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67104    |
| _max_adv        | 3.73       |
| _max_discrew    | 4.15       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0985536 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0354     |
| _min_adv        | -8.84      |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.42      |
| _std_act        | 0.662512   |
| _std_adv        | 1          |
| _std_discrew    | 0.983      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00259283  |
| Phi_loss        | 362.779     |
| PolicyEntropy   | 1.37182     |
| PolicyLoss      | -0.00128399 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00692     |
| _MeanReward     | 3.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66503     |
| _max_adv        | 4.09        |
| _max_discrew    | 4.22        |
| _max_obs        | 1.11        |
| _mean_act       | -0.104165   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.17        |
| _mean_obs       | 0.0345      |
| _min_adv        | -6.25       |
| _min_discrew    | 0.0145      |
| _min_obs        | -1.48       |
| _std_act        | 0.657859    |
| _std_adv        | 1           |
| _std_discrew    | 0.979       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00234005  |
| Phi_loss        | 429.82      |
| PolicyEntropy   | 1.35516     |
| PolicyLoss      | -0.00195661 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00788     |
| _MeanReward     | 3.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52559     |
| _max_adv        | 2.78        |
| _max_discrew    | 4.17        |
| _max_obs        | 1.09        |
| _mean_act       | -0.0989653  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.19        |
| _mean_obs       | 0.0355      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.79       |
| _std_act        | 0.666546    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00283047 |
| Phi_loss        | 408.81     |
| PolicyEntropy   | 1.32605    |
| PolicyLoss      | 0.0118457  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0103     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93524    |
| _max_adv        | 4.4        |
| _max_discrew    | 4.22       |
| _max_obs        | 1.11       |
| _mean_act       | -0.100156  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0353     |
| _min_adv        | -8.64      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.41      |
| _std_act        | 0.666693   |
| _std_adv        | 1          |
| _std_discrew    | 0.984      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00244386 |
| Phi_loss        | 403.051    |
| PolicyEntropy   | 1.30452    |
| PolicyLoss      | -0.0151783 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00999    |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03993    |
| _max_adv        | 3.9        |
| _max_discrew    | 4.22       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0986103 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0359     |
| _min_adv        | -9.77      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.41      |
| _std_act        | 0.665443   |
| _std_adv        | 1          |
| _std_discrew    | 0.975      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00292112 |
| Phi_loss        | 413.083    |
| PolicyEntropy   | 1.26403    |
| PolicyLoss      | -0.0127713 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0159     |
| _MeanReward     | 3.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56924    |
| _max_adv        | 4.18       |
| _max_discrew    | 4.18       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0996734 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0356     |
| _min_adv        | -5.39      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.43      |
| _std_act        | 0.660846   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.0023878  |
| Phi_loss        | 410.952    |
| PolicyEntropy   | 1.24208    |
| PolicyLoss      | -0.0061806 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00824    |
| _MeanReward     | 3.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.88795    |
| _max_adv        | 6.16       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.21       |
| _mean_act       | -0.103786  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0353     |
| _min_adv        | -11.8      |
| _min_discrew    | 0.0128     |
| _min_obs        | -1.51      |
| _std_act        | 0.66989    |
| _std_adv        | 1          |
| _std_discrew    | 0.983      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00237836 |
| Phi_loss        | 408.6      |
| PolicyEntropy   | 1.23587    |
| PolicyLoss      | -0.0132929 |
| Steps           | 10000      |
| VarFuncLoss     | 0.023      |
| _MeanReward     | 3.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8002     |
| _max_adv        | 5.82       |
| _max_discrew    | 4.16       |
| _max_obs        | 1.12       |
| _mean_act       | -0.101195  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.22       |
| _mean_obs       | 0.0357     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.4       |
| _std_act        | 0.671353   |
| _std_adv        | 1          |
| _std_discrew    | 0.999      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00261009 |
| Phi_loss        | 436.089    |
| PolicyEntropy   | 1.21902    |
| PolicyLoss      | -0.0181892 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0138     |
| _MeanReward     | 3.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88704    |
| _max_adv        | 4.76       |
| _max_discrew    | 4.19       |
| _max_obs        | 1.05       |
| _mean_act       | -0.100926  |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0352     |
| _min_adv        | -9.07      |
| _min_discrew    | 0.0128     |
| _min_obs        | -1.31      |
| _std_act        | 0.673796   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00227044 |
| Phi_loss        | 465.457    |
| PolicyEntropy   | 1.19499    |
| PolicyLoss      | -0.0274771 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00884    |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56562    |
| _max_adv        | 4.61       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0959417 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.0364     |
| _min_adv        | -5.67      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.42      |
| _std_act        | 0.673004   |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00248571 |
| Phi_loss        | 485.71     |
| PolicyEntropy   | 1.17741    |
| PolicyLoss      | -0.0538897 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00679    |
| _MeanReward     | 3.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80972    |
| _max_adv        | 4.39       |
| _max_discrew    | 4.29       |
| _max_obs        | 1.07       |
| _mean_act       | -0.100872  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0355     |
| _min_adv        | -12.3      |
| _min_discrew    | 0.0131     |
| _min_obs        | -1.4       |
| _std_act        | 0.677107   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00269374 |
| Phi_loss        | 431.517    |
| PolicyEntropy   | 1.14647    |
| PolicyLoss      | -0.0113881 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0115     |
| _MeanReward     | 3.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82223    |
| _max_adv        | 3.51       |
| _max_discrew    | 4.29       |
| _max_obs        | 1.19       |
| _mean_act       | -0.101354  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0358     |
| _min_adv        | -9.76      |
| _min_discrew    | -0.000617  |
| _min_obs        | -1.45      |
| _std_act        | 0.682676   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00383008 |
| Phi_loss        | 419.819    |
| PolicyEntropy   | 1.1272     |
| PolicyLoss      | 0.00975805 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0126     |
| _MeanReward     | 3.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77429    |
| _max_adv        | 5.89       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.13       |
| _mean_act       | -0.100891  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0352     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.43      |
| _std_act        | 0.675662   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.0028088  |
| Phi_loss        | 450.862    |
| PolicyEntropy   | 1.11327    |
| PolicyLoss      | -0.0329427 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0117     |
| _MeanReward     | 3.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.2047     |
| _max_adv        | 4.42       |
| _max_discrew    | 4.33       |
| _max_obs        | 1.13       |
| _mean_act       | -0.101644  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0346     |
| _min_adv        | -14.1      |
| _min_discrew    | 0.00278    |
| _min_obs        | -1.44      |
| _std_act        | 0.678642   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00714005 |
| Phi_loss        | 503.094    |
| PolicyEntropy   | 1.11689    |
| PolicyLoss      | -0.0573837 |
| Steps           | 10000      |
| VarFuncLoss     | 0.019      |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.83934    |
| _max_adv        | 5.91       |
| _max_discrew    | 4.33       |
| _max_obs        | 1.12       |
| _mean_act       | -0.101874  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0351     |
| _min_adv        | -4.69      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.4       |
| _std_act        | 0.681276   |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.0131704  |
| Phi_loss        | 548.19     |
| PolicyEntropy   | 1.10821    |
| PolicyLoss      | -0.0231052 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00808    |
| _MeanReward     | 3.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62644    |
| _max_adv        | 7.65       |
| _max_discrew    | 4.33       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0971983 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0351     |
| _min_adv        | -12.2      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.4       |
| _std_act        | 0.678199   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
--------------------------------
| Beta            | 1.5        |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.0249597  |
| Phi_loss        | 496.363    |
| PolicyEntropy   | 1.10665    |
| PolicyLoss      | 0.0473699  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0213     |
| _MeanReward     | 4.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73425    |
| _max_adv        | 4.25       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0991857 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.29       |
| _mean_obs       | 0.035      |
| _min_adv        | -6.78      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.33      |
| _std_act        | 0.685507   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
--------------------------------
| Beta            | 2.25       |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.0206587  |
| Phi_loss        | 544.968    |
| PolicyEntropy   | 1.10472    |
| PolicyLoss      | 0.0123779  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88301    |
| _max_adv        | 3.58       |
| _max_discrew    | 4.25       |
| _max_obs        | 1.04       |
| _mean_act       | -0.0977211 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.0348     |
| _min_adv        | -13.3      |
| _min_discrew    | 0.0111     |
| _min_obs        | -1.43      |
| _std_act        | 0.691288   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
-------------------------------
| Beta            | 3.38      |
| ExplainedVarNew | 0.982     |
| ExplainedVarOld | 0.981     |
| KL              | 0.0154928 |
| Phi_loss        | 440.118   |
| PolicyEntropy   | 1.1026    |
| PolicyLoss      | 0.0218358 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0195    |
| _MeanReward     | 3.84e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.80976   |
| _max_adv        | 5.95      |
| _max_discrew    | 4.22      |
| _max_obs        | 1.12      |
| _mean_act       | -0.095423 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 3.18      |
| _mean_obs       | 0.0333    |
| _min_adv        | -12.8     |
| _min_discrew    | 0.0139    |
| _min_obs        | -1.35     |
| _std_act        | 0.681466  |
| _std_adv        | 1         |
| _std_discrew    | 0.991     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
--------------------------------
| Beta            | 5.06       |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0768048  |
| Phi_loss        | 556.597    |
| PolicyEntropy   | 1.10077    |
| PolicyLoss      | 0.501311   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76944    |
| _max_adv        | 4.63       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0958768 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0354     |
| _min_adv        | -9.31      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.39      |
| _std_act        | 0.688328   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
--------------------------------
| Beta            | 7.59       |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.121134   |
| Phi_loss        | 517.266    |
| PolicyEntropy   | 1.1006     |
| PolicyLoss      | 1.26299    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 4.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80153    |
| _max_adv        | 5.35       |
| _max_discrew    | 4.26       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0965315 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0352     |
| _min_adv        | -8.89      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.45      |
| _std_act        | 0.683481   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
--------------------------------
| Beta            | 11.4       |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.0997755  |
| Phi_loss        | 561.824    |
| PolicyEntropy   | 1.1        |
| PolicyLoss      | 1.18361    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00648    |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85973    |
| _max_adv        | 3.86       |
| _max_discrew    | 4.16       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0925458 |
| _mean_adv       | 6.82e-17   |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0345     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.41      |
| _std_act        | 0.676856   |
| _std_adv        | 1          |
| _std_discrew    | 0.968      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
--------------------------------
| Beta            | 17.1       |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.988      |
| KL              | 0.0772435  |
| Phi_loss        | 567.268    |
| PolicyEntropy   | 1.09921    |
| PolicyLoss      | 1.11585    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 3.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6831     |
| _max_adv        | 3.74       |
| _max_discrew    | 4.1        |
| _max_obs        | 1.02       |
| _mean_act       | -0.0903468 |
| _mean_adv       | -1.14e-16  |
| _mean_discrew   | 3.06       |
| _mean_obs       | 0.0328     |
| _min_adv        | -8.16      |
| _min_discrew    | 0.00782    |
| _min_obs        | -1.47      |
| _std_act        | 0.6727     |
| _std_adv        | 1          |
| _std_discrew    | 0.917      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
--------------------------------
| Beta            | 25.6       |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0585955  |
| Phi_loss        | 574.615    |
| PolicyEntropy   | 1.09838    |
| PolicyLoss      | 1.12769    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 3.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.89705    |
| _max_adv        | 3.85       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0853798 |
| _mean_adv       | 1.36e-16   |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.0322     |
| _min_adv        | -4.43      |
| _min_discrew    | 0.0104     |
| _min_obs        | -1.35      |
| _std_act        | 0.671369   |
| _std_adv        | 1          |
| _std_discrew    | 0.866      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.989      |
| KL              | 0.0424568  |
| Phi_loss        | 552.312    |
| PolicyEntropy   | 1.09713    |
| PolicyLoss      | 1.12019    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0117     |
| _MeanReward     | 3.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00238    |
| _max_adv        | 3.89       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0827233 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.8        |
| _mean_obs       | 0.0304     |
| _min_adv        | -3.86      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.4       |
| _std_act        | 0.66867    |
| _std_adv        | 1          |
| _std_discrew    | 0.831      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.031795   |
| Phi_loss        | 544.943    |
| PolicyEntropy   | 1.09549    |
| PolicyLoss      | 1.14833    |
| Steps           | 10000      |
| VarFuncLoss     | 0.012      |
| _MeanReward     | 3.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79762    |
| _max_adv        | 3.27       |
| _max_discrew    | 3.5        |
| _max_obs        | 1.03       |
| _mean_act       | -0.0786663 |
| _mean_adv       | 6.82e-17   |
| _mean_discrew   | 2.63       |
| _mean_obs       | 0.0284     |
| _min_adv        | -4.16      |
| _min_discrew    | 0.00877    |
| _min_obs        | -1.39      |
| _std_act        | 0.66872    |
| _std_adv        | 1          |
| _std_discrew    | 0.727      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.982      |
| KL              | 0.022882   |
| Phi_loss        | 544.473    |
| PolicyEntropy   | 1.09368    |
| PolicyLoss      | 0.779855   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0128     |
| _MeanReward     | 3.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93659    |
| _max_adv        | 3.56       |
| _max_discrew    | 3.51       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0814182 |
| _mean_adv       | -1.25e-16  |
| _mean_discrew   | 2.48       |
| _mean_obs       | 0.0262     |
| _min_adv        | -3.84      |
| _min_discrew    | 0.00474    |
| _min_obs        | -1.39      |
| _std_act        | 0.667166   |
| _std_adv        | 1          |
| _std_discrew    | 0.693      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0161889  |
| Phi_loss        | 531.889    |
| PolicyEntropy   | 1.09171    |
| PolicyLoss      | 0.560249   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92633    |
| _max_adv        | 3.34       |
| _max_discrew    | 3.36       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0827121 |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 2.41       |
| _mean_obs       | 0.0255     |
| _min_adv        | -4.87      |
| _min_discrew    | 0.00694    |
| _min_obs        | -1.44      |
| _std_act        | 0.668418   |
| _std_adv        | 1          |
| _std_discrew    | 0.681      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0838261  |
| Phi_loss        | 579.289    |
| PolicyEntropy   | 1.09486    |
| PolicyLoss      | 3.20977    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0136     |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93823    |
| _max_adv        | 3.16       |
| _max_discrew    | 3.61       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0835438 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.65       |
| _mean_obs       | 0.0284     |
| _min_adv        | -5.93      |
| _min_discrew    | 0.00396    |
| _min_obs        | -1.39      |
| _std_act        | 0.666411   |
| _std_adv        | 1          |
| _std_discrew    | 0.756      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.1275     |
| Phi_loss        | 652.009    |
| PolicyEntropy   | 1.09929    |
| PolicyLoss      | 5.15089    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0203     |
| _MeanReward     | 3.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67285    |
| _max_adv        | 3.79       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.04       |
| _mean_act       | -0.0835175 |
| _mean_adv       | 3.84e-17   |
| _mean_discrew   | 2.92       |
| _mean_obs       | 0.0313     |
| _min_adv        | -3.76      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.37      |
| _std_act        | 0.669345   |
| _std_adv        | 1          |
| _std_discrew    | 0.85       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.976      |
| KL              | 0.10457    |
| Phi_loss        | 576.902    |
| PolicyEntropy   | 1.10304    |
| PolicyLoss      | 4.12725    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0247     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70279    |
| _max_adv        | 3.6        |
| _max_discrew    | 4.07       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0861734 |
| _mean_adv       | -6.82e-17  |
| _mean_discrew   | 3.1        |
| _mean_obs       | 0.0334     |
| _min_adv        | -5.76      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.44      |
| _std_act        | 0.673882   |
| _std_adv        | 1          |
| _std_discrew    | 0.942      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.983      |
| KL              | 0.0843314  |
| Phi_loss        | 504.432    |
| PolicyEntropy   | 1.10608    |
| PolicyLoss      | 3.25951    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0168     |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89774    |
| _max_adv        | 3.89       |
| _max_discrew    | 4.19       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0908872 |
| _mean_adv       | 1.11e-16   |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0338     |
| _min_adv        | -9.13      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.39      |
| _std_act        | 0.673649   |
| _std_adv        | 1          |
| _std_discrew    | 0.989      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0670376  |
| Phi_loss        | 786.003    |
| PolicyEntropy   | 1.10855    |
| PolicyLoss      | 2.53651    |
| Steps           | 10000      |
| VarFuncLoss     | 0.013      |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73063    |
| _max_adv        | 3.74       |
| _max_discrew    | 4.25       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0927163 |
| _mean_adv       | 1.19e-16   |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0336     |
| _min_adv        | -5.99      |
| _min_discrew    | 0.0102     |
| _min_obs        | -1.41      |
| _std_act        | 0.671348   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.992     |
| KL              | 0.0535514 |
| Phi_loss        | 578.23    |
| PolicyEntropy   | 1.11052   |
| PolicyLoss      | 1.94032   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0074    |
| _MeanReward     | 3.54e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.53604   |
| _max_adv        | 1.4       |
| _max_discrew    | 4.22      |
| _max_obs        | 1.82      |
| _mean_act       | -0.11837  |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 2.88      |
| _mean_obs       | 0.0329    |
| _min_adv        | -12.5     |
| _min_discrew    | -0.736    |
| _min_obs        | -1.43     |
| _std_act        | 0.718515  |
| _std_adv        | 1         |
| _std_discrew    | 2.12      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.808      |
| KL              | 0.0383339  |
| Phi_loss        | 251.047    |
| PolicyEntropy   | 1.11225    |
| PolicyLoss      | 1.36096    |
| Steps           | 10000      |
| VarFuncLoss     | 0.157      |
| _MeanReward     | 3.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.68728    |
| _max_adv        | 11.9       |
| _max_discrew    | 4.29       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0918833 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.0339     |
| _min_adv        | -12.8      |
| _min_discrew    | 0.0104     |
| _min_obs        | -1.35      |
| _std_act        | 0.678622   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.0336589  |
| Phi_loss        | 376.852    |
| PolicyEntropy   | 1.11367    |
| PolicyLoss      | 1.17863    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0206     |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71186    |
| _max_adv        | 8.35       |
| _max_discrew    | 4.18       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0882717 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0331     |
| _min_adv        | -5.36      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.37      |
| _std_act        | 0.664291   |
| _std_adv        | 1          |
| _std_discrew    | 0.998      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.984     |
| ExplainedVarOld | 0.98      |
| KL              | 0.0268673 |
| Phi_loss        | 512.593   |
| PolicyEntropy   | 1.11489   |
| PolicyLoss      | 0.932112  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0162    |
| _MeanReward     | 3.63e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.72318   |
| _max_adv        | 1.86      |
| _max_discrew    | 4.18      |
| _max_obs        | 1.8       |
| _mean_act       | -0.101953 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 2.94      |
| _mean_obs       | 0.032     |
| _min_adv        | -15.6     |
| _min_discrew    | -0.664    |
| _min_obs        | -1.38     |
| _std_act        | 0.695792  |
| _std_adv        | 1         |
| _std_discrew    | 1.54      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.905      |
| ExplainedVarOld | 0.893      |
| KL              | 0.0199202  |
| Phi_loss        | 397.365    |
| PolicyEntropy   | 1.11594    |
| PolicyLoss      | 0.725559   |
| Steps           | 10000      |
| VarFuncLoss     | 0.151      |
| _MeanReward     | 3.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.71207    |
| _max_adv        | 17.6       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0869572 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0323     |
| _min_adv        | -7.46      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.39      |
| _std_act        | 0.667254   |
| _std_adv        | 1          |
| _std_discrew    | 0.943      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.95       |
| KL              | 0.0166853  |
| Phi_loss        | 346.286    |
| PolicyEntropy   | 1.11694    |
| PolicyLoss      | 0.561624   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0324     |
| _MeanReward     | 3.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75081    |
| _max_adv        | 8.57       |
| _max_discrew    | 4.08       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0841213 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0315     |
| _min_adv        | -8.4       |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.38      |
| _std_act        | 0.661613   |
| _std_adv        | 1          |
| _std_discrew    | 0.961      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.976     |
| ExplainedVarOld | 0.975     |
| KL              | 0.0133453 |
| Phi_loss        | 517.988   |
| PolicyEntropy   | 1.11776   |
| PolicyLoss      | 0.451662  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0233    |
| _MeanReward     | 3.74e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.74361   |
| _max_adv        | 4.15      |
| _max_discrew    | 4.09      |
| _max_obs        | 1.23      |
| _mean_act       | -0.085386 |
| _mean_adv       | 2.84e-17  |
| _mean_discrew   | 3.06      |
| _mean_obs       | 0.0313    |
| _min_adv        | -5.35     |
| _min_discrew    | 0.00938   |
| _min_obs        | -1.39     |
| _std_act        | 0.667244  |
| _std_adv        | 1         |
| _std_discrew    | 0.99      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.0151768  |
| Phi_loss        | 597.517    |
| PolicyEntropy   | 1.12152    |
| PolicyLoss      | 0.512077   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 3.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.7745     |
| _max_adv        | 9.71       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0871112 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0314     |
| _min_adv        | -9.06      |
| _min_discrew    | 0.0131     |
| _min_obs        | -1.59      |
| _std_act        | 0.653566   |
| _std_adv        | 1          |
| _std_discrew    | 0.996      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.971     |
| ExplainedVarOld | 0.97      |
| KL              | 0.0392771 |
| Phi_loss        | 521.523   |
| PolicyEntropy   | 1.12406   |
| PolicyLoss      | 1.41861   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0293    |
| _MeanReward     | 3.75e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.76361   |
| _max_adv        | 2.71      |
| _max_discrew    | 4.19      |
| _max_obs        | 1.23      |
| _mean_act       | -0.087742 |
| _mean_adv       | 2.13e-17  |
| _mean_discrew   | 3.06      |
| _mean_obs       | 0.0315    |
| _min_adv        | -8.67     |
| _min_discrew    | 0.00768   |
| _min_obs        | -1.34     |
| _std_act        | 0.662723  |
| _std_adv        | 1         |
| _std_discrew    | 1.01      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.973      |
| KL              | 0.0315224  |
| Phi_loss        | 561.124    |
| PolicyEntropy   | 1.12603    |
| PolicyLoss      | 1.11164    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0268     |
| _MeanReward     | 3.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81369    |
| _max_adv        | 3.22       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0857946 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0323     |
| _min_adv        | -6.48      |
| _min_discrew    | 0.00895    |
| _min_obs        | -1.4       |
| _std_act        | 0.66664    |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.025521   |
| Phi_loss        | 607.049    |
| PolicyEntropy   | 1.12772    |
| PolicyLoss      | 0.894239   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0141     |
| _MeanReward     | 3.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.0555     |
| _max_adv        | 3.62       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0877722 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.18       |
| _mean_obs       | 0.0327     |
| _min_adv        | -7         |
| _min_discrew    | 0.00289    |
| _min_obs        | -1.39      |
| _std_act        | 0.669886   |
| _std_adv        | 1          |
| _std_discrew    | 0.994      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.0206527  |
| Phi_loss        | 511.794    |
| PolicyEntropy   | 1.12903    |
| PolicyLoss      | 0.742843   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0153     |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65554    |
| _max_adv        | 6.56       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0922534 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0331     |
| _min_adv        | -6.98      |
| _min_discrew    | 0.0139     |
| _min_obs        | -1.31      |
| _std_act        | 0.668741   |
| _std_adv        | 1          |
| _std_discrew    | 0.99       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.0164953  |
| Phi_loss        | 451.662    |
| PolicyEntropy   | 1.12999    |
| PolicyLoss      | 0.583146   |
| Steps           | 10000      |
| VarFuncLoss     | 0.022      |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58274    |
| _max_adv        | 4.38       |
| _max_discrew    | 4.25       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0877374 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0333     |
| _min_adv        | -5.98      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.34      |
| _std_act        | 0.672932   |
| _std_adv        | 1          |
| _std_discrew    | 0.989      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.992     |
| ExplainedVarOld | 0.991     |
| KL              | 0.0133211 |
| Phi_loss        | 545.858   |
| PolicyEntropy   | 1.13052   |
| PolicyLoss      | 0.450476  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00859   |
| _MeanReward     | 3.67e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.98515   |
| _max_adv        | 1.8       |
| _max_discrew    | 4.34      |
| _max_obs        | 1.84      |
| _mean_act       | -0.10395  |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 2.99      |
| _mean_obs       | 0.0332    |
| _min_adv        | -16.6     |
| _min_discrew    | -0.648    |
| _min_obs        | -1.38     |
| _std_act        | 0.698779  |
| _std_adv        | 1         |
| _std_discrew    | 1.7       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
---------------------------------
| Beta            | 23.3        |
| ExplainedVarNew | 0.901       |
| ExplainedVarOld | 0.89        |
| KL              | 0.000832984 |
| Phi_loss        | 440.819     |
| PolicyEntropy   | 1.12928     |
| PolicyLoss      | 0.0123737   |
| Steps           | 10000       |
| VarFuncLoss     | 0.171       |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87449     |
| _max_adv        | 9.49        |
| _max_discrew    | 4.29        |
| _max_obs        | 1.03        |
| _mean_act       | -0.0926582  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.22        |
| _mean_obs       | 0.0327      |
| _min_adv        | -8.88       |
| _min_discrew    | 0.00986     |
| _min_obs        | -1.53       |
| _std_act        | 0.670476    |
| _std_adv        | 1           |
| _std_discrew    | 0.996       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
---------------------------------
| Beta            | 15.6        |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.983       |
| KL              | 8.87322e-05 |
| Phi_loss        | 425.045     |
| PolicyEntropy   | 1.12907     |
| PolicyLoss      | -0.0304946  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0188      |
| _MeanReward     | 3.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74154     |
| _max_adv        | 6.95        |
| _max_discrew    | 4.23        |
| _max_obs        | 1.15        |
| _mean_act       | -0.0912555  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.24        |
| _mean_obs       | 0.0328      |
| _min_adv        | -4.95       |
| _min_discrew    | 0.00888     |
| _min_obs        | -1.53       |
| _std_act        | 0.663184    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 8.75809e-06 |
| Phi_loss        | 412.824     |
| PolicyEntropy   | 1.12854     |
| PolicyLoss      | -0.0228931  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00894     |
| _MeanReward     | 3.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74677     |
| _max_adv        | 7.18        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.11        |
| _mean_act       | -0.0953427  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.21        |
| _mean_obs       | 0.0323      |
| _min_adv        | -11.6       |
| _min_discrew    | 0.0123      |
| _min_obs        | -1.47       |
| _std_act        | 0.665687    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
---------------------------------
| Beta            | 6.91        |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 3.54495e-06 |
| Phi_loss        | 376.195     |
| PolicyEntropy   | 1.12786     |
| PolicyLoss      | 0.00583276  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0142      |
| _MeanReward     | 3.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.14991     |
| _max_adv        | 6.42        |
| _max_discrew    | 4.24        |
| _max_obs        | 1.11        |
| _mean_act       | -0.0906608  |
| _mean_adv       | -2.2e-17    |
| _mean_discrew   | 3.22        |
| _mean_obs       | 0.0328      |
| _min_adv        | -8.4        |
| _min_discrew    | 0.0122      |
| _min_obs        | -1.43       |
| _std_act        | 0.662033    |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 3.99325e-06 |
| Phi_loss        | 525.628     |
| PolicyEntropy   | 1.12669     |
| PolicyLoss      | -0.00449474 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0139      |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92904     |
| _max_adv        | 9.25        |
| _max_discrew    | 4.19        |
| _max_obs        | 1.05        |
| _mean_act       | -0.0894572  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.24        |
| _mean_obs       | 0.0326      |
| _min_adv        | -9.52       |
| _min_discrew    | 0.0132      |
| _min_obs        | -1.41       |
| _std_act        | 0.670978    |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 7.37717e-06 |
| Phi_loss        | 486.566     |
| PolicyEntropy   | 1.12498     |
| PolicyLoss      | -0.0217681  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0123      |
| _MeanReward     | 3.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85009     |
| _max_adv        | 4.08        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.83        |
| _mean_act       | -0.115658   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.88        |
| _mean_obs       | 0.0317      |
| _min_adv        | -17.8       |
| _min_discrew    | -0.674      |
| _min_obs        | -1.4        |
| _std_act        | 0.700018    |
| _std_adv        | 1           |
| _std_discrew    | 1.9         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
---------------------------------
| Beta            | 2.05        |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.9         |
| KL              | 4.58458e-05 |
| Phi_loss        | 402.289     |
| PolicyEntropy   | 1.12517     |
| PolicyLoss      | -0.0279762  |
| Steps           | 10000       |
| VarFuncLoss     | 0.181       |
| _MeanReward     | 3.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.6534      |
| _max_adv        | 4.62        |
| _max_discrew    | 4.2         |
| _max_obs        | 1.08        |
| _mean_act       | -0.0911792  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.22        |
| _mean_obs       | 0.0326      |
| _min_adv        | -8.7        |
| _min_discrew    | 0.0123      |
| _min_obs        | -1.42       |
| _std_act        | 0.668969    |
| _std_adv        | 1           |
| _std_discrew    | 0.986       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.98        |
| KL              | 2.98061e-05 |
| Phi_loss        | 482.563     |
| PolicyEntropy   | 1.12338     |
| PolicyLoss      | -0.0272505  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0214      |
| _MeanReward     | 3.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.89886     |
| _max_adv        | 15.3        |
| _max_discrew    | 4.11        |
| _max_obs        | 1.15        |
| _mean_act       | -0.0907915  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.19        |
| _mean_obs       | 0.0326      |
| _min_adv        | -10.3       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.37       |
| _std_act        | 0.673319    |
| _std_adv        | 1           |
| _std_discrew    | 0.98        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.978       |
| KL              | 7.16629e-05 |
| Phi_loss        | 456.92      |
| PolicyEntropy   | 1.11785     |
| PolicyLoss      | 0.0267741   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0193      |
| _MeanReward     | 3.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85296     |
| _max_adv        | 6.09        |
| _max_discrew    | 4.36        |
| _max_obs        | 1.01        |
| _mean_act       | -0.0903362  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0327      |
| _min_adv        | -4.29       |
| _min_discrew    | 0.019       |
| _min_obs        | -1.49       |
| _std_act        | 0.669305    |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.000167282 |
| Phi_loss        | 524.585     |
| PolicyEntropy   | 1.10444     |
| PolicyLoss      | -0.0226149  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0114      |
| _MeanReward     | 3.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68801     |
| _max_adv        | 5.57        |
| _max_discrew    | 4.22        |
| _max_obs        | 1.08        |
| _mean_act       | -0.0939135  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.22        |
| _mean_obs       | 0.0321      |
| _min_adv        | -7.59       |
| _min_discrew    | 0.01        |
| _min_obs        | -1.41       |
| _std_act        | 0.666664    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
---------------------------------
| Beta            | 0.405       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.000237402 |
| Phi_loss        | 588.136     |
| PolicyEntropy   | 1.08862     |
| PolicyLoss      | -0.00712345 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0142      |
| _MeanReward     | 3.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67147     |
| _max_adv        | 7.38        |
| _max_discrew    | 4.24        |
| _max_obs        | 1.06        |
| _mean_act       | -0.0916288  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0327      |
| _min_adv        | -7          |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.53       |
| _std_act        | 0.663927    |
| _std_adv        | 1           |
| _std_discrew    | 0.99        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.000510814 |
| Phi_loss        | 530.908     |
| PolicyEntropy   | 1.08364     |
| PolicyLoss      | -0.00800407 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00853     |
| _MeanReward     | 3.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64269     |
| _max_adv        | 3.83        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.06        |
| _mean_act       | -0.0895493  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0321      |
| _min_adv        | -6.28       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.42       |
| _std_act        | 0.661905    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.000921778 |
| Phi_loss        | 548.392     |
| PolicyEntropy   | 1.06467     |
| PolicyLoss      | -0.0141294  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00849     |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.49871     |
| _max_adv        | 3.39        |
| _max_discrew    | 4.23        |
| _max_obs        | 1.03        |
| _mean_act       | -0.0894394  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.24        |
| _mean_obs       | 0.032       |
| _min_adv        | -11.3       |
| _min_discrew    | 0.0132      |
| _min_obs        | -1.52       |
| _std_act        | 0.665289    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00129871 |
| Phi_loss        | 460.815    |
| PolicyEntropy   | 1.04323    |
| PolicyLoss      | -0.0293345 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0108     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63431    |
| _max_adv        | 5.06       |
| _max_discrew    | 4.21       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0907702 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0327     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.5       |
| _std_act        | 0.670924   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.000630621 |
| Phi_loss        | 582.766     |
| PolicyEntropy   | 1.02194     |
| PolicyLoss      | -0.0015388  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00801     |
| _MeanReward     | 3.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67864     |
| _max_adv        | 3.22        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0905033  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.23        |
| _mean_obs       | 0.0327      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.45       |
| _std_act        | 0.667746    |
| _std_adv        | 1           |
| _std_discrew    | 0.993       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.98        |
| KL              | 0.000878013 |
| Phi_loss        | 518.464     |
| PolicyEntropy   | 1.01826     |
| PolicyLoss      | -0.0103049  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0185      |
| _MeanReward     | 3.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55292     |
| _max_adv        | 1.53        |
| _max_discrew    | 4.15        |
| _max_obs        | 1.87        |
| _mean_act       | -0.132708   |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 2.7         |
| _mean_obs       | 0.0315      |
| _min_adv        | -12.8       |
| _min_discrew    | -0.675      |
| _min_obs        | -1.4        |
| _std_act        | 0.729947    |
| _std_adv        | 1           |
| _std_discrew    | 2.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.872       |
| ExplainedVarOld | 0.853       |
| KL              | 0.00284627  |
| Phi_loss        | 412.003     |
| PolicyEntropy   | 1.01481     |
| PolicyLoss      | 0.000167077 |
| Steps           | 10000       |
| VarFuncLoss     | 0.313       |
| _MeanReward     | 3.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60434     |
| _max_adv        | 7.26        |
| _max_discrew    | 4.26        |
| _max_obs        | 1.89        |
| _mean_act       | -0.116972   |
| _mean_adv       | -9.95e-18   |
| _mean_discrew   | 2.87        |
| _mean_obs       | 0.0317      |
| _min_adv        | -17.8       |
| _min_discrew    | -0.682      |
| _min_obs        | -1.42       |
| _std_act        | 0.708259    |
| _std_adv        | 1           |
| _std_discrew    | 2.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.937       |
| KL              | 0.000929604 |
| Phi_loss        | 433.051     |
| PolicyEntropy   | 1.00577     |
| PolicyLoss      | -0.0021327  |
| Steps           | 10000       |
| VarFuncLoss     | 0.128       |
| _MeanReward     | 3.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54619     |
| _max_adv        | 9.84        |
| _max_discrew    | 4.28        |
| _max_obs        | 1.08        |
| _mean_act       | -0.0927527  |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 3.24        |
| _mean_obs       | 0.032       |
| _min_adv        | -6.34       |
| _min_discrew    | 0.00674     |
| _min_obs        | -1.43       |
| _std_act        | 0.668853    |
| _std_adv        | 1           |
| _std_discrew    | 0.989       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00089115  |
| Phi_loss        | 365.343     |
| PolicyEntropy   | 0.996455    |
| PolicyLoss      | -0.00220629 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0124      |
| _MeanReward     | 3.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69187     |
| _max_adv        | 31.1        |
| _max_discrew    | 4.23        |
| _max_obs        | 1.06        |
| _mean_act       | -0.0943604  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0318      |
| _min_adv        | -7.61       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.43       |
| _std_act        | 0.667325    |
| _std_adv        | 1           |
| _std_discrew    | 0.992       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.982       |
| KL              | 0.000468903 |
| Phi_loss        | 337.375     |
| PolicyEntropy   | 0.979474    |
| PolicyLoss      | -0.0149279  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0125      |
| _MeanReward     | 3.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96664     |
| _max_adv        | 1.97        |
| _max_discrew    | 4.19        |
| _max_obs        | 1.84        |
| _mean_act       | -0.123901   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.88        |
| _mean_obs       | 0.0311      |
| _min_adv        | -18.6       |
| _min_discrew    | -0.687      |
| _min_obs        | -1.33       |
| _std_act        | 0.709496    |
| _std_adv        | 1           |
| _std_discrew    | 2.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.935      |
| KL              | 0.0100705  |
| Phi_loss        | 539.73     |
| PolicyEntropy   | 0.941442   |
| PolicyLoss      | -0.0590894 |
| Steps           | 10000      |
| VarFuncLoss     | 0.127      |
| _MeanReward     | 3.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85602    |
| _max_adv        | 12.1       |
| _max_discrew    | 4.31       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0946632 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0315     |
| _min_adv        | -12.1      |
| _min_discrew    | 0.0181     |
| _min_obs        | -1.54      |
| _std_act        | 0.66458    |
| _std_adv        | 1          |
| _std_discrew    | 0.99       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
----------------------------------
| Beta            | 0.0429       |
| ExplainedVarNew | 0.982        |
| ExplainedVarOld | 0.981        |
| KL              | 0.00156398   |
| Phi_loss        | 533.493      |
| PolicyEntropy   | 0.919153     |
| PolicyLoss      | -0.000831535 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0181       |
| _MeanReward     | 3.91e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.66334      |
| _max_adv        | 29           |
| _max_discrew    | 4.19         |
| _max_obs        | 1.81         |
| _mean_act       | -0.0969506   |
| _mean_adv       | 6.39e-18     |
| _mean_discrew   | 3.21         |
| _mean_obs       | 0.0312       |
| _min_adv        | -14.9        |
| _min_discrew    | -0.0715      |
| _min_obs        | -1.45        |
| _std_act        | 0.662432     |
| _std_adv        | 1            |
| _std_discrew    | 1.03         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.972       |
| KL              | 0.000920146 |
| Phi_loss        | 314.162     |
| PolicyEntropy   | 0.914435    |
| PolicyLoss      | -0.00373445 |
| Steps           | 10000       |
| VarFuncLoss     | 0.021       |
| _MeanReward     | 3.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9562      |
| _max_adv        | 15.2        |
| _max_discrew    | 4.27        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0931357  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.28        |
| _mean_obs       | 0.0327      |
| _min_adv        | -6.2        |
| _min_discrew    | 0.01        |
| _min_obs        | -1.5        |
| _std_act        | 0.669805    |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00134566  |
| Phi_loss        | 516.609     |
| PolicyEntropy   | 0.905695    |
| PolicyLoss      | -0.00809279 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00812     |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85681     |
| _max_adv        | 14          |
| _max_discrew    | 4.33        |
| _max_obs        | 1.16        |
| _mean_act       | -0.0909373  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0324      |
| _min_adv        | -8.14       |
| _min_discrew    | 0.0117      |
| _min_obs        | -1.51       |
| _std_act        | 0.666669    |
| _std_adv        | 1           |
| _std_discrew    | 1.05        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00191428 |
| Phi_loss        | 550.391    |
| PolicyEntropy   | 0.877998   |
| PolicyLoss      | -0.0203864 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0115     |
| _MeanReward     | 3.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6591     |
| _max_adv        | 23.5       |
| _max_discrew    | 4.29       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0921942 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0325     |
| _min_adv        | -12.1      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.46      |
| _std_act        | 0.666927   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.976      |
| KL              | 0.0013581  |
| Phi_loss        | 592.045    |
| PolicyEntropy   | 0.859201   |
| PolicyLoss      | -0.0182824 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0236     |
| _MeanReward     | 3.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.30423    |
| _max_adv        | 14.4       |
| _max_discrew    | 4.3        |
| _max_obs        | 1.09       |
| _mean_act       | -0.0902113 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0327     |
| _min_adv        | -12.6      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.42      |
| _std_act        | 0.66604    |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00174755 |
| Phi_loss        | 570.717    |
| PolicyEntropy   | 0.843589   |
| PolicyLoss      | -0.0176678 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.61188    |
| _max_adv        | 4.03       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0888451 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0326     |
| _min_adv        | -5.64      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.46      |
| _std_act        | 0.667601   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00282906  |
| Phi_loss        | 668.678     |
| PolicyEntropy   | 0.826333    |
| PolicyLoss      | -0.00170013 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00767     |
| _MeanReward     | 3.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.29231     |
| _max_adv        | 5.71        |
| _max_discrew    | 4.24        |
| _max_obs        | 1.06        |
| _mean_act       | -0.0883627  |
| _mean_adv       | 5.68e-17    |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0324      |
| _min_adv        | -11.3       |
| _min_discrew    | 0.0131      |
| _min_obs        | -1.6        |
| _std_act        | 0.670595    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00212179  |
| Phi_loss        | 621.377     |
| PolicyEntropy   | 0.80407     |
| PolicyLoss      | -0.00421548 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0174      |
| _MeanReward     | 3.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56091     |
| _max_adv        | 8.44        |
| _max_discrew    | 4.22        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0865758  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.27        |
| _mean_obs       | 0.0333      |
| _min_adv        | -9.37       |
| _min_discrew    | 0.0134      |
| _min_obs        | -1.49       |
| _std_act        | 0.66642     |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00308957 |
| Phi_loss        | 602.638    |
| PolicyEntropy   | 0.785117   |
| PolicyLoss      | 0.00724196 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.78194    |
| _max_adv        | 6.18       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0833469 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0339     |
| _min_adv        | -7.62      |
| _min_discrew    | 0.00863    |
| _min_obs        | -1.39      |
| _std_act        | 0.667666   |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00190951 |
| Phi_loss        | 579.012    |
| PolicyEntropy   | 0.758216   |
| PolicyLoss      | 0.00515374 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77094    |
| _max_adv        | 5.28       |
| _max_discrew    | 4.3        |
| _max_obs        | 1.02       |
| _mean_act       | -0.0851625 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.0329     |
| _min_adv        | -6.92      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.44      |
| _std_act        | 0.663873   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0031601  |
| Phi_loss        | 621.847    |
| PolicyEntropy   | 0.747449   |
| PolicyLoss      | -0.0233514 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0152     |
| _MeanReward     | 4.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71929    |
| _max_adv        | 6.33       |
| _max_discrew    | 4.36       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0820527 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0335     |
| _min_adv        | -9.46      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.45      |
| _std_act        | 0.667103   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
----------------------------------
| Beta            | 0.0286       |
| ExplainedVarNew | 0.989        |
| ExplainedVarOld | 0.989        |
| KL              | 0.00262027   |
| Phi_loss        | 584.629      |
| PolicyEntropy   | 0.727911     |
| PolicyLoss      | -0.000938946 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0121       |
| _MeanReward     | 3.98e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.72063      |
| _max_adv        | 7.07         |
| _max_discrew    | 4.34         |
| _max_obs        | 1.19         |
| _mean_act       | -0.087792    |
| _mean_adv       | -3.98e-17    |
| _mean_discrew   | 3.29         |
| _mean_obs       | 0.0334       |
| _min_adv        | -11.4        |
| _min_discrew    | 0.016        |
| _min_obs        | -1.45        |
| _std_act        | 0.664015     |
| _std_adv        | 1            |
| _std_discrew    | 1.01         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00129506 |
| Phi_loss        | 558.971    |
| PolicyEntropy   | 0.704844   |
| PolicyLoss      | 0.00021573 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0274     |
| _MeanReward     | 3.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70977    |
| _max_adv        | 6.99       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.05       |
| _mean_act       | -0.088769  |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0328     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.52      |
| _std_act        | 0.659021   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00139841 |
| Phi_loss        | 682.973    |
| PolicyEntropy   | 0.661207   |
| PolicyLoss      | -0.026654  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74273    |
| _max_adv        | 1.64       |
| _max_discrew    | 4.19       |
| _max_obs        | 1.86       |
| _mean_act       | -0.0957121 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0324     |
| _min_adv        | -17.9      |
| _min_discrew    | -0.531     |
| _min_obs        | -1.47      |
| _std_act        | 0.681233   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.903      |
| KL              | 0.00149073 |
| Phi_loss        | 682.405    |
| PolicyEntropy   | 0.640886   |
| PolicyLoss      | -0.0162592 |
| Steps           | 10000      |
| VarFuncLoss     | 0.121      |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.64561    |
| _max_adv        | 4.22       |
| _max_discrew    | 4.37       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0885011 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0332     |
| _min_adv        | -4.27      |
| _min_discrew    | 0.00968    |
| _min_obs        | -1.41      |
| _std_act        | 0.664765   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00279647 |
| Phi_loss        | 595.13     |
| PolicyEntropy   | 0.634377   |
| PolicyLoss      | -0.0158298 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7004     |
| _max_adv        | 13.5       |
| _max_discrew    | 4.42       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0936622 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0334     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0042     |
| _min_obs        | -1.45      |
| _std_act        | 0.666605   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00200794 |
| Phi_loss        | 469.534    |
| PolicyEntropy   | 0.624506   |
| PolicyLoss      | -0.0143226 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0143     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03071    |
| _max_adv        | 10.3       |
| _max_discrew    | 4.4        |
| _max_obs        | 1.84       |
| _mean_act       | -0.0943732 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0337     |
| _min_adv        | -15.7      |
| _min_discrew    | -0.309     |
| _min_obs        | -1.45      |
| _std_act        | 0.68388    |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00238399 |
| Phi_loss        | 701.242    |
| PolicyEntropy   | 0.597627   |
| PolicyLoss      | -0.015422  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0535     |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86661    |
| _max_adv        | 14.3       |
| _max_discrew    | 4.41       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0916923 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.35       |
| _mean_obs       | 0.0334     |
| _min_adv        | -8.14      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.39      |
| _std_act        | 0.667015   |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00240549 |
| Phi_loss        | 567.099    |
| PolicyEntropy   | 0.565326   |
| PolicyLoss      | 0.0176978  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78397    |
| _max_adv        | 5.9        |
| _max_discrew    | 4.37       |
| _max_obs        | 1.85       |
| _mean_act       | -0.106767  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.033      |
| _min_adv        | -18.1      |
| _min_discrew    | -0.649     |
| _min_obs        | -1.41      |
| _std_act        | 0.699974   |
| _std_adv        | 1          |
| _std_discrew    | 1.78       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.891      |
| KL              | 0.00697641 |
| Phi_loss        | 653.566    |
| PolicyEntropy   | 0.544823   |
| PolicyLoss      | -0.0295681 |
| Steps           | 10000      |
| VarFuncLoss     | 0.184      |
| _MeanReward     | 4.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60797    |
| _max_adv        | 10.6       |
| _max_discrew    | 4.33       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0912275 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0327     |
| _min_adv        | -10.8      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.45      |
| _std_act        | 0.668633   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00243903 |
| Phi_loss        | 589.349    |
| PolicyEntropy   | 0.538277   |
| PolicyLoss      | -0.0328811 |
| Steps           | 10000      |
| VarFuncLoss     | 0.013      |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67659    |
| _max_adv        | 6.26       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0935003 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0336     |
| _min_adv        | -5.84      |
| _min_discrew    | 0.00964    |
| _min_obs        | -1.37      |
| _std_act        | 0.680684   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00347649 |
| Phi_loss        | 673.721    |
| PolicyEntropy   | 0.501857   |
| PolicyLoss      | -0.0134843 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00821    |
| _MeanReward     | 4.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65018    |
| _max_adv        | 4.38       |
| _max_discrew    | 4.41       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0968961 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0331     |
| _min_adv        | -14.1      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.31      |
| _std_act        | 0.681773   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00314014 |
| Phi_loss        | 491.193    |
| PolicyEntropy   | 0.471336   |
| PolicyLoss      | -0.0232177 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0124     |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73144    |
| _max_adv        | 8.47       |
| _max_discrew    | 4.4        |
| _max_obs        | 1.02       |
| _mean_act       | -0.0973054 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.41       |
| _mean_obs       | 0.0331     |
| _min_adv        | -5.55      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.46      |
| _std_act        | 0.675103   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00260181 |
| Phi_loss        | 690.537    |
| PolicyEntropy   | 0.449802   |
| PolicyLoss      | -0.0160847 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00782    |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64661    |
| _max_adv        | 8.38       |
| _max_discrew    | 4.46       |
| _max_obs        | 1.03       |
| _mean_act       | -0.09911   |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0342     |
| _min_adv        | -5.4       |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.51      |
| _std_act        | 0.686807   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00178368  |
| Phi_loss        | 636.589     |
| PolicyEntropy   | 0.427405    |
| PolicyLoss      | -0.00432528 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00692     |
| _MeanReward     | 4.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63459     |
| _max_adv        | 22.1        |
| _max_discrew    | 4.41        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0976705  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.38        |
| _mean_obs       | 0.0332      |
| _min_adv        | -9.56       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.58       |
| _std_act        | 0.685274    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00211857 |
| Phi_loss        | 622.409    |
| PolicyEntropy   | 0.41138    |
| PolicyLoss      | -0.0100198 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0161     |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65577    |
| _max_adv        | 22.8       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.15       |
| _mean_act       | -0.100261  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0329     |
| _min_adv        | -11.4      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.35      |
| _std_act        | 0.681698   |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 0.0035546   |
| Phi_loss        | 665.63      |
| PolicyEntropy   | 0.385991    |
| PolicyLoss      | -0.00793692 |
| Steps           | 10000       |
| VarFuncLoss     | 0.014       |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62123     |
| _max_adv        | 2.89        |
| _max_discrew    | 4.43        |
| _max_obs        | 1.87        |
| _mean_act       | -0.11012    |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.32        |
| _mean_obs       | 0.0335      |
| _min_adv        | -15.9       |
| _min_discrew    | -0.476      |
| _min_obs        | -1.54       |
| _std_act        | 0.698261    |
| _std_adv        | 1           |
| _std_discrew    | 1.39        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00239012 |
| Phi_loss        | 591.146    |
| PolicyEntropy   | 0.363645   |
| PolicyLoss      | -0.0128167 |
| Steps           | 10000      |
| VarFuncLoss     | 0.101      |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51777    |
| _max_adv        | 6.77       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.03       |
| _mean_act       | -0.100067  |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0338     |
| _min_adv        | -6.47      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.48      |
| _std_act        | 0.682633   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00360833 |
| Phi_loss        | 536.87     |
| PolicyEntropy   | 0.339577   |
| PolicyLoss      | -0.011267  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54137    |
| _max_adv        | 6.26       |
| _max_discrew    | 4.52       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0988009 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0342     |
| _min_adv        | -5.88      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.35      |
| _std_act        | 0.685737   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00400706 |
| Phi_loss        | 639.761    |
| PolicyEntropy   | 0.307981   |
| PolicyLoss      | -0.002414  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00902    |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70335    |
| _max_adv        | 12.8       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0968264 |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0349     |
| _min_adv        | -9.53      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.53      |
| _std_act        | 0.688192   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00443102 |
| Phi_loss        | 742.4      |
| PolicyEntropy   | 0.284122   |
| PolicyLoss      | -0.0112989 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 3.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64352    |
| _max_adv        | 2.24       |
| _max_discrew    | 4.5        |
| _max_obs        | 1.88       |
| _mean_act       | -0.114009  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0339     |
| _min_adv        | -15.8      |
| _min_discrew    | -0.677     |
| _min_obs        | -1.4       |
| _std_act        | 0.722648   |
| _std_adv        | 1          |
| _std_discrew    | 1.83       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00434737 |
| Phi_loss        | 517.481    |
| PolicyEntropy   | 0.277764   |
| PolicyLoss      | 0.00591022 |
| Steps           | 10000      |
| VarFuncLoss     | 0.192      |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69704    |
| _max_adv        | 29.4       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0955057 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0346     |
| _min_adv        | -9.78      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.35      |
| _std_act        | 0.694097   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00271825 |
| Phi_loss        | 592.929    |
| PolicyEntropy   | 0.247073   |
| PolicyLoss      | 0.0192269  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0165     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72882    |
| _max_adv        | 23.1       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.09       |
| _mean_act       | -0.100975  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0343     |
| _min_adv        | -10        |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.36      |
| _std_act        | 0.688575   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.984      |
| KL              | 0.00162984 |
| Phi_loss        | 530.773    |
| PolicyEntropy   | 0.230226   |
| PolicyLoss      | 0.0131702  |
| Steps           | 10000      |
| VarFuncLoss     | 0.012      |
| _MeanReward     | 4.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89475    |
| _max_adv        | 16.8       |
| _max_discrew    | 4.52       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0999331 |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.51       |
| _mean_obs       | 0.0345     |
| _min_adv        | -8.65      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.46      |
| _std_act        | 0.685483   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00288503 |
| Phi_loss        | 633.925    |
| PolicyEntropy   | 0.206439   |
| PolicyLoss      | -0.0208799 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00932    |
| _MeanReward     | 3.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57998    |
| _max_adv        | 1.81       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.86       |
| _mean_act       | -0.121373  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0335     |
| _min_adv        | -15.4      |
| _min_discrew    | -0.68      |
| _min_obs        | -1.34      |
| _std_act        | 0.726579   |
| _std_adv        | 1          |
| _std_discrew    | 2.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.907      |
| ExplainedVarOld | 0.864      |
| KL              | 0.0120159  |
| Phi_loss        | 446.335    |
| PolicyEntropy   | 0.223725   |
| PolicyLoss      | -0.0283432 |
| Steps           | 10000      |
| VarFuncLoss     | 0.209      |
| _MeanReward     | 3.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15564    |
| _max_adv        | 5.79       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.86       |
| _mean_act       | -0.112046  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.034      |
| _min_adv        | -16.2      |
| _min_discrew    | -0.645     |
| _min_obs        | -1.29      |
| _std_act        | 0.714366   |
| _std_adv        | 1          |
| _std_discrew    | 1.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.885      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00265946 |
| Phi_loss        | 667.87     |
| PolicyEntropy   | 0.241591   |
| PolicyLoss      | -0.0205078 |
| Steps           | 10000      |
| VarFuncLoss     | 0.201      |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68355    |
| _max_adv        | 8.53       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0983275 |
| _mean_adv       | -1.02e-16  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0347     |
| _min_adv        | -8.44      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.37      |
| _std_act        | 0.695437   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00213842 |
| Phi_loss        | 749.397    |
| PolicyEntropy   | 0.233042   |
| PolicyLoss      | -0.0210385 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0181     |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54844    |
| _max_adv        | 22.8       |
| _max_discrew    | 4.46       |
| _max_obs        | 1.07       |
| _mean_act       | -0.100789  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0344     |
| _min_adv        | -8.7       |
| _min_discrew    | 0.013      |
| _min_obs        | -1.44      |
| _std_act        | 0.694752   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00263601 |
| Phi_loss        | 570.827    |
| PolicyEntropy   | 0.216409   |
| PolicyLoss      | 0.00699068 |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64549    |
| _max_adv        | 19.5       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.09       |
| _mean_act       | -0.102556  |
| _mean_adv       | -2.7e-17   |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0345     |
| _min_adv        | -10.8      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.44      |
| _std_act        | 0.699796   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00146994 |
| Phi_loss        | 770.493    |
| PolicyEntropy   | 0.199403   |
| PolicyLoss      | 0.00991021 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0229     |
| _MeanReward     | 4.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10796    |
| _max_adv        | 7.28       |
| _max_discrew    | 4.64       |
| _max_obs        | 1.04       |
| _mean_act       | -0.10322   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.5        |
| _mean_obs       | 0.0345     |
| _min_adv        | -9.25      |
| _min_discrew    | 0.015      |
| _min_obs        | -1.31      |
| _std_act        | 0.696106   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00313874 |
| Phi_loss        | 712.754    |
| PolicyEntropy   | 0.199574   |
| PolicyLoss      | -0.0231706 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0316     |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87487    |
| _max_adv        | 4.62       |
| _max_discrew    | 4.7        |
| _max_obs        | 2          |
| _mean_act       | -0.113747  |
| _mean_adv       | 5.68e-17   |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.0344     |
| _min_adv        | -15.3      |
| _min_discrew    | -0.506     |
| _min_obs        | -1.41      |
| _std_act        | 0.711626   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.885      |
| KL              | 0.00274434 |
| Phi_loss        | 657.364    |
| PolicyEntropy   | 0.18143    |
| PolicyLoss      | -0.0152554 |
| Steps           | 10000      |
| VarFuncLoss     | 0.158      |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.13296    |
| _max_adv        | 14.5       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.09       |
| _mean_act       | -0.103716  |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0344     |
| _min_adv        | -9         |
| _min_discrew    | -0.0139    |
| _min_obs        | -1.43      |
| _std_act        | 0.690016   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00335398 |
| Phi_loss        | 654.368    |
| PolicyEntropy   | 0.164224   |
| PolicyLoss      | -0.0103955 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0285     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7635     |
| _max_adv        | 11         |
| _max_discrew    | 4.64       |
| _max_obs        | 1.06       |
| _mean_act       | -0.103572  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0341     |
| _min_adv        | -9.9       |
| _min_discrew    | 0.0155     |
| _min_obs        | -1.4       |
| _std_act        | 0.688967   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
----------------------------------
| Beta            | 0.0429       |
| ExplainedVarNew | 0.971        |
| ExplainedVarOld | 0.967        |
| KL              | 0.00355471   |
| Phi_loss        | 731.735      |
| PolicyEntropy   | 0.13902      |
| PolicyLoss      | -1.68153e-05 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0333       |
| _MeanReward     | 3.84e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.55626      |
| _max_adv        | 2.07         |
| _max_discrew    | 4.56         |
| _max_obs        | 1.89         |
| _mean_act       | -0.124616    |
| _mean_adv       | 3.98e-17     |
| _mean_discrew   | 3.14         |
| _mean_obs       | 0.0329       |
| _min_adv        | -17.6        |
| _min_discrew    | -0.697       |
| _min_obs        | -1.38        |
| _std_act        | 0.730878     |
| _std_adv        | 1            |
| _std_discrew    | 2.34         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00761778 |
| Phi_loss        | 753.327    |
| PolicyEntropy   | 0.13132    |
| PolicyLoss      | -0.0221671 |
| Steps           | 10000      |
| VarFuncLoss     | 0.19       |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61858    |
| _max_adv        | 13.3       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.05       |
| _mean_act       | -0.103407  |
| _mean_adv       | -4.97e-18  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0338     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.47      |
| _std_act        | 0.689449   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00521465  |
| Phi_loss        | 706.267     |
| PolicyEntropy   | 0.104074    |
| PolicyLoss      | 0.000292377 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0151      |
| _MeanReward     | 3.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66345     |
| _max_adv        | 10.9        |
| _max_discrew    | 4.54        |
| _max_obs        | 1.88        |
| _mean_act       | -0.110748   |
| _mean_adv       | -1.56e-17   |
| _mean_discrew   | 3.27        |
| _mean_obs       | 0.0342      |
| _min_adv        | -17.7       |
| _min_discrew    | -0.642      |
| _min_obs        | -1.32       |
| _std_act        | 0.712188    |
| _std_adv        | 1           |
| _std_discrew    | 1.72        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.893       |
| ExplainedVarOld | 0.887       |
| KL              | 0.00438927  |
| Phi_loss        | 877.717     |
| PolicyEntropy   | 0.0607157   |
| PolicyLoss      | -0.00987093 |
| Steps           | 10000       |
| VarFuncLoss     | 0.188       |
| _MeanReward     | 4.21e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83468     |
| _max_adv        | 14.2        |
| _max_discrew    | 4.59        |
| _max_obs        | 1.02        |
| _mean_act       | -0.100627   |
| _mean_adv       | -3.69e-17   |
| _mean_discrew   | 3.48        |
| _mean_obs       | 0.0344      |
| _min_adv        | -9.8        |
| _min_discrew    | 0.0157      |
| _min_obs        | -1.48       |
| _std_act        | 0.684493    |
| _std_adv        | 1           |
| _std_discrew    | 1.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00286641 |
| Phi_loss        | 706.634    |
| PolicyEntropy   | 0.0566158  |
| PolicyLoss      | -0.0136057 |
| Steps           | 10000      |
| VarFuncLoss     | 0.031      |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.91283    |
| _max_adv        | 12.2       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.9        |
| _mean_act       | -0.100471  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0349     |
| _min_adv        | -11.9      |
| _min_discrew    | -0.251     |
| _min_obs        | -1.43      |
| _std_act        | 0.688239   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00379684 |
| Phi_loss        | 742.893    |
| PolicyEntropy   | 0.0506506  |
| PolicyLoss      | 0.00365351 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0414     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64041    |
| _max_adv        | 10.6       |
| _max_discrew    | 4.5        |
| _max_obs        | 1.07       |
| _mean_act       | -0.0935846 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0343     |
| _min_adv        | -9.03      |
| _min_discrew    | 0.0132     |
| _min_obs        | -1.37      |
| _std_act        | 0.678092   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00297842 |
| Phi_loss        | 736.043    |
| PolicyEntropy   | 0.0626173  |
| PolicyLoss      | -0.0191457 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61878    |
| _max_adv        | 7.27       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.88       |
| _mean_act       | -0.0986913 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0346     |
| _min_adv        | -15.5      |
| _min_discrew    | -0.297     |
| _min_obs        | -1.41      |
| _std_act        | 0.687748   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.00424925 |
| Phi_loss        | 763.94     |
| PolicyEntropy   | 0.0649986  |
| PolicyLoss      | 0.00112026 |
| Steps           | 10000      |
| VarFuncLoss     | 0.041      |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69249    |
| _max_adv        | 11.9       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.86       |
| _mean_act       | -0.125972  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0329     |
| _min_adv        | -15.4      |
| _min_discrew    | -0.749     |
| _min_obs        | -1.46      |
| _std_act        | 0.732104   |
| _std_adv        | 1          |
| _std_discrew    | 2.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.909      |
| KL              | 0.00453064 |
| Phi_loss        | 587.134    |
| PolicyEntropy   | 0.0510149  |
| PolicyLoss      | 0.0214416  |
| Steps           | 10000      |
| VarFuncLoss     | 0.184      |
| _MeanReward     | 4.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49671    |
| _max_adv        | 14.7       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0980197 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0344     |
| _min_adv        | -7.2       |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.44      |
| _std_act        | 0.684908   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00378643 |
| Phi_loss        | 724.534    |
| PolicyEntropy   | 0.0449505  |
| PolicyLoss      | -0.0259292 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0191     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63695    |
| _max_adv        | 22.3       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0972394 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0342     |
| _min_adv        | -8.61      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.38      |
| _std_act        | 0.691347   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00332086 |
| Phi_loss        | 583.64     |
| PolicyEntropy   | 0.0288115  |
| PolicyLoss      | 0.00338237 |
| Steps           | 10000      |
| VarFuncLoss     | 0.024      |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51519    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.6        |
| _max_obs        | 1.1        |
| _mean_act       | -0.098417  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0345     |
| _min_adv        | -11        |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.42      |
| _std_act        | 0.687034   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00373905 |
| Phi_loss        | 820.41     |
| PolicyEntropy   | 0.0181704  |
| PolicyLoss      | -0.0330099 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 4.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79213    |
| _max_adv        | 9.46       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.86       |
| _mean_act       | -0.103814  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0345     |
| _min_adv        | -10.1      |
| _min_discrew    | -0.161     |
| _min_obs        | -1.43      |
| _std_act        | 0.687253   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.964       |
| ExplainedVarOld | 0.96        |
| KL              | 0.00457866  |
| Phi_loss        | 728.941     |
| PolicyEntropy   | 0.0193338   |
| PolicyLoss      | -0.00671212 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0455      |
| _MeanReward     | 4.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56293     |
| _max_adv        | 8.25        |
| _max_discrew    | 4.71        |
| _max_obs        | 1.14        |
| _mean_act       | -0.104447   |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 3.52        |
| _mean_obs       | 0.0349      |
| _min_adv        | -10.9       |
| _min_discrew    | 0.016       |
| _min_obs        | -1.46       |
| _std_act        | 0.692237    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.955       |
| ExplainedVarOld | 0.948       |
| KL              | 0.00371776  |
| Phi_loss        | 690.177     |
| PolicyEntropy   | -0.00104046 |
| PolicyLoss      | -0.00809109 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0556      |
| _MeanReward     | 3.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55734     |
| _max_adv        | 3.57        |
| _max_discrew    | 4.57        |
| _max_obs        | 1.88        |
| _mean_act       | -0.129499   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.16        |
| _mean_obs       | 0.033       |
| _min_adv        | -17.6       |
| _min_discrew    | -0.752      |
| _min_obs        | -1.41       |
| _std_act        | 0.73337     |
| _std_adv        | 1           |
| _std_discrew    | 2.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.906       |
| KL              | 0.008214    |
| Phi_loss        | 756.449     |
| PolicyEntropy   | -0.00765324 |
| PolicyLoss      | -0.114428   |
| Steps           | 10000       |
| VarFuncLoss     | 0.201       |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.15338     |
| _max_adv        | 11.9        |
| _max_discrew    | 4.59        |
| _max_obs        | 1.08        |
| _mean_act       | -0.101202   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.6         |
| _mean_obs       | 0.0347      |
| _min_adv        | -10.9       |
| _min_discrew    | 0.0143      |
| _min_obs        | -1.47       |
| _std_act        | 0.691164    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00417974 |
| Phi_loss        | 744.622    |
| PolicyEntropy   | -0.0133886 |
| PolicyLoss      | -0.0124769 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0193     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09049    |
| _max_adv        | 31         |
| _max_discrew    | 4.51       |
| _max_obs        | 1.05       |
| _mean_act       | -0.105194  |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0335     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.44      |
| _std_act        | 0.685781   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00213324 |
| Phi_loss        | 659.1      |
| PolicyEntropy   | -0.0300407 |
| PolicyLoss      | -0.0115314 |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 4.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58865    |
| _max_adv        | 15         |
| _max_discrew    | 4.7        |
| _max_obs        | 1.05       |
| _mean_act       | -0.105576  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0338     |
| _min_adv        | -14.6      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.36      |
| _std_act        | 0.692192   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.968      |
| KL              | 0.00482813 |
| Phi_loss        | 631.477    |
| PolicyEntropy   | -0.0425253 |
| PolicyLoss      | 0.00296548 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0354     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57933    |
| _max_adv        | 3.86       |
| _max_discrew    | 4.6        |
| _max_obs        | 1.88       |
| _mean_act       | -0.109909  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0333     |
| _min_adv        | -13.7      |
| _min_discrew    | -0.373     |
| _min_obs        | -1.37      |
| _std_act        | 0.694014   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.943      |
| KL              | 0.00313684 |
| Phi_loss        | 751.285    |
| PolicyEntropy   | -0.0483513 |
| PolicyLoss      | -0.0128156 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0721     |
| _MeanReward     | 4.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57823    |
| _max_adv        | 13.3       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.08       |
| _mean_act       | -0.104539  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0332     |
| _min_adv        | -8.03      |
| _min_discrew    | 0.012      |
| _min_obs        | -1.29      |
| _std_act        | 0.684236   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00252628 |
| Phi_loss        | 711.411    |
| PolicyEntropy   | -0.0546274 |
| PolicyLoss      | 0.019773   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91599    |
| _max_adv        | 9.23       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.09       |
| _mean_act       | -0.107709  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0331     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.33      |
| _std_act        | 0.680711   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00320214 |
| Phi_loss        | 783.464    |
| PolicyEntropy   | -0.0749912 |
| PolicyLoss      | 0.00658769 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0276     |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50703    |
| _max_adv        | 12.7       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.3        |
| _mean_act       | -0.109054  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.51       |
| _mean_obs       | 0.0335     |
| _min_adv        | -9.01      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.47      |
| _std_act        | 0.681064   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00250424 |
| Phi_loss        | 844.8      |
| PolicyEntropy   | -0.0738544 |
| PolicyLoss      | -0.0279148 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5837     |
| _max_adv        | 6.1        |
| _max_discrew    | 4.56       |
| _max_obs        | 1.88       |
| _mean_act       | -0.115769  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0336     |
| _min_adv        | -14.3      |
| _min_discrew    | -0.395     |
| _min_obs        | -1.27      |
| _std_act        | 0.695887   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.944      |
| ExplainedVarOld | 0.94       |
| KL              | 0.00275677 |
| Phi_loss        | 701.614    |
| PolicyEntropy   | -0.083848  |
| PolicyLoss      | -0.0116181 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0788     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60201    |
| _max_adv        | 3.94       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.87       |
| _mean_act       | -0.120376  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.033      |
| _min_adv        | -17.2      |
| _min_discrew    | -0.565     |
| _min_obs        | -1.36      |
| _std_act        | 0.706495   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00300879 |
| Phi_loss        | 710.498    |
| PolicyEntropy   | -0.0789633 |
| PolicyLoss      | 0.0152174  |
| Steps           | 10000      |
| VarFuncLoss     | 0.13       |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52286    |
| _max_adv        | 6.07       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.09       |
| _mean_act       | -0.106856  |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0326     |
| _min_adv        | -4         |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.37      |
| _std_act        | 0.679139   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00260736  |
| Phi_loss        | 672.48      |
| PolicyEntropy   | -0.0920563  |
| PolicyLoss      | -0.00235387 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0109      |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51451     |
| _max_adv        | 9.79        |
| _max_discrew    | 4.66        |
| _max_obs        | 1.88        |
| _mean_act       | -0.131715   |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 3.29        |
| _mean_obs       | 0.0318      |
| _min_adv        | -17.9       |
| _min_discrew    | -0.735      |
| _min_obs        | -1.45       |
| _std_act        | 0.717171    |
| _std_adv        | 1           |
| _std_discrew    | 1.96        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.893      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00663521 |
| Phi_loss        | 873.92     |
| PolicyEntropy   | -0.0993614 |
| PolicyLoss      | 0.0167121  |
| Steps           | 10000      |
| VarFuncLoss     | 0.212      |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.41039    |
| _max_adv        | 11.2       |
| _max_discrew    | 4.68       |
| _max_obs        | 0.999      |
| _mean_act       | -0.110746  |
| _mean_adv       | -3.2e-17   |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0326     |
| _min_adv        | -4.62      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.29      |
| _std_act        | 0.685504   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00302687 |
| Phi_loss        | 764.285    |
| PolicyEntropy   | -0.114426  |
| PolicyLoss      | 0.00426068 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0126     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55869    |
| _max_adv        | 5.41       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.05       |
| _mean_act       | -0.112492  |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0323     |
| _min_adv        | -5.9       |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.35      |
| _std_act        | 0.68017    |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00291515 |
| Phi_loss        | 850.796    |
| PolicyEntropy   | -0.132186  |
| PolicyLoss      | -0.0138743 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00921    |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80985    |
| _max_adv        | 29.5       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.13       |
| _mean_act       | -0.114964  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0324     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.45      |
| _std_act        | 0.682009   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00214445 |
| Phi_loss        | 826.253    |
| PolicyEntropy   | -0.154327  |
| PolicyLoss      | 0.00386116 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00935    |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67128    |
| _max_adv        | 17.2       |
| _max_discrew    | 4.61       |
| _max_obs        | 0.999      |
| _mean_act       | -0.114917  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0324     |
| _min_adv        | -12.3      |
| _min_discrew    | 0.00963    |
| _min_obs        | -1.32      |
| _std_act        | 0.681698   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00140989 |
| Phi_loss        | 661.59     |
| PolicyEntropy   | -0.169784  |
| PolicyLoss      | 0.0100418  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00917    |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44222    |
| _max_adv        | 40.2       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.18       |
| _mean_act       | -0.116212  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.032      |
| _min_adv        | -9.13      |
| _min_discrew    | 0.0166     |
| _min_obs        | -1.3       |
| _std_act        | 0.674759   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00658427 |
| Phi_loss        | 804.359    |
| PolicyEntropy   | -0.16831   |
| PolicyLoss      | 0.0112071  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00801    |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82073    |
| _max_adv        | 4.14       |
| _max_discrew    | 4.58       |
| _max_obs        | 1.02       |
| _mean_act       | -0.110901  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0333     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0085     |
| _min_obs        | -1.37      |
| _std_act        | 0.683096   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.99        |
| KL              | 0.0028195   |
| Phi_loss        | 918.352     |
| PolicyEntropy   | -0.177759   |
| PolicyLoss      | -0.00126685 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0112      |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57304     |
| _max_adv        | 4.94        |
| _max_discrew    | 4.62        |
| _max_obs        | 1.08        |
| _mean_act       | -0.109122   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.59        |
| _mean_obs       | 0.0331      |
| _min_adv        | -11.8       |
| _min_discrew    | 0.0124      |
| _min_obs        | -1.59       |
| _std_act        | 0.688258    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00295055 |
| Phi_loss        | 921.712    |
| PolicyEntropy   | -0.18655   |
| PolicyLoss      | -0.0174716 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 4.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56359    |
| _max_adv        | 4.59       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.11       |
| _mean_act       | -0.108197  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0335     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.49      |
| _std_act        | 0.688668   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00326251  |
| Phi_loss        | 1026.22     |
| PolicyEntropy   | -0.205377   |
| PolicyLoss      | 0.000999621 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0111      |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69044     |
| _max_adv        | 4.13        |
| _max_discrew    | 4.63        |
| _max_obs        | 1.92        |
| _mean_act       | -0.11932    |
| _mean_adv       | 6.82e-17    |
| _mean_discrew   | 3.36        |
| _mean_obs       | 0.0326      |
| _min_adv        | -14.4       |
| _min_discrew    | -0.568      |
| _min_obs        | -1.34       |
| _std_act        | 0.709414    |
| _std_adv        | 1           |
| _std_discrew    | 1.72        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.911      |
| ExplainedVarOld | 0.851      |
| KL              | 0.00527152 |
| Phi_loss        | 792.218    |
| PolicyEntropy   | -0.24484   |
| PolicyLoss      | -0.0451964 |
| Steps           | 10000      |
| VarFuncLoss     | 0.156      |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51797    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.15       |
| _mean_act       | -0.106036  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0331     |
| _min_adv        | -12.6      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.38      |
| _std_act        | 0.690169   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.952      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00245045 |
| Phi_loss        | 723.508    |
| PolicyEntropy   | -0.244565  |
| PolicyLoss      | -0.0048578 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0577     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70409    |
| _max_adv        | 6.03       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.92       |
| _mean_act       | -0.125715  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.0327     |
| _min_adv        | -19.1      |
| _min_discrew    | -0.794     |
| _min_obs        | -1.34      |
| _std_act        | 0.744802   |
| _std_adv        | 1          |
| _std_discrew    | 2.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.911      |
| KL              | 0.005946   |
| Phi_loss        | 1238.41    |
| PolicyEntropy   | -0.263383  |
| PolicyLoss      | -0.0158484 |
| Steps           | 10000      |
| VarFuncLoss     | 0.197      |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.545      |
| _max_adv        | 23.4       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.07       |
| _mean_act       | -0.104084  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.52       |
| _mean_obs       | 0.0338     |
| _min_adv        | -9.04      |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.43      |
| _std_act        | 0.696514   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00283257 |
| Phi_loss        | 766.508    |
| PolicyEntropy   | -0.271848  |
| PolicyLoss      | 0.0164393  |
| Steps           | 10000      |
| VarFuncLoss     | 0.058      |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61156    |
| _max_adv        | 23.7       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.16       |
| _mean_act       | -0.101845  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0339     |
| _min_adv        | -10.8      |
| _min_discrew    | 0.0123     |
| _min_obs        | -1.35      |
| _std_act        | 0.691659   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00275707 |
| Phi_loss        | 818.62     |
| PolicyEntropy   | -0.286139  |
| PolicyLoss      | 0.0129126  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0172     |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54684    |
| _max_adv        | 15.9       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.19       |
| _mean_act       | -0.100884  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0338     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.42      |
| _std_act        | 0.685826   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00464429 |
| Phi_loss        | 881.866    |
| PolicyEntropy   | -0.285033  |
| PolicyLoss      | -0.0115538 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0135     |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77677    |
| _max_adv        | 7.96       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0990754 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0334     |
| _min_adv        | -7.5       |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.4       |
| _std_act        | 0.688117   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00392048 |
| Phi_loss        | 1034.92    |
| PolicyEntropy   | -0.298016  |
| PolicyLoss      | -0.0108408 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59179    |
| _max_adv        | 3.98       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0959825 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0341     |
| _min_adv        | -8.06      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.34      |
| _std_act        | 0.690897   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00311224  |
| Phi_loss        | 1238.23     |
| PolicyEntropy   | -0.322465   |
| PolicyLoss      | -0.00585172 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0106      |
| _MeanReward     | 4.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63318     |
| _max_adv        | 4.31        |
| _max_discrew    | 4.59        |
| _max_obs        | 0.999       |
| _mean_act       | -0.098356   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.59        |
| _mean_obs       | 0.0336      |
| _min_adv        | -8.63       |
| _min_discrew    | 0.0151      |
| _min_obs        | -1.34       |
| _std_act        | 0.691504    |
| _std_adv        | 1           |
| _std_discrew    | 1.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00330602 |
| Phi_loss        | 1111.1     |
| PolicyEntropy   | -0.351596  |
| PolicyLoss      | 0.00617484 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00994    |
| _MeanReward     | 4.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65205    |
| _max_adv        | 5.71       |
| _max_discrew    | 4.68       |
| _max_obs        | 1          |
| _mean_act       | -0.101091  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0335     |
| _min_adv        | -10.5      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.35      |
| _std_act        | 0.683176   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00376958 |
| Phi_loss        | 1087.52    |
| PolicyEntropy   | -0.379345  |
| PolicyLoss      | -0.0234205 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0108     |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74233    |
| _max_adv        | 2.84       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.21       |
| _mean_act       | -0.108461  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0327     |
| _min_adv        | -9.57      |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.4       |
| _std_act        | 0.689978   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.89        |
| ExplainedVarOld | 0.816       |
| KL              | 0.0026527   |
| Phi_loss        | 591.581     |
| PolicyEntropy   | -0.387399   |
| PolicyLoss      | -0.00211888 |
| Steps           | 10000       |
| VarFuncLoss     | 0.146       |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57017     |
| _max_adv        | 17.5        |
| _max_discrew    | 4.65        |
| _max_obs        | 1.23        |
| _mean_act       | -0.102481   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.0332      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.0172      |
| _min_obs        | -1.33       |
| _std_act        | 0.688636    |
| _std_adv        | 1           |
| _std_discrew    | 1.2         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00467241 |
| Phi_loss        | 924.46     |
| PolicyEntropy   | -0.404798  |
| PolicyLoss      | -0.0158883 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0299     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56624    |
| _max_adv        | 6.3        |
| _max_discrew    | 4.65       |
| _max_obs        | 1.02       |
| _mean_act       | -0.101549  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0339     |
| _min_adv        | -5.41      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.47      |
| _std_act        | 0.692935   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00411005 |
| Phi_loss        | 998.497    |
| PolicyEntropy   | -0.437802  |
| PolicyLoss      | -0.0175404 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00669    |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93627    |
| _max_adv        | 5.9        |
| _max_discrew    | 4.72       |
| _max_obs        | 1.04       |
| _mean_act       | -0.102118  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0339     |
| _min_adv        | -6.84      |
| _min_discrew    | 0.0156     |
| _min_obs        | -1.46      |
| _std_act        | 0.698602   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00234637 |
| Phi_loss        | 1177.68    |
| PolicyEntropy   | -0.465958  |
| PolicyLoss      | -0.0107473 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00913    |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66635    |
| _max_adv        | 13.9       |
| _max_discrew    | 4.63       |
| _max_obs        | 1.24       |
| _mean_act       | -0.10277   |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0345     |
| _min_adv        | -14.2      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.28      |
| _std_act        | 0.70296    |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00300728 |
| Phi_loss        | 898.559    |
| PolicyEntropy   | -0.479147  |
| PolicyLoss      | -0.0136242 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0344     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.563      |
| _max_adv        | 5.66       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.07       |
| _mean_act       | -0.101866  |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.0339     |
| _min_adv        | -10        |
| _min_discrew    | 0.0123     |
| _min_obs        | -1.28      |
| _std_act        | 0.700838   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00269516 |
| Phi_loss        | 894.75     |
| PolicyEntropy   | -0.489182  |
| PolicyLoss      | -0.0111639 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 4.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61524    |
| _max_adv        | 9.85       |
| _max_discrew    | 4.77       |
| _max_obs        | 1          |
| _mean_act       | -0.104809  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0346     |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.36      |
| _std_act        | 0.702218   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.96       |
| KL              | 0.00362398 |
| Phi_loss        | 1124.31    |
| PolicyEntropy   | -0.509786  |
| PolicyLoss      | 0.00679832 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0476     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4147     |
| _max_adv        | 4.25       |
| _max_discrew    | 4.64       |
| _max_obs        | 1.98       |
| _mean_act       | -0.105166  |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0343     |
| _min_adv        | -18.1      |
| _min_discrew    | -0.436     |
| _min_obs        | -1.36      |
| _std_act        | 0.714969   |
| _std_adv        | 1          |
| _std_discrew    | 1.52       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.944      |
| KL              | 0.00216576 |
| Phi_loss        | 1347.79    |
| PolicyEntropy   | -0.517862  |
| PolicyLoss      | 0.00757112 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0782     |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57998    |
| _max_adv        | 14.4       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.04       |
| _mean_act       | -0.0970163 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0351     |
| _min_adv        | -9.97      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.25      |
| _std_act        | 0.70112    |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00406759  |
| Phi_loss        | 910.91      |
| PolicyEntropy   | -0.532855   |
| PolicyLoss      | -0.00387189 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0168      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62393     |
| _max_adv        | 3.13        |
| _max_discrew    | 4.77        |
| _max_obs        | 1.11        |
| _mean_act       | -0.103033   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.63        |
| _mean_obs       | 0.0343      |
| _min_adv        | -12.6       |
| _min_discrew    | 0.0148      |
| _min_obs        | -1.37       |
| _std_act        | 0.7054      |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00299531 |
| Phi_loss        | 1002.39    |
| PolicyEntropy   | -0.536968  |
| PolicyLoss      | 0.00252709 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0473     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81795    |
| _max_adv        | 12.7       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.09       |
| _mean_act       | -0.101824  |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0343     |
| _min_adv        | -15        |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.45      |
| _std_act        | 0.700635   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00436855  |
| Phi_loss        | 1293.75     |
| PolicyEntropy   | -0.544724   |
| PolicyLoss      | -0.00821214 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0151      |
| _MeanReward     | 4.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62299     |
| _max_adv        | 19.4        |
| _max_discrew    | 4.69        |
| _max_obs        | 1.03        |
| _mean_act       | -0.0998207  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0343      |
| _min_adv        | -7.44       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.4        |
| _std_act        | 0.702207    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00302576 |
| Phi_loss        | 1255.31    |
| PolicyEntropy   | -0.574709  |
| PolicyLoss      | -0.0263639 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00971    |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65105    |
| _max_adv        | 7.52       |
| _max_discrew    | 4.73       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0977857 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0345     |
| _min_adv        | -9.97      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.4       |
| _std_act        | 0.700357   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00479577 |
| Phi_loss        | 1270.52    |
| PolicyEntropy   | -0.597453  |
| PolicyLoss      | -0.0242864 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.59724    |
| _max_adv        | 2.39       |
| _max_discrew    | 4.76       |
| _max_obs        | 2.02       |
| _mean_act       | -0.121947  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0345     |
| _min_adv        | -15.3      |
| _min_discrew    | -0.784     |
| _min_obs        | -1.38      |
| _std_act        | 0.758909   |
| _std_adv        | 1          |
| _std_discrew    | 2.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.857      |
| KL              | 0.0101908  |
| Phi_loss        | 1045.18    |
| PolicyEntropy   | -0.587955  |
| PolicyLoss      | 0.122893   |
| Steps           | 10000      |
| VarFuncLoss     | 0.288      |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6324     |
| _max_adv        | 14.8       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0998573 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0347     |
| _min_adv        | -20.9      |
| _min_discrew    | 0.0098     |
| _min_obs        | -1.38      |
| _std_act        | 0.705163   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00242668 |
| Phi_loss        | 883.535    |
| PolicyEntropy   | -0.588034  |
| PolicyLoss      | 0.0030521  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0314     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.58263    |
| _max_adv        | 18.4       |
| _max_discrew    | 4.72       |
| _max_obs        | 1          |
| _mean_act       | -0.0959636 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0344     |
| _min_adv        | -9.75      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.38      |
| _std_act        | 0.708129   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00183136 |
| Phi_loss        | 910.741    |
| PolicyEntropy   | -0.599542  |
| PolicyLoss      | -0.0126233 |
| Steps           | 10000      |
| VarFuncLoss     | 0.016      |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60149    |
| _max_adv        | 20         |
| _max_discrew    | 4.77       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0979739 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0348     |
| _min_adv        | -9.8       |
| _min_discrew    | 0.018      |
| _min_obs        | -1.33      |
| _std_act        | 0.706239   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
-------------------------------
| Beta            | 0.217     |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.99      |
| KL              | 0.0015201 |
| Phi_loss        | 1183.69   |
| PolicyEntropy   | -0.618167 |
| PolicyLoss      | 0.0086499 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0127    |
| _MeanReward     | 4.33e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.92774   |
| _max_adv        | 4.15      |
| _max_discrew    | 4.68      |
| _max_obs        | 1.93      |
| _mean_act       | -0.102652 |
| _mean_adv       | -5.4e-17  |
| _mean_discrew   | 3.55      |
| _mean_obs       | 0.0344    |
| _min_adv        | -13.3     |
| _min_discrew    | -0.379    |
| _min_obs        | -1.39     |
| _std_act        | 0.715429  |
| _std_adv        | 1         |
| _std_discrew    | 1.47      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.935      |
| KL              | 0.00471155 |
| Phi_loss        | 1008.33    |
| PolicyEntropy   | -0.620142  |
| PolicyLoss      | 0.0255642  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0826     |
| _MeanReward     | 4.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69718    |
| _max_adv        | 7.78       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.91       |
| _mean_act       | -0.10421   |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0347     |
| _min_adv        | -14.7      |
| _min_discrew    | -0.0702    |
| _min_obs        | -1.35      |
| _std_act        | 0.710756   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.936      |
| KL              | 0.00526653 |
| Phi_loss        | 855.811    |
| PolicyEntropy   | -0.610669  |
| PolicyLoss      | -0.0342973 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0515     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61887    |
| _max_adv        | 7.51       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.92       |
| _mean_act       | -0.10875   |
| _mean_adv       | -2.77e-17  |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0343     |
| _min_adv        | -14        |
| _min_discrew    | -0.534     |
| _min_obs        | -1.28      |
| _std_act        | 0.720325   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.899       |
| ExplainedVarOld | 0.885       |
| KL              | 0.00217733  |
| Phi_loss        | 1121.87     |
| PolicyEntropy   | -0.601584   |
| PolicyLoss      | -0.00139904 |
| Steps           | 10000       |
| VarFuncLoss     | 0.175       |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83328     |
| _max_adv        | 12.1        |
| _max_discrew    | 4.7         |
| _max_obs        | 1.23        |
| _mean_act       | -0.0981383  |
| _mean_adv       | 9.59e-18    |
| _mean_discrew   | 3.62        |
| _mean_obs       | 0.0342      |
| _min_adv        | -12.8       |
| _min_discrew    | 0.0173      |
| _min_obs        | -1.44       |
| _std_act        | 0.708648    |
| _std_adv        | 1           |
| _std_discrew    | 1.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00252309 |
| Phi_loss        | 1222.1     |
| PolicyEntropy   | -0.619495  |
| PolicyLoss      | -0.0355116 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0282     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.68257    |
| _max_adv        | 5.82       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0984093 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.0345     |
| _min_adv        | -9.52      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.46      |
| _std_act        | 0.714891   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00230915 |
| Phi_loss        | 1152.6     |
| PolicyEntropy   | -0.630437  |
| PolicyLoss      | -0.0113736 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0303     |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60046    |
| _max_adv        | 11.4       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0970906 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0347     |
| _min_adv        | -14.9      |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.38      |
| _std_act        | 0.707367   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00171569 |
| Phi_loss        | 1340.81    |
| PolicyEntropy   | -0.624494  |
| PolicyLoss      | 0.00476568 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0318     |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55551    |
| _max_adv        | 15.3       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0966457 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0353     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.43      |
| _std_act        | 0.707569   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00141313 |
| Phi_loss        | 1012.77    |
| PolicyEntropy   | -0.625751  |
| PolicyLoss      | -0.0247731 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0149     |
| _MeanReward     | 4.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7295     |
| _max_adv        | 5.67       |
| _max_discrew    | 4.73       |
| _max_obs        | 1.04       |
| _mean_act       | -0.0933194 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0352     |
| _min_adv        | -5.44      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.44      |
| _std_act        | 0.710626   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00388911 |
| Phi_loss        | 1426.62    |
| PolicyEntropy   | -0.654669  |
| PolicyLoss      | 0.0112333  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00964    |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56274    |
| _max_adv        | 5.23       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0949651 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0353     |
| _min_adv        | -6.13      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.37      |
| _std_act        | 0.704205   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00211362 |
| Phi_loss        | 1435.55    |
| PolicyEntropy   | -0.66711   |
| PolicyLoss      | -0.0173272 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00664    |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65984    |
| _max_adv        | 1.65       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.91       |
| _mean_act       | -0.117827  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.034      |
| _min_adv        | -17.5      |
| _min_discrew    | -0.746     |
| _min_obs        | -1.41      |
| _std_act        | 0.753551   |
| _std_adv        | 1          |
| _std_discrew    | 2.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.885      |
| KL              | 0.012618   |
| Phi_loss        | 1210.05    |
| PolicyEntropy   | -0.68502   |
| PolicyLoss      | 0.190973   |
| Steps           | 10000      |
| VarFuncLoss     | 0.223      |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5564     |
| _max_adv        | 5.05       |
| _max_discrew    | 4.73       |
| _max_obs        | 1.97       |
| _mean_act       | -0.0976057 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0352     |
| _min_adv        | -17.5      |
| _min_discrew    | -0.338     |
| _min_obs        | -1.36      |
| _std_act        | 0.717454   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.95       |
| KL              | 0.00321654 |
| Phi_loss        | 1200.14    |
| PolicyEntropy   | -0.684439  |
| PolicyLoss      | 0.0347971  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0705     |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.21718    |
| _max_adv        | 15.6       |
| _max_discrew    | 4.75       |
| _max_obs        | 1.92       |
| _mean_act       | -0.129044  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.22       |
| _mean_obs       | 0.0336     |
| _min_adv        | -18.2      |
| _min_discrew    | -0.715     |
| _min_obs        | -1.33      |
| _std_act        | 0.760883   |
| _std_adv        | 1          |
| _std_discrew    | 2.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00327082 |
| Phi_loss        | 883.978    |
| PolicyEntropy   | -0.695428  |
| PolicyLoss      | 0.00383052 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0988     |
| _MeanReward     | 4.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.5738     |
| _max_adv        | 12.9       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.36       |
| _mean_act       | -0.0971938 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0346     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0198     |
| _min_obs        | -1.43      |
| _std_act        | 0.709492   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.945       |
| ExplainedVarOld | 0.939       |
| KL              | 0.00174493  |
| Phi_loss        | 1280.87     |
| PolicyEntropy   | -0.703313   |
| PolicyLoss      | -0.00651014 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0689      |
| _MeanReward     | 4.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55425     |
| _max_adv        | 10.4        |
| _max_discrew    | 4.74        |
| _max_obs        | 1.03        |
| _mean_act       | -0.0915609  |
| _mean_adv       | -7.39e-17   |
| _mean_discrew   | 3.69        |
| _mean_obs       | 0.035       |
| _min_adv        | -5.74       |
| _min_discrew    | 0.0129      |
| _min_obs        | -1.36       |
| _std_act        | 0.708333    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00214141 |
| Phi_loss        | 1143.29    |
| PolicyEntropy   | -0.69551   |
| PolicyLoss      | -0.0185749 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0137     |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59339    |
| _max_adv        | 10         |
| _max_discrew    | 4.8        |
| _max_obs        | 1.28       |
| _mean_act       | -0.0952665 |
| _mean_adv       | -7.11e-19  |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.035      |
| _min_adv        | -15.8      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.39      |
| _std_act        | 0.709683   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00198859 |
| Phi_loss        | 836.14     |
| PolicyEntropy   | -0.708764  |
| PolicyLoss      | 0.0109128  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0204     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65597    |
| _max_adv        | 9.44       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0948578 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0354     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.42      |
| _std_act        | 0.716025   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
----------------------------------
| Beta            | 0.217        |
| ExplainedVarNew | 0.976        |
| ExplainedVarOld | 0.975        |
| KL              | 0.002599     |
| Phi_loss        | 1189.98      |
| PolicyEntropy   | -0.70334     |
| PolicyLoss      | -0.000535372 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0304       |
| _MeanReward     | 4.48e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.87472      |
| _max_adv        | 17.9         |
| _max_discrew    | 4.78         |
| _max_obs        | 1.04         |
| _mean_act       | -0.0957932   |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 3.7          |
| _mean_obs       | 0.0352       |
| _min_adv        | -8.51        |
| _min_discrew    | 0.0141       |
| _min_obs        | -1.35        |
| _std_act        | 0.714812     |
| _std_adv        | 1            |
| _std_discrew    | 1.29         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.00209218  |
| Phi_loss        | 1218.77     |
| PolicyEntropy   | -0.714991   |
| PolicyLoss      | -0.00101861 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0141      |
| _MeanReward     | 4.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.19906     |
| _max_adv        | 2.69        |
| _max_discrew    | 4.8         |
| _max_obs        | 1.03        |
| _mean_act       | -0.0978477  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.57        |
| _mean_obs       | 0.0345      |
| _min_adv        | -13.4       |
| _min_discrew    | 0.0155      |
| _min_obs        | -1.38       |
| _std_act        | 0.711236    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00256921 |
| Phi_loss        | 1179.52    |
| PolicyEntropy   | -0.722316  |
| PolicyLoss      | 0.0122482  |
| Steps           | 10000      |
| VarFuncLoss     | 0.038      |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63204    |
| _max_adv        | 8.03       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.03       |
| _mean_act       | -0.092063  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0349     |
| _min_adv        | -8.3       |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.31      |
| _std_act        | 0.710926   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00160113 |
| Phi_loss        | 1517.7     |
| PolicyEntropy   | -0.755055  |
| PolicyLoss      | -0.0220828 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0129     |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61522    |
| _max_adv        | 4.05       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0961324 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0353     |
| _min_adv        | -19.5      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.3       |
| _std_act        | 0.720911   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00270717 |
| Phi_loss        | 815.817    |
| PolicyEntropy   | -0.762095  |
| PolicyLoss      | 0.00657965 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0349     |
| _MeanReward     | 4.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63465    |
| _max_adv        | 11.9       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0923302 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0357     |
| _min_adv        | -17.4      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.43      |
| _std_act        | 0.717001   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.978       |
| KL              | 0.00202578  |
| Phi_loss        | 634.621     |
| PolicyEntropy   | -0.76722    |
| PolicyLoss      | -0.00597255 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0174      |
| _MeanReward     | 4.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77255     |
| _max_adv        | 10.7        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.05        |
| _mean_act       | -0.093171   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0358      |
| _min_adv        | -9.04       |
| _min_discrew    | 0.0115      |
| _min_obs        | -1.41       |
| _std_act        | 0.711846    |
| _std_adv        | 1           |
| _std_discrew    | 1.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00168803 |
| Phi_loss        | 1121.58    |
| PolicyEntropy   | -0.783212  |
| PolicyLoss      | -0.0263712 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 4.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7519     |
| _max_adv        | 12.5       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.99       |
| _mean_act       | -0.0949518 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0349     |
| _min_adv        | -9.91      |
| _min_discrew    | -0.0765    |
| _min_obs        | -1.46      |
| _std_act        | 0.71093    |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00241017 |
| Phi_loss        | 1114.95    |
| PolicyEntropy   | -0.788358  |
| PolicyLoss      | -0.0302753 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0283     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80673    |
| _max_adv        | 12.4       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0895345 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0359     |
| _min_adv        | -12.1      |
| _min_discrew    | 0.017      |
| _min_obs        | -1.38      |
| _std_act        | 0.708411   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00118984 |
| Phi_loss        | 1084.38    |
| PolicyEntropy   | -0.792842  |
| PolicyLoss      | 0.00581686 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.83944    |
| _max_adv        | 2.93       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.25       |
| _mean_act       | -0.09447   |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0357     |
| _min_adv        | -11        |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.4       |
| _std_act        | 0.711766   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.941      |
| KL              | 0.00896369 |
| Phi_loss        | 727.26     |
| PolicyEntropy   | -0.788962  |
| PolicyLoss      | 0.0781102  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0367     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67544    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0925208 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0353     |
| _min_adv        | -12.6      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.37      |
| _std_act        | 0.704006   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00400529 |
| Phi_loss        | 925.745    |
| PolicyEntropy   | -0.824942  |
| PolicyLoss      | 0.0342013  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0478     |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64484    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.93       |
| _mean_act       | -0.094206  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0353     |
| _min_adv        | -9.37      |
| _min_discrew    | -0.0905    |
| _min_obs        | -1.55      |
| _std_act        | 0.705775   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.962       |
| ExplainedVarOld | 0.958       |
| KL              | 0.00392363  |
| Phi_loss        | 1174.78     |
| PolicyEntropy   | -0.837874   |
| PolicyLoss      | -0.00254475 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0494      |
| _MeanReward     | 4.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78372     |
| _max_adv        | 3.34        |
| _max_discrew    | 4.82        |
| _max_obs        | 1.94        |
| _mean_act       | -0.126276   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.034       |
| _min_adv        | -17.2       |
| _min_discrew    | -0.728      |
| _min_obs        | -1.36       |
| _std_act        | 0.753385    |
| _std_adv        | 1           |
| _std_discrew    | 2.82        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.935      |
| KL              | 0.00371563 |
| Phi_loss        | 883.743    |
| PolicyEntropy   | -0.836937  |
| PolicyLoss      | 0.0237073  |
| Steps           | 10000      |
| VarFuncLoss     | 0.154      |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72513    |
| _max_adv        | 16.4       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0910292 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0353     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.34      |
| _std_act        | 0.707651   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00262841 |
| Phi_loss        | 967.533    |
| PolicyEntropy   | -0.833283  |
| PolicyLoss      | 0.00427585 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0194     |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65187    |
| _max_adv        | 14.8       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.92       |
| _mean_act       | -0.0933005 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0349     |
| _min_adv        | -9.56      |
| _min_discrew    | -0.12      |
| _min_obs        | -1.38      |
| _std_act        | 0.708733   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00301156  |
| Phi_loss        | 944.914     |
| PolicyEntropy   | -0.852955   |
| PolicyLoss      | -0.00956981 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0214      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5713      |
| _max_adv        | 3.76        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.01        |
| _mean_act       | -0.0952026  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0349      |
| _min_adv        | -9.48       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.44       |
| _std_act        | 0.708274    |
| _std_adv        | 1           |
| _std_discrew    | 1.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.927       |
| KL              | 0.00770836  |
| Phi_loss        | 596.405     |
| PolicyEntropy   | -0.872739   |
| PolicyLoss      | 0.000824464 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0377      |
| _MeanReward     | 4.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54722     |
| _max_adv        | 6.22        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.96        |
| _mean_act       | -0.118265   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.37        |
| _mean_obs       | 0.0349      |
| _min_adv        | -18.7       |
| _min_discrew    | -0.683      |
| _min_obs        | -1.32       |
| _std_act        | 0.747317    |
| _std_adv        | 1           |
| _std_discrew    | 2.46        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.911      |
| ExplainedVarOld | 0.907      |
| KL              | 0.00649703 |
| Phi_loss        | 1356.8     |
| PolicyEntropy   | -0.886331  |
| PolicyLoss      | -0.091093  |
| Steps           | 10000      |
| VarFuncLoss     | 0.218      |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54446    |
| _max_adv        | 26.1       |
| _max_discrew    | 4.76       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0897329 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0357     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.015      |
| _min_obs        | -1.39      |
| _std_act        | 0.707788   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00158457 |
| Phi_loss        | 1183.42    |
| PolicyEntropy   | -0.887267  |
| PolicyLoss      | 0.0295108  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0245     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.89698    |
| _max_adv        | 25.4       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.09       |
| _mean_act       | -0.090755  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0354     |
| _min_adv        | -8.87      |
| _min_discrew    | -0.0217    |
| _min_obs        | -1.43      |
| _std_act        | 0.711434   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.971       |
| KL              | 0.000744136 |
| Phi_loss        | 980.153     |
| PolicyEntropy   | -0.879363   |
| PolicyLoss      | -0.00285243 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0289      |
| _MeanReward     | 4.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54958     |
| _max_adv        | 18.2        |
| _max_discrew    | 4.89        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0902007  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0356      |
| _min_adv        | -14.3       |
| _min_discrew    | 0.0176      |
| _min_obs        | -1.39       |
| _std_act        | 0.705533    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00100901 |
| Phi_loss        | 1282.37    |
| PolicyEntropy   | -0.881703  |
| PolicyLoss      | 0.019822   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0286     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61679    |
| _max_adv        | 7.57       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0880887 |
| _mean_adv       | -7.11e-18  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0355     |
| _min_adv        | -5.51      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.35      |
| _std_act        | 0.71023    |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00159451 |
| Phi_loss        | 1433.96    |
| PolicyEntropy   | -0.901451  |
| PolicyLoss      | -0.0137729 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00672    |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.51738    |
| _max_adv        | 9.94       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0904403 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0349     |
| _min_adv        | -7.37      |
| _min_discrew    | 0.0219     |
| _min_obs        | -1.38      |
| _std_act        | 0.703755   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 477
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00282591 |
| Phi_loss        | 1592.62    |
| PolicyEntropy   | -0.923444  |
| PolicyLoss      | -0.0320098 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00921    |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.6978     |
| _max_adv        | 1.55       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.95       |
| _mean_act       | -0.102006  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0349     |
| _min_adv        | -16.3      |
| _min_discrew    | -0.563     |
| _min_obs        | -1.36      |
| _std_act        | 0.72869    |
| _std_adv        | 1          |
| _std_discrew    | 1.79       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 478
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.9        |
| KL              | 0.00330252 |
| Phi_loss        | 1054.4     |
| PolicyEntropy   | -0.933073  |
| PolicyLoss      | 0.00989273 |
| Steps           | 10000      |
| VarFuncLoss     | 0.156      |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59467    |
| _max_adv        | 9.59       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.98       |
| _mean_act       | -0.120425  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0339     |
| _min_adv        | -18.4      |
| _min_discrew    | -0.697     |
| _min_obs        | -1.31      |
| _std_act        | 0.748612   |
| _std_adv        | 1          |
| _std_discrew    | 2.63       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 479
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00306649 |
| Phi_loss        | 1492.34    |
| PolicyEntropy   | -0.944293  |
| PolicyLoss      | 0.00841292 |
| Steps           | 10000      |
| VarFuncLoss     | 0.213      |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54584    |
| _max_adv        | 11.6       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0896784 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.035      |
| _min_adv        | -9.19      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.45      |
| _std_act        | 0.704997   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 480
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00311927  |
| Phi_loss        | 1294.58     |
| PolicyEntropy   | -0.96779    |
| PolicyLoss      | -0.00516575 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0234      |
| _MeanReward     | 4.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69438     |
| _max_adv        | 27          |
| _max_discrew    | 4.8         |
| _max_obs        | 1.3         |
| _mean_act       | -0.089792   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.69        |
| _mean_obs       | 0.0348      |
| _min_adv        | -8.68       |
| _min_discrew    | 0.0126      |
| _min_obs        | -1.33       |
| _std_act        | 0.705281    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 481
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.98       |
| KL              | 0.003195   |
| Phi_loss        | 1056.87    |
| PolicyEntropy   | -0.983423  |
| PolicyLoss      | -0.0385088 |
| Steps           | 10000      |
| VarFuncLoss     | 0.016      |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67647    |
| _max_adv        | 8.16       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0916511 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0353     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0182     |
| _min_obs        | -1.39      |
| _std_act        | 0.712497   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 482
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.976      |
| KL              | 0.003761   |
| Phi_loss        | 1546.62    |
| PolicyEntropy   | -1.00459   |
| PolicyLoss      | -0.0539513 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0297     |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70606    |
| _max_adv        | 3.43       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0927336 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0354     |
| _min_adv        | -13.9      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.34      |
| _std_act        | 0.712271   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 483
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00234277 |
| Phi_loss        | 1329.55    |
| PolicyEntropy   | -1.0152    |
| PolicyLoss      | -0.0132691 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0225     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62518    |
| _max_adv        | 15.6       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0904664 |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.035      |
| _min_adv        | -8.04      |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.35      |
| _std_act        | 0.71351    |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 484
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00222386 |
| Phi_loss        | 1340.36    |
| PolicyEntropy   | -1.00405   |
| PolicyLoss      | -0.0189972 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.57566    |
| _max_adv        | 18.2       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0935673 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0348     |
| _min_adv        | -20.7      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.44      |
| _std_act        | 0.711217   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 485
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00229953 |
| Phi_loss        | 1541.73    |
| PolicyEntropy   | -1.0024    |
| PolicyLoss      | -0.0227689 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60342    |
| _max_adv        | 7.38       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.01       |
| _mean_act       | -0.090321  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.035      |
| _min_adv        | -6.91      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.49      |
| _std_act        | 0.712226   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 486
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.988      |
| KL              | 0.00210297 |
| Phi_loss        | 1516.56    |
| PolicyEntropy   | -1.00037   |
| PolicyLoss      | 0.00107626 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0133     |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62724    |
| _max_adv        | 13.1       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0938132 |
| _mean_adv       | -7.11e-18  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0357     |
| _min_adv        | -21.2      |
| _min_discrew    | 0.0171     |
| _min_obs        | -1.49      |
| _std_act        | 0.715544   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 487
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00219684 |
| Phi_loss        | 1315.55    |
| PolicyEntropy   | -1.00712   |
| PolicyLoss      | 0.0118425  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62224    |
| _max_adv        | 6.5        |
| _max_discrew    | 4.85       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0925988 |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0355     |
| _min_adv        | -7.33      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.35      |
| _std_act        | 0.721086   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 488
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00279869 |
| Phi_loss        | 1752.17    |
| PolicyEntropy   | -1.0288    |
| PolicyLoss      | -0.0201338 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00868    |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67352    |
| _max_adv        | 6.99       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0912078 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0353     |
| _min_adv        | -7.13      |
| _min_discrew    | 0.0171     |
| _min_obs        | -1.33      |
| _std_act        | 0.716784   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 489
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.0040367  |
| Phi_loss        | 1896.39    |
| PolicyEntropy   | -1.03596   |
| PolicyLoss      | 0.00381595 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00908    |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7478     |
| _max_adv        | 5.91       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0897275 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0358     |
| _min_adv        | -4.9       |
| _min_discrew    | 0.019      |
| _min_obs        | -1.39      |
| _std_act        | 0.718107   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 490
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00267072 |
| Phi_loss        | 1910.79    |
| PolicyEntropy   | -1.05432   |
| PolicyLoss      | -0.0378299 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00628    |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63776    |
| _max_adv        | 11.8       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.05       |
| _mean_act       | -0.0905252 |
| _mean_adv       | -6.39e-18  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0359     |
| _min_adv        | -9.8       |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.37      |
| _std_act        | 0.719946   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 491
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00256158 |
| Phi_loss        | 1636.94    |
| PolicyEntropy   | -1.05795   |
| PolicyLoss      | 0.00485723 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00929    |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68157    |
| _max_adv        | 6.95       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0921991 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0356     |
| _min_adv        | -9.46      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.35      |
| _std_act        | 0.717183   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 492
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00255118 |
| Phi_loss        | 1798.57    |
| PolicyEntropy   | -1.06072   |
| PolicyLoss      | 0.00274812 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59009    |
| _max_adv        | 4.23       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0939356 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0356     |
| _min_adv        | -12.2      |
| _min_discrew    | 0.02       |
| _min_obs        | -1.34      |
| _std_act        | 0.719714   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 493
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.0022402  |
| Phi_loss        | 1743.19    |
| PolicyEntropy   | -1.07258   |
| PolicyLoss      | -0.0288414 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7017     |
| _max_adv        | 17.5       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.38       |
| _mean_act       | -0.08982   |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0357     |
| _min_adv        | -12.6      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.41      |
| _std_act        | 0.713919   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 494
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.989       |
| KL              | 0.0029504   |
| Phi_loss        | 1526.11     |
| PolicyEntropy   | -1.08576    |
| PolicyLoss      | 0.000285774 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0124      |
| _MeanReward     | 4.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.49307     |
| _max_adv        | 5.89        |
| _max_discrew    | 4.84        |
| _max_obs        | 1.02        |
| _mean_act       | -0.091222   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.78        |
| _mean_obs       | 0.0358      |
| _min_adv        | -6.07       |
| _min_discrew    | 0.0213      |
| _min_obs        | -1.41       |
| _std_act        | 0.723248    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 495
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00264248 |
| Phi_loss        | 1860.57    |
| PolicyEntropy   | -1.10114   |
| PolicyLoss      | -0.0356285 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00989    |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79757    |
| _max_adv        | 3.8        |
| _max_discrew    | 4.84       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0947774 |
| _mean_adv       | 7.11e-19   |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0354     |
| _min_adv        | -15        |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.34      |
| _std_act        | 0.728354   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 496
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.989       |
| KL              | 0.00284067  |
| Phi_loss        | 1234.97     |
| PolicyEntropy   | -1.10636    |
| PolicyLoss      | -0.00385759 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0127      |
| _MeanReward     | 4.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79405     |
| _max_adv        | 6.77        |
| _max_discrew    | 4.89        |
| _max_obs        | 1.97        |
| _mean_act       | -0.0939155  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0363      |
| _min_adv        | -11.1       |
| _min_discrew    | -0.0629     |
| _min_obs        | -1.43       |
| _std_act        | 0.726635    |
| _std_adv        | 1           |
| _std_discrew    | 1.39        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 497
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00371947 |
| Phi_loss        | 1419.62    |
| PolicyEntropy   | -1.11213   |
| PolicyLoss      | 0.0121758  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0253     |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56044    |
| _max_adv        | 10.8       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0913261 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0358     |
| _min_adv        | -13.7      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.31      |
| _std_act        | 0.725125   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 498
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00246196 |
| Phi_loss        | 1541.57    |
| PolicyEntropy   | -1.11178   |
| PolicyLoss      | -0.0181406 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81849    |
| _max_adv        | 3.7        |
| _max_discrew    | 4.91       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0918581 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0362     |
| _min_adv        | -12.2      |
| _min_discrew    | 0.0181     |
| _min_obs        | -1.36      |
| _std_act        | 0.726175   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 499
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00423276 |
| Phi_loss        | 1608.94    |
| PolicyEntropy   | -1.11546   |
| PolicyLoss      | -0.0349216 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0336     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81066    |
| _max_adv        | 5.67       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0927038 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0361     |
| _min_adv        | -15.2      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.36      |
| _std_act        | 0.73112    |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 500
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00207326 |
| Phi_loss        | 1136.3     |
| PolicyEntropy   | -1.12822   |
| PolicyLoss      | -0.0245312 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63656    |
| _max_adv        | 12.7       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0901079 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0357     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.44      |
| _std_act        | 0.725194   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 501
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00195956 |
| Phi_loss        | 1901.13    |
| PolicyEntropy   | -1.13355   |
| PolicyLoss      | -0.0302521 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0249     |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65261    |
| _max_adv        | 10.8       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.25       |
| _mean_act       | -0.0891991 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0367     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.48      |
| _std_act        | 0.728155   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 502
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00282421 |
| Phi_loss        | 1518.28    |
| PolicyEntropy   | -1.14027   |
| PolicyLoss      | 0.01486    |
| Steps           | 10000      |
| VarFuncLoss     | 0.024      |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63546    |
| _max_adv        | 5.43       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0884799 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0356     |
| _min_adv        | -9.86      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.46      |
| _std_act        | 0.727479   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 503
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00278971 |
| Phi_loss        | 1846.32    |
| PolicyEntropy   | -1.15601   |
| PolicyLoss      | -0.0437571 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0126     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.71868    |
| _max_adv        | 8.06       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0933199 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0358     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0194     |
| _min_obs        | -1.31      |
| _std_act        | 0.733227   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 504
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.956       |
| KL              | 0.00434792  |
| Phi_loss        | 1834.33     |
| PolicyEntropy   | -1.1874     |
| PolicyLoss      | -0.00824099 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0513      |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80779     |
| _max_adv        | 15.3        |
| _max_discrew    | 4.89        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0900681  |
| _mean_adv       | 3.45e-17    |
| _mean_discrew   | 3.81        |
| _mean_obs       | 0.0362      |
| _min_adv        | -7.88       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.44       |
| _std_act        | 0.735122    |
| _std_adv        | 1           |
| _std_discrew    | 1.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 505
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00405011 |
| Phi_loss        | 1248.54    |
| PolicyEntropy   | -1.21498   |
| PolicyLoss      | 0.00541905 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0172     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61013    |
| _max_adv        | 7.31       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.08       |
| _mean_act       | -0.091383  |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0357     |
| _min_adv        | -14.5      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.4       |
| _std_act        | 0.731576   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 506
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00504805  |
| Phi_loss        | 1703.19     |
| PolicyEntropy   | -1.22523    |
| PolicyLoss      | -0.00535482 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0281      |
| _MeanReward     | 4.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64463     |
| _max_adv        | 2.6         |
| _max_discrew    | 4.92        |
| _max_obs        | 1.96        |
| _mean_act       | -0.0939262  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0369      |
| _min_adv        | -11.9       |
| _min_discrew    | -0.288      |
| _min_obs        | -1.34       |
| _std_act        | 0.743986    |
| _std_adv        | 1           |
| _std_discrew    | 1.57        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 507
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00449509 |
| Phi_loss        | 1650.82    |
| PolicyEntropy   | -1.25725   |
| PolicyLoss      | 0.0152032  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0808     |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69689    |
| _max_adv        | 5.84       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0907143 |
| _mean_adv       | 2.77e-17   |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.0358     |
| _min_adv        | -11.6      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.35      |
| _std_act        | 0.73266    |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 508
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00429734 |
| Phi_loss        | 1597.32    |
| PolicyEntropy   | -1.27581   |
| PolicyLoss      | 0.0170862  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79154    |
| _max_adv        | 12.9       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.1        |
| _mean_act       | -0.0895221 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0366     |
| _min_adv        | -6.53      |
| _min_discrew    | -0.00431   |
| _min_obs        | -1.33      |
| _std_act        | 0.731279   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 509
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00341721 |
| Phi_loss        | 1780.45    |
| PolicyEntropy   | -1.2887    |
| PolicyLoss      | -0.0407045 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0108     |
| _MeanReward     | 4.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.93063    |
| _max_adv        | 4.18       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.99       |
| _mean_act       | -0.110539  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0359     |
| _min_adv        | -14.8      |
| _min_discrew    | -0.618     |
| _min_obs        | -1.5       |
| _std_act        | 0.770029   |
| _std_adv        | 1          |
| _std_discrew    | 2.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 510
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.882       |
| KL              | 0.00406135  |
| Phi_loss        | 1807.91     |
| PolicyEntropy   | -1.29845    |
| PolicyLoss      | -0.00580994 |
| Steps           | 10000       |
| VarFuncLoss     | 0.246       |
| _MeanReward     | 4.67e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58864     |
| _max_adv        | 15.2        |
| _max_discrew    | 4.92        |
| _max_obs        | 0.999       |
| _mean_act       | -0.0899538  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.85        |
| _mean_obs       | 0.0364      |
| _min_adv        | -5.41       |
| _min_discrew    | 0.0158      |
| _min_obs        | -1.4        |
| _std_act        | 0.732548    |
| _std_adv        | 1           |
| _std_discrew    | 1.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 511
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00278462  |
| Phi_loss        | 1942.08     |
| PolicyEntropy   | -1.31961    |
| PolicyLoss      | -0.00683893 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0161      |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76176     |
| _max_adv        | 3.64        |
| _max_discrew    | 4.98        |
| _max_obs        | 1.98        |
| _mean_act       | -0.139637   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.27        |
| _mean_obs       | 0.0358      |
| _min_adv        | -14.7       |
| _min_discrew    | -0.707      |
| _min_obs        | -1.36       |
| _std_act        | 0.801679    |
| _std_adv        | 1           |
| _std_discrew    | 3.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 512
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.885      |
| ExplainedVarOld | 0.87       |
| KL              | 0.00334424 |
| Phi_loss        | 1304.56    |
| PolicyEntropy   | -1.3318    |
| PolicyLoss      | -0.0205287 |
| Steps           | 10000      |
| VarFuncLoss     | 0.394      |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69152    |
| _max_adv        | 17.4       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0910613 |
| _mean_adv       | 1.85e-17   |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0362     |
| _min_adv        | -6.4       |
| _min_discrew    | 0.016      |
| _min_obs        | -1.43      |
| _std_act        | 0.731845   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 513
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00366193 |
| Phi_loss        | 2235.15    |
| PolicyEntropy   | -1.32488   |
| PolicyLoss      | -0.0512977 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0221     |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71544    |
| _max_adv        | 20.1       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0906072 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.0368     |
| _min_adv        | -4.91      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.37      |
| _std_act        | 0.744775   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 514
Draw Samples..
-------------------------------
| Beta            | 0.325     |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.988     |
| KL              | 0.0192791 |
| Phi_loss        | 5621.88   |
| PolicyEntropy   | -1.31246  |
| PolicyLoss      | 0.352497  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00732   |
| _MeanReward     | 4.26e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.60841   |
| _max_adv        | 6.48      |
| _max_discrew    | 4.88      |
| _max_obs        | 1.98      |
| _mean_act       | -0.115342 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.5       |
| _mean_obs       | 0.0351    |
| _min_adv        | -17.3     |
| _min_discrew    | -0.696    |
| _min_obs        | -1.3      |
| _std_act        | 0.77127   |
| _std_adv        | 1         |
| _std_discrew    | 2.34      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 515
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.892      |
| KL              | 0.0138735  |
| Phi_loss        | 3756.76    |
| PolicyEntropy   | -1.29549   |
| PolicyLoss      | -0.0239438 |
| Steps           | 10000      |
| VarFuncLoss     | 0.241      |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60748    |
| _max_adv        | 9.85       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0954775 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0356     |
| _min_adv        | -17.5      |
| _min_discrew    | 0.0191     |
| _min_obs        | -1.37      |
| _std_act        | 0.736035   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 516
Draw Samples..
---------------------------------
| Beta            | 0.488       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00308705  |
| Phi_loss        | 2329.12     |
| PolicyEntropy   | -1.28493    |
| PolicyLoss      | -0.00315137 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0246      |
| _MeanReward     | 4.69e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79786     |
| _max_adv        | 12.3        |
| _max_discrew    | 4.97        |
| _max_obs        | 1.05        |
| _mean_act       | -0.0924645  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.86        |
| _mean_obs       | 0.0362      |
| _min_adv        | -5.68       |
| _min_discrew    | 0.0194      |
| _min_obs        | -1.34       |
| _std_act        | 0.736148    |
| _std_adv        | 1           |
| _std_discrew    | 1.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 517
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00130764 |
| Phi_loss        | 2565.01    |
| PolicyEntropy   | -1.29714   |
| PolicyLoss      | -0.0192335 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0105     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67974    |
| _max_adv        | 7.32       |
| _max_discrew    | 4.94       |
| _max_obs        | 1.97       |
| _mean_act       | -0.130736  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0354     |
| _min_adv        | -14        |
| _min_discrew    | -0.708     |
| _min_obs        | -1.44      |
| _std_act        | 0.792936   |
| _std_adv        | 1          |
| _std_discrew    | 2.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 518
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.885      |
| ExplainedVarOld | 0.869      |
| KL              | 0.00273134 |
| Phi_loss        | 2246.13    |
| PolicyEntropy   | -1.29088   |
| PolicyLoss      | -0.0512519 |
| Steps           | 10000      |
| VarFuncLoss     | 0.32       |
| _MeanReward     | 4.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74066    |
| _max_adv        | 10         |
| _max_discrew    | 4.91       |
| _max_obs        | 1.97       |
| _mean_act       | -0.128024  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.38       |
| _mean_obs       | 0.035      |
| _min_adv        | -14.7      |
| _min_discrew    | -0.712     |
| _min_obs        | -1.36      |
| _std_act        | 0.780069   |
| _std_adv        | 1          |
| _std_discrew    | 2.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 519
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.893      |
| KL              | 0.00200834 |
| Phi_loss        | 2397.13    |
| PolicyEntropy   | -1.29396   |
| PolicyLoss      | -0.0285035 |
| Steps           | 10000      |
| VarFuncLoss     | 0.25       |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73809    |
| _max_adv        | 3.46       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.95       |
| _mean_act       | -0.132618  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0347     |
| _min_adv        | -19.8      |
| _min_discrew    | -0.719     |
| _min_obs        | -1.29      |
| _std_act        | 0.792846   |
| _std_adv        | 1          |
| _std_discrew    | 3.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 520
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00180379 |
| Phi_loss        | 1674.72    |
| PolicyEntropy   | -1.29841   |
| PolicyLoss      | -0.0265172 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0829     |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.617      |
| _max_adv        | 20.3       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0898376 |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0358     |
| _min_adv        | -4.43      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.39      |
| _std_act        | 0.736313   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 521
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.989       |
| KL              | 0.00222061  |
| Phi_loss        | 1873.41     |
| PolicyEntropy   | -1.30154    |
| PolicyLoss      | -0.00223997 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00889     |
| _MeanReward     | 4.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.869       |
| _max_adv        | 6.75        |
| _max_discrew    | 4.98        |
| _max_obs        | 2.02        |
| _mean_act       | -0.130969   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.41        |
| _mean_obs       | 0.035       |
| _min_adv        | -18.8       |
| _min_discrew    | -0.71       |
| _min_obs        | -1.35       |
| _std_act        | 0.788975    |
| _std_adv        | 1           |
| _std_discrew    | 2.92        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 522
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.925      |
| KL              | 0.0027134  |
| Phi_loss        | 2171.59    |
| PolicyEntropy   | -1.30748   |
| PolicyLoss      | 0.0211008  |
| Steps           | 10000      |
| VarFuncLoss     | 0.214      |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43625    |
| _max_adv        | 10.9       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.97       |
| _mean_act       | -0.0972514 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0353     |
| _min_adv        | -10.7      |
| _min_discrew    | -0.000578  |
| _min_obs        | -1.43      |
| _std_act        | 0.736591   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 523
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00237921 |
| Phi_loss        | 1969.24    |
| PolicyEntropy   | -1.31781   |
| PolicyLoss      | 0.0459782  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0355     |
| _MeanReward     | 3.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56293    |
| _max_adv        | 5.29       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.96       |
| _mean_act       | -0.142079  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.0341     |
| _min_adv        | -13.9      |
| _min_discrew    | -0.698     |
| _min_obs        | -1.31      |
| _std_act        | 0.786167   |
| _std_adv        | 1          |
| _std_discrew    | 3.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 524
Draw Samples..
-------------------------------
| Beta            | 0.325     |
| ExplainedVarNew | 0.89      |
| ExplainedVarOld | 0.884     |
| KL              | 0.0017071 |
| Phi_loss        | 2033.51   |
| PolicyEntropy   | -1.32733  |
| PolicyLoss      | -0.026621 |
| Steps           | 10000     |
| VarFuncLoss     | 0.35      |
| _MeanReward     | 4.56e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.7228    |
| _max_adv        | 3.45      |
| _max_discrew    | 4.96      |
| _max_obs        | 1.93      |
| _mean_act       | -0.100788 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.74      |
| _mean_obs       | 0.0354    |
| _min_adv        | -16.4     |
| _min_discrew    | -0.435    |
| _min_obs        | -1.4      |
| _std_act        | 0.75068   |
| _std_adv        | 1         |
| _std_discrew    | 1.7       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 525
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.938      |
| KL              | 0.00144883 |
| Phi_loss        | 1856.3     |
| PolicyEntropy   | -1.31965   |
| PolicyLoss      | 0.0134748  |
| Steps           | 10000      |
| VarFuncLoss     | 0.103      |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65935    |
| _max_adv        | 13.5       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0936912 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0358     |
| _min_adv        | -7.73      |
| _min_discrew    | 0.0123     |
| _min_obs        | -1.48      |
| _std_act        | 0.738315   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 526
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00290127 |
| Phi_loss        | 1919.45    |
| PolicyEntropy   | -1.33046   |
| PolicyLoss      | -0.0214088 |
| Steps           | 10000      |
| VarFuncLoss     | 0.01       |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61025    |
| _max_adv        | 15.3       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.94       |
| _mean_act       | -0.0941096 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0361     |
| _min_adv        | -8.21      |
| _min_discrew    | -0.00773   |
| _min_obs        | -1.34      |
| _std_act        | 0.737399   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 527
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.987      |
| KL              | 0.00957039 |
| Phi_loss        | 1959.28    |
| PolicyEntropy   | -1.33142   |
| PolicyLoss      | 0.0705158  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69275    |
| _max_adv        | 6.81       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.93       |
| _mean_act       | -0.0955713 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0358     |
| _min_adv        | -15.4      |
| _min_discrew    | -0.176     |
| _min_obs        | -1.45      |
| _std_act        | 0.739909   |
| _std_adv        | 1          |
| _std_discrew    | 1.53       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 528
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00302108  |
| Phi_loss        | 1839.4      |
| PolicyEntropy   | -1.33148    |
| PolicyLoss      | -0.00451971 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0322      |
| _MeanReward     | 4.65e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73067     |
| _max_adv        | 26.1        |
| _max_discrew    | 4.96        |
| _max_obs        | 1.09        |
| _mean_act       | -0.0907454  |
| _mean_adv       | 4.26e-18    |
| _mean_discrew   | 3.86        |
| _mean_obs       | 0.0359      |
| _min_adv        | -10.2       |
| _min_discrew    | 0.0125      |
| _min_obs        | -1.46       |
| _std_act        | 0.738302    |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 529
Draw Samples..
---------------------------------
| Beta            | 0.488       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00857975  |
| Phi_loss        | 1001.06     |
| PolicyEntropy   | -1.34619    |
| PolicyLoss      | -0.00318632 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0117      |
| _MeanReward     | 4.16e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62824     |
| _max_adv        | 1.22        |
| _max_discrew    | 5.06        |
| _max_obs        | 1.93        |
| _mean_act       | -0.128937   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.42        |
| _mean_obs       | 0.034       |
| _min_adv        | -17.2       |
| _min_discrew    | -0.67       |
| _min_obs        | -1.42       |
| _std_act        | 0.772564    |
| _std_adv        | 1           |
| _std_discrew    | 2.77        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 530
Draw Samples..
-------------------------------
| Beta            | 0.732     |
| ExplainedVarNew | 0.922     |
| ExplainedVarOld | 0.909     |
| KL              | 0.0129996 |
| Phi_loss        | 2935.76   |
| PolicyEntropy   | -1.35159  |
| PolicyLoss      | 0.102825  |
| Steps           | 10000     |
| VarFuncLoss     | 0.219     |
| _MeanReward     | 4.3e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.53998   |
| _max_adv        | 5.73      |
| _max_discrew    | 4.95      |
| _max_obs        | 2.01      |
| _mean_act       | -0.121421 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.53      |
| _mean_obs       | 0.0348    |
| _min_adv        | -16.3     |
| _min_discrew    | -0.649    |
| _min_obs        | -1.31     |
| _std_act        | 0.761153  |
| _std_adv        | 1         |
| _std_discrew    | 2.39      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
