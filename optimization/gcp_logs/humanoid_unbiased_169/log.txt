Logging to humanoid_unbiased_169
using small structure
Policy Params -- h1: 377, h2: 80,                     h3: 17, lr: 0.000101, logvar_speed: 3
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
-------------------------------
| Steps         | 10016       |
| _MeanReward   | 105         |
| _max_act      | 2.90255     |
| _max_adv      | 3.17        |
| _max_discrew  | 0.978       |
| _max_obs      | 1.02e+03    |
| _mean_act     | -0.00614038 |
| _mean_adv     | 1.22e-16    |
| _mean_discrew | 0.286       |
| _mean_obs     | 0.00142     |
| _min_adv      | -3.76       |
| _min_discrew  | 0.00858     |
| _min_obs      | -667        |
| _std_act      | 0.404792    |
| _std_adv      | 1           |
| _std_discrew  | 0.0311      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.732       |
| ExplainedVarOld | -0.461      |
| KL              | 0.000647924 |
| Phi_loss        | 7.27647     |
| PolicyEntropy   | 15.6227     |
| PolicyLoss      | -0.00126772 |
| Steps           | 10017       |
| VarFuncLoss     | 0.00834     |
| _MeanReward     | 112         |
| _lr_multiplier  | 1           |
| _max_act        | 2.82158     |
| _max_adv        | 9.8         |
| _max_discrew    | 1.25        |
| _max_obs        | 26          |
| _mean_act       | -0.00348484 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.303       |
| _mean_obs       | -0.000211   |
| _min_adv        | -3.47       |
| _min_discrew    | 0.015       |
| _min_obs        | -24.3       |
| _std_act        | 0.396348    |
| _std_adv        | 1           |
| _std_discrew    | 0.0354      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
---------------------------------
| Beta            | 1           |
| ExplainedVarNew | 0.723       |
| ExplainedVarOld | 0.557       |
| KL              | 0.00648411  |
| Phi_loss        | 58.8189     |
| PolicyEntropy   | 15.6104     |
| PolicyLoss      | -0.00627334 |
| Steps           | 10020       |
| VarFuncLoss     | 0.00979     |
| _MeanReward     | 111         |
| _lr_multiplier  | 1           |
| _max_act        | 2.6223      |
| _max_adv        | 7.77        |
| _max_discrew    | 1.36        |
| _max_obs        | 31.6        |
| _mean_act       | 0.000174916 |
| _mean_adv       | 1.84e-17    |
| _mean_discrew   | 0.303       |
| _mean_obs       | 0.000644    |
| _min_adv        | -3.2        |
| _min_discrew    | 0.00861     |
| _min_obs        | -27.8       |
| _std_act        | 0.401725    |
| _std_adv        | 1           |
| _std_discrew    | 0.0377      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
---------------------------------
| Beta            | 1           |
| ExplainedVarNew | 0.683       |
| ExplainedVarOld | 0.628       |
| KL              | 0.00166701  |
| Phi_loss        | 85.1929     |
| PolicyEntropy   | 15.6141     |
| PolicyLoss      | -0.00584277 |
| Steps           | 10020       |
| VarFuncLoss     | 0.012       |
| _MeanReward     | 110         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13828     |
| _max_adv        | 4.76        |
| _max_discrew    | 1.07        |
| _max_obs        | 50.8        |
| _mean_act       | 0.00151909  |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.297       |
| _mean_obs       | 0.000682    |
| _min_adv        | -5.14       |
| _min_discrew    | 0.0144      |
| _min_obs        | -52.5       |
| _std_act        | 0.399179    |
| _std_adv        | 1           |
| _std_discrew    | 0.0339      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.742       |
| ExplainedVarOld | 0.708       |
| KL              | 0.000611357 |
| Phi_loss        | 82.2184     |
| PolicyEntropy   | 15.619      |
| PolicyLoss      | -0.00293014 |
| Steps           | 10003       |
| VarFuncLoss     | 0.00875     |
| _MeanReward     | 113         |
| _lr_multiplier  | 1           |
| _max_act        | 3.22187     |
| _max_adv        | 5.57        |
| _max_discrew    | 1.01        |
| _max_obs        | 49.6        |
| _mean_act       | -0.00169413 |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 0.304       |
| _mean_obs       | 0.000446    |
| _min_adv        | -5.8        |
| _min_discrew    | 0.014       |
| _min_obs        | -41.5       |
| _std_act        | 0.403803    |
| _std_adv        | 1           |
| _std_discrew    | 0.0346      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.751       |
| ExplainedVarOld | 0.708       |
| KL              | 0.000868229 |
| Phi_loss        | 82.314      |
| PolicyEntropy   | 15.6106     |
| PolicyLoss      | 0.00465838  |
| Steps           | 10023       |
| VarFuncLoss     | 0.00863     |
| _MeanReward     | 116         |
| _lr_multiplier  | 1           |
| _max_act        | 3.33588     |
| _max_adv        | 5.27        |
| _max_discrew    | 1.15        |
| _max_obs        | 47.8        |
| _mean_act       | 0.00342362  |
| _mean_adv       | 1.98e-17    |
| _mean_discrew   | 0.314       |
| _mean_obs       | 0.000317    |
| _min_adv        | -3.23       |
| _min_discrew    | 0.0102      |
| _min_obs        | -48.2       |
| _std_act        | 0.402163    |
| _std_adv        | 1           |
| _std_discrew    | 0.0386      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.719      |
| ExplainedVarOld | 0.678      |
| KL              | 0.0126715  |
| Phi_loss        | 798.281    |
| PolicyEntropy   | 15.6099    |
| PolicyLoss      | 0.278786   |
| Steps           | 10025      |
| VarFuncLoss     | 0.0109     |
| _MeanReward     | 121        |
| _lr_multiplier  | 1          |
| _max_act        | 2.80139    |
| _max_adv        | 5          |
| _max_discrew    | 1.28       |
| _max_obs        | 62         |
| _mean_act       | 0.00319044 |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.328      |
| _mean_obs       | 0.000838   |
| _min_adv        | -3.32      |
| _min_discrew    | 0.00593    |
| _min_obs        | -43.8      |
| _std_act        | 0.400586   |
| _std_adv        | 1          |
| _std_discrew    | 0.0417     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.721      |
| ExplainedVarOld | 0.668      |
| KL              | 0.00724345 |
| Phi_loss        | 123.868    |
| PolicyEntropy   | 15.5959    |
| PolicyLoss      | -0.259537  |
| Steps           | 10004      |
| VarFuncLoss     | 0.0117     |
| _MeanReward     | 126        |
| _lr_multiplier  | 1          |
| _max_act        | 2.83488    |
| _max_adv        | 5.12       |
| _max_discrew    | 1.27       |
| _max_obs        | 34.9       |
| _mean_act       | 0.00528507 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.343      |
| _mean_obs       | -2.08e-05  |
| _min_adv        | -4.18      |
| _min_discrew    | 0.0072     |
| _min_obs        | -25        |
| _std_act        | 0.401764   |
| _std_adv        | 1          |
| _std_discrew    | 0.0473     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.712       |
| ExplainedVarOld | 0.651       |
| KL              | 0.000594733 |
| Phi_loss        | 86.1688     |
| PolicyEntropy   | 15.5907     |
| PolicyLoss      | -0.0019347  |
| Steps           | 10009       |
| VarFuncLoss     | 0.0137      |
| _MeanReward     | 123         |
| _lr_multiplier  | 1           |
| _max_act        | 2.84595     |
| _max_adv        | 5.47        |
| _max_discrew    | 1.37        |
| _max_obs        | 43.1        |
| _mean_act       | 0.00550458  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.335       |
| _mean_obs       | 0.00104     |
| _min_adv        | -3.21       |
| _min_discrew    | 0.0121      |
| _min_obs        | -32.1       |
| _std_act        | 0.401006    |
| _std_adv        | 1           |
| _std_discrew    | 0.0446      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.714       |
| ExplainedVarOld | 0.662       |
| KL              | 0.00065528  |
| Phi_loss        | 89.0378     |
| PolicyEntropy   | 15.5932     |
| PolicyLoss      | -0.00277041 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0128      |
| _MeanReward     | 127         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93874     |
| _max_adv        | 5.75        |
| _max_discrew    | 1.61        |
| _max_obs        | 39.6        |
| _mean_act       | 0.00674931  |
| _mean_adv       | -1.84e-17   |
| _mean_discrew   | 0.352       |
| _mean_obs       | 0.0011      |
| _min_adv        | -3          |
| _min_discrew    | 0.0102      |
| _min_obs        | -27.4       |
| _std_act        | 0.402037    |
| _std_adv        | 1           |
| _std_discrew    | 0.0515      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.7          |
| ExplainedVarOld | 0.639        |
| KL              | 0.00113798   |
| Phi_loss        | 80.2396      |
| PolicyEntropy   | 15.5916      |
| PolicyLoss      | -0.000503789 |
| Steps           | 10003        |
| VarFuncLoss     | 0.0154       |
| _MeanReward     | 131          |
| _lr_multiplier  | 1            |
| _max_act        | 2.94585      |
| _max_adv        | 4.66         |
| _max_discrew    | 1.48         |
| _max_obs        | 39.8         |
| _mean_act       | 0.00843515   |
| _mean_adv       | 8.52e-18     |
| _mean_discrew   | 0.36         |
| _mean_obs       | 0.00118      |
| _min_adv        | -2.83        |
| _min_discrew    | 0.0156       |
| _min_obs        | -39          |
| _std_act        | 0.402455     |
| _std_adv        | 1            |
| _std_discrew    | 0.0542       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.717       |
| ExplainedVarOld | 0.641       |
| KL              | 0.00248165  |
| Phi_loss        | 79.368      |
| PolicyEntropy   | 15.59       |
| PolicyLoss      | -0.00280735 |
| Steps           | 10004       |
| VarFuncLoss     | 0.0154      |
| _MeanReward     | 137         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04386     |
| _max_adv        | 4.79        |
| _max_discrew    | 1.32        |
| _max_obs        | 31.6        |
| _mean_act       | 0.00849975  |
| _mean_adv       | -1.35e-17   |
| _mean_discrew   | 0.374       |
| _mean_obs       | 0.00107     |
| _min_adv        | -3.56       |
| _min_discrew    | 0.00923     |
| _min_obs        | -30.8       |
| _std_act        | 0.405381    |
| _std_adv        | 1           |
| _std_discrew    | 0.0568      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.712       |
| ExplainedVarOld | 0.638       |
| KL              | 0.00267792  |
| Phi_loss        | 89.2023     |
| PolicyEntropy   | 15.5895     |
| PolicyLoss      | -0.00686443 |
| Steps           | 10004       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 142         |
| _lr_multiplier  | 1           |
| _max_act        | 2.7767      |
| _max_adv        | 4.89        |
| _max_discrew    | 1.41        |
| _max_obs        | 30.6        |
| _mean_act       | 0.0105156   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.389       |
| _mean_obs       | 0.00122     |
| _min_adv        | -2.78       |
| _min_discrew    | 0.00865     |
| _min_obs        | -29.3       |
| _std_act        | 0.405849    |
| _std_adv        | 1           |
| _std_discrew    | 0.0618      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.707      |
| ExplainedVarOld | 0.632      |
| KL              | 0.00218013 |
| Phi_loss        | 83.3243    |
| PolicyEntropy   | 15.5845    |
| PolicyLoss      | 0.00163929 |
| Steps           | 10011      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 146        |
| _lr_multiplier  | 1          |
| _max_act        | 2.74973    |
| _max_adv        | 4.55       |
| _max_discrew    | 1.31       |
| _max_obs        | 33.1       |
| _mean_act       | 0.0110963  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.397      |
| _mean_obs       | 0.00197    |
| _min_adv        | -3.45      |
| _min_discrew    | 0.00955    |
| _min_obs        | -28.3      |
| _std_act        | 0.406986   |
| _std_adv        | 1          |
| _std_discrew    | 0.0624     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.721       |
| ExplainedVarOld | 0.628       |
| KL              | 0.00278563  |
| Phi_loss        | 80.5143     |
| PolicyEntropy   | 15.5811     |
| PolicyLoss      | -0.00265505 |
| Steps           | 10025       |
| VarFuncLoss     | 0.0174      |
| _MeanReward     | 151         |
| _lr_multiplier  | 1           |
| _max_act        | 2.68705     |
| _max_adv        | 4.6         |
| _max_discrew    | 1.53        |
| _max_obs        | 29          |
| _mean_act       | 0.0123259   |
| _mean_adv       | 8.51e-18    |
| _mean_discrew   | 0.419       |
| _mean_obs       | 0.00202     |
| _min_adv        | -3.3        |
| _min_discrew    | 0.0127      |
| _min_obs        | -23         |
| _std_act        | 0.406731    |
| _std_adv        | 1           |
| _std_discrew    | 0.0732      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.689      |
| ExplainedVarOld | 0.601      |
| KL              | 0.00242479 |
| Phi_loss        | 80.9968    |
| PolicyEntropy   | 15.5785    |
| PolicyLoss      | 0.00106422 |
| Steps           | 10038      |
| VarFuncLoss     | 0.0228     |
| _MeanReward     | 162        |
| _lr_multiplier  | 1          |
| _max_act        | 2.90729    |
| _max_adv        | 5.29       |
| _max_discrew    | 1.57       |
| _max_obs        | 50.7       |
| _mean_act       | 0.0169078  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.434      |
| _mean_obs       | 0.00245    |
| _min_adv        | -3.26      |
| _min_discrew    | 0.0149     |
| _min_obs        | -50.5      |
| _std_act        | 0.407974   |
| _std_adv        | 1          |
| _std_discrew    | 0.072      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.722       |
| ExplainedVarOld | 0.631       |
| KL              | 0.00322571  |
| Phi_loss        | 71.2768     |
| PolicyEntropy   | 15.5761     |
| PolicyLoss      | -0.00376619 |
| Steps           | 10002       |
| VarFuncLoss     | 0.0201      |
| _MeanReward     | 160         |
| _lr_multiplier  | 1           |
| _max_act        | 3.35251     |
| _max_adv        | 4.39        |
| _max_discrew    | 1.58        |
| _max_obs        | 37.1        |
| _mean_act       | 0.0139025   |
| _mean_adv       | 1.85e-17    |
| _mean_discrew   | 0.431       |
| _mean_obs       | 0.00306     |
| _min_adv        | -3.45       |
| _min_discrew    | 0.00871     |
| _min_obs        | -30.9       |
| _std_act        | 0.407015    |
| _std_adv        | 1           |
| _std_discrew    | 0.0722      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.735      |
| ExplainedVarOld | 0.633      |
| KL              | 0.00253307 |
| Phi_loss        | 68.7192    |
| PolicyEntropy   | 15.5733    |
| PolicyLoss      | -0.0024224 |
| Steps           | 10036      |
| VarFuncLoss     | 0.0191     |
| _MeanReward     | 172        |
| _lr_multiplier  | 1          |
| _max_act        | 3.12239    |
| _max_adv        | 4.55       |
| _max_discrew    | 1.56       |
| _max_obs        | 29.5       |
| _mean_act       | 0.0167988  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.464      |
| _mean_obs       | 0.00262    |
| _min_adv        | -3.04      |
| _min_discrew    | 0.00973    |
| _min_obs        | -20.8      |
| _std_act        | 0.407098   |
| _std_adv        | 1          |
| _std_discrew    | 0.0843     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.722       |
| ExplainedVarOld | 0.604       |
| KL              | 0.00300309  |
| Phi_loss        | 69.6328     |
| PolicyEntropy   | 15.5686     |
| PolicyLoss      | 0.000380765 |
| Steps           | 10044       |
| VarFuncLoss     | 0.0237      |
| _MeanReward     | 178         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0889      |
| _max_adv        | 4.09        |
| _max_discrew    | 1.63        |
| _max_obs        | 29.9        |
| _mean_act       | 0.0174178   |
| _mean_adv       | -1.7e-17    |
| _mean_discrew   | 0.473       |
| _mean_obs       | 0.00195     |
| _min_adv        | -3.4        |
| _min_discrew    | 0.00803     |
| _min_obs        | -25         |
| _std_act        | 0.40674     |
| _std_adv        | 1           |
| _std_discrew    | 0.0865      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.74        |
| ExplainedVarOld | 0.632       |
| KL              | 0.00257109  |
| Phi_loss        | 67.482      |
| PolicyEntropy   | 15.5681     |
| PolicyLoss      | -0.00476645 |
| Steps           | 10005       |
| VarFuncLoss     | 0.0226      |
| _MeanReward     | 178         |
| _lr_multiplier  | 1           |
| _max_act        | 2.8396      |
| _max_adv        | 5.54        |
| _max_discrew    | 1.69        |
| _max_obs        | 25.4        |
| _mean_act       | 0.0182446   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.478       |
| _mean_obs       | 0.00202     |
| _min_adv        | -3.68       |
| _min_discrew    | 0.0122      |
| _min_obs        | -27.7       |
| _std_act        | 0.407324    |
| _std_adv        | 1           |
| _std_discrew    | 0.0888      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.746      |
| ExplainedVarOld | 0.627      |
| KL              | 0.00384202 |
| Phi_loss        | 76.9046    |
| PolicyEntropy   | 15.5628    |
| PolicyLoss      | 0.0185418  |
| Steps           | 10060      |
| VarFuncLoss     | 0.0226     |
| _MeanReward     | 181        |
| _lr_multiplier  | 1          |
| _max_act        | 3.00764    |
| _max_adv        | 4.32       |
| _max_discrew    | 1.42       |
| _max_obs        | 70.2       |
| _mean_act       | 0.0179248  |
| _mean_adv       | 3.96e-17   |
| _mean_discrew   | 0.482      |
| _mean_obs       | 0.00263    |
| _min_adv        | -3.56      |
| _min_discrew    | 0.011      |
| _min_obs        | -31.6      |
| _std_act        | 0.405457   |
| _std_adv        | 1          |
| _std_discrew    | 0.0882     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.759        |
| ExplainedVarOld | 0.644        |
| KL              | 0.00280954   |
| Phi_loss        | 75.95        |
| PolicyEntropy   | 15.5573      |
| PolicyLoss      | -0.000681359 |
| Steps           | 10004        |
| VarFuncLoss     | 0.0213       |
| _MeanReward     | 199          |
| _lr_multiplier  | 1            |
| _max_act        | 2.76633      |
| _max_adv        | 5.39         |
| _max_discrew    | 1.94         |
| _max_obs        | 42.7         |
| _mean_act       | 0.0233642    |
| _mean_adv       | 1.42e-18     |
| _mean_discrew   | 0.534        |
| _mean_obs       | 0.00392      |
| _min_adv        | -3.1         |
| _min_discrew    | 0.0127       |
| _min_obs        | -33.4        |
| _std_act        | 0.405446     |
| _std_adv        | 1            |
| _std_discrew    | 0.115        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.743      |
| ExplainedVarOld | 0.6        |
| KL              | 0.00258662 |
| Phi_loss        | 69.2602    |
| PolicyEntropy   | 15.555     |
| PolicyLoss      | -0.0052827 |
| Steps           | 10009      |
| VarFuncLoss     | 0.0297     |
| _MeanReward     | 206        |
| _lr_multiplier  | 1          |
| _max_act        | 2.85323    |
| _max_adv        | 4.88       |
| _max_discrew    | 1.64       |
| _max_obs        | 44         |
| _mean_act       | 0.0271604  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.536      |
| _mean_obs       | 0.00341    |
| _min_adv        | -3.82      |
| _min_discrew    | 0.0119     |
| _min_obs        | -45.5      |
| _std_act        | 0.406892   |
| _std_adv        | 1          |
| _std_discrew    | 0.103      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
-------------------------------
| Beta            | 0.296     |
| ExplainedVarNew | 0.781     |
| ExplainedVarOld | 0.647     |
| KL              | 0.0056055 |
| Phi_loss        | 91.7967   |
| PolicyEntropy   | 15.5452   |
| PolicyLoss      | 0.0258193 |
| Steps           | 10020     |
| VarFuncLoss     | 0.0229    |
| _MeanReward     | 206       |
| _lr_multiplier  | 1         |
| _max_act        | 2.84328   |
| _max_adv        | 5.02      |
| _max_discrew    | 1.81      |
| _max_obs        | 39        |
| _mean_act       | 0.0237253 |
| _mean_adv       | 3.12e-17  |
| _mean_discrew   | 0.542     |
| _mean_obs       | 0.00282   |
| _min_adv        | -4.06     |
| _min_discrew    | 0.0141    |
| _min_obs        | -30.1     |
| _std_act        | 0.408307  |
| _std_adv        | 1         |
| _std_discrew    | 0.111     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.768        |
| ExplainedVarOld | 0.622        |
| KL              | 0.00363456   |
| Phi_loss        | 90.4646      |
| PolicyEntropy   | 15.5358      |
| PolicyLoss      | -0.000955712 |
| Steps           | 10007        |
| VarFuncLoss     | 0.0259       |
| _MeanReward     | 220          |
| _lr_multiplier  | 1            |
| _max_act        | 3.28195      |
| _max_adv        | 4.8          |
| _max_discrew    | 1.81         |
| _max_obs        | 30.6         |
| _mean_act       | 0.0256741    |
| _mean_adv       | 1.49e-17     |
| _mean_discrew   | 0.579        |
| _mean_obs       | 0.00412      |
| _min_adv        | -3.82        |
| _min_discrew    | 0.0106       |
| _min_obs        | -45.8        |
| _std_act        | 0.407639     |
| _std_adv        | 1            |
| _std_discrew    | 0.126        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.773       |
| ExplainedVarOld | 0.656       |
| KL              | 0.00236807  |
| Phi_loss        | 84.3407     |
| PolicyEntropy   | 15.5366     |
| PolicyLoss      | -0.00513779 |
| Steps           | 10010       |
| VarFuncLoss     | 0.0288      |
| _MeanReward     | 221         |
| _lr_multiplier  | 1           |
| _max_act        | 2.8016      |
| _max_adv        | 4.45        |
| _max_discrew    | 1.91        |
| _max_obs        | 30.5        |
| _mean_act       | 0.0289585   |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.585       |
| _mean_obs       | 0.00403     |
| _min_adv        | -3.97       |
| _min_discrew    | 0.0179      |
| _min_obs        | -25.7       |
| _std_act        | 0.406709    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.771       |
| ExplainedVarOld | 0.627       |
| KL              | 0.00280181  |
| Phi_loss        | 81.4179     |
| PolicyEntropy   | 15.5354     |
| PolicyLoss      | -0.00211127 |
| Steps           | 10019       |
| VarFuncLoss     | 0.0303      |
| _MeanReward     | 223         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18344     |
| _max_adv        | 5.03        |
| _max_discrew    | 1.71        |
| _max_obs        | 42.1        |
| _mean_act       | 0.0303972   |
| _mean_adv       | 5.67e-18    |
| _mean_discrew   | 0.582       |
| _mean_obs       | 0.00303     |
| _min_adv        | -3.66       |
| _min_discrew    | 0.0121      |
| _min_obs        | -21.1       |
| _std_act        | 0.412182    |
| _std_adv        | 1           |
| _std_discrew    | 0.124       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.76       |
| ExplainedVarOld | 0.581      |
| KL              | 0.00460484 |
| Phi_loss        | 91.2023    |
| PolicyEntropy   | 15.5274    |
| PolicyLoss      | -0.142386  |
| Steps           | 10010      |
| VarFuncLoss     | 0.0299     |
| _MeanReward     | 233        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8107     |
| _max_adv        | 4.52       |
| _max_discrew    | 1.95       |
| _max_obs        | 36.3       |
| _mean_act       | 0.0330841  |
| _mean_adv       | 1.7e-17    |
| _mean_discrew   | 0.605      |
| _mean_obs       | 0.00418    |
| _min_adv        | -3.66      |
| _min_discrew    | -0.000251  |
| _min_obs        | -35.8      |
| _std_act        | 0.407386   |
| _std_adv        | 1          |
| _std_discrew    | 0.134      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.774       |
| ExplainedVarOld | 0.629       |
| KL              | 0.0030821   |
| Phi_loss        | 91.1047     |
| PolicyEntropy   | 15.52       |
| PolicyLoss      | -0.00531384 |
| Steps           | 10046       |
| VarFuncLoss     | 0.0303      |
| _MeanReward     | 248         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1131      |
| _max_adv        | 4.2         |
| _max_discrew    | 1.93        |
| _max_obs        | 31.4        |
| _mean_act       | 0.0308459   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.624       |
| _mean_obs       | 0.00298     |
| _min_adv        | -3.57       |
| _min_discrew    | 0.00792     |
| _min_obs        | -22.8       |
| _std_act        | 0.406802    |
| _std_adv        | 1           |
| _std_discrew    | 0.137       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.803       |
| ExplainedVarOld | 0.649       |
| KL              | 0.00281927  |
| Phi_loss        | 89.3341     |
| PolicyEntropy   | 15.5175     |
| PolicyLoss      | -0.00113579 |
| Steps           | 10032       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 244         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03257     |
| _max_adv        | 4.02        |
| _max_discrew    | 1.98        |
| _max_obs        | 44.8        |
| _mean_act       | 0.0307069   |
| _mean_adv       | 1.84e-17    |
| _mean_discrew   | 0.629       |
| _mean_obs       | 0.00493     |
| _min_adv        | -4.27       |
| _min_discrew    | 0.00937     |
| _min_obs        | -32.9       |
| _std_act        | 0.409543    |
| _std_adv        | 1           |
| _std_discrew    | 0.145       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.795       |
| ExplainedVarOld | 0.641       |
| KL              | 0.00277875  |
| Phi_loss        | 94.3542     |
| PolicyEntropy   | 15.5144     |
| PolicyLoss      | -0.00317679 |
| Steps           | 10024       |
| VarFuncLoss     | 0.0297      |
| _MeanReward     | 252         |
| _lr_multiplier  | 1           |
| _max_act        | 2.9052      |
| _max_adv        | 3.95        |
| _max_discrew    | 1.79        |
| _max_obs        | 41.1        |
| _mean_act       | 0.0345926   |
| _mean_adv       | -1.28e-17   |
| _mean_discrew   | 0.64        |
| _mean_obs       | 0.00399     |
| _min_adv        | -4.05       |
| _min_discrew    | 0.00143     |
| _min_obs        | -29.9       |
| _std_act        | 0.407149    |
| _std_adv        | 1           |
| _std_discrew    | 0.144       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.813      |
| ExplainedVarOld | 0.656      |
| KL              | 0.00324063 |
| Phi_loss        | 91.6278    |
| PolicyEntropy   | 15.51      |
| PolicyLoss      | 0.00694044 |
| Steps           | 10047      |
| VarFuncLoss     | 0.0268     |
| _MeanReward     | 262        |
| _lr_multiplier  | 1          |
| _max_act        | 2.99093    |
| _max_adv        | 4.77       |
| _max_discrew    | 2.19       |
| _max_obs        | 33.2       |
| _mean_act       | 0.0357646  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.66       |
| _mean_obs       | 0.0038     |
| _min_adv        | -3.66      |
| _min_discrew    | 0.0105     |
| _min_obs        | -30.4      |
| _std_act        | 0.406209   |
| _std_adv        | 1          |
| _std_discrew    | 0.158      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.811        |
| ExplainedVarOld | 0.632        |
| KL              | 0.00334634   |
| Phi_loss        | 90.5205      |
| PolicyEntropy   | 15.5049      |
| PolicyLoss      | -0.000276121 |
| Steps           | 10027        |
| VarFuncLoss     | 0.03         |
| _MeanReward     | 269          |
| _lr_multiplier  | 1            |
| _max_act        | 2.84107      |
| _max_adv        | 4.26         |
| _max_discrew    | 2.56         |
| _max_obs        | 25.8         |
| _mean_act       | 0.0401725    |
| _mean_adv       | -3.4e-17     |
| _mean_discrew   | 0.693        |
| _mean_obs       | 0.00471      |
| _min_adv        | -3.84        |
| _min_discrew    | 0.0173       |
| _min_obs        | -27.9        |
| _std_act        | 0.405493     |
| _std_adv        | 1            |
| _std_discrew    | 0.183        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.798        |
| ExplainedVarOld | 0.627        |
| KL              | 0.00254387   |
| Phi_loss        | 86.2822      |
| PolicyEntropy   | 15.4977      |
| PolicyLoss      | -0.000699846 |
| Steps           | 10032        |
| VarFuncLoss     | 0.0371       |
| _MeanReward     | 273          |
| _lr_multiplier  | 1            |
| _max_act        | 2.87593      |
| _max_adv        | 4.58         |
| _max_discrew    | 2.14         |
| _max_obs        | 29.5         |
| _mean_act       | 0.0392737    |
| _mean_adv       | -1.7e-17     |
| _mean_discrew   | 0.695        |
| _mean_obs       | 0.00541      |
| _min_adv        | -3.98        |
| _min_discrew    | 0.0171       |
| _min_obs        | -32.8        |
| _std_act        | 0.405254     |
| _std_adv        | 1            |
| _std_discrew    | 0.177        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.813       |
| ExplainedVarOld | 0.657       |
| KL              | 0.00284927  |
| Phi_loss        | 81.9604     |
| PolicyEntropy   | 15.4938     |
| PolicyLoss      | -0.00230436 |
| Steps           | 10004       |
| VarFuncLoss     | 0.0333      |
| _MeanReward     | 276         |
| _lr_multiplier  | 1           |
| _max_act        | 3.00857     |
| _max_adv        | 4.4         |
| _max_discrew    | 2.27        |
| _max_obs        | 35.3        |
| _mean_act       | 0.0425043   |
| _mean_adv       | -8.52e-18   |
| _mean_discrew   | 0.695       |
| _mean_obs       | 0.00501     |
| _min_adv        | -3.87       |
| _min_discrew    | 0.0118      |
| _min_obs        | -40         |
| _std_act        | 0.404716    |
| _std_adv        | 1           |
| _std_discrew    | 0.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.826       |
| ExplainedVarOld | 0.658       |
| KL              | 0.00307628  |
| Phi_loss        | 78.4625     |
| PolicyEntropy   | 15.4915     |
| PolicyLoss      | -0.00594838 |
| Steps           | 10053       |
| VarFuncLoss     | 0.0296      |
| _MeanReward     | 283         |
| _lr_multiplier  | 1           |
| _max_act        | 2.75826     |
| _max_adv        | 5.81        |
| _max_discrew    | 2.06        |
| _max_obs        | 53.6        |
| _mean_act       | 0.0418315   |
| _mean_adv       | 1.98e-17    |
| _mean_discrew   | 0.71        |
| _mean_obs       | 0.00475     |
| _min_adv        | -3.74       |
| _min_discrew    | 0.0149      |
| _min_obs        | -36.3       |
| _std_act        | 0.405741    |
| _std_adv        | 1           |
| _std_discrew    | 0.177       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.837       |
| ExplainedVarOld | 0.661       |
| KL              | 0.0028666   |
| Phi_loss        | 80.294      |
| PolicyEntropy   | 15.4882     |
| PolicyLoss      | -0.00062741 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0292      |
| _MeanReward     | 286         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14022     |
| _max_adv        | 4.65        |
| _max_discrew    | 1.94        |
| _max_obs        | 33.1        |
| _mean_act       | 0.045167    |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 0.713       |
| _mean_obs       | 0.0056      |
| _min_adv        | -3.86       |
| _min_discrew    | 0.0098      |
| _min_obs        | -27.6       |
| _std_act        | 0.405768    |
| _std_adv        | 1           |
| _std_discrew    | 0.168       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.849      |
| ExplainedVarOld | 0.698      |
| KL              | 0.00260531 |
| Phi_loss        | 76.0998    |
| PolicyEntropy   | 15.4865    |
| PolicyLoss      | -0.0022351 |
| Steps           | 10015      |
| VarFuncLoss     | 0.0253     |
| _MeanReward     | 287        |
| _lr_multiplier  | 1          |
| _max_act        | 3.16657    |
| _max_adv        | 5.61       |
| _max_discrew    | 2.89       |
| _max_obs        | 40.2       |
| _mean_act       | 0.038797   |
| _mean_adv       | -8.51e-18  |
| _mean_discrew   | 0.723      |
| _mean_obs       | 0.00417    |
| _min_adv        | -4.08      |
| _min_discrew    | 0.0151     |
| _min_obs        | -41.8      |
| _std_act        | 0.406641   |
| _std_adv        | 1          |
| _std_discrew    | 0.194      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.825       |
| ExplainedVarOld | 0.617       |
| KL              | 0.00308927  |
| Phi_loss        | 62.5225     |
| PolicyEntropy   | 15.4836     |
| PolicyLoss      | 0.000241085 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0338      |
| _MeanReward     | 297         |
| _lr_multiplier  | 1           |
| _max_act        | 3.37031     |
| _max_adv        | 4.54        |
| _max_discrew    | 2.02        |
| _max_obs        | 32.2        |
| _mean_act       | 0.0445822   |
| _mean_adv       | -1.28e-17   |
| _mean_discrew   | 0.738       |
| _mean_obs       | 0.0049      |
| _min_adv        | -3.63       |
| _min_discrew    | 0.0109      |
| _min_obs        | -23         |
| _std_act        | 0.406775    |
| _std_adv        | 1           |
| _std_discrew    | 0.183       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.838       |
| ExplainedVarOld | 0.669       |
| KL              | 0.00346228  |
| Phi_loss        | 67.0262     |
| PolicyEntropy   | 15.4845     |
| PolicyLoss      | -0.00736112 |
| Steps           | 10053       |
| VarFuncLoss     | 0.0298      |
| _MeanReward     | 291         |
| _lr_multiplier  | 1           |
| _max_act        | 2.81727     |
| _max_adv        | 5.31        |
| _max_discrew    | 2.07        |
| _max_obs        | 46.4        |
| _mean_act       | 0.0431568   |
| _mean_adv       | -5.65e-18   |
| _mean_discrew   | 0.725       |
| _mean_obs       | 0.00469     |
| _min_adv        | -4.52       |
| _min_discrew    | 0.0122      |
| _min_obs        | -38.6       |
| _std_act        | 0.404702    |
| _std_adv        | 1           |
| _std_discrew    | 0.175       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.85      |
| ExplainedVarOld | 0.68      |
| KL              | 0.0126148 |
| Phi_loss        | 521.567   |
| PolicyEntropy   | 15.4859   |
| PolicyLoss      | -0.406839 |
| Steps           | 10031     |
| VarFuncLoss     | 0.0263    |
| _MeanReward     | 313       |
| _lr_multiplier  | 1         |
| _max_act        | 2.75453   |
| _max_adv        | 4.37      |
| _max_discrew    | 2.32      |
| _max_obs        | 51.6      |
| _mean_act       | 0.0489535 |
| _mean_adv       | -2.83e-18 |
| _mean_discrew   | 0.772     |
| _mean_obs       | 0.00523   |
| _min_adv        | -5.1      |
| _min_discrew    | 0.0069    |
| _min_obs        | -41.5     |
| _std_act        | 0.404697  |
| _std_adv        | 1         |
| _std_discrew    | 0.204     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.853     |
| ExplainedVarOld | 0.672     |
| KL              | 0.0120119 |
| Phi_loss        | 853.955   |
| PolicyEntropy   | 15.4765   |
| PolicyLoss      | -1.61923  |
| Steps           | 10016     |
| VarFuncLoss     | 0.0303    |
| _MeanReward     | 295       |
| _lr_multiplier  | 1         |
| _max_act        | 2.87433   |
| _max_adv        | 3.75      |
| _max_discrew    | 1.97      |
| _max_obs        | 33        |
| _mean_act       | 0.0484552 |
| _mean_adv       | -1.99e-17 |
| _mean_discrew   | 0.73      |
| _mean_obs       | 0.0044    |
| _min_adv        | -4.46     |
| _min_discrew    | 0.00865   |
| _min_obs        | -20.7     |
| _std_act        | 0.408583  |
| _std_adv        | 1         |
| _std_discrew    | 0.179     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.861       |
| ExplainedVarOld | 0.706       |
| KL              | 0.00455274  |
| Phi_loss        | 102.156     |
| PolicyEntropy   | 15.4578     |
| PolicyLoss      | -0.00051758 |
| Steps           | 10060       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 316         |
| _lr_multiplier  | 1           |
| _max_act        | 3.50018     |
| _max_adv        | 5.39        |
| _max_discrew    | 2.54        |
| _max_obs        | 49.6        |
| _mean_act       | 0.0510927   |
| _mean_adv       | 2.33e-17    |
| _mean_discrew   | 0.781       |
| _mean_obs       | 0.00571     |
| _min_adv        | -4.66       |
| _min_discrew    | 0.011       |
| _min_obs        | -22.9       |
| _std_act        | 0.402861    |
| _std_adv        | 1           |
| _std_discrew    | 0.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.854       |
| ExplainedVarOld | 0.676       |
| KL              | 0.000649813 |
| Phi_loss        | 97.3801     |
| PolicyEntropy   | 15.4571     |
| PolicyLoss      | -0.00151985 |
| Steps           | 10030       |
| VarFuncLoss     | 0.0307      |
| _MeanReward     | 297         |
| _lr_multiplier  | 1           |
| _max_act        | 3.39784     |
| _max_adv        | 4.65        |
| _max_discrew    | 2.2         |
| _max_obs        | 28          |
| _mean_act       | 0.0466189   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.742       |
| _mean_obs       | 0.00498     |
| _min_adv        | -4.73       |
| _min_discrew    | 0.011       |
| _min_obs        | -25.4       |
| _std_act        | 0.405506    |
| _std_adv        | 1           |
| _std_discrew    | 0.194       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.832       |
| ExplainedVarOld | 0.647       |
| KL              | 0.0011755   |
| Phi_loss        | 90.8828     |
| PolicyEntropy   | 15.456      |
| PolicyLoss      | -0.00308177 |
| Steps           | 10002       |
| VarFuncLoss     | 0.0328      |
| _MeanReward     | 316         |
| _lr_multiplier  | 1           |
| _max_act        | 2.98804     |
| _max_adv        | 3.82        |
| _max_discrew    | 2.26        |
| _max_obs        | 35.8        |
| _mean_act       | 0.0493636   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.779       |
| _mean_obs       | 0.00526     |
| _min_adv        | -4.95       |
| _min_discrew    | 0.0177      |
| _min_obs        | -24.6       |
| _std_act        | 0.407093    |
| _std_adv        | 1           |
| _std_discrew    | 0.203       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.862       |
| ExplainedVarOld | 0.699       |
| KL              | 0.00231519  |
| Phi_loss        | 85.0857     |
| PolicyEntropy   | 15.4552     |
| PolicyLoss      | -0.00430966 |
| Steps           | 10007       |
| VarFuncLoss     | 0.0282      |
| _MeanReward     | 308         |
| _lr_multiplier  | 1           |
| _max_act        | 2.89514     |
| _max_adv        | 4.47        |
| _max_discrew    | 2.32        |
| _max_obs        | 25.5        |
| _mean_act       | 0.0486212   |
| _mean_adv       | 1.35e-17    |
| _mean_discrew   | 0.77        |
| _mean_obs       | 0.00518     |
| _min_adv        | -4.45       |
| _min_discrew    | 0.0127      |
| _min_obs        | -22.9       |
| _std_act        | 0.404111    |
| _std_adv        | 1           |
| _std_discrew    | 0.203       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.858       |
| ExplainedVarOld | 0.657       |
| KL              | 0.00219986  |
| Phi_loss        | 80.1956     |
| PolicyEntropy   | 15.4531     |
| PolicyLoss      | -0.00209377 |
| Steps           | 10068       |
| VarFuncLoss     | 0.0288      |
| _MeanReward     | 316         |
| _lr_multiplier  | 1           |
| _max_act        | 3.20615     |
| _max_adv        | 4.45        |
| _max_discrew    | 2.07        |
| _max_obs        | 24.7        |
| _mean_act       | 0.0517634   |
| _mean_adv       | -8.47e-18   |
| _mean_discrew   | 0.768       |
| _mean_obs       | 0.0052      |
| _min_adv        | -5.2        |
| _min_discrew    | 0.0159      |
| _min_obs        | -22.4       |
| _std_act        | 0.402901    |
| _std_adv        | 1           |
| _std_discrew    | 0.192       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.87       |
| ExplainedVarOld | 0.696      |
| KL              | 0.00277289 |
| Phi_loss        | 92.0136    |
| PolicyEntropy   | 15.4497    |
| PolicyLoss      | -0.0360107 |
| Steps           | 10043      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 324        |
| _lr_multiplier  | 1          |
| _max_act        | 2.75121    |
| _max_adv        | 4.83       |
| _max_discrew    | 2.14       |
| _max_obs        | 26.3       |
| _mean_act       | 0.0516244  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.792      |
| _mean_obs       | 0.00558    |
| _min_adv        | -4.93      |
| _min_discrew    | 0.00605    |
| _min_obs        | -22.7      |
| _std_act        | 0.405237   |
| _std_adv        | 1          |
| _std_discrew    | 0.205      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.879        |
| ExplainedVarOld | 0.725        |
| KL              | 0.00246674   |
| Phi_loss        | 86.4642      |
| PolicyEntropy   | 15.449       |
| PolicyLoss      | -0.000906138 |
| Steps           | 10047        |
| VarFuncLoss     | 0.025        |
| _MeanReward     | 322          |
| _lr_multiplier  | 1            |
| _max_act        | 3.21827      |
| _max_adv        | 4.9          |
| _max_discrew    | 2.34         |
| _max_obs        | 24.8         |
| _mean_act       | 0.0490252    |
| _mean_adv       | 8.49e-18     |
| _mean_discrew   | 0.788        |
| _mean_obs       | 0.00505      |
| _min_adv        | -3.71        |
| _min_discrew    | 0.0154       |
| _min_obs        | -30.7        |
| _std_act        | 0.404225     |
| _std_adv        | 1            |
| _std_discrew    | 0.209        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.877       |
| ExplainedVarOld | 0.659       |
| KL              | 0.00225824  |
| Phi_loss        | 83.2147     |
| PolicyEntropy   | 15.4487     |
| PolicyLoss      | -0.00260346 |
| Steps           | 10010       |
| VarFuncLoss     | 0.0258      |
| _MeanReward     | 330         |
| _lr_multiplier  | 1           |
| _max_act        | 2.73154     |
| _max_adv        | 4.63        |
| _max_discrew    | 2.26        |
| _max_obs        | 32.4        |
| _mean_act       | 0.0514936   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.805       |
| _mean_obs       | 0.00597     |
| _min_adv        | -3.91       |
| _min_discrew    | 0.0156      |
| _min_obs        | -30.4       |
| _std_act        | 0.404669    |
| _std_adv        | 1           |
| _std_discrew    | 0.211       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.72        |
| KL              | 0.00241634  |
| Phi_loss        | 86.8648     |
| PolicyEntropy   | 15.4461     |
| PolicyLoss      | -0.00280827 |
| Steps           | 10041       |
| VarFuncLoss     | 0.0251      |
| _MeanReward     | 324         |
| _lr_multiplier  | 1           |
| _max_act        | 2.69254     |
| _max_adv        | 5.53        |
| _max_discrew    | 2.31        |
| _max_obs        | 36.2        |
| _mean_act       | 0.0534096   |
| _mean_adv       | -5.66e-18   |
| _mean_discrew   | 0.794       |
| _mean_obs       | 0.00597     |
| _min_adv        | -4.31       |
| _min_discrew    | 0.0136      |
| _min_obs        | -24         |
| _std_act        | 0.402381    |
| _std_adv        | 1           |
| _std_discrew    | 0.211       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.873     |
| ExplainedVarOld | 0.677     |
| KL              | 0.0166322 |
| Phi_loss        | 8046.28   |
| PolicyEntropy   | 15.4364   |
| PolicyLoss      | 9.6947    |
| Steps           | 10045     |
| VarFuncLoss     | 0.027     |
| _MeanReward     | 314       |
| _lr_multiplier  | 1         |
| _max_act        | 3.0709    |
| _max_adv        | 5.05      |
| _max_discrew    | 2.4       |
| _max_obs        | 27.9      |
| _mean_act       | 0.0582864 |
| _mean_adv       | -8.49e-18 |
| _mean_discrew   | 0.772     |
| _mean_obs       | 0.00656   |
| _min_adv        | -4.38     |
| _min_discrew    | 0.0143    |
| _min_obs        | -31.3     |
| _std_act        | 0.40817   |
| _std_adv        | 1         |
| _std_discrew    | 0.195     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.718      |
| KL              | 0.00660507 |
| Phi_loss        | 96.9016    |
| PolicyEntropy   | 15.4013    |
| PolicyLoss      | 0.0100376  |
| Steps           | 10035      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 336        |
| _lr_multiplier  | 1          |
| _max_act        | 3.02057    |
| _max_adv        | 4.39       |
| _max_discrew    | 2.28       |
| _max_obs        | 38.2       |
| _mean_act       | 0.0574416  |
| _mean_adv       | -1.27e-17  |
| _mean_discrew   | 0.82       |
| _mean_obs       | 0.00564    |
| _min_adv        | -4.61      |
| _min_discrew    | 0.0134     |
| _min_obs        | -22.1      |
| _std_act        | 0.404261   |
| _std_adv        | 1          |
| _std_discrew    | 0.223      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.702       |
| KL              | 0.000677181 |
| Phi_loss        | 96.341      |
| PolicyEntropy   | 15.3984     |
| PolicyLoss      | -0.00232486 |
| Steps           | 10075       |
| VarFuncLoss     | 0.0259      |
| _MeanReward     | 324         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0312      |
| _max_adv        | 4.21        |
| _max_discrew    | 2.22        |
| _max_obs        | 33.7        |
| _mean_act       | 0.0579013   |
| _mean_adv       | -4.23e-18   |
| _mean_discrew   | 0.789       |
| _mean_obs       | 0.00628     |
| _min_adv        | -4.57       |
| _min_discrew    | 0.0132      |
| _min_obs        | -32.6       |
| _std_act        | 0.404731    |
| _std_adv        | 1           |
| _std_discrew    | 0.199       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.901      |
| ExplainedVarOld | 0.765      |
| KL              | 0.00191947 |
| Phi_loss        | 106.712    |
| PolicyEntropy   | 15.3979    |
| PolicyLoss      | 0.00652476 |
| Steps           | 10012      |
| VarFuncLoss     | 0.0197     |
| _MeanReward     | 330        |
| _lr_multiplier  | 1          |
| _max_act        | 3.26011    |
| _max_adv        | 5.03       |
| _max_discrew    | 2.2        |
| _max_obs        | 55.9       |
| _mean_act       | 0.0580835  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.811      |
| _mean_obs       | 0.0059     |
| _min_adv        | -4.78      |
| _min_discrew    | 0.0166     |
| _min_obs        | -40        |
| _std_act        | 0.402517   |
| _std_adv        | 1          |
| _std_discrew    | 0.217      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.7        |
| KL              | 0.00101254 |
| Phi_loss        | 98.7896    |
| PolicyEntropy   | 15.3971    |
| PolicyLoss      | -0.0020803 |
| Steps           | 10003      |
| VarFuncLoss     | 0.0253     |
| _MeanReward     | 330        |
| _lr_multiplier  | 1          |
| _max_act        | 3.27915    |
| _max_adv        | 4.58       |
| _max_discrew    | 2.08       |
| _max_obs        | 22.8       |
| _mean_act       | 0.0608666  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.802      |
| _mean_obs       | 0.0064     |
| _min_adv        | -4.43      |
| _min_discrew    | 0.0142     |
| _min_obs        | -25.6      |
| _std_act        | 0.403985   |
| _std_adv        | 1          |
| _std_discrew    | 0.205      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.692       |
| KL              | 0.00153042  |
| Phi_loss        | 94.693      |
| PolicyEntropy   | 15.3967     |
| PolicyLoss      | -0.00142382 |
| Steps           | 10055       |
| VarFuncLoss     | 0.0235      |
| _MeanReward     | 338         |
| _lr_multiplier  | 1           |
| _max_act        | 2.79105     |
| _max_adv        | 4.92        |
| _max_discrew    | 2.61        |
| _max_obs        | 29.1        |
| _mean_act       | 0.0582162   |
| _mean_adv       | 7.07e-18    |
| _mean_discrew   | 0.821       |
| _mean_obs       | 0.00595     |
| _min_adv        | -3.71       |
| _min_discrew    | 0.0141      |
| _min_obs        | -46.2       |
| _std_act        | 0.403152    |
| _std_adv        | 1           |
| _std_discrew    | 0.226       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.892       |
| ExplainedVarOld | 0.729       |
| KL              | 0.00170939  |
| Phi_loss        | 101.524     |
| PolicyEntropy   | 15.3962     |
| PolicyLoss      | -0.00060149 |
| Steps           | 10061       |
| VarFuncLoss     | 0.0248      |
| _MeanReward     | 348         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03357     |
| _max_adv        | 4.68        |
| _max_discrew    | 2.35        |
| _max_obs        | 43.4        |
| _mean_act       | 0.0608123   |
| _mean_adv       | 1.69e-17    |
| _mean_discrew   | 0.842       |
| _mean_obs       | 0.00684     |
| _min_adv        | -4.98       |
| _min_discrew    | 0.0165      |
| _min_obs        | -32.9       |
| _std_act        | 0.403357    |
| _std_adv        | 1           |
| _std_discrew    | 0.228       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.897       |
| ExplainedVarOld | 0.739       |
| KL              | 0.00150063  |
| Phi_loss        | 95.2583     |
| PolicyEntropy   | 15.3962     |
| PolicyLoss      | -0.00395498 |
| Steps           | 10043       |
| VarFuncLoss     | 0.0236      |
| _MeanReward     | 327         |
| _lr_multiplier  | 1           |
| _max_act        | 3.35682     |
| _max_adv        | 4.66        |
| _max_discrew    | 2.34        |
| _max_obs        | 31.5        |
| _mean_act       | 0.0616483   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.796       |
| _mean_obs       | 0.00558     |
| _min_adv        | -4.74       |
| _min_discrew    | 0.00498     |
| _min_obs        | -20.6       |
| _std_act        | 0.401036    |
| _std_adv        | 1           |
| _std_discrew    | 0.208       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.893       |
| ExplainedVarOld | 0.734       |
| KL              | 0.00166857  |
| Phi_loss        | 93.8219     |
| PolicyEntropy   | 15.3959     |
| PolicyLoss      | -0.00360166 |
| Steps           | 10059       |
| VarFuncLoss     | 0.0225      |
| _MeanReward     | 347         |
| _lr_multiplier  | 1           |
| _max_act        | 4.02472     |
| _max_adv        | 4.22        |
| _max_discrew    | 2.48        |
| _max_obs        | 21.1        |
| _mean_act       | 0.0647271   |
| _mean_adv       | 8.48e-18    |
| _mean_discrew   | 0.837       |
| _mean_obs       | 0.00609     |
| _min_adv        | -4.84       |
| _min_discrew    | 0.015       |
| _min_obs        | -25.7       |
| _std_act        | 0.403782    |
| _std_adv        | 1           |
| _std_discrew    | 0.223       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.737       |
| KL              | 0.00163041  |
| Phi_loss        | 95.2764     |
| PolicyEntropy   | 15.3957     |
| PolicyLoss      | -0.00336308 |
| Steps           | 10020       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 339         |
| _lr_multiplier  | 1           |
| _max_act        | 3.09699     |
| _max_adv        | 4.14        |
| _max_discrew    | 2.3         |
| _max_obs        | 28.2        |
| _mean_act       | 0.0615192   |
| _mean_adv       | 5.67e-18    |
| _mean_discrew   | 0.815       |
| _mean_obs       | 0.00574     |
| _min_adv        | -5.24       |
| _min_discrew    | 0.014       |
| _min_obs        | -24.1       |
| _std_act        | 0.403389    |
| _std_adv        | 1           |
| _std_discrew    | 0.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.898        |
| ExplainedVarOld | 0.72         |
| KL              | 0.0016547    |
| Phi_loss        | 90.2724      |
| PolicyEntropy   | 15.3956      |
| PolicyLoss      | -0.000530069 |
| Steps           | 10041        |
| VarFuncLoss     | 0.0217       |
| _MeanReward     | 341          |
| _lr_multiplier  | 1            |
| _max_act        | 3.11759      |
| _max_adv        | 4.65         |
| _max_discrew    | 2.26         |
| _max_obs        | 30           |
| _mean_act       | 0.062492     |
| _mean_adv       | 0            |
| _mean_discrew   | 0.831        |
| _mean_obs       | 0.00593      |
| _min_adv        | -4.26        |
| _min_discrew    | 0.00119      |
| _min_obs        | -33.4        |
| _std_act        | 0.403521     |
| _std_adv        | 1            |
| _std_discrew    | 0.224        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.889       |
| ExplainedVarOld | 0.745       |
| KL              | 0.00151228  |
| Phi_loss        | 92.1172     |
| PolicyEntropy   | 15.3952     |
| PolicyLoss      | -0.00156952 |
| Steps           | 10050       |
| VarFuncLoss     | 0.0249      |
| _MeanReward     | 341         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1357      |
| _max_adv        | 4.46        |
| _max_discrew    | 2.18        |
| _max_obs        | 28.6        |
| _mean_act       | 0.0617323   |
| _mean_adv       | -1.56e-17   |
| _mean_discrew   | 0.822       |
| _mean_obs       | 0.00622     |
| _min_adv        | -4.36       |
| _min_discrew    | 0.00898     |
| _min_obs        | -33.1       |
| _std_act        | 0.404227    |
| _std_adv        | 1           |
| _std_discrew    | 0.219       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.76       |
| KL              | 0.00160263 |
| Phi_loss        | 84.955     |
| PolicyEntropy   | 15.3947    |
| PolicyLoss      | 0.0026754  |
| Steps           | 10061      |
| VarFuncLoss     | 0.0219     |
| _MeanReward     | 355        |
| _lr_multiplier  | 1          |
| _max_act        | 3.11512    |
| _max_adv        | 4.88       |
| _max_discrew    | 2.49       |
| _max_obs        | 30.5       |
| _mean_act       | 0.0656784  |
| _mean_adv       | -2.4e-17   |
| _mean_discrew   | 0.865      |
| _mean_obs       | 0.00664    |
| _min_adv        | -5.9       |
| _min_discrew    | 0.0157     |
| _min_obs        | -35.6      |
| _std_act        | 0.399305   |
| _std_adv        | 1          |
| _std_discrew    | 0.251      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.894      |
| ExplainedVarOld | 0.704      |
| KL              | 0.00180769 |
| Phi_loss        | 79.0756    |
| PolicyEntropy   | 15.3933    |
| PolicyLoss      | 0.00394675 |
| Steps           | 10009      |
| VarFuncLoss     | 0.0266     |
| _MeanReward     | 338        |
| _lr_multiplier  | 1          |
| _max_act        | 2.83929    |
| _max_adv        | 4.89       |
| _max_discrew    | 2.34       |
| _max_obs        | 29.5       |
| _mean_act       | 0.0624694  |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 0.815      |
| _mean_obs       | 0.00489    |
| _min_adv        | -4.62      |
| _min_discrew    | 0.0148     |
| _min_obs        | -32.1      |
| _std_act        | 0.404198   |
| _std_adv        | 1          |
| _std_discrew    | 0.211      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00167081  |
| Phi_loss        | 98.1744     |
| PolicyEntropy   | 15.393      |
| PolicyLoss      | -0.00385069 |
| Steps           | 10015       |
| VarFuncLoss     | 0.0223      |
| _MeanReward     | 356         |
| _lr_multiplier  | 1           |
| _max_act        | 3.42229     |
| _max_adv        | 4.95        |
| _max_discrew    | 2.81        |
| _max_obs        | 31.3        |
| _mean_act       | 0.0645533   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.878       |
| _mean_obs       | 0.00678     |
| _min_adv        | -4.75       |
| _min_discrew    | 0.0149      |
| _min_obs        | -29.4       |
| _std_act        | 0.404698    |
| _std_adv        | 1           |
| _std_discrew    | 0.271       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.88        |
| ExplainedVarOld | 0.717       |
| KL              | 0.00165364  |
| Phi_loss        | 93.1521     |
| PolicyEntropy   | 15.3921     |
| PolicyLoss      | 0.000776945 |
| Steps           | 10071       |
| VarFuncLoss     | 0.0328      |
| _MeanReward     | 348         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13468     |
| _max_adv        | 4.53        |
| _max_discrew    | 2.25        |
| _max_obs        | 21.4        |
| _mean_act       | 0.0627503   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 0.839       |
| _mean_obs       | 0.00539     |
| _min_adv        | -4.43       |
| _min_discrew    | 0.0148      |
| _min_obs        | -21.4       |
| _std_act        | 0.399473    |
| _std_adv        | 1           |
| _std_discrew    | 0.225       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.899       |
| ExplainedVarOld | 0.76        |
| KL              | 0.00173894  |
| Phi_loss        | 92.4362     |
| PolicyEntropy   | 15.3919     |
| PolicyLoss      | -0.00568488 |
| Steps           | 10044       |
| VarFuncLoss     | 0.0227      |
| _MeanReward     | 348         |
| _lr_multiplier  | 1           |
| _max_act        | 3.49257     |
| _max_adv        | 4.98        |
| _max_discrew    | 2.96        |
| _max_obs        | 32.7        |
| _mean_act       | 0.0627139   |
| _mean_adv       | -1.98e-17   |
| _mean_discrew   | 0.854       |
| _mean_obs       | 0.00606     |
| _min_adv        | -6.17       |
| _min_discrew    | 0.0133      |
| _min_obs        | -24.9       |
| _std_act        | 0.403152    |
| _std_adv        | 1           |
| _std_discrew    | 0.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.691       |
| KL              | 0.00182999  |
| Phi_loss        | 86.4664     |
| PolicyEntropy   | 15.3931     |
| PolicyLoss      | -0.00611531 |
| Steps           | 10066       |
| VarFuncLoss     | 0.0286      |
| _MeanReward     | 354         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18947     |
| _max_adv        | 5.42        |
| _max_discrew    | 2.36        |
| _max_obs        | 26.1        |
| _mean_act       | 0.0645269   |
| _mean_adv       | -1.69e-17   |
| _mean_discrew   | 0.856       |
| _mean_obs       | 0.00634     |
| _min_adv        | -4.11       |
| _min_discrew    | 0.0149      |
| _min_obs        | -24.6       |
| _std_act        | 0.402965    |
| _std_adv        | 1           |
| _std_discrew    | 0.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.907        |
| ExplainedVarOld | 0.747        |
| KL              | 0.00199029   |
| Phi_loss        | 91.8592      |
| PolicyEntropy   | 15.3931      |
| PolicyLoss      | -0.000481639 |
| Steps           | 10032        |
| VarFuncLoss     | 0.0214       |
| _MeanReward     | 345          |
| _lr_multiplier  | 1            |
| _max_act        | 3.16888      |
| _max_adv        | 4.68         |
| _max_discrew    | 2.3          |
| _max_obs        | 52.4         |
| _mean_act       | 0.0626342    |
| _mean_adv       | -8.5e-18     |
| _mean_discrew   | 0.836        |
| _mean_obs       | 0.00492      |
| _min_adv        | -4.18        |
| _min_discrew    | 0.017        |
| _min_obs        | -21.7        |
| _std_act        | 0.401998     |
| _std_adv        | 1            |
| _std_discrew    | 0.223        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.905       |
| ExplainedVarOld | 0.726       |
| KL              | 0.00191894  |
| Phi_loss        | 90.6619     |
| PolicyEntropy   | 15.3927     |
| PolicyLoss      | -0.00252251 |
| Steps           | 10131       |
| VarFuncLoss     | 0.0212      |
| _MeanReward     | 360         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14104     |
| _max_adv        | 4.67        |
| _max_discrew    | 2.58        |
| _max_obs        | 23.4        |
| _mean_act       | 0.063339    |
| _mean_adv       | 2.81e-18    |
| _mean_discrew   | 0.878       |
| _mean_obs       | 0.00548     |
| _min_adv        | -4.7        |
| _min_discrew    | 0.00471     |
| _min_obs        | -19.3       |
| _std_act        | 0.404821    |
| _std_adv        | 1           |
| _std_discrew    | 0.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.886       |
| ExplainedVarOld | 0.68        |
| KL              | 0.00189008  |
| Phi_loss        | 82.8617     |
| PolicyEntropy   | 15.3927     |
| PolicyLoss      | -0.00492997 |
| Steps           | 10063       |
| VarFuncLoss     | 0.0308      |
| _MeanReward     | 339         |
| _lr_multiplier  | 1           |
| _max_act        | 3.31606     |
| _max_adv        | 4.33        |
| _max_discrew    | 2.32        |
| _max_obs        | 41.7        |
| _mean_act       | 0.0637464   |
| _mean_adv       | -2.82e-18   |
| _mean_discrew   | 0.822       |
| _mean_obs       | 0.0053      |
| _min_adv        | -5.24       |
| _min_discrew    | 0.0127      |
| _min_obs        | -49.7       |
| _std_act        | 0.407406    |
| _std_adv        | 1           |
| _std_discrew    | 0.214       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.75       |
| KL              | 0.00186389 |
| Phi_loss        | 91.8813    |
| PolicyEntropy   | 15.3937    |
| PolicyLoss      | -0.0085009 |
| Steps           | 10044      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 356        |
| _lr_multiplier  | 1          |
| _max_act        | 3.25451    |
| _max_adv        | 5.28       |
| _max_discrew    | 2.37       |
| _max_obs        | 24.5       |
| _mean_act       | 0.0656525  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.853      |
| _mean_obs       | 0.00536    |
| _min_adv        | -5.19      |
| _min_discrew    | 0.0104     |
| _min_obs        | -23.3      |
| _std_act        | 0.403255   |
| _std_adv        | 1          |
| _std_discrew    | 0.235      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.753      |
| KL              | 0.00166556 |
| Phi_loss        | 92.1558    |
| PolicyEntropy   | 15.394     |
| PolicyLoss      | 0.00088668 |
| Steps           | 10031      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 362        |
| _lr_multiplier  | 1          |
| _max_act        | 3.11159    |
| _max_adv        | 5.66       |
| _max_discrew    | 2.56       |
| _max_obs        | 40.4       |
| _mean_act       | 0.0648484  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.876      |
| _mean_obs       | 0.00543    |
| _min_adv        | -4.37      |
| _min_discrew    | 0.00875    |
| _min_obs        | -27.4      |
| _std_act        | 0.405132   |
| _std_adv        | 1          |
| _std_discrew    | 0.252      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.898       |
| ExplainedVarOld | 0.722       |
| KL              | 0.00204687  |
| Phi_loss        | 83.926      |
| PolicyEntropy   | 15.3938     |
| PolicyLoss      | -0.00659497 |
| Steps           | 10039       |
| VarFuncLoss     | 0.0257      |
| _MeanReward     | 350         |
| _lr_multiplier  | 1           |
| _max_act        | 3.28385     |
| _max_adv        | 3.8         |
| _max_discrew    | 2.25        |
| _max_obs        | 40.5        |
| _mean_act       | 0.0627069   |
| _mean_adv       | -8.49e-18   |
| _mean_discrew   | 0.837       |
| _mean_obs       | 0.00551     |
| _min_adv        | -5.73       |
| _min_discrew    | 0.015       |
| _min_obs        | -31.8       |
| _std_act        | 0.405773    |
| _std_adv        | 1           |
| _std_discrew    | 0.213       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.911      |
| ExplainedVarOld | 0.767      |
| KL              | 0.00208532 |
| Phi_loss        | 82.1568    |
| PolicyEntropy   | 15.3933    |
| PolicyLoss      | 0.00332588 |
| Steps           | 10068      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 361        |
| _lr_multiplier  | 1          |
| _max_act        | 2.79541    |
| _max_adv        | 4.5        |
| _max_discrew    | 2.51       |
| _max_obs        | 34.2       |
| _mean_act       | 0.0688732  |
| _mean_adv       | -2.54e-17  |
| _mean_discrew   | 0.873      |
| _mean_obs       | 0.00631    |
| _min_adv        | -4.24      |
| _min_discrew    | 0.0165     |
| _min_obs        | -23.9      |
| _std_act        | 0.403315   |
| _std_adv        | 1          |
| _std_discrew    | 0.249      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.726       |
| KL              | 0.00180099  |
| Phi_loss        | 84.2119     |
| PolicyEntropy   | 15.3926     |
| PolicyLoss      | -0.00130696 |
| Steps           | 10042       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 351         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13054     |
| _max_adv        | 4.78        |
| _max_discrew    | 2.4         |
| _max_obs        | 36.4        |
| _mean_act       | 0.067703    |
| _mean_adv       | 5.66e-18    |
| _mean_discrew   | 0.848       |
| _mean_obs       | 0.00536     |
| _min_adv        | -5          |
| _min_discrew    | 0.0162      |
| _min_obs        | -24.3       |
| _std_act        | 0.404235    |
| _std_adv        | 1           |
| _std_discrew    | 0.231       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.748       |
| KL              | 0.00202604  |
| Phi_loss        | 79.0217     |
| PolicyEntropy   | 15.3921     |
| PolicyLoss      | -0.00418334 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0218      |
| _MeanReward     | 365         |
| _lr_multiplier  | 1           |
| _max_act        | 2.96113     |
| _max_adv        | 4.56        |
| _max_discrew    | 2.39        |
| _max_obs        | 46.5        |
| _mean_act       | 0.0712023   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 0.87        |
| _mean_obs       | 0.00598     |
| _min_adv        | -4.32       |
| _min_discrew    | 0.0162      |
| _min_obs        | -20.9       |
| _std_act        | 0.403078    |
| _std_adv        | 1           |
| _std_discrew    | 0.245       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.908       |
| ExplainedVarOld | 0.73        |
| KL              | 0.00221032  |
| Phi_loss        | 81.4199     |
| PolicyEntropy   | 15.3921     |
| PolicyLoss      | -0.00205449 |
| Steps           | 10051       |
| VarFuncLoss     | 0.0225      |
| _MeanReward     | 351         |
| _lr_multiplier  | 1           |
| _max_act        | 3.68341     |
| _max_adv        | 3.8         |
| _max_discrew    | 2.16        |
| _max_obs        | 45.5        |
| _mean_act       | 0.0683365   |
| _mean_adv       | -2.83e-18   |
| _mean_discrew   | 0.839       |
| _mean_obs       | 0.00573     |
| _min_adv        | -5.04       |
| _min_discrew    | 0.0153      |
| _min_obs        | -25.4       |
| _std_act        | 0.406259    |
| _std_adv        | 1           |
| _std_discrew    | 0.219       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.765      |
| KL              | 0.00261977 |
| Phi_loss        | 96.5349    |
| PolicyEntropy   | 15.3919    |
| PolicyLoss      | -0.0146688 |
| Steps           | 10023      |
| VarFuncLoss     | 0.0205     |
| _MeanReward     | 366        |
| _lr_multiplier  | 1          |
| _max_act        | 3.99276    |
| _max_adv        | 5.31       |
| _max_discrew    | 2.27       |
| _max_obs        | 24.3       |
| _mean_act       | 0.0686284  |
| _mean_adv       | -8.51e-18  |
| _mean_discrew   | 0.873      |
| _mean_obs       | 0.00635    |
| _min_adv        | -5.12      |
| _min_discrew    | 0.0168     |
| _min_obs        | -22.1      |
| _std_act        | 0.406242   |
| _std_adv        | 1          |
| _std_discrew    | 0.236      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.918        |
| ExplainedVarOld | 0.753        |
| KL              | 0.00210846   |
| Phi_loss        | 89.0291      |
| PolicyEntropy   | 15.3917      |
| PolicyLoss      | -0.000550499 |
| Steps           | 10011        |
| VarFuncLoss     | 0.0193       |
| _MeanReward     | 366          |
| _lr_multiplier  | 1            |
| _max_act        | 3.49211      |
| _max_adv        | 3.89         |
| _max_discrew    | 2.25         |
| _max_obs        | 26.8         |
| _mean_act       | 0.0697536    |
| _mean_adv       | -8.52e-18    |
| _mean_discrew   | 0.875        |
| _mean_obs       | 0.0054       |
| _min_adv        | -6.18        |
| _min_discrew    | 0.0165       |
| _min_obs        | -29.9        |
| _std_act        | 0.406642     |
| _std_adv        | 1            |
| _std_discrew    | 0.247        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.733       |
| KL              | 0.00194954  |
| Phi_loss        | 87.0856     |
| PolicyEntropy   | 15.3927     |
| PolicyLoss      | -0.00738935 |
| Steps           | 10049       |
| VarFuncLoss     | 0.0219      |
| _MeanReward     | 354         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19494     |
| _max_adv        | 4           |
| _max_discrew    | 2.24        |
| _max_obs        | 45.8        |
| _mean_act       | 0.0635653   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 0.847       |
| _mean_obs       | 0.00459     |
| _min_adv        | -5          |
| _min_discrew    | 0.0164      |
| _min_obs        | -33.3       |
| _std_act        | 0.403805    |
| _std_adv        | 1           |
| _std_discrew    | 0.227       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.759      |
| KL              | 0.00241881 |
| Phi_loss        | 100.231    |
| PolicyEntropy   | 15.3922    |
| PolicyLoss      | 0.0402526  |
| Steps           | 10071      |
| VarFuncLoss     | 0.0206     |
| _MeanReward     | 360        |
| _lr_multiplier  | 1          |
| _max_act        | 2.90503    |
| _max_adv        | 5.03       |
| _max_discrew    | 2.37       |
| _max_obs        | 23.2       |
| _mean_act       | 0.0664767  |
| _mean_adv       | -2.82e-17  |
| _mean_discrew   | 0.865      |
| _mean_obs       | 0.0053     |
| _min_adv        | -5.53      |
| _min_discrew    | 0.0158     |
| _min_obs        | -21.7      |
| _std_act        | 0.403404   |
| _std_adv        | 1          |
| _std_discrew    | 0.243      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.901       |
| ExplainedVarOld | 0.737       |
| KL              | 0.00171294  |
| Phi_loss        | 89.1746     |
| PolicyEntropy   | 15.3905     |
| PolicyLoss      | -0.00172648 |
| Steps           | 10010       |
| VarFuncLoss     | 0.0243      |
| _MeanReward     | 365         |
| _lr_multiplier  | 1           |
| _max_act        | 3.64161     |
| _max_adv        | 4.04        |
| _max_discrew    | 2.21        |
| _max_obs        | 35          |
| _mean_act       | 0.072809    |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.869       |
| _mean_obs       | 0.00587     |
| _min_adv        | -5.16       |
| _min_discrew    | 0.0124      |
| _min_obs        | -22         |
| _std_act        | 0.406559    |
| _std_adv        | 1           |
| _std_discrew    | 0.237       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.767       |
| KL              | 0.00205291  |
| Phi_loss        | 92.2899     |
| PolicyEntropy   | 15.3899     |
| PolicyLoss      | -0.00460707 |
| Steps           | 10022       |
| VarFuncLoss     | 0.0211      |
| _MeanReward     | 363         |
| _lr_multiplier  | 1           |
| _max_act        | 3.51473     |
| _max_adv        | 5.5         |
| _max_discrew    | 2.41        |
| _max_obs        | 27.1        |
| _mean_act       | 0.0715602   |
| _mean_adv       | 3.19e-17    |
| _mean_discrew   | 0.865       |
| _mean_obs       | 0.00508     |
| _min_adv        | -6.13       |
| _min_discrew    | 0.014       |
| _min_obs        | -29.4       |
| _std_act        | 0.405411    |
| _std_adv        | 1           |
| _std_discrew    | 0.238       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.771       |
| KL              | 0.00188923  |
| Phi_loss        | 90.0643     |
| PolicyEntropy   | 15.3894     |
| PolicyLoss      | 0.000838688 |
| Steps           | 10077       |
| VarFuncLoss     | 0.0188      |
| _MeanReward     | 372         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18805     |
| _max_adv        | 4.77        |
| _max_discrew    | 2.46        |
| _max_obs        | 23.3        |
| _mean_act       | 0.069261    |
| _mean_adv       | 8.46e-18    |
| _mean_discrew   | 0.891       |
| _mean_obs       | 0.00517     |
| _min_adv        | -5.08       |
| _min_discrew    | 0.0157      |
| _min_obs        | -20.9       |
| _std_act        | 0.404501    |
| _std_adv        | 1           |
| _std_discrew    | 0.248       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.923       |
| ExplainedVarOld | 0.785       |
| KL              | 0.00194041  |
| Phi_loss        | 87.7716     |
| PolicyEntropy   | 15.3887     |
| PolicyLoss      | 0.000629664 |
| Steps           | 10061       |
| VarFuncLoss     | 0.0192      |
| _MeanReward     | 360         |
| _lr_multiplier  | 1           |
| _max_act        | 3.46776     |
| _max_adv        | 5.36        |
| _max_discrew    | 2.33        |
| _max_obs        | 35.1        |
| _mean_act       | 0.0646753   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 0.858       |
| _mean_obs       | 0.0056      |
| _min_adv        | -5.19       |
| _min_discrew    | 0.0134      |
| _min_obs        | -29.2       |
| _std_act        | 0.408561    |
| _std_adv        | 1           |
| _std_discrew    | 0.227       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.783      |
| KL              | 0.00227037 |
| Phi_loss        | 95.5785    |
| PolicyEntropy   | 15.3866    |
| PolicyLoss      | 0.0115873  |
| Steps           | 10058      |
| VarFuncLoss     | 0.0193     |
| _MeanReward     | 380        |
| _lr_multiplier  | 1          |
| _max_act        | 3.255      |
| _max_adv        | 4.97       |
| _max_discrew    | 2.72       |
| _max_obs        | 27.9       |
| _mean_act       | 0.0689718  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.912      |
| _mean_obs       | 0.00541    |
| _min_adv        | -5.02      |
| _min_discrew    | 0.0165     |
| _min_obs        | -33.6      |
| _std_act        | 0.403208   |
| _std_adv        | 1          |
| _std_discrew    | 0.264      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.769      |
| KL              | 0.00231285 |
| Phi_loss        | 98.3226    |
| PolicyEntropy   | 15.3846    |
| PolicyLoss      | 0.00165814 |
| Steps           | 10076      |
| VarFuncLoss     | 0.0232     |
| _MeanReward     | 369        |
| _lr_multiplier  | 1          |
| _max_act        | 2.78901    |
| _max_adv        | 5.89       |
| _max_discrew    | 2.43       |
| _max_obs        | 24.4       |
| _mean_act       | 0.0700923  |
| _mean_adv       | -1.13e-17  |
| _mean_discrew   | 0.882      |
| _mean_obs       | 0.00551    |
| _min_adv        | -5.38      |
| _min_discrew    | 0.0166     |
| _min_obs        | -24.6      |
| _std_act        | 0.405757   |
| _std_adv        | 1          |
| _std_discrew    | 0.243      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.764       |
| KL              | 0.00176507  |
| Phi_loss        | 84.4392     |
| PolicyEntropy   | 15.3845     |
| PolicyLoss      | -0.00408098 |
| Steps           | 10029       |
| VarFuncLoss     | 0.0208      |
| _MeanReward     | 374         |
| _lr_multiplier  | 1           |
| _max_act        | 3.53107     |
| _max_adv        | 6.14        |
| _max_discrew    | 2.6         |
| _max_obs        | 27          |
| _mean_act       | 0.0696938   |
| _mean_adv       | -5.67e-18   |
| _mean_discrew   | 0.906       |
| _mean_obs       | 0.00541     |
| _min_adv        | -6.1        |
| _min_discrew    | 0.015       |
| _min_obs        | -25.9       |
| _std_act        | 0.407179    |
| _std_adv        | 1           |
| _std_discrew    | 0.273       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.905       |
| ExplainedVarOld | 0.732       |
| KL              | 0.00192986  |
| Phi_loss        | 86.8069     |
| PolicyEntropy   | 15.3849     |
| PolicyLoss      | -0.00232667 |
| Steps           | 10100       |
| VarFuncLoss     | 0.026       |
| _MeanReward     | 379         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97043     |
| _max_adv        | 5.05        |
| _max_discrew    | 2.62        |
| _max_obs        | 35.7        |
| _mean_act       | 0.0721654   |
| _mean_adv       | -8.44e-18   |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.00642     |
| _min_adv        | -4.63       |
| _min_discrew    | 0.0134      |
| _min_obs        | -18.6       |
| _std_act        | 0.403868    |
| _std_adv        | 1           |
| _std_discrew    | 0.274       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.725       |
| KL              | 0.00184233  |
| Phi_loss        | 83.0898     |
| PolicyEntropy   | 15.385      |
| PolicyLoss      | -0.00225275 |
| Steps           | 10038       |
| VarFuncLoss     | 0.0248      |
| _MeanReward     | 363         |
| _lr_multiplier  | 1           |
| _max_act        | 4.27038     |
| _max_adv        | 5.17        |
| _max_discrew    | 2.18        |
| _max_obs        | 23.7        |
| _mean_act       | 0.0711731   |
| _mean_adv       | 8.49e-18    |
| _mean_discrew   | 0.866       |
| _mean_obs       | 0.00629     |
| _min_adv        | -5.84       |
| _min_discrew    | 0.0134      |
| _min_obs        | -33.9       |
| _std_act        | 0.407252    |
| _std_adv        | 1           |
| _std_discrew    | 0.228       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.925       |
| ExplainedVarOld | 0.786       |
| KL              | 0.00206621  |
| Phi_loss        | 72.8596     |
| PolicyEntropy   | 15.3851     |
| PolicyLoss      | -0.00251154 |
| Steps           | 10057       |
| VarFuncLoss     | 0.0172      |
| _MeanReward     | 385         |
| _lr_multiplier  | 1           |
| _max_act        | 3.25149     |
| _max_adv        | 5.52        |
| _max_discrew    | 2.3         |
| _max_obs        | 26.1        |
| _mean_act       | 0.0715581   |
| _mean_adv       | 2.83e-18    |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.0055      |
| _min_adv        | -5.68       |
| _min_discrew    | 0.016       |
| _min_obs        | -27.2       |
| _std_act        | 0.406364    |
| _std_adv        | 1           |
| _std_discrew    | 0.253       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.767      |
| KL              | 0.00263646 |
| Phi_loss        | 82.1201    |
| PolicyEntropy   | 15.3856    |
| PolicyLoss      | 0.00121829 |
| Steps           | 10002      |
| VarFuncLoss     | 0.0194     |
| _MeanReward     | 363        |
| _lr_multiplier  | 1          |
| _max_act        | 3.16254    |
| _max_adv        | 4.37       |
| _max_discrew    | 2.74       |
| _max_obs        | 28.9       |
| _mean_act       | 0.0680787  |
| _mean_adv       | -2.13e-18  |
| _mean_discrew   | 0.87       |
| _mean_obs       | 0.00453    |
| _min_adv        | -5         |
| _min_discrew    | 0.0137     |
| _min_obs        | -27.5      |
| _std_act        | 0.405448   |
| _std_adv        | 1          |
| _std_discrew    | 0.248      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.914        |
| ExplainedVarOld | 0.757        |
| KL              | 0.00207033   |
| Phi_loss        | 87.009       |
| PolicyEntropy   | 15.3852      |
| PolicyLoss      | -0.000110781 |
| Steps           | 10047        |
| VarFuncLoss     | 0.0213       |
| _MeanReward     | 372          |
| _lr_multiplier  | 1            |
| _max_act        | 2.96385      |
| _max_adv        | 5.1          |
| _max_discrew    | 2.81         |
| _max_obs        | 27.2         |
| _mean_act       | 0.0685612    |
| _mean_adv       | 5.66e-18     |
| _mean_discrew   | 0.886        |
| _mean_obs       | 0.00464      |
| _min_adv        | -4.38        |
| _min_discrew    | 0.0153       |
| _min_obs        | -24.3        |
| _std_act        | 0.404143     |
| _std_adv        | 1            |
| _std_discrew    | 0.251        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.763      |
| KL              | 0.0018767  |
| Phi_loss        | 82.1121    |
| PolicyEntropy   | 15.3836    |
| PolicyLoss      | 0.00140952 |
| Steps           | 10047      |
| VarFuncLoss     | 0.0192     |
| _MeanReward     | 381        |
| _lr_multiplier  | 1          |
| _max_act        | 3.26739    |
| _max_adv        | 4.38       |
| _max_discrew    | 2.49       |
| _max_obs        | 75.7       |
| _mean_act       | 0.0693528  |
| _mean_adv       | 1.7e-17    |
| _mean_discrew   | 0.899      |
| _mean_obs       | 0.00614    |
| _min_adv        | -4.73      |
| _min_discrew    | 0.0161     |
| _min_obs        | -45.8      |
| _std_act        | 0.408551   |
| _std_adv        | 1          |
| _std_discrew    | 0.249      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.921      |
| ExplainedVarOld | 0.777      |
| KL              | 0.00234216 |
| Phi_loss        | 78.141     |
| PolicyEntropy   | 15.3834    |
| PolicyLoss      | -0.0046931 |
| Steps           | 10017      |
| VarFuncLoss     | 0.0197     |
| _MeanReward     | 369        |
| _lr_multiplier  | 1          |
| _max_act        | 3.09058    |
| _max_adv        | 5.01       |
| _max_discrew    | 2.35       |
| _max_obs        | 29.6       |
| _mean_act       | 0.0674576  |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 0.883      |
| _mean_obs       | 0.00504    |
| _min_adv        | -5.42      |
| _min_discrew    | 0.00467    |
| _min_obs        | -25.8      |
| _std_act        | 0.406711   |
| _std_adv        | 1          |
| _std_discrew    | 0.247      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.771      |
| KL              | 0.00208297 |
| Phi_loss        | 89.3076    |
| PolicyEntropy   | 15.382     |
| PolicyLoss      | 0.00646156 |
| Steps           | 10007      |
| VarFuncLoss     | 0.0198     |
| _MeanReward     | 355        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0769     |
| _max_adv        | 4.56       |
| _max_discrew    | 2.19       |
| _max_obs        | 25.9       |
| _mean_act       | 0.0706881  |
| _mean_adv       | 1.35e-17   |
| _mean_discrew   | 0.844      |
| _mean_obs       | 0.00503    |
| _min_adv        | -5.92      |
| _min_discrew    | 0.00802    |
| _min_obs        | -29        |
| _std_act        | 0.409012   |
| _std_adv        | 1          |
| _std_discrew    | 0.213      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.8        |
| KL              | 0.00201766 |
| Phi_loss        | 80.2187    |
| PolicyEntropy   | 15.3805    |
| PolicyLoss      | 0.00168106 |
| Steps           | 10075      |
| VarFuncLoss     | 0.0153     |
| _MeanReward     | 388        |
| _lr_multiplier  | 1          |
| _max_act        | 3.06737    |
| _max_adv        | 4.61       |
| _max_discrew    | 2.56       |
| _max_obs        | 44.4       |
| _mean_act       | 0.0716086  |
| _mean_adv       | -1.41e-17  |
| _mean_discrew   | 0.929      |
| _mean_obs       | 0.00574    |
| _min_adv        | -6.18      |
| _min_discrew    | 0.0136     |
| _min_obs        | -38.1      |
| _std_act        | 0.408889   |
| _std_adv        | 1          |
| _std_discrew    | 0.277      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.752       |
| KL              | 0.00257415  |
| Phi_loss        | 76.6522     |
| PolicyEntropy   | 15.3797     |
| PolicyLoss      | 0.000538261 |
| Steps           | 10003       |
| VarFuncLoss     | 0.0225      |
| _MeanReward     | 377         |
| _lr_multiplier  | 1           |
| _max_act        | 2.96824     |
| _max_adv        | 4.79        |
| _max_discrew    | 2.58        |
| _max_obs        | 28.1        |
| _mean_act       | 0.0677501   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 0.905       |
| _mean_obs       | 0.00523     |
| _min_adv        | -4.85       |
| _min_discrew    | 0.0108      |
| _min_obs        | -19.8       |
| _std_act        | 0.40776     |
| _std_adv        | 1           |
| _std_discrew    | 0.264       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.751       |
| KL              | 0.00200211  |
| Phi_loss        | 72.2913     |
| PolicyEntropy   | 15.3794     |
| PolicyLoss      | -0.00290105 |
| Steps           | 10046       |
| VarFuncLoss     | 0.022       |
| _MeanReward     | 373         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16262     |
| _max_adv        | 4.49        |
| _max_discrew    | 2.42        |
| _max_obs        | 26          |
| _mean_act       | 0.0715966   |
| _mean_adv       | -5.66e-18   |
| _mean_discrew   | 0.888       |
| _mean_obs       | 0.00513     |
| _min_adv        | -4.64       |
| _min_discrew    | 0.0144      |
| _min_obs        | -31.2       |
| _std_act        | 0.405821    |
| _std_adv        | 1           |
| _std_discrew    | 0.253       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.767      |
| KL              | 0.00341603 |
| Phi_loss        | 82.7748    |
| PolicyEntropy   | 15.379     |
| PolicyLoss      | -0.0138635 |
| Steps           | 10049      |
| VarFuncLoss     | 0.0194     |
| _MeanReward     | 374        |
| _lr_multiplier  | 1          |
| _max_act        | 3.18559    |
| _max_adv        | 6.04       |
| _max_discrew    | 2.68       |
| _max_obs        | 22.5       |
| _mean_act       | 0.0738204  |
| _mean_adv       | -2.55e-17  |
| _mean_discrew   | 0.894      |
| _mean_obs       | 0.00518    |
| _min_adv        | -5.06      |
| _min_discrew    | 0.00648    |
| _min_obs        | -18.7      |
| _std_act        | 0.407113   |
| _std_adv        | 1          |
| _std_discrew    | 0.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.713       |
| KL              | 0.00256123  |
| Phi_loss        | 63.0281     |
| PolicyEntropy   | 15.3784     |
| PolicyLoss      | -0.00133454 |
| Steps           | 10020       |
| VarFuncLoss     | 0.0225      |
| _MeanReward     | 377         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86752     |
| _max_adv        | 4.41        |
| _max_discrew    | 2.71        |
| _max_obs        | 24.6        |
| _mean_act       | 0.0704616   |
| _mean_adv       | 7.09e-19    |
| _mean_discrew   | 0.899       |
| _mean_obs       | 0.00471     |
| _min_adv        | -4.61       |
| _min_discrew    | 0.017       |
| _min_obs        | -27.4       |
| _std_act        | 0.407021    |
| _std_adv        | 1           |
| _std_discrew    | 0.263       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.747      |
| KL              | 0.00562406 |
| Phi_loss        | 92.7609    |
| PolicyEntropy   | 15.3788    |
| PolicyLoss      | -0.077068  |
| Steps           | 10013      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 387        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8244     |
| _max_adv        | 6.37       |
| _max_discrew    | 2.46       |
| _max_obs        | 24.7       |
| _mean_act       | 0.0735945  |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 0.913      |
| _mean_obs       | 0.0056     |
| _min_adv        | -5.6       |
| _min_discrew    | 0.0071     |
| _min_obs        | -29.3      |
| _std_act        | 0.404728   |
| _std_adv        | 1          |
| _std_discrew    | 0.255      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.934       |
| ExplainedVarOld | 0.814       |
| KL              | 0.00329284  |
| Phi_loss        | 91.3336     |
| PolicyEntropy   | 15.3796     |
| PolicyLoss      | -0.00221171 |
| Steps           | 10076       |
| VarFuncLoss     | 0.0169      |
| _MeanReward     | 383         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93636     |
| _max_adv        | 4.23        |
| _max_discrew    | 2.72        |
| _max_obs        | 28.5        |
| _mean_act       | 0.0769012   |
| _mean_adv       | 5.64e-18    |
| _mean_discrew   | 0.924       |
| _mean_obs       | 0.00599     |
| _min_adv        | -4.44       |
| _min_discrew    | 0.0135      |
| _min_obs        | -33.8       |
| _std_act        | 0.406985    |
| _std_adv        | 1           |
| _std_discrew    | 0.291       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.714       |
| KL              | 0.00212217  |
| Phi_loss        | 87.4342     |
| PolicyEntropy   | 15.3786     |
| PolicyLoss      | 0.000232554 |
| Steps           | 10055       |
| VarFuncLoss     | 0.0237      |
| _MeanReward     | 380         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02962     |
| _max_adv        | 4.77        |
| _max_discrew    | 2.36        |
| _max_obs        | 35.4        |
| _mean_act       | 0.0740308   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 0.912       |
| _mean_obs       | 0.0061      |
| _min_adv        | -5.64       |
| _min_discrew    | 0.0162      |
| _min_obs        | -33.9       |
| _std_act        | 0.409469    |
| _std_adv        | 1           |
| _std_discrew    | 0.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.748      |
| KL              | 0.00201161 |
| Phi_loss        | 96.3967    |
| PolicyEntropy   | 15.3769    |
| PolicyLoss      | 0.00284604 |
| Steps           | 10007      |
| VarFuncLoss     | 0.0235     |
| _MeanReward     | 387        |
| _lr_multiplier  | 1          |
| _max_act        | 3.39188    |
| _max_adv        | 4.69       |
| _max_discrew    | 2.54       |
| _max_obs        | 23.2       |
| _mean_act       | 0.072479   |
| _mean_adv       | -8.52e-18  |
| _mean_discrew   | 0.919      |
| _mean_obs       | 0.00508    |
| _min_adv        | -4.72      |
| _min_discrew    | 0.0154     |
| _min_obs        | -20.3      |
| _std_act        | 0.406963   |
| _std_adv        | 1          |
| _std_discrew    | 0.269      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.77        |
| KL              | 0.0017921   |
| Phi_loss        | 93.1597     |
| PolicyEntropy   | 15.3759     |
| PolicyLoss      | 0.000227726 |
| Steps           | 10062       |
| VarFuncLoss     | 0.022       |
| _MeanReward     | 390         |
| _lr_multiplier  | 1           |
| _max_act        | 3.49141     |
| _max_adv        | 4.9         |
| _max_discrew    | 2.47        |
| _max_obs        | 29.6        |
| _mean_act       | 0.075284    |
| _mean_adv       | -1.41e-18   |
| _mean_discrew   | 0.927       |
| _mean_obs       | 0.00526     |
| _min_adv        | -4.27       |
| _min_discrew    | 0.0146      |
| _min_obs        | -24.4       |
| _std_act        | 0.41023     |
| _std_adv        | 1           |
| _std_discrew    | 0.276       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.734       |
| KL              | 0.00233733  |
| Phi_loss        | 79.8579     |
| PolicyEntropy   | 15.3758     |
| PolicyLoss      | -0.00181869 |
| Steps           | 10008       |
| VarFuncLoss     | 0.0226      |
| _MeanReward     | 374         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13553     |
| _max_adv        | 4.11        |
| _max_discrew    | 2.37        |
| _max_obs        | 18.3        |
| _mean_act       | 0.0746884   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.887       |
| _mean_obs       | 0.00557     |
| _min_adv        | -5.37       |
| _min_discrew    | 0.00247     |
| _min_obs        | -18.1       |
| _std_act        | 0.40883     |
| _std_adv        | 1           |
| _std_discrew    | 0.249       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.742       |
| KL              | 0.00232617  |
| Phi_loss        | 92.8887     |
| PolicyEntropy   | 15.3767     |
| PolicyLoss      | -0.00534726 |
| Steps           | 10065       |
| VarFuncLoss     | 0.0218      |
| _MeanReward     | 393         |
| _lr_multiplier  | 1           |
| _max_act        | 3.28876     |
| _max_adv        | 4.57        |
| _max_discrew    | 2.59        |
| _max_obs        | 42.3        |
| _mean_act       | 0.0736965   |
| _mean_adv       | 1.27e-17    |
| _mean_discrew   | 0.936       |
| _mean_obs       | 0.00603     |
| _min_adv        | -4.52       |
| _min_discrew    | 0.0175      |
| _min_obs        | -22.1       |
| _std_act        | 0.406442    |
| _std_adv        | 1           |
| _std_discrew    | 0.271       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.784       |
| KL              | 0.00188332  |
| Phi_loss        | 98.5225     |
| PolicyEntropy   | 15.377      |
| PolicyLoss      | -0.00215419 |
| Steps           | 10011       |
| VarFuncLoss     | 0.0242      |
| _MeanReward     | 399         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24196     |
| _max_adv        | 5.85        |
| _max_discrew    | 3.03        |
| _max_obs        | 28.2        |
| _mean_act       | 0.0731866   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.947       |
| _mean_obs       | 0.00531     |
| _min_adv        | -4.37       |
| _min_discrew    | 0.00522     |
| _min_obs        | -27.5       |
| _std_act        | 0.40811     |
| _std_adv        | 1           |
| _std_discrew    | 0.299       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.752      |
| KL              | 0.00196568 |
| Phi_loss        | 86.5359    |
| PolicyEntropy   | 15.3755    |
| PolicyLoss      | 0.00136598 |
| Steps           | 10065      |
| VarFuncLoss     | 0.0251     |
| _MeanReward     | 378        |
| _lr_multiplier  | 1          |
| _max_act        | 2.90337    |
| _max_adv        | 4.49       |
| _max_discrew    | 2.55       |
| _max_obs        | 19.2       |
| _mean_act       | 0.0714647  |
| _mean_adv       | 5.65e-18   |
| _mean_discrew   | 0.903      |
| _mean_obs       | 0.00481    |
| _min_adv        | -5.47      |
| _min_discrew    | 0.0118     |
| _min_obs        | -22.9      |
| _std_act        | 0.410177   |
| _std_adv        | 1          |
| _std_discrew    | 0.261      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.739       |
| KL              | 0.00209417  |
| Phi_loss        | 81.2421     |
| PolicyEntropy   | 15.373      |
| PolicyLoss      | 0.000869005 |
| Steps           | 10004       |
| VarFuncLoss     | 0.0219      |
| _MeanReward     | 382         |
| _lr_multiplier  | 1           |
| _max_act        | 2.99615     |
| _max_adv        | 5           |
| _max_discrew    | 2.41        |
| _max_obs        | 26.3        |
| _mean_act       | 0.0752346   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.907       |
| _mean_obs       | 0.00637     |
| _min_adv        | -5.39       |
| _min_discrew    | 0.0159      |
| _min_obs        | -25.2       |
| _std_act        | 0.411888    |
| _std_adv        | 1           |
| _std_discrew    | 0.256       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.926       |
| ExplainedVarOld | 0.781       |
| KL              | 0.00271158  |
| Phi_loss        | 93.6293     |
| PolicyEntropy   | 15.3703     |
| PolicyLoss      | -0.00231862 |
| Steps           | 10021       |
| VarFuncLoss     | 0.019       |
| _MeanReward     | 392         |
| _lr_multiplier  | 1           |
| _max_act        | 3.26235     |
| _max_adv        | 5.25        |
| _max_discrew    | 2.79        |
| _max_obs        | 31          |
| _mean_act       | 0.0748002   |
| _mean_adv       | -1.91e-17   |
| _mean_discrew   | 0.937       |
| _mean_obs       | 0.00539     |
| _min_adv        | -7.24       |
| _min_discrew    | 0.0176      |
| _min_obs        | -27.9       |
| _std_act        | 0.409956    |
| _std_adv        | 1           |
| _std_discrew    | 0.277       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.768       |
| KL              | 0.00235238  |
| Phi_loss        | 88.2943     |
| PolicyEntropy   | 15.3687     |
| PolicyLoss      | -0.00295366 |
| Steps           | 10024       |
| VarFuncLoss     | 0.0217      |
| _MeanReward     | 372         |
| _lr_multiplier  | 1           |
| _max_act        | 3.37762     |
| _max_adv        | 4.62        |
| _max_discrew    | 2.37        |
| _max_obs        | 39.3        |
| _mean_act       | 0.0758918   |
| _mean_adv       | 8.51e-18    |
| _mean_discrew   | 0.882       |
| _mean_obs       | 0.00526     |
| _min_adv        | -5.08       |
| _min_discrew    | 0.0124      |
| _min_obs        | -36.8       |
| _std_act        | 0.410663    |
| _std_adv        | 1           |
| _std_discrew    | 0.251       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.77        |
| KL              | 0.00231136  |
| Phi_loss        | 94.147      |
| PolicyEntropy   | 15.3671     |
| PolicyLoss      | -5.1912e-05 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0213      |
| _MeanReward     | 385         |
| _lr_multiplier  | 1           |
| _max_act        | 3.09246     |
| _max_adv        | 5.47        |
| _max_discrew    | 2.78        |
| _max_obs        | 32.2        |
| _mean_act       | 0.0722403   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.00525     |
| _min_adv        | -4.34       |
| _min_discrew    | 0.012       |
| _min_obs        | -27.9       |
| _std_act        | 0.40738     |
| _std_adv        | 1           |
| _std_discrew    | 0.264       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.783      |
| KL              | 0.00183667 |
| Phi_loss        | 98.0964    |
| PolicyEntropy   | 15.3659    |
| PolicyLoss      | 0.00152197 |
| Steps           | 10033      |
| VarFuncLoss     | 0.0215     |
| _MeanReward     | 416        |
| _lr_multiplier  | 1          |
| _max_act        | 3.1175     |
| _max_adv        | 4.55       |
| _max_discrew    | 2.65       |
| _max_obs        | 19.5       |
| _mean_act       | 0.0694178  |
| _mean_adv       | 5.67e-18   |
| _mean_discrew   | 0.981      |
| _mean_obs       | 0.00504    |
| _min_adv        | -4.07      |
| _min_discrew    | 0.016      |
| _min_obs        | -18.8      |
| _std_act        | 0.410483   |
| _std_adv        | 1          |
| _std_discrew    | 0.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.749      |
| KL              | 0.00180424 |
| Phi_loss        | 83.1774    |
| PolicyEntropy   | 15.3651    |
| PolicyLoss      | 0.00233855 |
| Steps           | 10048      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 380        |
| _lr_multiplier  | 1          |
| _max_act        | 3.29551    |
| _max_adv        | 5.21       |
| _max_discrew    | 2.73       |
| _max_obs        | 28         |
| _mean_act       | 0.0737557  |
| _mean_adv       | -2.83e-18  |
| _mean_discrew   | 0.899      |
| _mean_obs       | 0.00514    |
| _min_adv        | -5.88      |
| _min_discrew    | 0.0131     |
| _min_obs        | -43.1      |
| _std_act        | 0.412734   |
| _std_adv        | 1          |
| _std_discrew    | 0.255      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.71        |
| KL              | 0.00233421  |
| Phi_loss        | 80.9755     |
| PolicyEntropy   | 15.3652     |
| PolicyLoss      | -0.00140312 |
| Steps           | 10007       |
| VarFuncLoss     | 0.0212      |
| _MeanReward     | 380         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04215     |
| _max_adv        | 4.75        |
| _max_discrew    | 2.98        |
| _max_obs        | 25.2        |
| _mean_act       | 0.0752717   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.899       |
| _mean_obs       | 0.00569     |
| _min_adv        | -6.45       |
| _min_discrew    | 0.0108      |
| _min_obs        | -27.4       |
| _std_act        | 0.409483    |
| _std_adv        | 1           |
| _std_discrew    | 0.261       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.752       |
| KL              | 0.00198327  |
| Phi_loss        | 82.3785     |
| PolicyEntropy   | 15.3647     |
| PolicyLoss      | -0.00266755 |
| Steps           | 10058       |
| VarFuncLoss     | 0.0212      |
| _MeanReward     | 390         |
| _lr_multiplier  | 1           |
| _max_act        | 2.88115     |
| _max_adv        | 4.63        |
| _max_discrew    | 2.81        |
| _max_obs        | 29.7        |
| _mean_act       | 0.0747978   |
| _mean_adv       | 8.48e-18    |
| _mean_discrew   | 0.94        |
| _mean_obs       | 0.00453     |
| _min_adv        | -5.27       |
| _min_discrew    | 0.0147      |
| _min_obs        | -30.9       |
| _std_act        | 0.409069    |
| _std_adv        | 1           |
| _std_discrew    | 0.303       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.911     |
| ExplainedVarOld | 0.712     |
| KL              | 0.0132527 |
| Phi_loss        | 478.301   |
| PolicyEntropy   | 15.3646   |
| PolicyLoss      | 0.0577406 |
| Steps           | 10018     |
| VarFuncLoss     | 0.0269    |
| _MeanReward     | 388       |
| _lr_multiplier  | 1         |
| _max_act        | 2.97268   |
| _max_adv        | 4.6       |
| _max_discrew    | 2.34      |
| _max_obs        | 41.5      |
| _mean_act       | 0.0734132 |
| _mean_adv       | 5.67e-18  |
| _mean_discrew   | 0.91      |
| _mean_obs       | 0.00485   |
| _min_adv        | -4.37     |
| _min_discrew    | 0.0131    |
| _min_obs        | -37       |
| _std_act        | 0.411777  |
| _std_adv        | 1         |
| _std_discrew    | 0.256     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.748       |
| KL              | 0.00695325  |
| Phi_loss        | 102.816     |
| PolicyEntropy   | 15.3629     |
| PolicyLoss      | -0.00067124 |
| Steps           | 10056       |
| VarFuncLoss     | 0.0201      |
| _MeanReward     | 389         |
| _lr_multiplier  | 1           |
| _max_act        | 3.65428     |
| _max_adv        | 4.62        |
| _max_discrew    | 2.34        |
| _max_obs        | 49.3        |
| _mean_act       | 0.0735653   |
| _mean_adv       | 3.39e-17    |
| _mean_discrew   | 0.927       |
| _mean_obs       | 0.00481     |
| _min_adv        | -5.58       |
| _min_discrew    | 0.0147      |
| _min_obs        | -29.6       |
| _std_act        | 0.413465    |
| _std_adv        | 1           |
| _std_discrew    | 0.278       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.911        |
| ExplainedVarOld | 0.736        |
| KL              | 0.000624928  |
| Phi_loss        | 99.1425      |
| PolicyEntropy   | 15.3638      |
| PolicyLoss      | -0.000675678 |
| Steps           | 10033        |
| VarFuncLoss     | 0.0247       |
| _MeanReward     | 394          |
| _lr_multiplier  | 1            |
| _max_act        | 3.15155      |
| _max_adv        | 4.44         |
| _max_discrew    | 2.65         |
| _max_obs        | 30.6         |
| _mean_act       | 0.0753392    |
| _mean_adv       | -1.42e-17    |
| _mean_discrew   | 0.938        |
| _mean_obs       | 0.0053       |
| _min_adv        | -6.27        |
| _min_discrew    | 0.011        |
| _min_obs        | -25.8        |
| _std_act        | 0.410225     |
| _std_adv        | 1            |
| _std_discrew    | 0.285        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.916        |
| ExplainedVarOld | 0.741        |
| KL              | 0.00101742   |
| Phi_loss        | 100.347      |
| PolicyEntropy   | 15.3633      |
| PolicyLoss      | -0.000523592 |
| Steps           | 10055        |
| VarFuncLoss     | 0.0241       |
| _MeanReward     | 397          |
| _lr_multiplier  | 1            |
| _max_act        | 3.06161      |
| _max_adv        | 4.88         |
| _max_discrew    | 3.24         |
| _max_obs        | 36           |
| _mean_act       | 0.0724362    |
| _mean_adv       | 0            |
| _mean_discrew   | 0.954        |
| _mean_obs       | 0.00468      |
| _min_adv        | -4.85        |
| _min_discrew    | 0.0149       |
| _min_obs        | -32.7        |
| _std_act        | 0.409343     |
| _std_adv        | 1            |
| _std_discrew    | 0.31         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.717      |
| KL              | 0.00204814 |
| Phi_loss        | 102.025    |
| PolicyEntropy   | 15.3626    |
| PolicyLoss      | -0.0125081 |
| Steps           | 10005      |
| VarFuncLoss     | 0.0271     |
| _MeanReward     | 393        |
| _lr_multiplier  | 1          |
| _max_act        | 3.28611    |
| _max_adv        | 5.25       |
| _max_discrew    | 2.67       |
| _max_obs        | 32         |
| _mean_act       | 0.0724133  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.934      |
| _mean_obs       | 0.00547    |
| _min_adv        | -5.17      |
| _min_discrew    | 0.0152     |
| _min_obs        | -22.8      |
| _std_act        | 0.414566   |
| _std_adv        | 1          |
| _std_discrew    | 0.279      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.785       |
| KL              | 0.00168397  |
| Phi_loss        | 107.023     |
| PolicyEntropy   | 15.3625     |
| PolicyLoss      | -0.00416726 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0231      |
| _MeanReward     | 391         |
| _lr_multiplier  | 1           |
| _max_act        | 3.42404     |
| _max_adv        | 4.44        |
| _max_discrew    | 2.44        |
| _max_obs        | 38.2        |
| _mean_act       | 0.0704202   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 0.924       |
| _mean_obs       | 0.00483     |
| _min_adv        | -5.53       |
| _min_discrew    | 0.0142      |
| _min_obs        | -29.9       |
| _std_act        | 0.414877    |
| _std_adv        | 1           |
| _std_discrew    | 0.267       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.779      |
| KL              | 0.00149896 |
| Phi_loss        | 105.681    |
| PolicyEntropy   | 15.362     |
| PolicyLoss      | -0.0024684 |
| Steps           | 10029      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 398        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0529     |
| _max_adv        | 4.92       |
| _max_discrew    | 2.82       |
| _max_obs        | 28.7       |
| _mean_act       | 0.073477   |
| _mean_adv       | -1.13e-17  |
| _mean_discrew   | 0.938      |
| _mean_obs       | 0.00454    |
| _min_adv        | -5.45      |
| _min_discrew    | 0.012      |
| _min_obs        | -28.2      |
| _std_act        | 0.411516   |
| _std_adv        | 1          |
| _std_discrew    | 0.286      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.917        |
| ExplainedVarOld | 0.75         |
| KL              | 0.00263021   |
| Phi_loss        | 98.5071      |
| PolicyEntropy   | 15.3612      |
| PolicyLoss      | -0.000213715 |
| Steps           | 10010        |
| VarFuncLoss     | 0.0239       |
| _MeanReward     | 387          |
| _lr_multiplier  | 1            |
| _max_act        | 3.13386      |
| _max_adv        | 4.69         |
| _max_discrew    | 2.79         |
| _max_obs        | 26.3         |
| _mean_act       | 0.0715219    |
| _mean_adv       | -1.42e-18    |
| _mean_discrew   | 0.923        |
| _mean_obs       | 0.00446      |
| _min_adv        | -5.18        |
| _min_discrew    | 0.0124       |
| _min_obs        | -33.6        |
| _std_act        | 0.409711     |
| _std_adv        | 1            |
| _std_discrew    | 0.282        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.76        |
| KL              | 0.00274077  |
| Phi_loss        | 101.257     |
| PolicyEntropy   | 15.3607     |
| PolicyLoss      | -0.00105322 |
| Steps           | 10032       |
| VarFuncLoss     | 0.0237      |
| _MeanReward     | 408         |
| _lr_multiplier  | 1           |
| _max_act        | 2.99967     |
| _max_adv        | 5.63        |
| _max_discrew    | 2.74        |
| _max_obs        | 26.2        |
| _mean_act       | 0.0752894   |
| _mean_adv       | -5.67e-18   |
| _mean_discrew   | 0.959       |
| _mean_obs       | 0.00568     |
| _min_adv        | -5.18       |
| _min_discrew    | 0.0159      |
| _min_obs        | -23         |
| _std_act        | 0.411016    |
| _std_adv        | 1           |
| _std_discrew    | 0.296       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.773       |
| KL              | 0.00284553  |
| Phi_loss        | 96.2195     |
| PolicyEntropy   | 15.3607     |
| PolicyLoss      | -0.00317973 |
| Steps           | 10031       |
| VarFuncLoss     | 0.0239      |
| _MeanReward     | 400         |
| _lr_multiplier  | 1           |
| _max_act        | 3.48946     |
| _max_adv        | 5.48        |
| _max_discrew    | 2.49        |
| _max_obs        | 38          |
| _mean_act       | 0.0730204   |
| _mean_adv       | 3.97e-17    |
| _mean_discrew   | 0.945       |
| _mean_obs       | 0.00526     |
| _min_adv        | -5.94       |
| _min_discrew    | 0.0162      |
| _min_obs        | -29.2       |
| _std_act        | 0.413667    |
| _std_adv        | 1           |
| _std_discrew    | 0.273       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.926       |
| ExplainedVarOld | 0.789       |
| KL              | 0.00298812  |
| Phi_loss        | 97.2899     |
| PolicyEntropy   | 15.3612     |
| PolicyLoss      | -0.00403157 |
| Steps           | 10103       |
| VarFuncLoss     | 0.0203      |
| _MeanReward     | 384         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24752     |
| _max_adv        | 4.25        |
| _max_discrew    | 2.48        |
| _max_obs        | 32.8        |
| _mean_act       | 0.0722755   |
| _mean_adv       | -8.44e-18   |
| _mean_discrew   | 0.914       |
| _mean_obs       | 0.00485     |
| _min_adv        | -4.92       |
| _min_discrew    | 0.0155      |
| _min_obs        | -21.8       |
| _std_act        | 0.413823    |
| _std_adv        | 1           |
| _std_discrew    | 0.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.916        |
| ExplainedVarOld | 0.765        |
| KL              | 0.00301485   |
| Phi_loss        | 92.7558      |
| PolicyEntropy   | 15.3612      |
| PolicyLoss      | -0.000846259 |
| Steps           | 10004        |
| VarFuncLoss     | 0.0221       |
| _MeanReward     | 386          |
| _lr_multiplier  | 1            |
| _max_act        | 3.5904       |
| _max_adv        | 4.93         |
| _max_discrew    | 3.28         |
| _max_obs        | 25.6         |
| _mean_act       | 0.0737362    |
| _mean_adv       | 1.42e-17     |
| _mean_discrew   | 0.919        |
| _mean_obs       | 0.00445      |
| _min_adv        | -5.73        |
| _min_discrew    | 0.0149       |
| _min_obs        | -25.4        |
| _std_act        | 0.413129     |
| _std_adv        | 1            |
| _std_discrew    | 0.29         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.915        |
| ExplainedVarOld | 0.738        |
| KL              | 0.0029945    |
| Phi_loss        | 91.7205      |
| PolicyEntropy   | 15.361       |
| PolicyLoss      | -0.000908424 |
| Steps           | 10054        |
| VarFuncLoss     | 0.0249       |
| _MeanReward     | 399          |
| _lr_multiplier  | 1            |
| _max_act        | 3.06497      |
| _max_adv        | 6.04         |
| _max_discrew    | 2.65         |
| _max_obs        | 32.9         |
| _mean_act       | 0.0713808    |
| _mean_adv       | -1.13e-17    |
| _mean_discrew   | 0.945        |
| _mean_obs       | 0.0038       |
| _min_adv        | -4.13        |
| _min_discrew    | 0.0167       |
| _min_obs        | -44.5        |
| _std_act        | 0.414669     |
| _std_adv        | 1            |
| _std_discrew    | 0.295        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.756       |
| KL              | 0.00362637  |
| Phi_loss        | 95.1949     |
| PolicyEntropy   | 15.3609     |
| PolicyLoss      | -0.00659156 |
| Steps           | 10092       |
| VarFuncLoss     | 0.0216      |
| _MeanReward     | 396         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14405     |
| _max_adv        | 5.03        |
| _max_discrew    | 2.93        |
| _max_obs        | 31.1        |
| _mean_act       | 0.0773844   |
| _mean_adv       | 2.11e-18    |
| _mean_discrew   | 0.953       |
| _mean_obs       | 0.00467     |
| _min_adv        | -5.74       |
| _min_discrew    | 0.0168      |
| _min_obs        | -28.3       |
| _std_act        | 0.409908    |
| _std_adv        | 1           |
| _std_discrew    | 0.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.733      |
| KL              | 0.00382379 |
| Phi_loss        | 99.557     |
| PolicyEntropy   | 15.3577    |
| PolicyLoss      | 0.0419678  |
| Steps           | 10034      |
| VarFuncLoss     | 0.0271     |
| _MeanReward     | 395        |
| _lr_multiplier  | 1          |
| _max_act        | 3.04207    |
| _max_adv        | 5.39       |
| _max_discrew    | 2.56       |
| _max_obs        | 28.3       |
| _mean_act       | 0.0751854  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.939      |
| _mean_obs       | 0.00514    |
| _min_adv        | -4.87      |
| _min_discrew    | 0.0148     |
| _min_obs        | -25.3      |
| _std_act        | 0.412921   |
| _std_adv        | 1          |
| _std_discrew    | 0.277      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.729       |
| KL              | 0.00313402  |
| Phi_loss        | 92.028      |
| PolicyEntropy   | 15.3506     |
| PolicyLoss      | -0.00374672 |
| Steps           | 10030       |
| VarFuncLoss     | 0.0229      |
| _MeanReward     | 395         |
| _lr_multiplier  | 1           |
| _max_act        | 3.27915     |
| _max_adv        | 4.91        |
| _max_discrew    | 3.12        |
| _max_obs        | 42.7        |
| _mean_act       | 0.0743922   |
| _mean_adv       | 4.25e-18    |
| _mean_discrew   | 0.95        |
| _mean_obs       | 0.0043      |
| _min_adv        | -5.35       |
| _min_discrew    | 0.0173      |
| _min_obs        | -41.2       |
| _std_act        | 0.410455    |
| _std_adv        | 1           |
| _std_discrew    | 0.305       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.736       |
| KL              | 0.00296341  |
| Phi_loss        | 92.7895     |
| PolicyEntropy   | 15.3493     |
| PolicyLoss      | -0.00184639 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0262      |
| _MeanReward     | 392         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86924     |
| _max_adv        | 4.75        |
| _max_discrew    | 2.55        |
| _max_obs        | 28.8        |
| _mean_act       | 0.0783417   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.932       |
| _mean_obs       | 0.00435     |
| _min_adv        | -4.73       |
| _min_discrew    | 0.0158      |
| _min_obs        | -33.6       |
| _std_act        | 0.412723    |
| _std_adv        | 1           |
| _std_discrew    | 0.285       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.768       |
| KL              | 0.00282123  |
| Phi_loss        | 85.8332     |
| PolicyEntropy   | 15.3498     |
| PolicyLoss      | -0.00581853 |
| Steps           | 10001       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 389         |
| _lr_multiplier  | 1           |
| _max_act        | 2.96485     |
| _max_adv        | 4.49        |
| _max_discrew    | 2.6         |
| _max_obs        | 36.2        |
| _mean_act       | 0.0744631   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.928       |
| _mean_obs       | 0.00379     |
| _min_adv        | -5.13       |
| _min_discrew    | 0.00745     |
| _min_obs        | -25.7       |
| _std_act        | 0.416125    |
| _std_adv        | 1           |
| _std_discrew    | 0.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.72        |
| KL              | 0.0031288   |
| Phi_loss        | 88.157      |
| PolicyEntropy   | 15.3505     |
| PolicyLoss      | -0.00315095 |
| Steps           | 10067       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 401         |
| _lr_multiplier  | 1           |
| _max_act        | 2.99193     |
| _max_adv        | 5.03        |
| _max_discrew    | 2.53        |
| _max_obs        | 30.5        |
| _mean_act       | 0.0769214   |
| _mean_adv       | 1.41e-17    |
| _mean_discrew   | 0.942       |
| _mean_obs       | 0.00385     |
| _min_adv        | -6.05       |
| _min_discrew    | 0.0156      |
| _min_obs        | -29.8       |
| _std_act        | 0.412256    |
| _std_adv        | 1           |
| _std_discrew    | 0.283       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.768       |
| KL              | 0.00287497  |
| Phi_loss        | 94.3176     |
| PolicyEntropy   | 15.351      |
| PolicyLoss      | -0.00449381 |
| Steps           | 10038       |
| VarFuncLoss     | 0.0247      |
| _MeanReward     | 399         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97597     |
| _max_adv        | 5.12        |
| _max_discrew    | 2.95        |
| _max_obs        | 24.1        |
| _mean_act       | 0.0738338   |
| _mean_adv       | 1.27e-17    |
| _mean_discrew   | 0.943       |
| _mean_obs       | 0.00335     |
| _min_adv        | -5.04       |
| _min_discrew    | 0.0152      |
| _min_obs        | -22         |
| _std_act        | 0.412254    |
| _std_adv        | 1           |
| _std_discrew    | 0.298       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.769       |
| KL              | 0.00260954  |
| Phi_loss        | 89.6798     |
| PolicyEntropy   | 15.3517     |
| PolicyLoss      | -0.00525747 |
| Steps           | 10088       |
| VarFuncLoss     | 0.0243      |
| _MeanReward     | 399         |
| _lr_multiplier  | 1           |
| _max_act        | 3.18077     |
| _max_adv        | 4.65        |
| _max_discrew    | 2.81        |
| _max_obs        | 28.9        |
| _mean_act       | 0.0744537   |
| _mean_adv       | -1.69e-17   |
| _mean_discrew   | 0.944       |
| _mean_obs       | 0.00467     |
| _min_adv        | -5          |
| _min_discrew    | 0.0131      |
| _min_obs        | -25.6       |
| _std_act        | 0.418197    |
| _std_adv        | 1           |
| _std_discrew    | 0.292       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.768       |
| KL              | 0.00358898  |
| Phi_loss        | 88.7014     |
| PolicyEntropy   | 15.3521     |
| PolicyLoss      | -0.00516426 |
| Steps           | 10042       |
| VarFuncLoss     | 0.0242      |
| _MeanReward     | 383         |
| _lr_multiplier  | 1           |
| _max_act        | 3.32315     |
| _max_adv        | 4.16        |
| _max_discrew    | 2.38        |
| _max_obs        | 34.7        |
| _mean_act       | 0.0742882   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 0.902       |
| _mean_obs       | 0.00408     |
| _min_adv        | -5.66       |
| _min_discrew    | 0.0157      |
| _min_obs        | -25.1       |
| _std_act        | 0.414677    |
| _std_adv        | 1           |
| _std_discrew    | 0.256       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.915       |
| ExplainedVarOld | 0.763       |
| KL              | 0.00352637  |
| Phi_loss        | 87.1689     |
| PolicyEntropy   | 15.3536     |
| PolicyLoss      | -0.00375837 |
| Steps           | 10086       |
| VarFuncLoss     | 0.0218      |
| _MeanReward     | 404         |
| _lr_multiplier  | 1           |
| _max_act        | 2.943       |
| _max_adv        | 4.57        |
| _max_discrew    | 3.01        |
| _max_obs        | 24.2        |
| _mean_act       | 0.0767519   |
| _mean_adv       | 1.27e-17    |
| _mean_discrew   | 0.955       |
| _mean_obs       | 0.00408     |
| _min_adv        | -4.73       |
| _min_discrew    | 0.014       |
| _min_obs        | -16.8       |
| _std_act        | 0.414399    |
| _std_adv        | 1           |
| _std_discrew    | 0.304       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00283996  |
| Phi_loss        | 90.0856     |
| PolicyEntropy   | 15.3551     |
| PolicyLoss      | -0.00457057 |
| Steps           | 10076       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 388         |
| _lr_multiplier  | 1           |
| _max_act        | 3.09382     |
| _max_adv        | 5.23        |
| _max_discrew    | 2.45        |
| _max_obs        | 26          |
| _mean_act       | 0.0754934   |
| _mean_adv       | -2.82e-18   |
| _mean_discrew   | 0.915       |
| _mean_obs       | 0.00412     |
| _min_adv        | -4.61       |
| _min_discrew    | 0.0148      |
| _min_obs        | -30.7       |
| _std_act        | 0.415564    |
| _std_adv        | 1           |
| _std_discrew    | 0.265       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.765      |
| KL              | 0.00340614 |
| Phi_loss        | 88.8403    |
| PolicyEntropy   | 15.3541    |
| PolicyLoss      | 0.00029953 |
| Steps           | 10016      |
| VarFuncLoss     | 0.0225     |
| _MeanReward     | 402        |
| _lr_multiplier  | 1          |
| _max_act        | 3.22043    |
| _max_adv        | 4.3        |
| _max_discrew    | 2.33       |
| _max_obs        | 33.4       |
| _mean_act       | 0.0691639  |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 0.945      |
| _mean_obs       | 0.00377    |
| _min_adv        | -6         |
| _min_discrew    | 0.0167     |
| _min_obs        | -25.8      |
| _std_act        | 0.415414   |
| _std_adv        | 1          |
| _std_discrew    | 0.279      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.771       |
| KL              | 0.00303215  |
| Phi_loss        | 91.3934     |
| PolicyEntropy   | 15.3526     |
| PolicyLoss      | 0.000512544 |
| Steps           | 10009       |
| VarFuncLoss     | 0.0232      |
| _MeanReward     | 399         |
| _lr_multiplier  | 1           |
| _max_act        | 2.92946     |
| _max_adv        | 5.1         |
| _max_discrew    | 2.62        |
| _max_obs        | 25.2        |
| _mean_act       | 0.0806642   |
| _mean_adv       | 1.85e-17    |
| _mean_discrew   | 0.951       |
| _mean_obs       | 0.00437     |
| _min_adv        | -5.03       |
| _min_discrew    | 0.0166      |
| _min_obs        | -27.1       |
| _std_act        | 0.41566     |
| _std_adv        | 1           |
| _std_discrew    | 0.301       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.78       |
| KL              | 0.00343741 |
| Phi_loss        | 87.3142    |
| PolicyEntropy   | 15.3497    |
| PolicyLoss      | 0.00516394 |
| Steps           | 10089      |
| VarFuncLoss     | 0.0234     |
| _MeanReward     | 395        |
| _lr_multiplier  | 1          |
| _max_act        | 3.04543    |
| _max_adv        | 4.48       |
| _max_discrew    | 2.66       |
| _max_obs        | 30.5       |
| _mean_act       | 0.077288   |
| _mean_adv       | 1.69e-17   |
| _mean_discrew   | 0.932      |
| _mean_obs       | 0.00408    |
| _min_adv        | -4.78      |
| _min_discrew    | 0.00867    |
| _min_obs        | -25.9      |
| _std_act        | 0.419001   |
| _std_adv        | 1          |
| _std_discrew    | 0.283      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.736      |
| KL              | 0.00355756 |
| Phi_loss        | 88.1637    |
| PolicyEntropy   | 15.3473    |
| PolicyLoss      | 0.00162809 |
| Steps           | 10108      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 403        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8836     |
| _max_adv        | 4.45       |
| _max_discrew    | 2.64       |
| _max_obs        | 21.9       |
| _mean_act       | 0.0786958  |
| _mean_adv       | -7.03e-18  |
| _mean_discrew   | 0.943      |
| _mean_obs       | 0.00413    |
| _min_adv        | -5.95      |
| _min_discrew    | 0.0141     |
| _min_obs        | -31.9      |
| _std_act        | 0.415936   |
| _std_adv        | 1          |
| _std_discrew    | 0.283      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.769      |
| KL              | 0.00335132 |
| Phi_loss        | 85.4415    |
| PolicyEntropy   | 15.3465    |
| PolicyLoss      | -0.0015896 |
| Steps           | 10023      |
| VarFuncLoss     | 0.0209     |
| _MeanReward     | 399        |
| _lr_multiplier  | 1          |
| _max_act        | 3.09727    |
| _max_adv        | 6.58       |
| _max_discrew    | 2.58       |
| _max_obs        | 24.6       |
| _mean_act       | 0.0767368  |
| _mean_adv       | 5.67e-18   |
| _mean_discrew   | 0.941      |
| _mean_obs       | 0.00356    |
| _min_adv        | -5.77      |
| _min_discrew    | 0.0133     |
| _min_obs        | -21.8      |
| _std_act        | 0.414955   |
| _std_adv        | 1          |
| _std_discrew    | 0.286      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.92         |
| ExplainedVarOld | 0.784        |
| KL              | 0.00352513   |
| Phi_loss        | 91.0102      |
| PolicyEntropy   | 15.3454      |
| PolicyLoss      | -0.000548617 |
| Steps           | 10031        |
| VarFuncLoss     | 0.0229       |
| _MeanReward     | 404          |
| _lr_multiplier  | 1            |
| _max_act        | 3.1517       |
| _max_adv        | 5.06         |
| _max_discrew    | 2.52         |
| _max_obs        | 28.7         |
| _mean_act       | 0.0743432    |
| _mean_adv       | 1.13e-17     |
| _mean_discrew   | 0.949        |
| _mean_obs       | 0.00378      |
| _min_adv        | -7.01        |
| _min_discrew    | 0.0151       |
| _min_obs        | -26.3        |
| _std_act        | 0.416583     |
| _std_adv        | 1            |
| _std_discrew    | 0.288        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.775      |
| KL              | 0.00667881 |
| Phi_loss        | 104.843    |
| PolicyEntropy   | 15.3464    |
| PolicyLoss      | -0.11087   |
| Steps           | 10008      |
| VarFuncLoss     | 0.023      |
| _MeanReward     | 423        |
| _lr_multiplier  | 1          |
| _max_act        | 2.83221    |
| _max_adv        | 4.32       |
| _max_discrew    | 2.72       |
| _max_obs        | 30.1       |
| _mean_act       | 0.0717685  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.988      |
| _mean_obs       | 0.00452    |
| _min_adv        | -5.25      |
| _min_discrew    | 0.0147     |
| _min_obs        | -25.9      |
| _std_act        | 0.415131   |
| _std_adv        | 1          |
| _std_discrew    | 0.296      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.792      |
| KL              | 0.00287336 |
| Phi_loss        | 108.767    |
| PolicyEntropy   | 15.347     |
| PolicyLoss      | 0.00225503 |
| Steps           | 10051      |
| VarFuncLoss     | 0.0207     |
| _MeanReward     | 416        |
| _lr_multiplier  | 1          |
| _max_act        | 3.08219    |
| _max_adv        | 4.25       |
| _max_discrew    | 2.63       |
| _max_obs        | 30         |
| _mean_act       | 0.0771692  |
| _mean_adv       | -2.83e-18  |
| _mean_discrew   | 0.962      |
| _mean_obs       | 0.00442    |
| _min_adv        | -6.99      |
| _min_discrew    | 0.0158     |
| _min_obs        | -23.1      |
| _std_act        | 0.417893   |
| _std_adv        | 1          |
| _std_discrew    | 0.288      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.789       |
| KL              | 0.00173075  |
| Phi_loss        | 110.426     |
| PolicyEntropy   | 15.3449     |
| PolicyLoss      | 6.31092e-05 |
| Steps           | 10075       |
| VarFuncLoss     | 0.021       |
| _MeanReward     | 412         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16172     |
| _max_adv        | 4.83        |
| _max_discrew    | 2.79        |
| _max_obs        | 47.4        |
| _mean_act       | 0.0772722   |
| _mean_adv       | -8.46e-18   |
| _mean_discrew   | 0.959       |
| _mean_obs       | 0.00477     |
| _min_adv        | -5.26       |
| _min_discrew    | 0.0164      |
| _min_obs        | -34.5       |
| _std_act        | 0.415446    |
| _std_adv        | 1           |
| _std_discrew    | 0.289       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.794       |
| KL              | 0.00196065  |
| Phi_loss        | 106.693     |
| PolicyEntropy   | 15.3438     |
| PolicyLoss      | -0.00100075 |
| Steps           | 10006       |
| VarFuncLoss     | 0.0232      |
| _MeanReward     | 406         |
| _lr_multiplier  | 1           |
| _max_act        | 3.73928     |
| _max_adv        | 6.39        |
| _max_discrew    | 2.93        |
| _max_obs        | 41.9        |
| _mean_act       | 0.0748466   |
| _mean_adv       | 9.94e-18    |
| _mean_discrew   | 0.958       |
| _mean_obs       | 0.00399     |
| _min_adv        | -5.26       |
| _min_discrew    | 0.016       |
| _min_obs        | -34.1       |
| _std_act        | 0.416776    |
| _std_adv        | 1           |
| _std_discrew    | 0.304       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.797      |
| KL              | 0.00158699 |
| Phi_loss        | 106.094    |
| PolicyEntropy   | 15.3411    |
| PolicyLoss      | 0.00239621 |
| Steps           | 10042      |
| VarFuncLoss     | 0.0224     |
| _MeanReward     | 405        |
| _lr_multiplier  | 1          |
| _max_act        | 3.27378    |
| _max_adv        | 4.61       |
| _max_discrew    | 2.54       |
| _max_obs        | 32.1       |
| _mean_act       | 0.0759336  |
| _mean_adv       | 2.83e-18   |
| _mean_discrew   | 0.947      |
| _mean_obs       | 0.00419    |
| _min_adv        | -5.67      |
| _min_discrew    | 0.0153     |
| _min_obs        | -31.7      |
| _std_act        | 0.416455   |
| _std_adv        | 1          |
| _std_discrew    | 0.281      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.928       |
| ExplainedVarOld | 0.798       |
| KL              | 0.00189766  |
| Phi_loss        | 105.259     |
| PolicyEntropy   | 15.3403     |
| PolicyLoss      | -0.00293243 |
| Steps           | 10003       |
| VarFuncLoss     | 0.0203      |
| _MeanReward     | 419         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13131     |
| _max_adv        | 5.64        |
| _max_discrew    | 3.43        |
| _max_obs        | 26.5        |
| _mean_act       | 0.076532    |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.996       |
| _mean_obs       | 0.00467     |
| _min_adv        | -4.95       |
| _min_discrew    | 0.0161      |
| _min_obs        | -26.9       |
| _std_act        | 0.417852    |
| _std_adv        | 1           |
| _std_discrew    | 0.346       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.918        |
| ExplainedVarOld | 0.713        |
| KL              | 0.00173785   |
| Phi_loss        | 96.0128      |
| PolicyEntropy   | 15.3412      |
| PolicyLoss      | -0.000909479 |
| Steps           | 10017        |
| VarFuncLoss     | 0.0284       |
| _MeanReward     | 407          |
| _lr_multiplier  | 1            |
| _max_act        | 2.86963      |
| _max_adv        | 4.71         |
| _max_discrew    | 2.88         |
| _max_obs        | 27.8         |
| _mean_act       | 0.0786016    |
| _mean_adv       | -9.93e-18    |
| _mean_discrew   | 0.971        |
| _mean_obs       | 0.00467      |
| _min_adv        | -4.34        |
| _min_discrew    | 0.0168       |
| _min_obs        | -26.9        |
| _std_act        | 0.418734     |
| _std_adv        | 1            |
| _std_discrew    | 0.311        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.734       |
| KL              | 0.00201174  |
| Phi_loss        | 104.257     |
| PolicyEntropy   | 15.3412     |
| PolicyLoss      | -0.00145904 |
| Steps           | 10060       |
| VarFuncLoss     | 0.0247      |
| _MeanReward     | 414         |
| _lr_multiplier  | 1           |
| _max_act        | 3.32168     |
| _max_adv        | 4.45        |
| _max_discrew    | 2.67        |
| _max_obs        | 29.4        |
| _mean_act       | 0.0736421   |
| _mean_adv       | 5.65e-18    |
| _mean_discrew   | 0.973       |
| _mean_obs       | 0.00469     |
| _min_adv        | -5.68       |
| _min_discrew    | 0.0123      |
| _min_obs        | -18.4       |
| _std_act        | 0.417006    |
| _std_adv        | 1           |
| _std_discrew    | 0.301       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.765       |
| KL              | 0.00178909  |
| Phi_loss        | 107.549     |
| PolicyEntropy   | 15.3406     |
| PolicyLoss      | -0.00118938 |
| Steps           | 10069       |
| VarFuncLoss     | 0.0243      |
| _MeanReward     | 407         |
| _lr_multiplier  | 1           |
| _max_act        | 3.12574     |
| _max_adv        | 4.78        |
| _max_discrew    | 2.5         |
| _max_obs        | 34.8        |
| _mean_act       | 0.076817    |
| _mean_adv       | -2.82e-17   |
| _mean_discrew   | 0.953       |
| _mean_obs       | 0.00393     |
| _min_adv        | -5.47       |
| _min_discrew    | 0.0156      |
| _min_obs        | -32.5       |
| _std_act        | 0.416639    |
| _std_adv        | 1           |
| _std_discrew    | 0.285       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.77        |
| KL              | 0.00173643  |
| Phi_loss        | 97.8065     |
| PolicyEntropy   | 15.3398     |
| PolicyLoss      | 0.000409647 |
| Steps           | 10029       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 411         |
| _lr_multiplier  | 1           |
| _max_act        | 2.98892     |
| _max_adv        | 5.26        |
| _max_discrew    | 2.79        |
| _max_obs        | 24          |
| _mean_act       | 0.0744645   |
| _mean_adv       | 2.83e-18    |
| _mean_discrew   | 0.967       |
| _mean_obs       | 0.00422     |
| _min_adv        | -5.57       |
| _min_discrew    | 0.0156      |
| _min_obs        | -27.6       |
| _std_act        | 0.414678    |
| _std_adv        | 1           |
| _std_discrew    | 0.296       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.784      |
| KL              | 0.00198491 |
| Phi_loss        | 99.47      |
| PolicyEntropy   | 15.3396    |
| PolicyLoss      | 0.00130692 |
| Steps           | 10042      |
| VarFuncLoss     | 0.0226     |
| _MeanReward     | 429        |
| _lr_multiplier  | 1          |
| _max_act        | 3.16275    |
| _max_adv        | 4.82       |
| _max_discrew    | 3          |
| _max_obs        | 36.3       |
| _mean_act       | 0.0794231  |
| _mean_adv       | 5.66e-18   |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.00481    |
| _min_adv        | -4.68      |
| _min_discrew    | 0.00894    |
| _min_obs        | -33.3      |
| _std_act        | 0.416042   |
| _std_adv        | 1          |
| _std_discrew    | 0.347      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.749       |
| KL              | 0.00182182  |
| Phi_loss        | 103.594     |
| PolicyEntropy   | 15.3394     |
| PolicyLoss      | -0.00204148 |
| Steps           | 10107       |
| VarFuncLoss     | 0.0301      |
| _MeanReward     | 410         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02116     |
| _max_adv        | 4.37        |
| _max_discrew    | 2.6         |
| _max_obs        | 24.2        |
| _mean_act       | 0.0774317   |
| _mean_adv       | -1.12e-17   |
| _mean_discrew   | 0.965       |
| _mean_obs       | 0.00428     |
| _min_adv        | -5.22       |
| _min_discrew    | 0.0152      |
| _min_obs        | -17.7       |
| _std_act        | 0.415971    |
| _std_adv        | 1           |
| _std_discrew    | 0.299       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.78        |
| KL              | 0.00168187  |
| Phi_loss        | 108.544     |
| PolicyEntropy   | 15.3396     |
| PolicyLoss      | -0.00146697 |
| Steps           | 10051       |
| VarFuncLoss     | 0.0246      |
| _MeanReward     | 415         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0624      |
| _max_adv        | 4.21        |
| _max_discrew    | 2.64        |
| _max_obs        | 28.1        |
| _mean_act       | 0.0786023   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 0.974       |
| _mean_obs       | 0.00456     |
| _min_adv        | -5.62       |
| _min_discrew    | 0.013       |
| _min_obs        | -22.6       |
| _std_act        | 0.417544    |
| _std_adv        | 1           |
| _std_discrew    | 0.307       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
-------------------------------
| Beta            | 0.296     |
| ExplainedVarNew | 0.917     |
| ExplainedVarOld | 0.755     |
| KL              | 0.0050521 |
| Phi_loss        | 507.63    |
| PolicyEntropy   | 15.3391   |
| PolicyLoss      | 0.161833  |
| Steps           | 10076     |
| VarFuncLoss     | 0.0258    |
| _MeanReward     | 412       |
| _lr_multiplier  | 1         |
| _max_act        | 3.14767   |
| _max_adv        | 6.52      |
| _max_discrew    | 2.51      |
| _max_obs        | 28        |
| _mean_act       | 0.0797836 |
| _mean_adv       | 9.17e-18  |
| _mean_discrew   | 0.965     |
| _mean_obs       | 0.00396   |
| _min_adv        | -4.74     |
| _min_discrew    | 0.0156    |
| _min_obs        | -27.4     |
| _std_act        | 0.417676  |
| _std_adv        | 1         |
| _std_discrew    | 0.303     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.912        |
| ExplainedVarOld | 0.77         |
| KL              | 0.00527242   |
| Phi_loss        | 111.261      |
| PolicyEntropy   | 15.336       |
| PolicyLoss      | -0.000435156 |
| Steps           | 10073        |
| VarFuncLoss     | 0.0267       |
| _MeanReward     | 405          |
| _lr_multiplier  | 1            |
| _max_act        | 3.04841      |
| _max_adv        | 4.5          |
| _max_discrew    | 3.04         |
| _max_obs        | 26.9         |
| _mean_act       | 0.0795911    |
| _mean_adv       | -2.82e-18    |
| _mean_discrew   | 0.948        |
| _mean_obs       | 0.00478      |
| _min_adv        | -4.55        |
| _min_discrew    | 0.0158       |
| _min_obs        | -18          |
| _std_act        | 0.416231     |
| _std_adv        | 1            |
| _std_discrew    | 0.292        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.926       |
| ExplainedVarOld | 0.764       |
| KL              | 0.00178589  |
| Phi_loss        | 109.694     |
| PolicyEntropy   | 15.3349     |
| PolicyLoss      | 0.000627338 |
| Steps           | 10064       |
| VarFuncLoss     | 0.0215      |
| _MeanReward     | 416         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16989     |
| _max_adv        | 5.11        |
| _max_discrew    | 2.61        |
| _max_obs        | 29.5        |
| _mean_act       | 0.0813762   |
| _mean_adv       | 5.65e-18    |
| _mean_discrew   | 0.98        |
| _mean_obs       | 0.00469     |
| _min_adv        | -5.23       |
| _min_discrew    | 0.0164      |
| _min_obs        | -25.1       |
| _std_act        | 0.415821    |
| _std_adv        | 1           |
| _std_discrew    | 0.303       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.77       |
| KL              | 0.00152646 |
| Phi_loss        | 108.689    |
| PolicyEntropy   | 15.3358    |
| PolicyLoss      | -0.0035309 |
| Steps           | 10019      |
| VarFuncLoss     | 0.0264     |
| _MeanReward     | 404        |
| _lr_multiplier  | 1          |
| _max_act        | 4.0938     |
| _max_adv        | 4.65       |
| _max_discrew    | 2.38       |
| _max_obs        | 34.6       |
| _mean_act       | 0.0748551  |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 0.943      |
| _mean_obs       | 0.00386    |
| _min_adv        | -5.83      |
| _min_discrew    | 0.0162     |
| _min_obs        | -25.1      |
| _std_act        | 0.41662    |
| _std_adv        | 1          |
| _std_discrew    | 0.266      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.929       |
| ExplainedVarOld | 0.827       |
| KL              | 0.00159811  |
| Phi_loss        | 108.079     |
| PolicyEntropy   | 15.3367     |
| PolicyLoss      | -0.00330276 |
| Steps           | 10019       |
| VarFuncLoss     | 0.0188      |
| _MeanReward     | 405         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13623     |
| _max_adv        | 5.4         |
| _max_discrew    | 2.9         |
| _max_obs        | 27          |
| _mean_act       | 0.0774219   |
| _mean_adv       | -8.51e-18   |
| _mean_discrew   | 0.952       |
| _mean_obs       | 0.00364     |
| _min_adv        | -6.28       |
| _min_discrew    | 0.0159      |
| _min_obs        | -35         |
| _std_act        | 0.421592    |
| _std_adv        | 1           |
| _std_discrew    | 0.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.918        |
| ExplainedVarOld | 0.785        |
| KL              | 0.00176497   |
| Phi_loss        | 114.493      |
| PolicyEntropy   | 15.3371      |
| PolicyLoss      | -0.000220951 |
| Steps           | 10078        |
| VarFuncLoss     | 0.0237       |
| _MeanReward     | 419          |
| _lr_multiplier  | 1            |
| _max_act        | 3.19726      |
| _max_adv        | 5.08         |
| _max_discrew    | 2.74         |
| _max_obs        | 22.9         |
| _mean_act       | 0.0767237    |
| _mean_adv       | 0            |
| _mean_discrew   | 0.985        |
| _mean_obs       | 0.00422      |
| _min_adv        | -5.2         |
| _min_discrew    | -0.000425    |
| _min_obs        | -24.4        |
| _std_act        | 0.420279     |
| _std_adv        | 1            |
| _std_discrew    | 0.31         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.782       |
| KL              | 0.00186027  |
| Phi_loss        | 107.325     |
| PolicyEntropy   | 15.3387     |
| PolicyLoss      | -0.00398854 |
| Steps           | 10015       |
| VarFuncLoss     | 0.0227      |
| _MeanReward     | 408         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0369      |
| _max_adv        | 4.47        |
| _max_discrew    | 2.68        |
| _max_obs        | 27          |
| _mean_act       | 0.0781709   |
| _mean_adv       | -8.51e-18   |
| _mean_discrew   | 0.966       |
| _mean_obs       | 0.00416     |
| _min_adv        | -5.51       |
| _min_discrew    | 0.0129      |
| _min_obs        | -20.6       |
| _std_act        | 0.420621    |
| _std_adv        | 1           |
| _std_discrew    | 0.302       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.763      |
| KL              | 0.00190459 |
| Phi_loss        | 107.085    |
| PolicyEntropy   | 15.3383    |
| PolicyLoss      | 0.00267846 |
| Steps           | 10035      |
| VarFuncLoss     | 0.0234     |
| _MeanReward     | 423        |
| _lr_multiplier  | 1          |
| _max_act        | 3.3284     |
| _max_adv        | 5.43       |
| _max_discrew    | 2.92       |
| _max_obs        | 32.8       |
| _mean_act       | 0.077814   |
| _mean_adv       | -1.13e-17  |
| _mean_discrew   | 0.995      |
| _mean_obs       | 0.00454    |
| _min_adv        | -5.85      |
| _min_discrew    | 0.0175     |
| _min_obs        | -30.2      |
| _std_act        | 0.422394   |
| _std_adv        | 1          |
| _std_discrew    | 0.322      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.92         |
| ExplainedVarOld | 0.761        |
| KL              | 0.00169524   |
| Phi_loss        | 107.011      |
| PolicyEntropy   | 15.338       |
| PolicyLoss      | -0.000308876 |
| Steps           | 10060        |
| VarFuncLoss     | 0.0256       |
| _MeanReward     | 424          |
| _lr_multiplier  | 1            |
| _max_act        | 3.253        |
| _max_adv        | 4.65         |
| _max_discrew    | 2.96         |
| _max_obs        | 25.8         |
| _mean_act       | 0.0767741    |
| _mean_adv       | 2.83e-18     |
| _mean_discrew   | 0.991        |
| _mean_obs       | 0.0044       |
| _min_adv        | -5.82        |
| _min_discrew    | 0.0145       |
| _min_obs        | -18.7        |
| _std_act        | 0.418036     |
| _std_adv        | 1            |
| _std_discrew    | 0.314        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.919        |
| ExplainedVarOld | 0.767        |
| KL              | 0.00173446   |
| Phi_loss        | 110.406      |
| PolicyEntropy   | 15.3371      |
| PolicyLoss      | -0.000690021 |
| Steps           | 10041        |
| VarFuncLoss     | 0.0253       |
| _MeanReward     | 398          |
| _lr_multiplier  | 1            |
| _max_act        | 3.53829      |
| _max_adv        | 4.8          |
| _max_discrew    | 2.51         |
| _max_obs        | 34.3         |
| _mean_act       | 0.0812333    |
| _mean_adv       | -1.13e-17    |
| _mean_discrew   | 0.925        |
| _mean_obs       | 0.00445      |
| _min_adv        | -5.46        |
| _min_discrew    | 0.015        |
| _min_obs        | -29.7        |
| _std_act        | 0.422344     |
| _std_adv        | 1            |
| _std_discrew    | 0.272        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.776      |
| KL              | 0.00139879 |
| Phi_loss        | 108.501    |
| PolicyEntropy   | 15.3363    |
| PolicyLoss      | 0.00081086 |
| Steps           | 10098      |
| VarFuncLoss     | 0.0233     |
| _MeanReward     | 415        |
| _lr_multiplier  | 1          |
| _max_act        | 2.85914    |
| _max_adv        | 4.51       |
| _max_discrew    | 2.55       |
| _max_obs        | 29.1       |
| _mean_act       | 0.0795336  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.975      |
| _mean_obs       | 0.005      |
| _min_adv        | -6.71      |
| _min_discrew    | 0.00522    |
| _min_obs        | -27.6      |
| _std_act        | 0.418463   |
| _std_adv        | 1          |
| _std_discrew    | 0.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.784      |
| KL              | 0.00703752 |
| Phi_loss        | 108.987    |
| PolicyEntropy   | 15.3359    |
| PolicyLoss      | 0.0145851  |
| Steps           | 10096      |
| VarFuncLoss     | 0.0236     |
| _MeanReward     | 413        |
| _lr_multiplier  | 1          |
| _max_act        | 2.93235    |
| _max_adv        | 3.86       |
| _max_discrew    | 2.46       |
| _max_obs        | 32.3       |
| _mean_act       | 0.081945   |
| _mean_adv       | -3.52e-18  |
| _mean_discrew   | 0.951      |
| _mean_obs       | 0.00385    |
| _min_adv        | -5.62      |
| _min_discrew    | 0.0141     |
| _min_obs        | -30.5      |
| _std_act        | 0.419806   |
| _std_adv        | 1          |
| _std_discrew    | 0.283      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.924        |
| ExplainedVarOld | 0.815        |
| KL              | 0.00284826   |
| Phi_loss        | 110.242      |
| PolicyEntropy   | 15.3343      |
| PolicyLoss      | -0.000978741 |
| Steps           | 10073        |
| VarFuncLoss     | 0.0215       |
| _MeanReward     | 420          |
| _lr_multiplier  | 1            |
| _max_act        | 3.18743      |
| _max_adv        | 4.11         |
| _max_discrew    | 2.52         |
| _max_obs        | 34.1         |
| _mean_act       | 0.0845587    |
| _mean_adv       | 1.13e-17     |
| _mean_discrew   | 0.983        |
| _mean_obs       | 0.00494      |
| _min_adv        | -5.64        |
| _min_discrew    | 0.0161       |
| _min_obs        | -31.5        |
| _std_act        | 0.417739     |
| _std_adv        | 1            |
| _std_discrew    | 0.307        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.922        |
| ExplainedVarOld | 0.802        |
| KL              | 0.0016572    |
| Phi_loss        | 118.125      |
| PolicyEntropy   | 15.3336      |
| PolicyLoss      | -0.000155767 |
| Steps           | 10011        |
| VarFuncLoss     | 0.0243       |
| _MeanReward     | 406          |
| _lr_multiplier  | 1            |
| _max_act        | 3.19857      |
| _max_adv        | 4.86         |
| _max_discrew    | 2.65         |
| _max_obs        | 22.1         |
| _mean_act       | 0.0787857    |
| _mean_adv       | 2.84e-18     |
| _mean_discrew   | 0.947        |
| _mean_obs       | 0.00415      |
| _min_adv        | -6.04        |
| _min_discrew    | 0.0154       |
| _min_obs        | -20.9        |
| _std_act        | 0.420737     |
| _std_adv        | 1            |
| _std_discrew    | 0.287        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
