Logging to halfcheetah_unbiased_144
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
-----------------------------
| Steps         | 10000     |
| _MeanReward   | -375      |
| _max_act      | 2.6737    |
| _max_adv      | 3.46      |
| _max_discrew  | 0.101     |
| _max_obs      | 1.94      |
| _mean_act     | 0.0125817 |
| _mean_adv     | 5.68e-18  |
| _mean_discrew | -0.303    |
| _mean_obs     | 0.0355    |
| _min_adv      | -3.4      |
| _min_discrew  | -0.688    |
| _min_obs      | -1.29     |
| _std_act      | 0.428904  |
| _std_adv      | 1         |
| _std_discrew  | 0.0222    |
-----------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.243       |
| ExplainedVarOld | -1.61       |
| KL              | 0.000200374 |
| Phi_loss        | 3.42129     |
| PolicyEntropy   | 5.5106      |
| PolicyLoss      | 0.00255571  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0168      |
| _MeanReward     | -376        |
| _lr_multiplier  | 1           |
| _max_act        | 2.73247     |
| _max_adv        | 3.82        |
| _max_discrew    | 0.0444      |
| _max_obs        | 1.23        |
| _mean_act       | 0.0214822   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | -0.293      |
| _mean_obs       | 0.0332      |
| _min_adv        | -3.21       |
| _min_discrew    | -0.694      |
| _min_obs        | -1.37       |
| _std_act        | 0.422906    |
| _std_adv        | 1           |
| _std_discrew    | 0.0181      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.497        |
| ExplainedVarOld | 0.306        |
| KL              | 0.000913091  |
| Phi_loss        | 17.6108      |
| PolicyEntropy   | 5.50182      |
| PolicyLoss      | 0.00747428   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00913      |
| _MeanReward     | -359         |
| _lr_multiplier  | 1            |
| _max_act        | 2.79358      |
| _max_adv        | 3.89         |
| _max_discrew    | 0.028        |
| _max_obs        | 1.31         |
| _mean_act       | -4.82599e-05 |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | -0.285       |
| _mean_obs       | 0.0253       |
| _min_adv        | -3.43        |
| _min_discrew    | -0.697       |
| _min_obs        | -1.32        |
| _std_act        | 0.418201     |
| _std_adv        | 1            |
| _std_discrew    | 0.0178       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.386      |
| ExplainedVarOld | 0.343      |
| KL              | 0.0015871  |
| Phi_loss        | 21.3338    |
| PolicyEntropy   | 5.49589    |
| PolicyLoss      | 0.00402332 |
| Steps           | 10000      |
| VarFuncLoss     | 0.011      |
| _MeanReward     | -310       |
| _lr_multiplier  | 1          |
| _max_act        | 3.10687    |
| _max_adv        | 3.84       |
| _max_discrew    | 0.145      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0112839 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.252     |
| _mean_obs       | 0.0251     |
| _min_adv        | -3.13      |
| _min_discrew    | -0.565     |
| _min_obs        | -1.62      |
| _std_act        | 0.41992    |
| _std_adv        | 1          |
| _std_discrew    | 0.0149     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.404       |
| ExplainedVarOld | 0.307       |
| KL              | 0.00129466  |
| Phi_loss        | 19.0064     |
| PolicyEntropy   | 5.49114     |
| PolicyLoss      | 0.000972138 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00904     |
| _MeanReward     | -339        |
| _lr_multiplier  | 1           |
| _max_act        | 2.90431     |
| _max_adv        | 5.48        |
| _max_discrew    | 0.0643      |
| _max_obs        | 1.82        |
| _mean_act       | 0.00269334  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | -0.277      |
| _mean_obs       | 0.0345      |
| _min_adv        | -3.59       |
| _min_discrew    | -0.605      |
| _min_obs        | -1.4        |
| _std_act        | 0.426754    |
| _std_adv        | 1           |
| _std_discrew    | 0.0173      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.48       |
| ExplainedVarOld | 0.424      |
| KL              | 0.00396215 |
| Phi_loss        | 17.2349    |
| PolicyEntropy   | 5.47663    |
| PolicyLoss      | 0.00529677 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00902    |
| _MeanReward     | -288       |
| _lr_multiplier  | 1          |
| _max_act        | 3.03065    |
| _max_adv        | 3.96       |
| _max_discrew    | 0.0688     |
| _max_obs        | 1.2        |
| _mean_act       | 0.00220049 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | -0.249     |
| _mean_obs       | 0.0285     |
| _min_adv        | -3.66      |
| _min_discrew    | -0.606     |
| _min_obs        | -1.33      |
| _std_act        | 0.413847   |
| _std_adv        | 1          |
| _std_discrew    | 0.0154     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.312       |
| ExplainedVarOld | 0.188       |
| KL              | 0.00454003  |
| Phi_loss        | 18.023      |
| PolicyEntropy   | 5.47452     |
| PolicyLoss      | 0.000954759 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0108      |
| _MeanReward     | -290        |
| _lr_multiplier  | 1           |
| _max_act        | 2.63915     |
| _max_adv        | 4.14        |
| _max_discrew    | 0.1         |
| _max_obs        | 1.37        |
| _mean_act       | -0.0037839  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.244      |
| _mean_obs       | 0.0275      |
| _min_adv        | -3.86       |
| _min_discrew    | -0.549      |
| _min_obs        | -1.35       |
| _std_act        | 0.413797    |
| _std_adv        | 1           |
| _std_discrew    | 0.0134      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.468      |
| ExplainedVarOld | 0.436      |
| KL              | 0.00227732 |
| Phi_loss        | 19.6856    |
| PolicyEntropy   | 5.45875    |
| PolicyLoss      | 0.00420052 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00715    |
| _MeanReward     | -265       |
| _lr_multiplier  | 1          |
| _max_act        | 2.63453    |
| _max_adv        | 4.23       |
| _max_discrew    | 0.0299     |
| _max_obs        | 1.39       |
| _mean_act       | -0.005292  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.225     |
| _mean_obs       | 0.0323     |
| _min_adv        | -4.09      |
| _min_discrew    | -0.505     |
| _min_obs        | -1.35      |
| _std_act        | 0.415283   |
| _std_adv        | 1          |
| _std_discrew    | 0.00978    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.461      |
| ExplainedVarOld | 0.418      |
| KL              | 0.00296537 |
| Phi_loss        | 17.3039    |
| PolicyEntropy   | 5.4474     |
| PolicyLoss      | 0.00640656 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0055     |
| _MeanReward     | -263       |
| _lr_multiplier  | 1          |
| _max_act        | 2.60687    |
| _max_adv        | 3.87       |
| _max_discrew    | 0.0542     |
| _max_obs        | 1.36       |
| _mean_act       | -0.0116437 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.223     |
| _mean_obs       | 0.0274     |
| _min_adv        | -3.7       |
| _min_discrew    | -0.553     |
| _min_obs        | -1.28      |
| _std_act        | 0.416456   |
| _std_adv        | 1          |
| _std_discrew    | 0.0122     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.264        |
| ExplainedVarOld | 0.17         |
| KL              | 0.00281181   |
| Phi_loss        | 17.9139      |
| PolicyEntropy   | 5.43357      |
| PolicyLoss      | -0.000781868 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00901      |
| _MeanReward     | -217         |
| _lr_multiplier  | 1            |
| _max_act        | 2.9973       |
| _max_adv        | 4.12         |
| _max_discrew    | 0.171        |
| _max_obs        | 1.37         |
| _mean_act       | -0.0109148   |
| _mean_adv       | 3.13e-17     |
| _mean_discrew   | -0.178       |
| _mean_obs       | 0.0284       |
| _min_adv        | -4.1         |
| _min_discrew    | -0.424       |
| _min_obs        | -1.37        |
| _std_act        | 0.412098     |
| _std_adv        | 1            |
| _std_discrew    | 0.0117       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.399       |
| ExplainedVarOld | 0.299       |
| KL              | 0.00300969  |
| Phi_loss        | 18.5045     |
| PolicyEntropy   | 5.43028     |
| PolicyLoss      | 0.00217966  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00756     |
| _MeanReward     | -268        |
| _lr_multiplier  | 1           |
| _max_act        | 2.84326     |
| _max_adv        | 4.08        |
| _max_discrew    | 0.0461      |
| _max_obs        | 1.39        |
| _mean_act       | -0.00145252 |
| _mean_adv       | 0           |
| _mean_discrew   | -0.217      |
| _mean_obs       | 0.0301      |
| _min_adv        | -4.24       |
| _min_discrew    | -0.451      |
| _min_obs        | -1.45       |
| _std_act        | 0.413821    |
| _std_adv        | 1           |
| _std_discrew    | 0.00976     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.514      |
| ExplainedVarOld | 0.455      |
| KL              | 0.00301718 |
| Phi_loss        | 16.1589    |
| PolicyEntropy   | 5.42669    |
| PolicyLoss      | 0.00465906 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00498    |
| _MeanReward     | -258       |
| _lr_multiplier  | 1          |
| _max_act        | 2.86262    |
| _max_adv        | 4.25       |
| _max_discrew    | 0.136      |
| _max_obs        | 1.36       |
| _mean_act       | 0.016349   |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | -0.226     |
| _mean_obs       | 0.0336     |
| _min_adv        | -5.37      |
| _min_discrew    | -0.454     |
| _min_obs        | -1.39      |
| _std_act        | 0.408606   |
| _std_adv        | 1          |
| _std_discrew    | 0.0127     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.523      |
| ExplainedVarOld | 0.496      |
| KL              | 0.00438525 |
| Phi_loss        | 15.9788    |
| PolicyEntropy   | 5.39733    |
| PolicyLoss      | 0.00713638 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00612    |
| _MeanReward     | -235       |
| _lr_multiplier  | 1          |
| _max_act        | 2.88395    |
| _max_adv        | 4.18       |
| _max_discrew    | 0.0324     |
| _max_obs        | 1.3        |
| _mean_act       | 0.00867814 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | -0.211     |
| _mean_obs       | 0.0353     |
| _min_adv        | -5.12      |
| _min_discrew    | -0.416     |
| _min_obs        | -1.24      |
| _std_act        | 0.403977   |
| _std_adv        | 1          |
| _std_discrew    | 0.00844    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.697      |
| ExplainedVarOld | 0.654      |
| KL              | 0.0035289  |
| Phi_loss        | 15.4006    |
| PolicyEntropy   | 5.37767    |
| PolicyLoss      | 0.00254842 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00266    |
| _MeanReward     | -215       |
| _lr_multiplier  | 1          |
| _max_act        | 2.79939    |
| _max_adv        | 4.05       |
| _max_discrew    | 0.136      |
| _max_obs        | 1.43       |
| _mean_act       | 0.00189669 |
| _mean_adv       | -7.11e-18  |
| _mean_discrew   | -0.185     |
| _mean_obs       | 0.0328     |
| _min_adv        | -4.65      |
| _min_discrew    | -0.503     |
| _min_obs        | -1.34      |
| _std_act        | 0.405833   |
| _std_adv        | 1          |
| _std_discrew    | 0.0125     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.504       |
| ExplainedVarOld | 0.402       |
| KL              | 0.00463772  |
| Phi_loss        | 16.3981     |
| PolicyEntropy   | 5.35398     |
| PolicyLoss      | 0.00874751  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0062      |
| _MeanReward     | -190        |
| _lr_multiplier  | 1           |
| _max_act        | 2.72301     |
| _max_adv        | 4.85        |
| _max_discrew    | 0.175       |
| _max_obs        | 1.36        |
| _mean_act       | -0.00127697 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.175      |
| _mean_obs       | 0.0332      |
| _min_adv        | -3.55       |
| _min_discrew    | -0.406      |
| _min_obs        | -1.52       |
| _std_act        | 0.405426    |
| _std_adv        | 1           |
| _std_discrew    | 0.0118      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.446      |
| ExplainedVarOld | 0.439      |
| KL              | 0.00355282 |
| Phi_loss        | 17.9842    |
| PolicyEntropy   | 5.32922    |
| PolicyLoss      | 0.00235839 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00663    |
| _MeanReward     | -223       |
| _lr_multiplier  | 1          |
| _max_act        | 2.58365    |
| _max_adv        | 4.11       |
| _max_discrew    | 0.187      |
| _max_obs        | 1.37       |
| _mean_act       | 0.00581965 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | -0.199     |
| _mean_obs       | 0.0278     |
| _min_adv        | -6.64      |
| _min_discrew    | -0.465     |
| _min_obs        | -1.46      |
| _std_act        | 0.411456   |
| _std_adv        | 1          |
| _std_discrew    | 0.0134     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.519       |
| ExplainedVarOld | 0.0514      |
| KL              | 0.00521153  |
| Phi_loss        | 14.6007     |
| PolicyEntropy   | 5.31223     |
| PolicyLoss      | 0.00411117  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00659     |
| _MeanReward     | -194        |
| _lr_multiplier  | 1           |
| _max_act        | 3.08654     |
| _max_adv        | 4.79        |
| _max_discrew    | 0.176       |
| _max_obs        | 1.31        |
| _mean_act       | -0.00532403 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | -0.174      |
| _mean_obs       | 0.0299      |
| _min_adv        | -4.06       |
| _min_discrew    | -0.465      |
| _min_obs        | -1.4        |
| _std_act        | 0.405842    |
| _std_adv        | 1           |
| _std_discrew    | 0.0124      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.416       |
| ExplainedVarOld | 0.368       |
| KL              | 0.00293232  |
| Phi_loss        | 17.9339     |
| PolicyEntropy   | 5.30991     |
| PolicyLoss      | -0.00551514 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00728     |
| _MeanReward     | -202        |
| _lr_multiplier  | 1           |
| _max_act        | 2.43434     |
| _max_adv        | 4.73        |
| _max_discrew    | 0.199       |
| _max_obs        | 1.51        |
| _mean_act       | 0.00394663  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | -0.18       |
| _mean_obs       | 0.0324      |
| _min_adv        | -4.38       |
| _min_discrew    | -0.398      |
| _min_obs        | -1.29       |
| _std_act        | 0.406018    |
| _std_adv        | 1           |
| _std_discrew    | 0.0127      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.563      |
| ExplainedVarOld | 0.509      |
| KL              | 0.00265773 |
| Phi_loss        | 17.423     |
| PolicyEntropy   | 5.27318    |
| PolicyLoss      | 0.0109654  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00561    |
| _MeanReward     | -158       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75265    |
| _max_adv        | 4.47       |
| _max_discrew    | 0.123      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0128486 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | -0.142     |
| _mean_obs       | 0.0305     |
| _min_adv        | -4.24      |
| _min_discrew    | -0.391     |
| _min_obs        | -1.48      |
| _std_act        | 0.400845   |
| _std_adv        | 1          |
| _std_discrew    | 0.011      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.468       |
| ExplainedVarOld | 0.447       |
| KL              | 0.00361359  |
| Phi_loss        | 18.8517     |
| PolicyEntropy   | 5.24656     |
| PolicyLoss      | 0.00401467  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00589     |
| _MeanReward     | -207        |
| _lr_multiplier  | 1           |
| _max_act        | 2.71711     |
| _max_adv        | 5.23        |
| _max_discrew    | 0.196       |
| _max_obs        | 1.31        |
| _mean_act       | -0.00267341 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.183      |
| _mean_obs       | 0.0336      |
| _min_adv        | -4.59       |
| _min_discrew    | -0.379      |
| _min_obs        | -1.3        |
| _std_act        | 0.398951    |
| _std_adv        | 1           |
| _std_discrew    | 0.00889     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.531       |
| ExplainedVarOld | 0.49        |
| KL              | 0.00404471  |
| Phi_loss        | 16.4629     |
| PolicyEntropy   | 5.25826     |
| PolicyLoss      | 0.000633324 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00427     |
| _MeanReward     | -166        |
| _lr_multiplier  | 1           |
| _max_act        | 2.93731     |
| _max_adv        | 5.2         |
| _max_discrew    | 0.326       |
| _max_obs        | 1.54        |
| _mean_act       | -0.0010272  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | -0.151      |
| _mean_obs       | 0.0329      |
| _min_adv        | -4.35       |
| _min_discrew    | -0.364      |
| _min_obs        | -1.35       |
| _std_act        | 0.399008    |
| _std_adv        | 1           |
| _std_discrew    | 0.0146      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.719       |
| ExplainedVarOld | 0.642       |
| KL              | 0.00318659  |
| Phi_loss        | 15.1357     |
| PolicyEntropy   | 5.26876     |
| PolicyLoss      | -0.00446515 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00432     |
| _MeanReward     | -182        |
| _lr_multiplier  | 1           |
| _max_act        | 2.63528     |
| _max_adv        | 4.66        |
| _max_discrew    | 0.222       |
| _max_obs        | 1.51        |
| _mean_act       | -0.00902483 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | -0.16       |
| _mean_obs       | 0.032       |
| _min_adv        | -4.75       |
| _min_discrew    | -0.465      |
| _min_obs        | -1.37       |
| _std_act        | 0.40244     |
| _std_adv        | 1           |
| _std_discrew    | 0.014       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.597      |
| ExplainedVarOld | 0.58       |
| KL              | 0.00409633 |
| Phi_loss        | 17.2383    |
| PolicyEntropy   | 5.24124    |
| PolicyLoss      | 0.00925359 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00574    |
| _MeanReward     | -207       |
| _lr_multiplier  | 1          |
| _max_act        | 2.75493    |
| _max_adv        | 4.57       |
| _max_discrew    | 0.15       |
| _max_obs        | 1.34       |
| _mean_act       | 0.0054671  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | -0.184     |
| _mean_obs       | 0.0331     |
| _min_adv        | -6.13      |
| _min_discrew    | -0.433     |
| _min_obs        | -1.59      |
| _std_act        | 0.397937   |
| _std_adv        | 1          |
| _std_discrew    | 0.00805    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.554      |
| ExplainedVarOld | 0.426      |
| KL              | 0.00351558 |
| Phi_loss        | 16.6617    |
| PolicyEntropy   | 5.20153    |
| PolicyLoss      | 0.00609254 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0036     |
| _MeanReward     | -148       |
| _lr_multiplier  | 1          |
| _max_act        | 2.83808    |
| _max_adv        | 5.83       |
| _max_discrew    | 0.213      |
| _max_obs        | 1.39       |
| _mean_act       | -0.0220606 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | -0.131     |
| _mean_obs       | 0.0312     |
| _min_adv        | -4.2       |
| _min_discrew    | -0.358     |
| _min_obs        | -1.42      |
| _std_act        | 0.405033   |
| _std_adv        | 1          |
| _std_discrew    | 0.0121     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.64        |
| ExplainedVarOld | 0.6         |
| KL              | 0.00489905  |
| Phi_loss        | 21.3748     |
| PolicyEntropy   | 5.21276     |
| PolicyLoss      | -0.00620101 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00444     |
| _MeanReward     | -133        |
| _lr_multiplier  | 1           |
| _max_act        | 2.78419     |
| _max_adv        | 4.13        |
| _max_discrew    | 0.142       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0200358  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.121      |
| _mean_obs       | 0.03        |
| _min_adv        | -4.71       |
| _min_discrew    | -0.31       |
| _min_obs        | -1.33       |
| _std_act        | 0.401185    |
| _std_adv        | 1           |
| _std_discrew    | 0.0105      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.671      |
| ExplainedVarOld | 0.638      |
| KL              | 0.00317657 |
| Phi_loss        | 22.0149    |
| PolicyEntropy   | 5.19183    |
| PolicyLoss      | 0.00563182 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00347    |
| _MeanReward     | -136       |
| _lr_multiplier  | 1          |
| _max_act        | 2.65105    |
| _max_adv        | 4.58       |
| _max_discrew    | 0.265      |
| _max_obs        | 1.34       |
| _mean_act       | -0.019958  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | -0.126     |
| _mean_obs       | 0.0309     |
| _min_adv        | -4.54      |
| _min_discrew    | -0.381     |
| _min_obs        | -1.38      |
| _std_act        | 0.401079   |
| _std_adv        | 1          |
| _std_discrew    | 0.0132     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.635      |
| ExplainedVarOld | 0.566      |
| KL              | 0.00273842 |
| Phi_loss        | 19.0634    |
| PolicyEntropy   | 5.17408    |
| PolicyLoss      | 0.00386223 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00484    |
| _MeanReward     | -62.8      |
| _lr_multiplier  | 1          |
| _max_act        | 2.61299    |
| _max_adv        | 3.76       |
| _max_discrew    | 0.276      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0365536 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.0648    |
| _mean_obs       | 0.0257     |
| _min_adv        | -3.27      |
| _min_discrew    | -0.342     |
| _min_obs        | -1.53      |
| _std_act        | 0.404338   |
| _std_adv        | 1          |
| _std_discrew    | 0.0153     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.398      |
| ExplainedVarOld | 0.347      |
| KL              | 0.00269139 |
| Phi_loss        | 22.3405    |
| PolicyEntropy   | 5.16141    |
| PolicyLoss      | 0.00384478 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00935    |
| _MeanReward     | -62.1      |
| _lr_multiplier  | 1          |
| _max_act        | 2.67516    |
| _max_adv        | 4.15       |
| _max_discrew    | 0.272      |
| _max_obs        | 1.54       |
| _mean_act       | -0.037283  |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | -0.0608    |
| _mean_obs       | 0.0271     |
| _min_adv        | -4.95      |
| _min_discrew    | -0.31      |
| _min_obs        | -1.51      |
| _std_act        | 0.401959   |
| _std_adv        | 1          |
| _std_discrew    | 0.0136     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.492        |
| ExplainedVarOld | 0.42         |
| KL              | 0.0030386    |
| Phi_loss        | 22.5981      |
| PolicyEntropy   | 5.158        |
| PolicyLoss      | -0.000719579 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00704      |
| _MeanReward     | -59          |
| _lr_multiplier  | 1            |
| _max_act        | 2.53276      |
| _max_adv        | 3.99         |
| _max_discrew    | 0.397        |
| _max_obs        | 1.58         |
| _mean_act       | -0.0356176   |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | -0.0437      |
| _mean_obs       | 0.0258       |
| _min_adv        | -4.25        |
| _min_discrew    | -0.41        |
| _min_obs        | -1.5         |
| _std_act        | 0.407026     |
| _std_adv        | 1            |
| _std_discrew    | 0.0175       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.345      |
| ExplainedVarOld | 0.332      |
| KL              | 0.00340026 |
| Phi_loss        | 22.3112    |
| PolicyEntropy   | 5.13714    |
| PolicyLoss      | 0.00803103 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0115     |
| _MeanReward     | -103       |
| _lr_multiplier  | 1          |
| _max_act        | 2.73805    |
| _max_adv        | 4.38       |
| _max_discrew    | 0.23       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0247549 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | -0.111     |
| _mean_obs       | 0.0307     |
| _min_adv        | -4.25      |
| _min_discrew    | -0.33      |
| _min_obs        | -1.5       |
| _std_act        | 0.40034    |
| _std_adv        | 1          |
| _std_discrew    | 0.0113     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.542        |
| ExplainedVarOld | 0.46         |
| KL              | 0.00280766   |
| Phi_loss        | 18.41        |
| PolicyEntropy   | 5.13601      |
| PolicyLoss      | -7.72442e-05 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00536      |
| _MeanReward     | -63.6        |
| _lr_multiplier  | 1            |
| _max_act        | 2.6841       |
| _max_adv        | 4.58         |
| _max_discrew    | 0.403        |
| _max_obs        | 1.45         |
| _mean_act       | -0.0205194   |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | -0.0635      |
| _mean_obs       | 0.0289       |
| _min_adv        | -4.23        |
| _min_discrew    | -0.31        |
| _min_obs        | -1.49        |
| _std_act        | 0.398696     |
| _std_adv        | 1            |
| _std_discrew    | 0.0197       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.573      |
| ExplainedVarOld | 0.572      |
| KL              | 0.00364698 |
| Phi_loss        | 22.6423    |
| PolicyEntropy   | 5.11879    |
| PolicyLoss      | 0.00510677 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00871    |
| _MeanReward     | -25.4      |
| _lr_multiplier  | 1          |
| _max_act        | 2.69077    |
| _max_adv        | 4.46       |
| _max_discrew    | 0.354      |
| _max_obs        | 1.41       |
| _mean_act       | -0.040244  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | -0.0323    |
| _mean_obs       | 0.0257     |
| _min_adv        | -4.29      |
| _min_discrew    | -0.359     |
| _min_obs        | -1.35      |
| _std_act        | 0.402124   |
| _std_adv        | 1          |
| _std_discrew    | 0.0204     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.355      |
| ExplainedVarOld | 0.317      |
| KL              | 0.00276185 |
| Phi_loss        | 23.8407    |
| PolicyEntropy   | 5.08857    |
| PolicyLoss      | 0.00445776 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 12.1       |
| _lr_multiplier  | 1          |
| _max_act        | 2.55037    |
| _max_adv        | 4.41       |
| _max_discrew    | 0.323      |
| _max_obs        | 1.33       |
| _mean_act       | -0.0371091 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.00331    |
| _mean_obs       | 0.0294     |
| _min_adv        | -4.11      |
| _min_discrew    | -0.275     |
| _min_obs        | -1.38      |
| _std_act        | 0.402733   |
| _std_adv        | 1          |
| _std_discrew    | 0.0137     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.446       |
| ExplainedVarOld | 0.433       |
| KL              | 0.00284458  |
| Phi_loss        | 24.8943     |
| PolicyEntropy   | 5.06862     |
| PolicyLoss      | 0.000931713 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00794     |
| _MeanReward     | -33         |
| _lr_multiplier  | 1           |
| _max_act        | 2.42153     |
| _max_adv        | 3.9         |
| _max_discrew    | 0.354       |
| _max_obs        | 1.37        |
| _mean_act       | -0.0401097  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | -0.0422     |
| _mean_obs       | 0.0278      |
| _min_adv        | -3.98       |
| _min_discrew    | -0.31       |
| _min_obs        | -1.79       |
| _std_act        | 0.401727    |
| _std_adv        | 1           |
| _std_discrew    | 0.0185      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.545      |
| ExplainedVarOld | 0.484      |
| KL              | 0.00341776 |
| Phi_loss        | 23.1987    |
| PolicyEntropy   | 5.05165    |
| PolicyLoss      | 0.00112671 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00876    |
| _MeanReward     | 41.4       |
| _lr_multiplier  | 1          |
| _max_act        | 2.40324    |
| _max_adv        | 4.85       |
| _max_discrew    | 0.488      |
| _max_obs        | 1.3        |
| _mean_act       | -0.0399391 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.0218     |
| _mean_obs       | 0.0252     |
| _min_adv        | -3.99      |
| _min_discrew    | -0.321     |
| _min_obs        | -1.56      |
| _std_act        | 0.398894   |
| _std_adv        | 1          |
| _std_discrew    | 0.0267     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.578      |
| ExplainedVarOld | 0.552      |
| KL              | 0.0036033  |
| Phi_loss        | 23.7326    |
| PolicyEntropy   | 5.02184    |
| PolicyLoss      | 0.00523843 |
| Steps           | 10000      |
| VarFuncLoss     | 0.012      |
| _MeanReward     | 86         |
| _lr_multiplier  | 1          |
| _max_act        | 3.09598    |
| _max_adv        | 4.41       |
| _max_discrew    | 0.49       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0524285 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.0717     |
| _mean_obs       | 0.0206     |
| _min_adv        | -3.82      |
| _min_discrew    | -0.255     |
| _min_obs        | -1.37      |
| _std_act        | 0.411837   |
| _std_adv        | 1          |
| _std_discrew    | 0.0218     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.431       |
| ExplainedVarOld | 0.391       |
| KL              | 0.00284463  |
| Phi_loss        | 28.8786     |
| PolicyEntropy   | 5.00444     |
| PolicyLoss      | -0.00215441 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0124      |
| _MeanReward     | 78.4        |
| _lr_multiplier  | 1           |
| _max_act        | 2.62292     |
| _max_adv        | 3.85        |
| _max_discrew    | 0.464       |
| _max_obs        | 1.46        |
| _mean_act       | -0.0343936  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.042       |
| _mean_obs       | 0.0256      |
| _min_adv        | -3.64       |
| _min_discrew    | -0.315      |
| _min_obs        | -1.74       |
| _std_act        | 0.398014    |
| _std_adv        | 1           |
| _std_discrew    | 0.0312      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.673      |
| ExplainedVarOld | 0.639      |
| KL              | 0.00298764 |
| Phi_loss        | 27.6124    |
| PolicyEntropy   | 4.98164    |
| PolicyLoss      | 0.00146385 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0104     |
| _MeanReward     | 16.9       |
| _lr_multiplier  | 1          |
| _max_act        | 2.5532     |
| _max_adv        | 4.26       |
| _max_discrew    | 0.329      |
| _max_obs        | 1.54       |
| _mean_act       | -0.0478083 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.00521   |
| _mean_obs       | 0.0239     |
| _min_adv        | -4.2       |
| _min_discrew    | -0.296     |
| _min_obs        | -1.44      |
| _std_act        | 0.403586   |
| _std_adv        | 1          |
| _std_discrew    | 0.017      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.47       |
| ExplainedVarOld | 0.424      |
| KL              | 0.00327426 |
| Phi_loss        | 29.2376    |
| PolicyEntropy   | 4.94053    |
| PolicyLoss      | 0.00880049 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00951    |
| _MeanReward     | 37.2       |
| _lr_multiplier  | 1          |
| _max_act        | 2.45838    |
| _max_adv        | 3.94       |
| _max_discrew    | 0.421      |
| _max_obs        | 1.45       |
| _mean_act       | -0.057378  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.0184     |
| _mean_obs       | 0.0249     |
| _min_adv        | -4.41      |
| _min_discrew    | -0.273     |
| _min_obs        | -1.33      |
| _std_act        | 0.397968   |
| _std_adv        | 1          |
| _std_discrew    | 0.0205     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.461       |
| ExplainedVarOld | 0.404       |
| KL              | 0.00247219  |
| Phi_loss        | 28.8293     |
| PolicyEntropy   | 4.93366     |
| PolicyLoss      | 0.000988943 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0111      |
| _MeanReward     | 109         |
| _lr_multiplier  | 1           |
| _max_act        | 2.58786     |
| _max_adv        | 4.18        |
| _max_discrew    | 0.567       |
| _max_obs        | 1.5         |
| _mean_act       | -0.0580059  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.0848      |
| _mean_obs       | 0.0236      |
| _min_adv        | -3.78       |
| _min_discrew    | -0.235      |
| _min_obs        | -1.36       |
| _std_act        | 0.401438    |
| _std_adv        | 1           |
| _std_discrew    | 0.0211      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.29        |
| ExplainedVarOld | 0.253       |
| KL              | 0.00305952  |
| Phi_loss        | 29.0256     |
| PolicyEntropy   | 4.90989     |
| PolicyLoss      | -0.00208663 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0155      |
| _MeanReward     | 86.5        |
| _lr_multiplier  | 1           |
| _max_act        | 2.86621     |
| _max_adv        | 4.28        |
| _max_discrew    | 0.589       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0537291  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.051       |
| _mean_obs       | 0.0241      |
| _min_adv        | -3.84       |
| _min_discrew    | -0.246      |
| _min_obs        | -1.48       |
| _std_act        | 0.407453    |
| _std_adv        | 1           |
| _std_discrew    | 0.0185      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.482       |
| ExplainedVarOld | 0.446       |
| KL              | 0.00304886  |
| Phi_loss        | 29.6953     |
| PolicyEntropy   | 4.91553     |
| PolicyLoss      | -0.00341586 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00983     |
| _MeanReward     | 197         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95328     |
| _max_adv        | 4.56        |
| _max_discrew    | 0.662       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0635902  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.151       |
| _mean_obs       | 0.0193      |
| _min_adv        | -3.41       |
| _min_discrew    | -0.174      |
| _min_obs        | -1.23       |
| _std_act        | 0.410435    |
| _std_adv        | 1           |
| _std_discrew    | 0.0267      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.467      |
| ExplainedVarOld | 0.423      |
| KL              | 0.00309404 |
| Phi_loss        | 32.4702    |
| PolicyEntropy   | 4.89172    |
| PolicyLoss      | 0.0010352  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0155     |
| _MeanReward     | 111        |
| _lr_multiplier  | 1          |
| _max_act        | 3.04816    |
| _max_adv        | 4.37       |
| _max_discrew    | 0.515      |
| _max_obs        | 1.47       |
| _mean_act       | -0.0482696 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.0734     |
| _mean_obs       | 0.0256     |
| _min_adv        | -6.08      |
| _min_discrew    | -0.32      |
| _min_obs        | -1.37      |
| _std_act        | 0.410768   |
| _std_adv        | 1          |
| _std_discrew    | 0.0273     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.596      |
| ExplainedVarOld | 0.565      |
| KL              | 0.0026578  |
| Phi_loss        | 32.3008    |
| PolicyEntropy   | 4.86252    |
| PolicyLoss      | 0.00380743 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 191        |
| _lr_multiplier  | 1          |
| _max_act        | 2.61281    |
| _max_adv        | 3.3        |
| _max_discrew    | 0.552      |
| _max_obs        | 1.42       |
| _mean_act       | -0.0600423 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.137      |
| _mean_obs       | 0.0222     |
| _min_adv        | -4.54      |
| _min_discrew    | -0.301     |
| _min_obs        | -1.41      |
| _std_act        | 0.40549    |
| _std_adv        | 1          |
| _std_discrew    | 0.0315     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.546      |
| ExplainedVarOld | 0.535      |
| KL              | 0.00334544 |
| Phi_loss        | 33.71      |
| PolicyEntropy   | 4.83644    |
| PolicyLoss      | 0.0042045  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0145     |
| _MeanReward     | 132        |
| _lr_multiplier  | 1          |
| _max_act        | 2.55312    |
| _max_adv        | 3.57       |
| _max_discrew    | 0.548      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0573178 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.0908     |
| _mean_obs       | 0.0233     |
| _min_adv        | -3.86      |
| _min_discrew    | -0.199     |
| _min_obs        | -1.37      |
| _std_act        | 0.399458   |
| _std_adv        | 1          |
| _std_discrew    | 0.0208     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.367        |
| ExplainedVarOld | 0.356        |
| KL              | 0.00334124   |
| Phi_loss        | 33.785       |
| PolicyEntropy   | 4.82263      |
| PolicyLoss      | -0.000582738 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0136       |
| _MeanReward     | 220          |
| _lr_multiplier  | 1            |
| _max_act        | 2.5758       |
| _max_adv        | 3.49         |
| _max_discrew    | 0.515        |
| _max_obs        | 1.34         |
| _mean_act       | -0.0668069   |
| _mean_adv       | 0            |
| _mean_discrew   | 0.172        |
| _mean_obs       | 0.0197       |
| _min_adv        | -4.63        |
| _min_discrew    | -0.16        |
| _min_obs        | -1.4         |
| _std_act        | 0.403879     |
| _std_adv        | 1            |
| _std_discrew    | 0.0194       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.372      |
| ExplainedVarOld | 0.366      |
| KL              | 0.00269529 |
| Phi_loss        | 35.3075    |
| PolicyEntropy   | 4.79216    |
| PolicyLoss      | 0.00393075 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 203        |
| _lr_multiplier  | 1          |
| _max_act        | 2.44077    |
| _max_adv        | 3.57       |
| _max_discrew    | 0.693      |
| _max_obs        | 1.62       |
| _mean_act       | -0.0497193 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.149      |
| _mean_obs       | 0.0256     |
| _min_adv        | -5.62      |
| _min_discrew    | -0.28      |
| _min_obs        | -1.31      |
| _std_act        | 0.406154   |
| _std_adv        | 1          |
| _std_discrew    | 0.0506     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.66        |
| ExplainedVarOld | 0.598       |
| KL              | 0.00538194  |
| Phi_loss        | 29.9419     |
| PolicyEntropy   | 4.78775     |
| PolicyLoss      | -0.00414844 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0174      |
| _MeanReward     | 235         |
| _lr_multiplier  | 1           |
| _max_act        | 2.6186      |
| _max_adv        | 3.7         |
| _max_discrew    | 0.677       |
| _max_obs        | 1.48        |
| _mean_act       | -0.0663744  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.163       |
| _mean_obs       | 0.0233      |
| _min_adv        | -5          |
| _min_discrew    | -0.177      |
| _min_obs        | -1.34       |
| _std_act        | 0.407481    |
| _std_adv        | 1           |
| _std_discrew    | 0.0337      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.614      |
| ExplainedVarOld | 0.548      |
| KL              | 0.00272381 |
| Phi_loss        | 34.2131    |
| PolicyEntropy   | 4.75983    |
| PolicyLoss      | 0.00143264 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 213        |
| _lr_multiplier  | 1          |
| _max_act        | 2.81534    |
| _max_adv        | 3.38       |
| _max_discrew    | 0.511      |
| _max_obs        | 1.35       |
| _mean_act       | -0.0755001 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.161      |
| _mean_obs       | 0.0208     |
| _min_adv        | -4.57      |
| _min_discrew    | -0.271     |
| _min_obs        | -1.29      |
| _std_act        | 0.405707   |
| _std_adv        | 1          |
| _std_discrew    | 0.0278     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.428       |
| ExplainedVarOld | 0.367       |
| KL              | 0.00365989  |
| Phi_loss        | 36.3294     |
| PolicyEntropy   | 4.7682      |
| PolicyLoss      | -0.00966895 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0159      |
| _MeanReward     | 304         |
| _lr_multiplier  | 1           |
| _max_act        | 2.79707     |
| _max_adv        | 3.36        |
| _max_discrew    | 0.795       |
| _max_obs        | 1.4         |
| _mean_act       | -0.0705642  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.252       |
| _mean_obs       | 0.02        |
| _min_adv        | -4.49       |
| _min_discrew    | -0.19       |
| _min_obs        | -1.47       |
| _std_act        | 0.412374    |
| _std_adv        | 1           |
| _std_discrew    | 0.0433      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.501       |
| ExplainedVarOld | 0.443       |
| KL              | 0.00285939  |
| Phi_loss        | 35.2397     |
| PolicyEntropy   | 4.7633      |
| PolicyLoss      | -0.00346519 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0226      |
| _MeanReward     | 321         |
| _lr_multiplier  | 1           |
| _max_act        | 2.76042     |
| _max_adv        | 4.23        |
| _max_discrew    | 0.709       |
| _max_obs        | 1.54        |
| _mean_act       | -0.0677008  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.249       |
| _mean_obs       | 0.0218      |
| _min_adv        | -4.28       |
| _min_discrew    | -0.159      |
| _min_obs        | -1.3        |
| _std_act        | 0.414498    |
| _std_adv        | 1           |
| _std_discrew    | 0.0329      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.655      |
| ExplainedVarOld | 0.601      |
| KL              | 0.00321559 |
| Phi_loss        | 36.3699    |
| PolicyEntropy   | 4.73773    |
| PolicyLoss      | -0.0035681 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 228        |
| _lr_multiplier  | 1          |
| _max_act        | 2.9193     |
| _max_adv        | 3.25       |
| _max_discrew    | 0.646      |
| _max_obs        | 1.51       |
| _mean_act       | -0.0473658 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.17       |
| _mean_obs       | 0.0278     |
| _min_adv        | -6.37      |
| _min_discrew    | -0.309     |
| _min_obs        | -1.66      |
| _std_act        | 0.422764   |
| _std_adv        | 1          |
| _std_discrew    | 0.0506     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.629      |
| ExplainedVarOld | 0.586      |
| KL              | 0.00673915 |
| Phi_loss        | 37.874     |
| PolicyEntropy   | 4.72285    |
| PolicyLoss      | -0.016883  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0188     |
| _MeanReward     | 301        |
| _lr_multiplier  | 1          |
| _max_act        | 2.94122    |
| _max_adv        | 4.59       |
| _max_discrew    | 0.801      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0416065 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.228      |
| _mean_obs       | 0.0257     |
| _min_adv        | -6.59      |
| _min_discrew    | -0.368     |
| _min_obs        | -1.32      |
| _std_act        | 0.428504   |
| _std_adv        | 1          |
| _std_discrew    | 0.0611     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.692       |
| ExplainedVarOld | 0.682       |
| KL              | 0.00129458  |
| Phi_loss        | 42.1728     |
| PolicyEntropy   | 4.71244     |
| PolicyLoss      | -0.00191689 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0192      |
| _MeanReward     | 319         |
| _lr_multiplier  | 1           |
| _max_act        | 2.66849     |
| _max_adv        | 3.92        |
| _max_discrew    | 0.793       |
| _max_obs        | 1.32        |
| _mean_act       | -0.0539951  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.261       |
| _mean_obs       | 0.0222      |
| _min_adv        | -6.33       |
| _min_discrew    | -0.348      |
| _min_obs        | -1.4        |
| _std_act        | 0.431453    |
| _std_adv        | 1           |
| _std_discrew    | 0.0514      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.747      |
| ExplainedVarOld | 0.727      |
| KL              | 0.00234039 |
| Phi_loss        | 36.6271    |
| PolicyEntropy   | 4.71542    |
| PolicyLoss      | -0.0014002 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 239        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0385     |
| _max_adv        | 4.03       |
| _max_discrew    | 0.76       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0347799 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.171      |
| _mean_obs       | 0.0273     |
| _min_adv        | -6.58      |
| _min_discrew    | -0.34      |
| _min_obs        | -1.29      |
| _std_act        | 0.441074   |
| _std_adv        | 1          |
| _std_discrew    | 0.062      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.725       |
| ExplainedVarOld | 0.716       |
| KL              | 0.00297669  |
| Phi_loss        | 37.6854     |
| PolicyEntropy   | 4.72973     |
| PolicyLoss      | -0.00778858 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0178      |
| _MeanReward     | 378         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14315     |
| _max_adv        | 4.62        |
| _max_discrew    | 0.678       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0729481  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.29        |
| _mean_obs       | 0.0219      |
| _min_adv        | -5.25       |
| _min_discrew    | -0.206      |
| _min_obs        | -1.36       |
| _std_act        | 0.427474    |
| _std_adv        | 1           |
| _std_discrew    | 0.0405      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.602      |
| ExplainedVarOld | 0.577      |
| KL              | 0.00309234 |
| Phi_loss        | 42.8105    |
| PolicyEntropy   | 4.71263    |
| PolicyLoss      | 0.00282523 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0168     |
| _MeanReward     | 376        |
| _lr_multiplier  | 1          |
| _max_act        | 2.90898    |
| _max_adv        | 3.84       |
| _max_discrew    | 0.675      |
| _max_obs        | 1.26       |
| _mean_act       | -0.0746276 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.304      |
| _mean_obs       | 0.021      |
| _min_adv        | -5.11      |
| _min_discrew    | -0.183     |
| _min_obs        | -1.45      |
| _std_act        | 0.428882   |
| _std_adv        | 1          |
| _std_discrew    | 0.0353     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.534       |
| ExplainedVarOld | 0.518       |
| KL              | 0.00323587  |
| Phi_loss        | 40.8836     |
| PolicyEntropy   | 4.69244     |
| PolicyLoss      | -0.00611525 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0165      |
| _MeanReward     | 418         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04973     |
| _max_adv        | 4.1         |
| _max_discrew    | 0.857       |
| _max_obs        | 1.37        |
| _mean_act       | -0.0661208  |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 0.332       |
| _mean_obs       | 0.0231      |
| _min_adv        | -4.51       |
| _min_discrew    | -0.158      |
| _min_obs        | -1.47       |
| _std_act        | 0.428686    |
| _std_adv        | 1           |
| _std_discrew    | 0.045       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.607      |
| ExplainedVarOld | 0.595      |
| KL              | 0.00270475 |
| Phi_loss        | 40.5148    |
| PolicyEntropy   | 4.68967    |
| PolicyLoss      | -0.0074715 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0179     |
| _MeanReward     | 422        |
| _lr_multiplier  | 1          |
| _max_act        | 2.93537    |
| _max_adv        | 4.47       |
| _max_discrew    | 0.801      |
| _max_obs        | 1.7        |
| _mean_act       | -0.068714  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.346      |
| _mean_obs       | 0.0225     |
| _min_adv        | -5.15      |
| _min_discrew    | -0.15      |
| _min_obs        | -1.38      |
| _std_act        | 0.43716    |
| _std_adv        | 1          |
| _std_discrew    | 0.0513     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.511       |
| ExplainedVarOld | 0.495       |
| KL              | 0.00234275  |
| Phi_loss        | 39.1215     |
| PolicyEntropy   | 4.69001     |
| PolicyLoss      | 0.000474206 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0251      |
| _MeanReward     | 431         |
| _lr_multiplier  | 1           |
| _max_act        | 2.80222     |
| _max_adv        | 3.96        |
| _max_discrew    | 0.953       |
| _max_obs        | 1.4         |
| _mean_act       | -0.0577285  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.333       |
| _mean_obs       | 0.0244      |
| _min_adv        | -6.46       |
| _min_discrew    | -0.318      |
| _min_obs        | -1.51       |
| _std_act        | 0.450318    |
| _std_adv        | 1           |
| _std_discrew    | 0.0584      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.666      |
| ExplainedVarOld | 0.662      |
| KL              | 0.00743851 |
| Phi_loss        | 39.9198    |
| PolicyEntropy   | 4.68481    |
| PolicyLoss      | 0.00289186 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 473        |
| _lr_multiplier  | 1          |
| _max_act        | 2.9423     |
| _max_adv        | 4.52       |
| _max_discrew    | 0.858      |
| _max_obs        | 1.49       |
| _mean_act       | -0.0673152 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.369      |
| _mean_obs       | 0.0231     |
| _min_adv        | -5.21      |
| _min_discrew    | -0.192     |
| _min_obs        | -1.64      |
| _std_act        | 0.431962   |
| _std_adv        | 1          |
| _std_discrew    | 0.0539     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.736       |
| ExplainedVarOld | 0.701       |
| KL              | 0.00109219  |
| Phi_loss        | 42.5286     |
| PolicyEntropy   | 4.68039     |
| PolicyLoss      | -0.00284397 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0143      |
| _MeanReward     | 436         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87542     |
| _max_adv        | 4.2         |
| _max_discrew    | 0.854       |
| _max_obs        | 1.5         |
| _mean_act       | -0.0651372  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.348       |
| _mean_obs       | 0.0237      |
| _min_adv        | -4.66       |
| _min_discrew    | -0.192      |
| _min_obs        | -1.31       |
| _std_act        | 0.438075    |
| _std_adv        | 1           |
| _std_discrew    | 0.0519      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.61       |
| ExplainedVarOld | 0.583      |
| KL              | 0.00276879 |
| Phi_loss        | 42.7681    |
| PolicyEntropy   | 4.65927    |
| PolicyLoss      | 0.00115448 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0203     |
| _MeanReward     | 469        |
| _lr_multiplier  | 1          |
| _max_act        | 2.73507    |
| _max_adv        | 5.01       |
| _max_discrew    | 0.857      |
| _max_obs        | 1.6        |
| _mean_act       | -0.0659017 |
| _mean_adv       | 7.11e-19   |
| _mean_discrew   | 0.37       |
| _mean_obs       | 0.0231     |
| _min_adv        | -4.89      |
| _min_discrew    | -0.152     |
| _min_obs        | -1.62      |
| _std_act        | 0.442099   |
| _std_adv        | 1          |
| _std_discrew    | 0.0563     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.73        |
| ExplainedVarOld | 0.719       |
| KL              | 0.00363423  |
| Phi_loss        | 43.8828     |
| PolicyEntropy   | 4.6415      |
| PolicyLoss      | -0.00172112 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0153      |
| _MeanReward     | 395         |
| _lr_multiplier  | 1           |
| _max_act        | 2.82337     |
| _max_adv        | 4.27        |
| _max_discrew    | 0.857       |
| _max_obs        | 1.41        |
| _mean_act       | -0.0458865  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.311       |
| _mean_obs       | 0.0262      |
| _min_adv        | -6.99       |
| _min_discrew    | -0.325      |
| _min_obs        | -1.43       |
| _std_act        | 0.460247    |
| _std_adv        | 1           |
| _std_discrew    | 0.068       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.703       |
| ExplainedVarOld | 0.682       |
| KL              | 0.00616534  |
| Phi_loss        | 44.4098     |
| PolicyEntropy   | 4.6348      |
| PolicyLoss      | -0.00615264 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0202      |
| _MeanReward     | 384         |
| _lr_multiplier  | 1           |
| _max_act        | 2.8886      |
| _max_adv        | 3.35        |
| _max_discrew    | 0.912       |
| _max_obs        | 1.31        |
| _mean_act       | -0.0272266  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.285       |
| _mean_obs       | 0.0295      |
| _min_adv        | -7.52       |
| _min_discrew    | -0.394      |
| _min_obs        | -1.38       |
| _std_act        | 0.47715     |
| _std_adv        | 1           |
| _std_discrew    | 0.108       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.808       |
| ExplainedVarOld | 0.791       |
| KL              | 0.00120938  |
| Phi_loss        | 42.6126     |
| PolicyEntropy   | 4.62684     |
| PolicyLoss      | -0.00206288 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0208      |
| _MeanReward     | 539         |
| _lr_multiplier  | 1           |
| _max_act        | 3.23767     |
| _max_adv        | 3.9         |
| _max_discrew    | 0.969       |
| _max_obs        | 1.49        |
| _mean_act       | -0.0637526  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.416       |
| _mean_obs       | 0.0228      |
| _min_adv        | -5.55       |
| _min_discrew    | -0.0705     |
| _min_obs        | -1.51       |
| _std_act        | 0.451772    |
| _std_adv        | 1           |
| _std_discrew    | 0.048       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.614       |
| ExplainedVarOld | 0.592       |
| KL              | 0.0035446   |
| Phi_loss        | 43.1715     |
| PolicyEntropy   | 4.61161     |
| PolicyLoss      | -0.00611797 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0186      |
| _MeanReward     | 545         |
| _lr_multiplier  | 1           |
| _max_act        | 3.53114     |
| _max_adv        | 4.84        |
| _max_discrew    | 0.884       |
| _max_obs        | 1.44        |
| _mean_act       | -0.059943   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.434       |
| _mean_obs       | 0.025       |
| _min_adv        | -4.95       |
| _min_discrew    | -0.0964     |
| _min_obs        | -1.39       |
| _std_act        | 0.457643    |
| _std_adv        | 1           |
| _std_discrew    | 0.0428      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.618       |
| ExplainedVarOld | 0.578       |
| KL              | 0.00285938  |
| Phi_loss        | 42.647      |
| PolicyEntropy   | 4.5992      |
| PolicyLoss      | -0.00227539 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0165      |
| _MeanReward     | 601         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86743     |
| _max_adv        | 4.17        |
| _max_discrew    | 0.997       |
| _max_obs        | 1.35        |
| _mean_act       | -0.0590721  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.485       |
| _mean_obs       | 0.0246      |
| _min_adv        | -4.36       |
| _min_discrew    | -0.118      |
| _min_obs        | -1.46       |
| _std_act        | 0.456982    |
| _std_adv        | 1           |
| _std_discrew    | 0.0596      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.701        |
| ExplainedVarOld | 0.671        |
| KL              | 0.00288478   |
| Phi_loss        | 47.2597      |
| PolicyEntropy   | 4.5788       |
| PolicyLoss      | -0.000431933 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0182       |
| _MeanReward     | 526          |
| _lr_multiplier  | 1            |
| _max_act        | 2.76448      |
| _max_adv        | 2.76         |
| _max_discrew    | 0.955        |
| _max_obs        | 1.39         |
| _mean_act       | -0.0412932   |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 0.411        |
| _mean_obs       | 0.0289       |
| _min_adv        | -6.66        |
| _min_discrew    | -0.383       |
| _min_obs        | -1.31        |
| _std_act        | 0.475587     |
| _std_adv        | 1            |
| _std_discrew    | 0.0985       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.702       |
| ExplainedVarOld | 0.697       |
| KL              | 0.0036706   |
| Phi_loss        | 43.8842     |
| PolicyEntropy   | 4.55402     |
| PolicyLoss      | -0.00357426 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0293      |
| _MeanReward     | 519         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93681     |
| _max_adv        | 3.94        |
| _max_discrew    | 0.983       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0450788  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.416       |
| _mean_obs       | 0.0282      |
| _min_adv        | -8.66       |
| _min_discrew    | -0.394      |
| _min_obs        | -1.36       |
| _std_act        | 0.483733    |
| _std_adv        | 1           |
| _std_discrew    | 0.116       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.801      |
| ExplainedVarOld | 0.793      |
| KL              | 0.00321579 |
| Phi_loss        | 43.7148    |
| PolicyEntropy   | 4.51675    |
| PolicyLoss      | 0.00510265 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 583        |
| _lr_multiplier  | 1          |
| _max_act        | 2.93249    |
| _max_adv        | 4.89       |
| _max_discrew    | 1.17       |
| _max_obs        | 1.4        |
| _mean_act       | -0.058112  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.46       |
| _mean_obs       | 0.0277     |
| _min_adv        | -4.8       |
| _min_discrew    | -0.127     |
| _min_obs        | -1.44      |
| _std_act        | 0.461192   |
| _std_adv        | 1          |
| _std_discrew    | 0.0701     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.58       |
| ExplainedVarOld | 0.56       |
| KL              | 0.00243737 |
| Phi_loss        | 48.272     |
| PolicyEntropy   | 4.4866     |
| PolicyLoss      | 0.00602598 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0295     |
| _MeanReward     | 573        |
| _lr_multiplier  | 1          |
| _max_act        | 3.10976    |
| _max_adv        | 4.1        |
| _max_discrew    | 1          |
| _max_obs        | 1.29       |
| _mean_act       | -0.051947  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.458      |
| _mean_obs       | 0.0265     |
| _min_adv        | -8.25      |
| _min_discrew    | -0.359     |
| _min_obs        | -1.47      |
| _std_act        | 0.470903   |
| _std_adv        | 1          |
| _std_discrew    | 0.0636     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.666       |
| ExplainedVarOld | 0.655       |
| KL              | 0.00341323  |
| Phi_loss        | 48.8841     |
| PolicyEntropy   | 4.48217     |
| PolicyLoss      | -0.00786467 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0212      |
| _MeanReward     | 704         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16538     |
| _max_adv        | 3.41        |
| _max_discrew    | 1.08        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0494414  |
| _mean_adv       | 9.95e-18    |
| _mean_discrew   | 0.563       |
| _mean_obs       | 0.0275      |
| _min_adv        | -4.56       |
| _min_discrew    | -0.136      |
| _min_obs        | -1.44       |
| _std_act        | 0.466713    |
| _std_adv        | 1           |
| _std_discrew    | 0.0548      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.733      |
| ExplainedVarOld | 0.716      |
| KL              | 0.00300082 |
| Phi_loss        | 49.3936    |
| PolicyEntropy   | 4.46508    |
| PolicyLoss      | 0.00036424 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0158     |
| _MeanReward     | 600        |
| _lr_multiplier  | 1          |
| _max_act        | 3.09075    |
| _max_adv        | 3.5        |
| _max_discrew    | 0.961      |
| _max_obs        | 1.48       |
| _mean_act       | -0.0485057 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.482      |
| _mean_obs       | 0.0288     |
| _min_adv        | -6.87      |
| _min_discrew    | -0.38      |
| _min_obs        | -1.58      |
| _std_act        | 0.48241    |
| _std_adv        | 1          |
| _std_discrew    | 0.0853     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.741      |
| ExplainedVarOld | 0.729      |
| KL              | 0.00272719 |
| Phi_loss        | 45.2504    |
| PolicyEntropy   | 4.45985    |
| PolicyLoss      | 0.00363055 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0224     |
| _MeanReward     | 666        |
| _lr_multiplier  | 1          |
| _max_act        | 3.05272    |
| _max_adv        | 4.06       |
| _max_discrew    | 0.995      |
| _max_obs        | 1.4        |
| _mean_act       | -0.0556994 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.552      |
| _mean_obs       | 0.0258     |
| _min_adv        | -5.37      |
| _min_discrew    | -0.138     |
| _min_obs        | -1.46      |
| _std_act        | 0.466604   |
| _std_adv        | 1          |
| _std_discrew    | 0.0576     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.692      |
| ExplainedVarOld | 0.674      |
| KL              | 0.00325737 |
| Phi_loss        | 47.8318    |
| PolicyEntropy   | 4.44814    |
| PolicyLoss      | 0.0013777  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0178     |
| _MeanReward     | 561        |
| _lr_multiplier  | 1          |
| _max_act        | 2.78945    |
| _max_adv        | 3.98       |
| _max_discrew    | 1.03       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0347442 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.434      |
| _mean_obs       | 0.0296     |
| _min_adv        | -8.49      |
| _min_discrew    | -0.423     |
| _min_obs        | -1.59      |
| _std_act        | 0.497295   |
| _std_adv        | 1          |
| _std_discrew    | 0.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.774       |
| ExplainedVarOld | 0.766       |
| KL              | 0.00428253  |
| Phi_loss        | 47.5442     |
| PolicyEntropy   | 4.42351     |
| PolicyLoss      | -0.00593079 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0275      |
| _MeanReward     | 678         |
| _lr_multiplier  | 1           |
| _max_act        | 3.43668     |
| _max_adv        | 5.46        |
| _max_discrew    | 1.01        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0545475  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.562       |
| _mean_obs       | 0.027       |
| _min_adv        | -4.91       |
| _min_discrew    | -0.0835     |
| _min_obs        | -1.5        |
| _std_act        | 0.46393     |
| _std_adv        | 1           |
| _std_discrew    | 0.0482      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.691      |
| ExplainedVarOld | 0.654      |
| KL              | 0.00271653 |
| Phi_loss        | 44.9658    |
| PolicyEntropy   | 4.42623    |
| PolicyLoss      | -0.0116538 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0152     |
| _MeanReward     | 700        |
| _lr_multiplier  | 1          |
| _max_act        | 2.73847    |
| _max_adv        | 3.19       |
| _max_discrew    | 1.07       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0548084 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.562      |
| _mean_obs       | 0.0277     |
| _min_adv        | -4.81      |
| _min_discrew    | -0.0946    |
| _min_obs        | -1.57      |
| _std_act        | 0.475964   |
| _std_adv        | 1          |
| _std_discrew    | 0.0818     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.633       |
| ExplainedVarOld | 0.574       |
| KL              | 0.00379628  |
| Phi_loss        | 45.0371     |
| PolicyEntropy   | 4.40291     |
| PolicyLoss      | -0.00885615 |
| Steps           | 10000       |
| VarFuncLoss     | 0.03        |
| _MeanReward     | 672         |
| _lr_multiplier  | 1           |
| _max_act        | 3.00521     |
| _max_adv        | 4.6         |
| _max_discrew    | 1.07        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0376554  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.527       |
| _mean_obs       | 0.0307      |
| _min_adv        | -8.19       |
| _min_discrew    | -0.467      |
| _min_obs        | -1.61       |
| _std_act        | 0.504545    |
| _std_adv        | 1           |
| _std_discrew    | 0.143       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.795       |
| ExplainedVarOld | 0.769       |
| KL              | 0.0047897   |
| Phi_loss        | 42.2017     |
| PolicyEntropy   | 4.39728     |
| PolicyLoss      | -0.00533208 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0293      |
| _MeanReward     | 594         |
| _lr_multiplier  | 1           |
| _max_act        | 3.37323     |
| _max_adv        | 5.15        |
| _max_discrew    | 1.15        |
| _max_obs        | 1.44        |
| _mean_act       | -0.0429573  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.48        |
| _mean_obs       | 0.0284      |
| _min_adv        | -9.86       |
| _min_discrew    | -0.477      |
| _min_obs        | -1.51       |
| _std_act        | 0.511336    |
| _std_adv        | 1           |
| _std_discrew    | 0.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.808      |
| ExplainedVarOld | 0.802      |
| KL              | 0.00355012 |
| Phi_loss        | 51.328     |
| PolicyEntropy   | 4.377      |
| PolicyLoss      | 0.00090231 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 729        |
| _lr_multiplier  | 1          |
| _max_act        | 3.07931    |
| _max_adv        | 4.45       |
| _max_discrew    | 1.07       |
| _max_obs        | 1.49       |
| _mean_act       | -0.051227  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.586      |
| _mean_obs       | 0.0296     |
| _min_adv        | -5.1       |
| _min_discrew    | -0.0678    |
| _min_obs        | -1.5       |
| _std_act        | 0.47907    |
| _std_adv        | 1          |
| _std_discrew    | 0.067      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.674       |
| ExplainedVarOld | 0.667       |
| KL              | 0.00245682  |
| Phi_loss        | 53.8916     |
| PolicyEntropy   | 4.35723     |
| PolicyLoss      | 0.000462004 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0226      |
| _MeanReward     | 658         |
| _lr_multiplier  | 1           |
| _max_act        | 2.89388     |
| _max_adv        | 4.51        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0534384  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.505       |
| _mean_obs       | 0.0306      |
| _min_adv        | -5.13       |
| _min_discrew    | -0.159      |
| _min_obs        | -1.53       |
| _std_act        | 0.484247    |
| _std_adv        | 1           |
| _std_discrew    | 0.0787      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.702       |
| ExplainedVarOld | 0.686       |
| KL              | 0.00331708  |
| Phi_loss        | 55.0462     |
| PolicyEntropy   | 4.35156     |
| PolicyLoss      | -0.00333871 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0245      |
| _MeanReward     | 721         |
| _lr_multiplier  | 1           |
| _max_act        | 3.11249     |
| _max_adv        | 3.32        |
| _max_discrew    | 1.21        |
| _max_obs        | 1.32        |
| _mean_act       | -0.047351   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.577       |
| _mean_obs       | 0.0298      |
| _min_adv        | -8.46       |
| _min_discrew    | -0.442      |
| _min_obs        | -1.62       |
| _std_act        | 0.500934    |
| _std_adv        | 1           |
| _std_discrew    | 0.115       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.662       |
| ExplainedVarOld | 0.633       |
| KL              | 0.00265944  |
| Phi_loss        | 52.2723     |
| PolicyEntropy   | 4.33378     |
| PolicyLoss      | -0.00487026 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0402      |
| _MeanReward     | 796         |
| _lr_multiplier  | 1           |
| _max_act        | 3.26457     |
| _max_adv        | 4.18        |
| _max_discrew    | 1.17        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0569158  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.648       |
| _mean_obs       | 0.0277      |
| _min_adv        | -5.12       |
| _min_discrew    | -0.0438     |
| _min_obs        | -1.47       |
| _std_act        | 0.481339    |
| _std_adv        | 1           |
| _std_discrew    | 0.0721      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.729      |
| ExplainedVarOld | 0.715      |
| KL              | 0.00353187 |
| Phi_loss        | 53.2342    |
| PolicyEntropy   | 4.30694    |
| PolicyLoss      | -0.0102884 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0196     |
| _MeanReward     | 708        |
| _lr_multiplier  | 1          |
| _max_act        | 3.09123    |
| _max_adv        | 4.12       |
| _max_discrew    | 1.14       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0491028 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.551      |
| _mean_obs       | 0.0306     |
| _min_adv        | -8.88      |
| _min_discrew    | -0.514     |
| _min_obs        | -1.48      |
| _std_act        | 0.520206   |
| _std_adv        | 1          |
| _std_discrew    | 0.136      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.8         |
| ExplainedVarOld | 0.783       |
| KL              | 0.0045116   |
| Phi_loss        | 53.6592     |
| PolicyEntropy   | 4.29377     |
| PolicyLoss      | 0.000627218 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0273      |
| _MeanReward     | 860         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19115     |
| _max_adv        | 3.86        |
| _max_discrew    | 1.22        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0596003  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 0.689       |
| _mean_obs       | 0.0295      |
| _min_adv        | -5.26       |
| _min_discrew    | -0.129      |
| _min_obs        | -1.53       |
| _std_act        | 0.486408    |
| _std_adv        | 1           |
| _std_discrew    | 0.098       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.808      |
| ExplainedVarOld | 0.791      |
| KL              | 0.00248897 |
| Phi_loss        | 56.3101    |
| PolicyEntropy   | 4.26605    |
| PolicyLoss      | 0.00540197 |
| Steps           | 10000      |
| VarFuncLoss     | 0.02       |
| _MeanReward     | 816        |
| _lr_multiplier  | 1          |
| _max_act        | 2.85344    |
| _max_adv        | 5.27       |
| _max_discrew    | 1.2        |
| _max_obs        | 1.33       |
| _mean_act       | -0.0586448 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.663      |
| _mean_obs       | 0.0275     |
| _min_adv        | -5.81      |
| _min_discrew    | -0.0342    |
| _min_obs        | -1.33      |
| _std_act        | 0.485704   |
| _std_adv        | 1          |
| _std_discrew    | 0.0662     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.787      |
| ExplainedVarOld | 0.783      |
| KL              | 0.00260076 |
| Phi_loss        | 56.0696    |
| PolicyEntropy   | 4.23521    |
| PolicyLoss      | 0.00414009 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 782        |
| _lr_multiplier  | 1          |
| _max_act        | 3.20863    |
| _max_adv        | 3.84       |
| _max_discrew    | 1.26       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0545761 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.621      |
| _mean_obs       | 0.0305     |
| _min_adv        | -5.53      |
| _min_discrew    | -0.148     |
| _min_obs        | -1.61      |
| _std_act        | 0.480995   |
| _std_adv        | 1          |
| _std_discrew    | 0.0873     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.69        |
| ExplainedVarOld | 0.665       |
| KL              | 0.00219754  |
| Phi_loss        | 56.0722     |
| PolicyEntropy   | 4.23811     |
| PolicyLoss      | -0.00613608 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0272      |
| _MeanReward     | 879         |
| _lr_multiplier  | 1           |
| _max_act        | 3.23148     |
| _max_adv        | 3.29        |
| _max_discrew    | 1.18        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0623239  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.704       |
| _mean_obs       | 0.027       |
| _min_adv        | -6.71       |
| _min_discrew    | -0.00296    |
| _min_obs        | -1.4        |
| _std_act        | 0.486126    |
| _std_adv        | 1           |
| _std_discrew    | 0.0774      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.774      |
| ExplainedVarOld | 0.764      |
| KL              | 0.00275766 |
| Phi_loss        | 56.6587    |
| PolicyEntropy   | 4.21534    |
| PolicyLoss      | 0.00331844 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0179     |
| _MeanReward     | 829        |
| _lr_multiplier  | 1          |
| _max_act        | 3.14621    |
| _max_adv        | 5.31       |
| _max_discrew    | 1.22       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0571152 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.655      |
| _mean_obs       | 0.0289     |
| _min_adv        | -5.31      |
| _min_discrew    | -0.113     |
| _min_obs        | -1.33      |
| _std_act        | 0.485796   |
| _std_adv        | 1          |
| _std_discrew    | 0.0864     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.702      |
| ExplainedVarOld | 0.694      |
| KL              | 0.00231094 |
| Phi_loss        | 57.7521    |
| PolicyEntropy   | 4.19504    |
| PolicyLoss      | 0.00436417 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0258     |
| _MeanReward     | 847        |
| _lr_multiplier  | 1          |
| _max_act        | 2.92752    |
| _max_adv        | 3.52       |
| _max_discrew    | 1.14       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0574403 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.685      |
| _mean_obs       | 0.0288     |
| _min_adv        | -5.59      |
| _min_discrew    | -0.0731    |
| _min_obs        | -1.34      |
| _std_act        | 0.489005   |
| _std_adv        | 1          |
| _std_discrew    | 0.0747     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.745       |
| ExplainedVarOld | 0.737       |
| KL              | 0.00244026  |
| Phi_loss        | 58.282      |
| PolicyEntropy   | 4.17598     |
| PolicyLoss      | -0.00232707 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0191      |
| _MeanReward     | 792         |
| _lr_multiplier  | 1           |
| _max_act        | 3.21818     |
| _max_adv        | 3.65        |
| _max_discrew    | 1.19        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0498708  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 0.637       |
| _mean_obs       | 0.0288      |
| _min_adv        | -9.94       |
| _min_discrew    | -0.48       |
| _min_obs        | -1.32       |
| _std_act        | 0.517634    |
| _std_adv        | 1           |
| _std_discrew    | 0.156       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.847      |
| ExplainedVarOld | 0.834      |
| KL              | 0.00602093 |
| Phi_loss        | 57.7306    |
| PolicyEntropy   | 4.16764    |
| PolicyLoss      | -0.0146299 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0239     |
| _MeanReward     | 931        |
| _lr_multiplier  | 1          |
| _max_act        | 3.12262    |
| _max_adv        | 3.66       |
| _max_discrew    | 1.27       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0659598 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.761      |
| _mean_obs       | 0.0258     |
| _min_adv        | -4.34      |
| _min_discrew    | -0.0708    |
| _min_obs        | -1.37      |
| _std_act        | 0.480168   |
| _std_adv        | 1          |
| _std_discrew    | 0.101      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.82       |
| ExplainedVarOld | 0.769      |
| KL              | 0.00169043 |
| Phi_loss        | 52.3674    |
| PolicyEntropy   | 4.14005    |
| PolicyLoss      | 0.00331921 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0186     |
| _MeanReward     | 902        |
| _lr_multiplier  | 1          |
| _max_act        | 3.07241    |
| _max_adv        | 3.39       |
| _max_discrew    | 1.29       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0620669 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.725      |
| _mean_obs       | 0.0284     |
| _min_adv        | -5.1       |
| _min_discrew    | -0.00313   |
| _min_obs        | -1.53      |
| _std_act        | 0.483685   |
| _std_adv        | 1          |
| _std_discrew    | 0.0846     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.73        |
| ExplainedVarOld | 0.71        |
| KL              | 0.00162501  |
| Phi_loss        | 55.5207     |
| PolicyEntropy   | 4.12685     |
| PolicyLoss      | -0.00647145 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0229      |
| _MeanReward     | 959         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83444     |
| _max_adv        | 4.43        |
| _max_discrew    | 1.29        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0590237  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.787       |
| _mean_obs       | 0.0284      |
| _min_adv        | -6.16       |
| _min_discrew    | -0.0638     |
| _min_obs        | -1.36       |
| _std_act        | 0.487918    |
| _std_adv        | 1           |
| _std_discrew    | 0.0976      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.809      |
| ExplainedVarOld | 0.804      |
| KL              | 0.00163607 |
| Phi_loss        | 68.2527    |
| PolicyEntropy   | 4.09713    |
| PolicyLoss      | 0.00341895 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0193     |
| _MeanReward     | 977        |
| _lr_multiplier  | 1          |
| _max_act        | 2.91321    |
| _max_adv        | 5.28       |
| _max_discrew    | 1.31       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0581643 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 0.785      |
| _mean_obs       | 0.029      |
| _min_adv        | -5.49      |
| _min_discrew    | -0.0255    |
| _min_obs        | -1.57      |
| _std_act        | 0.481518   |
| _std_adv        | 1          |
| _std_discrew    | 0.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.791       |
| ExplainedVarOld | 0.782       |
| KL              | 0.00153258  |
| Phi_loss        | 65.6269     |
| PolicyEntropy   | 4.07023     |
| PolicyLoss      | -0.00148705 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0209      |
| _MeanReward     | 986         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16851     |
| _max_adv        | 4.85        |
| _max_discrew    | 1.33        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0588504  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.799       |
| _mean_obs       | 0.0287      |
| _min_adv        | -5.84       |
| _min_discrew    | -0.0371     |
| _min_obs        | -1.4        |
| _std_act        | 0.485646    |
| _std_adv        | 1           |
| _std_discrew    | 0.0989      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.83       |
| ExplainedVarOld | 0.816      |
| KL              | 0.001448   |
| Phi_loss        | 63.1162    |
| PolicyEntropy   | 4.07189    |
| PolicyLoss      | -0.0133921 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0168     |
| _MeanReward     | 962        |
| _lr_multiplier  | 1          |
| _max_act        | 3.06204    |
| _max_adv        | 3.46       |
| _max_discrew    | 1.37       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0598396 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 0.789      |
| _mean_obs       | 0.0291     |
| _min_adv        | -5.91      |
| _min_discrew    | -0.0701    |
| _min_obs        | -1.67      |
| _std_act        | 0.491844   |
| _std_adv        | 1          |
| _std_discrew    | 0.0915     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.783        |
| ExplainedVarOld | 0.761        |
| KL              | 0.00243081   |
| Phi_loss        | 66.5824      |
| PolicyEntropy   | 4.04401      |
| PolicyLoss      | -0.000324368 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0199       |
| _MeanReward     | 986          |
| _lr_multiplier  | 1            |
| _max_act        | 2.89282      |
| _max_adv        | 3.38         |
| _max_discrew    | 1.34         |
| _max_obs        | 1.32         |
| _mean_act       | -0.0603577   |
| _mean_adv       | 0            |
| _mean_discrew   | 0.801        |
| _mean_obs       | 0.0273       |
| _min_adv        | -5.32        |
| _min_discrew    | -0.00167     |
| _min_obs        | -1.39        |
| _std_act        | 0.485167     |
| _std_adv        | 1            |
| _std_discrew    | 0.0944       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.845       |
| ExplainedVarOld | 0.827       |
| KL              | 0.00325536  |
| Phi_loss        | 66.1636     |
| PolicyEntropy   | 4.01083     |
| PolicyLoss      | -0.00264098 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0148      |
| _MeanReward     | 1.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09429     |
| _max_adv        | 3.91        |
| _max_discrew    | 1.4         |
| _max_obs        | 1.25        |
| _mean_act       | -0.0565774  |
| _mean_adv       | 5.68e-17    |
| _mean_discrew   | 0.815       |
| _mean_obs       | 0.0291      |
| _min_adv        | -5.91       |
| _min_discrew    | -0.0541     |
| _min_obs        | -1.39       |
| _std_act        | 0.488618    |
| _std_adv        | 1           |
| _std_discrew    | 0.101       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.782       |
| ExplainedVarOld | 0.775       |
| KL              | 0.00265309  |
| Phi_loss        | 62.9348     |
| PolicyEntropy   | 3.9787      |
| PolicyLoss      | 0.000967448 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 1.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.49233     |
| _max_adv        | 4.06        |
| _max_discrew    | 1.49        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0580106  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.841       |
| _mean_obs       | 0.0297      |
| _min_adv        | -7.75       |
| _min_discrew    | -0.433      |
| _min_obs        | -1.38       |
| _std_act        | 0.507363    |
| _std_adv        | 1           |
| _std_discrew    | 0.137       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.8        |
| ExplainedVarOld | 0.781      |
| KL              | 0.00658131 |
| Phi_loss        | 74.8505    |
| PolicyEntropy   | 3.94943    |
| PolicyLoss      | -0.0307266 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0279     |
| _MeanReward     | 980        |
| _lr_multiplier  | 1          |
| _max_act        | 3.50949    |
| _max_adv        | 3.75       |
| _max_discrew    | 1.4        |
| _max_obs        | 1.5        |
| _mean_act       | -0.0517227 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.79       |
| _mean_obs       | 0.0307     |
| _min_adv        | -10.6      |
| _min_discrew    | -0.58      |
| _min_obs        | -1.29      |
| _std_act        | 0.520007   |
| _std_adv        | 1          |
| _std_discrew    | 0.156      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.781      |
| ExplainedVarOld | 0.774      |
| KL              | 0.00155156 |
| Phi_loss        | 67.0719    |
| PolicyEntropy   | 3.95078    |
| PolicyLoss      | -0.0139958 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0343     |
| _MeanReward     | 1.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92614    |
| _max_adv        | 4.26       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0575987 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 0.856      |
| _mean_obs       | 0.031      |
| _min_adv        | -6.37      |
| _min_discrew    | 4.79e-05   |
| _min_obs        | -1.37      |
| _std_act        | 0.500457   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.829      |
| ExplainedVarOld | 0.822      |
| KL              | 0.0013524  |
| Phi_loss        | 71.1908    |
| PolicyEntropy   | 3.93759    |
| PolicyLoss      | -0.0029623 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0192     |
| _MeanReward     | 1.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.91814    |
| _max_adv        | 5.64       |
| _max_discrew    | 1.48       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0613906 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.903      |
| _mean_obs       | 0.0287     |
| _min_adv        | -5.82      |
| _min_discrew    | -0.00244   |
| _min_obs        | -1.6       |
| _std_act        | 0.493389   |
| _std_adv        | 1          |
| _std_discrew    | 0.101      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.854      |
| ExplainedVarOld | 0.844      |
| KL              | 0.00249391 |
| Phi_loss        | 68.7382    |
| PolicyEntropy   | 3.92021    |
| PolicyLoss      | -0.007828  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0152     |
| _MeanReward     | 1.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83724    |
| _max_adv        | 5.35       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0563553 |
| _mean_adv       | 1.35e-17   |
| _mean_discrew   | 0.924      |
| _mean_obs       | 0.0308     |
| _min_adv        | -5.67      |
| _min_discrew    | -0.155     |
| _min_obs        | -1.43      |
| _std_act        | 0.497552   |
| _std_adv        | 1          |
| _std_discrew    | 0.149      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.847      |
| KL              | 0.0043841  |
| Phi_loss        | 65.1741    |
| PolicyEntropy   | 3.9198     |
| PolicyLoss      | -0.0162669 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 1.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.99341    |
| _max_adv        | 4.58       |
| _max_discrew    | 1.5        |
| _max_obs        | 1.36       |
| _mean_act       | -0.0600413 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.894      |
| _mean_obs       | 0.0303     |
| _min_adv        | -6.04      |
| _min_discrew    | -0.00353   |
| _min_obs        | -1.44      |
| _std_act        | 0.502241   |
| _std_adv        | 1          |
| _std_discrew    | 0.108      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.795       |
| ExplainedVarOld | 0.786       |
| KL              | 0.0028889   |
| Phi_loss        | 72.6501     |
| PolicyEntropy   | 3.88783     |
| PolicyLoss      | -0.00244237 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 1.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91082     |
| _max_adv        | 5.47        |
| _max_discrew    | 1.57        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0654978  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.924       |
| _mean_obs       | 0.0288      |
| _min_adv        | -6.89       |
| _min_discrew    | -0.0327     |
| _min_obs        | -1.39       |
| _std_act        | 0.502032    |
| _std_adv        | 1           |
| _std_discrew    | 0.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.874       |
| ExplainedVarOld | 0.868       |
| KL              | 0.00356447  |
| Phi_loss        | 76.2685     |
| PolicyEntropy   | 3.84826     |
| PolicyLoss      | 0.000968486 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0151      |
| _MeanReward     | 1.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.18319     |
| _max_adv        | 5.79        |
| _max_discrew    | 1.55        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0603684  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.923       |
| _mean_obs       | 0.0301      |
| _min_adv        | -6.34       |
| _min_discrew    | -0.000244   |
| _min_obs        | -1.38       |
| _std_act        | 0.502744    |
| _std_adv        | 1           |
| _std_discrew    | 0.094       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.854       |
| ExplainedVarOld | 0.833       |
| KL              | 0.00220486  |
| Phi_loss        | 72.0677     |
| PolicyEntropy   | 3.81405     |
| PolicyLoss      | -0.00273755 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0138      |
| _MeanReward     | 1.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.95123     |
| _max_adv        | 3.68        |
| _max_discrew    | 1.49        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0620104  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.988       |
| _mean_obs       | 0.0306      |
| _min_adv        | -5.63       |
| _min_discrew    | -0.0902     |
| _min_obs        | -1.38       |
| _std_act        | 0.507482    |
| _std_adv        | 1           |
| _std_discrew    | 0.135       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.873      |
| ExplainedVarOld | 0.856      |
| KL              | 0.00325246 |
| Phi_loss        | 75.456     |
| PolicyEntropy   | 3.80006    |
| PolicyLoss      | -0.0137567 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0179     |
| _MeanReward     | 1.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.9593     |
| _max_adv        | 4.69       |
| _max_discrew    | 1.63       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0582532 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.943      |
| _mean_obs       | 0.0314     |
| _min_adv        | -5.41      |
| _min_discrew    | -0.00579   |
| _min_obs        | -1.42      |
| _std_act        | 0.503924   |
| _std_adv        | 1          |
| _std_discrew    | 0.127      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.737       |
| ExplainedVarOld | 0.703       |
| KL              | 0.00280413  |
| Phi_loss        | 73.4672     |
| PolicyEntropy   | 3.79552     |
| PolicyLoss      | -0.00921955 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0335      |
| _MeanReward     | 1.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.8521      |
| _max_adv        | 5.21        |
| _max_discrew    | 1.72        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0574954  |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 0.965       |
| _mean_obs       | 0.0324      |
| _min_adv        | -5.83       |
| _min_discrew    | -0.00941    |
| _min_obs        | -1.39       |
| _std_act        | 0.507881    |
| _std_adv        | 1           |
| _std_discrew    | 0.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.844       |
| ExplainedVarOld | 0.813       |
| KL              | 0.00292334  |
| Phi_loss        | 73.2315     |
| PolicyEntropy   | 3.75982     |
| PolicyLoss      | -0.00299207 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0235      |
| _MeanReward     | 1.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.43709     |
| _max_adv        | 4.09        |
| _max_discrew    | 1.63        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0369702  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.831       |
| _mean_obs       | 0.0337      |
| _min_adv        | -10.7       |
| _min_discrew    | -0.842      |
| _min_obs        | -1.34       |
| _std_act        | 0.58479     |
| _std_adv        | 1           |
| _std_discrew    | 0.332       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.831      |
| ExplainedVarOld | 0.792      |
| KL              | 0.00929004 |
| Phi_loss        | 83.229     |
| PolicyEntropy   | 3.7792     |
| PolicyLoss      | -0.0912018 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0562     |
| _MeanReward     | 1.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84592    |
| _max_adv        | 7.41       |
| _max_discrew    | 1.56       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0570532 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0322     |
| _min_adv        | -6.23      |
| _min_discrew    | -0.015     |
| _min_obs        | -1.35      |
| _std_act        | 0.518723   |
| _std_adv        | 1          |
| _std_discrew    | 0.129      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.864      |
| ExplainedVarOld | 0.863      |
| KL              | 0.00161394 |
| Phi_loss        | 83.163     |
| PolicyEntropy   | 3.77213    |
| PolicyLoss      | 0.00437175 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0181     |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.8422     |
| _max_adv        | 6.71       |
| _max_discrew    | 1.6        |
| _max_obs        | 1.32       |
| _mean_act       | -0.0595152 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0312     |
| _min_adv        | -6.59      |
| _min_discrew    | -0.0381    |
| _min_obs        | -1.41      |
| _std_act        | 0.506887   |
| _std_adv        | 1          |
| _std_discrew    | 0.135      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.869      |
| ExplainedVarOld | 0.858      |
| KL              | 0.00168047 |
| Phi_loss        | 83.598     |
| PolicyEntropy   | 3.75285    |
| PolicyLoss      | 0.00242019 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 1.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15394    |
| _max_adv        | 5.15       |
| _max_discrew    | 1.67       |
| _max_obs        | 1.31       |
| _mean_act       | -0.05615   |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0325     |
| _min_adv        | -7.46      |
| _min_discrew    | -0.101     |
| _min_obs        | -1.45      |
| _std_act        | 0.507365   |
| _std_adv        | 1          |
| _std_discrew    | 0.164      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.858      |
| ExplainedVarOld | 0.849      |
| KL              | 0.00124349 |
| Phi_loss        | 88.0532    |
| PolicyEntropy   | 3.74443    |
| PolicyLoss      | -0.0078922 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0236     |
| _MeanReward     | 1.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.30631    |
| _max_adv        | 4.18       |
| _max_discrew    | 1.72       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0537712 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0322     |
| _min_adv        | -6.21      |
| _min_discrew    | -0.0688    |
| _min_obs        | -1.35      |
| _std_act        | 0.511803   |
| _std_adv        | 1          |
| _std_discrew    | 0.178      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.839       |
| KL              | 0.00338279  |
| Phi_loss        | 79.72       |
| PolicyEntropy   | 3.73097     |
| PolicyLoss      | -0.00717104 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0265      |
| _MeanReward     | 1.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.99227     |
| _max_adv        | 4.15        |
| _max_discrew    | 1.59        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0586995  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.0326      |
| _min_adv        | -5.55       |
| _min_discrew    | -0.0891     |
| _min_obs        | -1.51       |
| _std_act        | 0.510696    |
| _std_adv        | 1           |
| _std_discrew    | 0.139       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.826      |
| ExplainedVarOld | 0.809      |
| KL              | 0.00313287 |
| Phi_loss        | 78.5194    |
| PolicyEntropy   | 3.72222    |
| PolicyLoss      | -0.0021825 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0243     |
| _MeanReward     | 1.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.59984    |
| _max_adv        | 2.82       |
| _max_discrew    | 1.79       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0420609 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.924      |
| _mean_obs       | 0.0329     |
| _min_adv        | -12.2      |
| _min_discrew    | -1         |
| _min_obs        | -1.41      |
| _std_act        | 0.606957   |
| _std_adv        | 1          |
| _std_discrew    | 0.437      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.86       |
| ExplainedVarOld | 0.82       |
| KL              | 0.0062985  |
| Phi_loss        | 77.0669    |
| PolicyEntropy   | 3.71253    |
| PolicyLoss      | -0.0122166 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0612     |
| _MeanReward     | 1.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.52998    |
| _max_adv        | 3.95       |
| _max_discrew    | 1.67       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0508895 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 0.996      |
| _mean_obs       | 0.0321     |
| _min_adv        | -13.9      |
| _min_discrew    | -0.943     |
| _min_obs        | -1.34      |
| _std_act        | 0.565669   |
| _std_adv        | 1          |
| _std_discrew    | 0.278      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.826       |
| ExplainedVarOld | 0.821       |
| KL              | 0.00143673  |
| Phi_loss        | 89.2555     |
| PolicyEntropy   | 3.69162     |
| PolicyLoss      | -0.00271651 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0486      |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.59225     |
| _max_adv        | 7.83        |
| _max_discrew    | 1.74        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0325754  |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 0.924       |
| _mean_obs       | 0.0338      |
| _min_adv        | -14.8       |
| _min_discrew    | -1.04       |
| _min_obs        | -1.33       |
| _std_act        | 0.629625    |
| _std_adv        | 1           |
| _std_discrew    | 0.485       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.933       |
| ExplainedVarOld | 0.929       |
| KL              | 0.00275983  |
| Phi_loss        | 77.7044     |
| PolicyEntropy   | 3.68096     |
| PolicyLoss      | -0.00348977 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0332      |
| _MeanReward     | 1.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00088     |
| _max_adv        | 13.4        |
| _max_discrew    | 1.78        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0558388  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.13        |
| _mean_obs       | 0.0322      |
| _min_adv        | -5.36       |
| _min_discrew    | -0.0708     |
| _min_obs        | -1.49       |
| _std_act        | 0.517934    |
| _std_adv        | 1           |
| _std_discrew    | 0.168       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.903       |
| ExplainedVarOld | 0.885       |
| KL              | 0.00298663  |
| Phi_loss        | 76.0134     |
| PolicyEntropy   | 3.65237     |
| PolicyLoss      | -0.00933053 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0167      |
| _MeanReward     | 1.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.03685     |
| _max_adv        | 4.59        |
| _max_discrew    | 1.71        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0561689  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.16        |
| _mean_obs       | 0.0321      |
| _min_adv        | -7.7        |
| _min_discrew    | -0.0464     |
| _min_obs        | -1.36       |
| _std_act        | 0.512771    |
| _std_adv        | 1           |
| _std_discrew    | 0.155       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.893      |
| KL              | 0.00286966 |
| Phi_loss        | 87.5822    |
| PolicyEntropy   | 3.64245    |
| PolicyLoss      | -0.0165399 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0159     |
| _MeanReward     | 1.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94737    |
| _max_adv        | 3.68       |
| _max_discrew    | 1.79       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0601683 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.19       |
| _mean_obs       | 0.0323     |
| _min_adv        | -6.17      |
| _min_discrew    | -0.00274   |
| _min_obs        | -1.34      |
| _std_act        | 0.522438   |
| _std_adv        | 1          |
| _std_discrew    | 0.159      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.895       |
| ExplainedVarOld | 0.892       |
| KL              | 0.00296207  |
| Phi_loss        | 92.4669     |
| PolicyEntropy   | 3.62351     |
| PolicyLoss      | -0.00821218 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0168      |
| _MeanReward     | 1.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.25794     |
| _max_adv        | 3.91        |
| _max_discrew    | 1.87        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0496876  |
| _mean_adv       | -1.85e-17   |
| _mean_discrew   | 1.17        |
| _mean_obs       | 0.0347      |
| _min_adv        | -6.37       |
| _min_discrew    | -0.0113     |
| _min_obs        | -1.5        |
| _std_act        | 0.525945    |
| _std_adv        | 1           |
| _std_discrew    | 0.202       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.859       |
| ExplainedVarOld | 0.851       |
| KL              | 0.00299615  |
| Phi_loss        | 87.8513     |
| PolicyEntropy   | 3.61078     |
| PolicyLoss      | -0.00844315 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0285      |
| _MeanReward     | 1.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.16935     |
| _max_adv        | 5           |
| _max_discrew    | 1.78        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0587454  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 1.15        |
| _mean_obs       | 0.0331      |
| _min_adv        | -5.26       |
| _min_discrew    | -0.0644     |
| _min_obs        | -1.46       |
| _std_act        | 0.52444     |
| _std_adv        | 1           |
| _std_discrew    | 0.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.886      |
| ExplainedVarOld | 0.879      |
| KL              | 0.00332492 |
| Phi_loss        | 89.6132    |
| PolicyEntropy   | 3.59571    |
| PolicyLoss      | -0.0144985 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 1.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.17712    |
| _max_adv        | 2.01       |
| _max_discrew    | 1.83       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0367178 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 1.05       |
| _mean_obs       | 0.0346     |
| _min_adv        | -14.3      |
| _min_discrew    | -1.18      |
| _min_obs        | -1.64      |
| _std_act        | 0.627873   |
| _std_adv        | 1          |
| _std_discrew    | 0.489      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.849       |
| ExplainedVarOld | 0.812       |
| KL              | 0.00306477  |
| Phi_loss        | 100.564     |
| PolicyEntropy   | 3.55881     |
| PolicyLoss      | -0.00966164 |
| Steps           | 10000       |
| VarFuncLoss     | 0.074       |
| _MeanReward     | 1.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.09425     |
| _max_adv        | 4.19        |
| _max_discrew    | 1.86        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0569398  |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 1.26        |
| _mean_obs       | 0.0338      |
| _min_adv        | -5.69       |
| _min_discrew    | -0.129      |
| _min_obs        | -1.45       |
| _std_act        | 0.531207    |
| _std_adv        | 1           |
| _std_discrew    | 0.195       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.896      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00315731 |
| Phi_loss        | 95.1237    |
| PolicyEntropy   | 3.53825    |
| PolicyLoss      | -0.0228932 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 1.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.07104    |
| _max_adv        | 12.5       |
| _max_discrew    | 2          |
| _max_obs        | 1.3        |
| _mean_act       | -0.0584214 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0345     |
| _min_adv        | -6.38      |
| _min_discrew    | -0.051     |
| _min_obs        | -1.55      |
| _std_act        | 0.537813   |
| _std_adv        | 1          |
| _std_discrew    | 0.194      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.878       |
| ExplainedVarOld | 0.857       |
| KL              | 0.00299719  |
| Phi_loss        | 90.1181     |
| PolicyEntropy   | 3.50436     |
| PolicyLoss      | -0.00288923 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0237      |
| _MeanReward     | 1.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.00222     |
| _max_adv        | 5.95        |
| _max_discrew    | 2.07        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0580958  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.31        |
| _mean_obs       | 0.0339      |
| _min_adv        | -6.13       |
| _min_discrew    | 0.000628    |
| _min_obs        | -1.35       |
| _std_act        | 0.52931     |
| _std_adv        | 1           |
| _std_discrew    | 0.184       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00319281 |
| Phi_loss        | 97.4828    |
| PolicyEntropy   | 3.48718    |
| PolicyLoss      | -0.0186879 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0157     |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.68868    |
| _max_adv        | 5.49       |
| _max_discrew    | 1.96       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0499794 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0372     |
| _min_adv        | -8.81      |
| _min_discrew    | -0.511     |
| _min_obs        | -1.54      |
| _std_act        | 0.565887   |
| _std_adv        | 1          |
| _std_discrew    | 0.232      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.814      |
| ExplainedVarOld | 0.804      |
| KL              | 0.00479261 |
| Phi_loss        | 89.7734    |
| PolicyEntropy   | 3.45019    |
| PolicyLoss      | 0.0015699  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0432     |
| _MeanReward     | 1.66e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91102    |
| _max_adv        | 9.49       |
| _max_discrew    | 2.05       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0567046 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 1.36       |
| _mean_obs       | 0.0356     |
| _min_adv        | -6.83      |
| _min_discrew    | -0.0135    |
| _min_obs        | -1.31      |
| _std_act        | 0.540545   |
| _std_adv        | 1          |
| _std_discrew    | 0.208      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.901       |
| ExplainedVarOld | 0.898       |
| KL              | 0.00317364  |
| Phi_loss        | 91.558      |
| PolicyEntropy   | 3.43695     |
| PolicyLoss      | -0.00203807 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0211      |
| _MeanReward     | 1.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92272     |
| _max_adv        | 8.01        |
| _max_discrew    | 1.91        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0595117  |
| _mean_adv       | 4.12e-17    |
| _mean_discrew   | 1.3         |
| _mean_obs       | 0.0347      |
| _min_adv        | -7.06       |
| _min_discrew    | -0.000966   |
| _min_obs        | -1.34       |
| _std_act        | 0.538231    |
| _std_adv        | 1           |
| _std_discrew    | 0.184       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.875      |
| ExplainedVarOld | 0.866      |
| KL              | 0.00264525 |
| Phi_loss        | 98.5367    |
| PolicyEntropy   | 3.41577    |
| PolicyLoss      | 0.0116826  |
| Steps           | 10000      |
| VarFuncLoss     | 0.024      |
| _MeanReward     | 1.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.96118    |
| _max_adv        | 2.49       |
| _max_discrew    | 2.08       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0373219 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.11       |
| _mean_obs       | 0.0362     |
| _min_adv        | -12.8      |
| _min_discrew    | -1.3       |
| _min_obs        | -1.67      |
| _std_act        | 0.652448   |
| _std_adv        | 1          |
| _std_discrew    | 0.574      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.85        |
| ExplainedVarOld | 0.819       |
| KL              | 0.00512815  |
| Phi_loss        | 79.4732     |
| PolicyEntropy   | 3.39768     |
| PolicyLoss      | -0.00299633 |
| Steps           | 10000       |
| VarFuncLoss     | 0.086       |
| _MeanReward     | 1.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.9062      |
| _max_adv        | 4.74        |
| _max_discrew    | 2.04        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0338298  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.09        |
| _mean_obs       | 0.0358      |
| _min_adv        | -16.8       |
| _min_discrew    | -1.3        |
| _min_obs        | -1.48       |
| _std_act        | 0.673736    |
| _std_adv        | 1           |
| _std_discrew    | 0.706       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.897      |
| KL              | 0.00392059 |
| Phi_loss        | 91.9815    |
| PolicyEntropy   | 3.37886    |
| PolicyLoss      | 0.0077032  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0652     |
| _MeanReward     | 1.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.31297    |
| _max_adv        | 11.6       |
| _max_discrew    | 2.13       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0532745 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0357     |
| _min_adv        | -8.26      |
| _min_discrew    | -0.111     |
| _min_obs        | -1.4       |
| _std_act        | 0.533041   |
| _std_adv        | 1          |
| _std_discrew    | 0.248      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.839       |
| ExplainedVarOld | 0.816       |
| KL              | 0.00377583  |
| Phi_loss        | 105.561     |
| PolicyEntropy   | 3.36719     |
| PolicyLoss      | -0.00841963 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0398      |
| _MeanReward     | 1.67e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.7621      |
| _max_adv        | 6.01        |
| _max_discrew    | 2.17        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0572631  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.36        |
| _mean_obs       | 0.0358      |
| _min_adv        | -9.77       |
| _min_discrew    | -0.528      |
| _min_obs        | -1.46       |
| _std_act        | 0.56273     |
| _std_adv        | 1           |
| _std_discrew    | 0.281       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.866      |
| ExplainedVarOld | 0.86       |
| KL              | 0.00296214 |
| Phi_loss        | 106.085    |
| PolicyEntropy   | 3.34835    |
| PolicyLoss      | 0.00442866 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0379     |
| _MeanReward     | 1.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06236    |
| _max_adv        | 10.5       |
| _max_discrew    | 2.15       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0557557 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 1.42       |
| _mean_obs       | 0.0353     |
| _min_adv        | -7.92      |
| _min_discrew    | -0.0495    |
| _min_obs        | -1.37      |
| _std_act        | 0.535931   |
| _std_adv        | 1          |
| _std_discrew    | 0.239      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.926      |
| KL              | 0.00306134 |
| Phi_loss        | 103.718    |
| PolicyEntropy   | 3.34055    |
| PolicyLoss      | -0.0198278 |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 1.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.22474    |
| _max_adv        | 8.84       |
| _max_discrew    | 2.12       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0591881 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.41       |
| _mean_obs       | 0.0358     |
| _min_adv        | -6.81      |
| _min_discrew    | 0.00225    |
| _min_obs        | -1.38      |
| _std_act        | 0.538913   |
| _std_adv        | 1          |
| _std_discrew    | 0.242      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.902       |
| ExplainedVarOld | 0.896       |
| KL              | 0.00389896  |
| Phi_loss        | 107.97      |
| PolicyEntropy   | 3.31612     |
| PolicyLoss      | -0.00388581 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0236      |
| _MeanReward     | 1.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9065      |
| _max_adv        | 3.17        |
| _max_discrew    | 2.05        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0555475  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.39        |
| _mean_obs       | 0.0359      |
| _min_adv        | -6.5        |
| _min_discrew    | -0.0707     |
| _min_obs        | -1.34       |
| _std_act        | 0.544859    |
| _std_adv        | 1           |
| _std_discrew    | 0.247       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.862       |
| ExplainedVarOld | 0.86        |
| KL              | 0.00361726  |
| Phi_loss        | 117.165     |
| PolicyEntropy   | 3.27681     |
| PolicyLoss      | -0.00632834 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0342      |
| _MeanReward     | 1.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.13763     |
| _max_adv        | 3.12        |
| _max_discrew    | 2.12        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0593693  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.42        |
| _mean_obs       | 0.0367      |
| _min_adv        | -6.72       |
| _min_discrew    | 0.00086     |
| _min_obs        | -1.38       |
| _std_act        | 0.555389    |
| _std_adv        | 1           |
| _std_discrew    | 0.256       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.862      |
| ExplainedVarOld | 0.853      |
| KL              | 0.00337329 |
| Phi_loss        | 102.098    |
| PolicyEntropy   | 3.25495    |
| PolicyLoss      | -0.0119073 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0358     |
| _MeanReward     | 1.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.02012    |
| _max_adv        | 4.93       |
| _max_discrew    | 2.23       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0565724 |
| _mean_adv       | -4.83e-17  |
| _mean_discrew   | 1.49       |
| _mean_obs       | 0.0371     |
| _min_adv        | -7.28      |
| _min_discrew    | -0.0896    |
| _min_obs        | -1.35      |
| _std_act        | 0.553657   |
| _std_adv        | 1          |
| _std_discrew    | 0.274      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.88       |
| ExplainedVarOld | 0.873      |
| KL              | 0.00291621 |
| Phi_loss        | 109.652    |
| PolicyEntropy   | 3.26173    |
| PolicyLoss      | -0.0211514 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0334     |
| _MeanReward     | 1.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.12057    |
| _max_adv        | 7.3        |
| _max_discrew    | 2.35       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0591606 |
| _mean_adv       | -1.35e-17  |
| _mean_discrew   | 1.48       |
| _mean_obs       | 0.0369     |
| _min_adv        | -6.23      |
| _min_discrew    | 0.00267    |
| _min_obs        | -1.45      |
| _std_act        | 0.556559   |
| _std_adv        | 1          |
| _std_discrew    | 0.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.861        |
| ExplainedVarOld | 0.857        |
| KL              | 0.00369923   |
| Phi_loss        | 112.567      |
| PolicyEntropy   | 3.23797      |
| PolicyLoss      | -0.000913817 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0347       |
| _MeanReward     | 1.89e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.11379      |
| _max_adv        | 4.99         |
| _max_discrew    | 2.27         |
| _max_obs        | 1.27         |
| _mean_act       | -0.0597052   |
| _mean_adv       | -5.68e-18    |
| _mean_discrew   | 1.53         |
| _mean_obs       | 0.0371       |
| _min_adv        | -7.18        |
| _min_discrew    | 0.00276      |
| _min_obs        | -1.34        |
| _std_act        | 0.550324     |
| _std_adv        | 1            |
| _std_discrew    | 0.273        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.889      |
| KL              | 0.00278765 |
| Phi_loss        | 120.819    |
| PolicyEntropy   | 3.21575    |
| PolicyLoss      | 0.00327112 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0281     |
| _MeanReward     | 1.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.82655    |
| _max_adv        | 4.09       |
| _max_discrew    | 2.28       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0566838 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.56       |
| _mean_obs       | 0.037      |
| _min_adv        | -7.07      |
| _min_discrew    | 0.00141    |
| _min_obs        | -1.32      |
| _std_act        | 0.553513   |
| _std_adv        | 1          |
| _std_discrew    | 0.261      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.934       |
| ExplainedVarOld | 0.932       |
| KL              | 0.00399579  |
| Phi_loss        | 118.926     |
| PolicyEntropy   | 3.18339     |
| PolicyLoss      | -0.00315276 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0173      |
| _MeanReward     | 1.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.91072     |
| _max_adv        | 4.34        |
| _max_discrew    | 2.35        |
| _max_obs        | 1.27        |
| _mean_act       | -0.059665   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 1.53        |
| _mean_obs       | 0.0372      |
| _min_adv        | -6.86       |
| _min_discrew    | -0.107      |
| _min_obs        | -1.28       |
| _std_act        | 0.558959    |
| _std_adv        | 1           |
| _std_discrew    | 0.311       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.881       |
| KL              | 0.00298571  |
| Phi_loss        | 111.876     |
| PolicyEntropy   | 3.16212     |
| PolicyLoss      | -0.00787721 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0333      |
| _MeanReward     | 1.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.98513     |
| _max_adv        | 4.18        |
| _max_discrew    | 2.27        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0597377  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.56        |
| _mean_obs       | 0.0371      |
| _min_adv        | -6.28       |
| _min_discrew    | 0.00135     |
| _min_obs        | -1.35       |
| _std_act        | 0.554985    |
| _std_adv        | 1           |
| _std_discrew    | 0.267       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.896      |
| ExplainedVarOld | 0.889      |
| KL              | 0.00517732 |
| Phi_loss        | 112.168    |
| PolicyEntropy   | 3.12452    |
| PolicyLoss      | -0.0124126 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0282     |
| _MeanReward     | 1.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.22025    |
| _max_adv        | 2.72       |
| _max_discrew    | 2.49       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0326561 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.29       |
| _mean_obs       | 0.0376     |
| _min_adv        | -11.7      |
| _min_discrew    | -1.65      |
| _min_obs        | -1.32      |
| _std_act        | 0.73558    |
| _std_adv        | 1          |
| _std_discrew    | 0.989      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.813      |
| KL              | 0.00681594 |
| Phi_loss        | 96.0842    |
| PolicyEntropy   | 3.13581    |
| PolicyLoss      | -0.0180203 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0897     |
| _MeanReward     | 2.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74079    |
| _max_adv        | 18.4       |
| _max_discrew    | 2.37       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0578325 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.64       |
| _mean_obs       | 0.0381     |
| _min_adv        | -7.95      |
| _min_discrew    | -0.012     |
| _min_obs        | -1.41      |
| _std_act        | 0.551111   |
| _std_adv        | 1          |
| _std_discrew    | 0.298      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.902       |
| KL              | 0.00316399  |
| Phi_loss        | 113.687     |
| PolicyEntropy   | 3.1214      |
| PolicyLoss      | -0.00358098 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0297      |
| _MeanReward     | 1.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86794     |
| _max_adv        | 8.94        |
| _max_discrew    | 2.54        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0596035  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 1.59        |
| _mean_obs       | 0.0369      |
| _min_adv        | -6.83       |
| _min_discrew    | 0.00163     |
| _min_obs        | -1.2        |
| _std_act        | 0.550093    |
| _std_adv        | 1           |
| _std_discrew    | 0.32        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.882      |
| KL              | 0.00170124 |
| Phi_loss        | 130.614    |
| PolicyEntropy   | 3.09688    |
| PolicyLoss      | -0.0041534 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0325     |
| _MeanReward     | 1.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.95182    |
| _max_adv        | 4.39       |
| _max_discrew    | 2.41       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0590473 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.57       |
| _mean_obs       | 0.0376     |
| _min_adv        | -6.9       |
| _min_discrew    | 0.00506    |
| _min_obs        | -1.38      |
| _std_act        | 0.558047   |
| _std_adv        | 1          |
| _std_discrew    | 0.284      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.838       |
| ExplainedVarOld | 0.832       |
| KL              | 0.00200539  |
| Phi_loss        | 134.28      |
| PolicyEntropy   | 3.07248     |
| PolicyLoss      | -0.00857852 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0461      |
| _MeanReward     | 1.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8821      |
| _max_adv        | 7.59        |
| _max_discrew    | 2.26        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0611187  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.6         |
| _mean_obs       | 0.037       |
| _min_adv        | -6.98       |
| _min_discrew    | 0.00796     |
| _min_obs        | -1.38       |
| _std_act        | 0.553859    |
| _std_adv        | 1           |
| _std_discrew    | 0.268       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00181492 |
| Phi_loss        | 135.257    |
| PolicyEntropy   | 3.05057    |
| PolicyLoss      | -0.0104913 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0277     |
| _MeanReward     | 2.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90193    |
| _max_adv        | 4.02       |
| _max_discrew    | 2.61       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0643215 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 1.68       |
| _mean_obs       | 0.0373     |
| _min_adv        | -7.56      |
| _min_discrew    | 0.00417    |
| _min_obs        | -1.33      |
| _std_act        | 0.557045   |
| _std_adv        | 1          |
| _std_discrew    | 0.276      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.888       |
| ExplainedVarOld | 0.886       |
| KL              | 0.0023659   |
| Phi_loss        | 136.71      |
| PolicyEntropy   | 3.01883     |
| PolicyLoss      | -0.00374475 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0323      |
| _MeanReward     | 1.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01545     |
| _max_adv        | 5.82        |
| _max_discrew    | 2.27        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0557118  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.62        |
| _mean_obs       | 0.0388      |
| _min_adv        | -8.09       |
| _min_discrew    | -0.108      |
| _min_obs        | -1.35       |
| _std_act        | 0.556891    |
| _std_adv        | 1           |
| _std_discrew    | 0.327       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.89       |
| KL              | 0.00185529 |
| Phi_loss        | 129.454    |
| PolicyEntropy   | 3.01019    |
| PolicyLoss      | -0.0121612 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0333     |
| _MeanReward     | 2.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78012    |
| _max_adv        | 4.73       |
| _max_discrew    | 2.71       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0571946 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.68       |
| _mean_obs       | 0.0389     |
| _min_adv        | -7.2       |
| _min_discrew    | 0.00547    |
| _min_obs        | -1.36      |
| _std_act        | 0.563157   |
| _std_adv        | 1          |
| _std_discrew    | 0.339      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.874      |
| KL              | 0.00149003 |
| Phi_loss        | 131.595    |
| PolicyEntropy   | 3.00235    |
| PolicyLoss      | -0.0100009 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0414     |
| _MeanReward     | 2.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85662    |
| _max_adv        | 6.39       |
| _max_discrew    | 2.57       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0571606 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 1.76       |
| _mean_obs       | 0.0391     |
| _min_adv        | -7.56      |
| _min_discrew    | 0.00787    |
| _min_obs        | -1.52      |
| _std_act        | 0.556586   |
| _std_adv        | 1          |
| _std_discrew    | 0.323      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.902       |
| ExplainedVarOld | 0.894       |
| KL              | 0.00413998  |
| Phi_loss        | 130.116     |
| PolicyEntropy   | 2.96677     |
| PolicyLoss      | -0.00393649 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0336      |
| _MeanReward     | 2.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.96704     |
| _max_adv        | 5.13        |
| _max_discrew    | 2.62        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0564928  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.71        |
| _mean_obs       | 0.0383      |
| _min_adv        | -7.67       |
| _min_discrew    | -0.0191     |
| _min_obs        | -1.3        |
| _std_act        | 0.548579    |
| _std_adv        | 1           |
| _std_discrew    | 0.344       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.89       |
| ExplainedVarOld | 0.889      |
| KL              | 0.00382088 |
| Phi_loss        | 145.589    |
| PolicyEntropy   | 2.94829    |
| PolicyLoss      | -0.0140387 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0383     |
| _MeanReward     | 2.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.04024    |
| _max_adv        | 5.61       |
| _max_discrew    | 2.56       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0604507 |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | 1.82       |
| _mean_obs       | 0.0387     |
| _min_adv        | -7.99      |
| _min_discrew    | -0.0076    |
| _min_obs        | -1.34      |
| _std_act        | 0.551955   |
| _std_adv        | 1          |
| _std_discrew    | 0.316      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.941      |
| KL              | 0.00382441 |
| Phi_loss        | 135.635    |
| PolicyEntropy   | 2.91806    |
| PolicyLoss      | -0.0175782 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0198     |
| _MeanReward     | 2.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95377    |
| _max_adv        | 4.49       |
| _max_discrew    | 2.72       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0561206 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.73       |
| _mean_obs       | 0.0393     |
| _min_adv        | -5.61      |
| _min_discrew    | -0.000886  |
| _min_obs        | -1.41      |
| _std_act        | 0.569874   |
| _std_adv        | 1          |
| _std_discrew    | 0.323      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.916       |
| KL              | 0.00281039  |
| Phi_loss        | 132.098     |
| PolicyEntropy   | 2.90495     |
| PolicyLoss      | -0.00729877 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0271      |
| _MeanReward     | 2.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02421     |
| _max_adv        | 4.7         |
| _max_discrew    | 2.64        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0556835  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.82        |
| _mean_obs       | 0.0397      |
| _min_adv        | -6.92       |
| _min_discrew    | 0.00237     |
| _min_obs        | -1.41       |
| _std_act        | 0.562557    |
| _std_adv        | 1           |
| _std_discrew    | 0.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.934      |
| KL              | 0.00353004 |
| Phi_loss        | 139.186    |
| PolicyEntropy   | 2.85538    |
| PolicyLoss      | 0.0040443  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0225     |
| _MeanReward     | 2.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00197    |
| _max_adv        | 3.89       |
| _max_discrew    | 2.63       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0606803 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.85       |
| _mean_obs       | 0.0394     |
| _min_adv        | -7.65      |
| _min_discrew    | 0.000607   |
| _min_obs        | -1.34      |
| _std_act        | 0.556235   |
| _std_adv        | 1          |
| _std_discrew    | 0.343      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.9         |
| ExplainedVarOld | 0.896       |
| KL              | 0.00412226  |
| Phi_loss        | 143.234     |
| PolicyEntropy   | 2.82761     |
| PolicyLoss      | -0.00259922 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0351      |
| _MeanReward     | 2.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7067      |
| _max_adv        | 5.25        |
| _max_discrew    | 2.67        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0608155  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.86        |
| _mean_obs       | 0.0389      |
| _min_adv        | -5.46       |
| _min_discrew    | 0.0027      |
| _min_obs        | -1.43       |
| _std_act        | 0.554126    |
| _std_adv        | 1           |
| _std_discrew    | 0.368       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00393153 |
| Phi_loss        | 160.075    |
| PolicyEntropy   | 2.7916     |
| PolicyLoss      | 0.00269997 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0243     |
| _MeanReward     | 2.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.71181    |
| _max_adv        | 5.01       |
| _max_discrew    | 2.69       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0579357 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 1.87       |
| _mean_obs       | 0.0401     |
| _min_adv        | -6.81      |
| _min_discrew    | -0.0643    |
| _min_obs        | -1.32      |
| _std_act        | 0.554496   |
| _std_adv        | 1          |
| _std_discrew    | 0.445      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.931       |
| ExplainedVarOld | 0.919       |
| KL              | 0.00346668  |
| Phi_loss        | 146.236     |
| PolicyEntropy   | 2.75522     |
| PolicyLoss      | -0.00368513 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0307      |
| _MeanReward     | 2.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87138     |
| _max_adv        | 4.32        |
| _max_discrew    | 2.79        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0583029  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 1.91        |
| _mean_obs       | 0.0403      |
| _min_adv        | -7.01       |
| _min_discrew    | 0.000834    |
| _min_obs        | -1.27       |
| _std_act        | 0.563152    |
| _std_adv        | 1           |
| _std_discrew    | 0.379       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.933       |
| ExplainedVarOld | 0.932       |
| KL              | 0.00419657  |
| Phi_loss        | 166.883     |
| PolicyEntropy   | 2.73421     |
| PolicyLoss      | -0.00722869 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0255      |
| _MeanReward     | 1.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.57865     |
| _max_adv        | 1.51        |
| _max_discrew    | 2.72        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0260248  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.53        |
| _mean_obs       | 0.0398      |
| _min_adv        | -15.2       |
| _min_discrew    | -1.9        |
| _min_obs        | -1.41       |
| _std_act        | 0.802047    |
| _std_adv        | 1           |
| _std_discrew    | 1.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.858      |
| KL              | 0.00661784 |
| Phi_loss        | 115.802    |
| PolicyEntropy   | 2.74954    |
| PolicyLoss      | -0.0808391 |
| Steps           | 10000      |
| VarFuncLoss     | 0.167      |
| _MeanReward     | 2.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60956    |
| _max_adv        | 11.2       |
| _max_discrew    | 2.68       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0634325 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.89       |
| _mean_obs       | 0.0395     |
| _min_adv        | -9.07      |
| _min_discrew    | -0.0219    |
| _min_obs        | -1.4       |
| _std_act        | 0.566461   |
| _std_adv        | 1          |
| _std_discrew    | 0.438      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.918      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00213865 |
| Phi_loss        | 157.058    |
| PolicyEntropy   | 2.73621    |
| PolicyLoss      | -0.0208255 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0359     |
| _MeanReward     | 2.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83072    |
| _max_adv        | 18.7       |
| _max_discrew    | 2.75       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0608551 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.94       |
| _mean_obs       | 0.04       |
| _min_adv        | -6.35      |
| _min_discrew    | 0.00344    |
| _min_obs        | -1.37      |
| _std_act        | 0.565442   |
| _std_adv        | 1          |
| _std_discrew    | 0.386      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.93       |
| ExplainedVarOld | 0.916      |
| KL              | 0.00184384 |
| Phi_loss        | 127.621    |
| PolicyEntropy   | 2.71769    |
| PolicyLoss      | -0.0105394 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0275     |
| _MeanReward     | 2.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81886    |
| _max_adv        | 6.16       |
| _max_discrew    | 2.91       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0624111 |
| _mean_adv       | -8.38e-17  |
| _mean_discrew   | 1.99       |
| _mean_obs       | 0.0399     |
| _min_adv        | -6.4       |
| _min_discrew    | -0.0128    |
| _min_obs        | -1.35      |
| _std_act        | 0.562537   |
| _std_adv        | 1          |
| _std_discrew    | 0.449      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.951      |
| KL              | 0.00241625 |
| Phi_loss        | 165.125    |
| PolicyEntropy   | 2.70866    |
| PolicyLoss      | -0.0282353 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 2.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.28971    |
| _max_adv        | 9.29       |
| _max_discrew    | 2.8        |
| _max_obs        | 1.4        |
| _mean_act       | -0.0612489 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.98       |
| _mean_obs       | 0.04       |
| _min_adv        | -8.96      |
| _min_discrew    | 0.00526    |
| _min_obs        | -1.38      |
| _std_act        | 0.575446   |
| _std_adv        | 1          |
| _std_discrew    | 0.395      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.935      |
| KL              | 0.0017512  |
| Phi_loss        | 167.548    |
| PolicyEntropy   | 2.68925    |
| PolicyLoss      | -0.0137312 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0235     |
| _MeanReward     | 2.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.80002    |
| _max_adv        | 6.86       |
| _max_discrew    | 2.77       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0627601 |
| _mean_adv       | 7.39e-17   |
| _mean_discrew   | 2.06       |
| _mean_obs       | 0.0405     |
| _min_adv        | -7.18      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.38      |
| _std_act        | 0.571762   |
| _std_adv        | 1          |
| _std_discrew    | 0.431      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.96       |
| KL              | 0.00182369 |
| Phi_loss        | 167.525    |
| PolicyEntropy   | 2.67568    |
| PolicyLoss      | -0.0165649 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0166     |
| _MeanReward     | 2.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86648    |
| _max_adv        | 3.34       |
| _max_discrew    | 2.88       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0633835 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 1.99       |
| _mean_obs       | 0.0405     |
| _min_adv        | -7.63      |
| _min_discrew    | 0.00241    |
| _min_obs        | -1.48      |
| _std_act        | 0.578772   |
| _std_adv        | 1          |
| _std_discrew    | 0.424      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.896       |
| KL              | 0.00194048  |
| Phi_loss        | 176.296     |
| PolicyEntropy   | 2.65656     |
| PolicyLoss      | -0.00738994 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0415      |
| _MeanReward     | 2.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78668     |
| _max_adv        | 4.91        |
| _max_discrew    | 2.97        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0603858  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 2.06        |
| _mean_obs       | 0.0414      |
| _min_adv        | -7.93       |
| _min_discrew    | 0.00352     |
| _min_obs        | -1.55       |
| _std_act        | 0.574157    |
| _std_adv        | 1           |
| _std_discrew    | 0.45        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.933      |
| KL              | 0.0021148  |
| Phi_loss        | 179.36     |
| PolicyEntropy   | 2.63081    |
| PolicyLoss      | 0.00619492 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 2.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83805    |
| _max_adv        | 4.87       |
| _max_discrew    | 2.94       |
| _max_obs        | 1.27       |
| _mean_act       | -0.062366  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.05       |
| _mean_obs       | 0.0413     |
| _min_adv        | -8.53      |
| _min_discrew    | 0.000374   |
| _min_obs        | -1.27      |
| _std_act        | 0.576113   |
| _std_adv        | 1          |
| _std_discrew    | 0.474      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.911       |
| KL              | 0.00213176  |
| Phi_loss        | 192.506     |
| PolicyEntropy   | 2.60802     |
| PolicyLoss      | 0.000118721 |
| Steps           | 10000       |
| VarFuncLoss     | 0.039       |
| _MeanReward     | 2.53e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71098     |
| _max_adv        | 8.48        |
| _max_discrew    | 2.96        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0635796  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.07        |
| _mean_obs       | 0.0406      |
| _min_adv        | -7.12       |
| _min_discrew    | 0.0048      |
| _min_obs        | -1.44       |
| _std_act        | 0.577812    |
| _std_adv        | 1           |
| _std_discrew    | 0.479       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.944      |
| KL              | 0.00229423 |
| Phi_loss        | 174.071    |
| PolicyEntropy   | 2.58525    |
| PolicyLoss      | -0.017142  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0253     |
| _MeanReward     | 2.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.82617    |
| _max_adv        | 7.28       |
| _max_discrew    | 2.87       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0634912 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.06       |
| _mean_obs       | 0.0401     |
| _min_adv        | -8.15      |
| _min_discrew    | -0.0161    |
| _min_obs        | -1.33      |
| _std_act        | 0.577479   |
| _std_adv        | 1          |
| _std_discrew    | 0.432      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.927      |
| KL              | 0.0025159  |
| Phi_loss        | 190.504    |
| PolicyEntropy   | 2.54934    |
| PolicyLoss      | -0.0154166 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0296     |
| _MeanReward     | 2.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.29135    |
| _max_adv        | 6.76       |
| _max_discrew    | 2.84       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0618768 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.08       |
| _mean_obs       | 0.0411     |
| _min_adv        | -6.98      |
| _min_discrew    | -0.331     |
| _min_obs        | -1.47      |
| _std_act        | 0.594313   |
| _std_adv        | 1          |
| _std_discrew    | 0.474      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.917      |
| KL              | 0.0031977  |
| Phi_loss        | 179.222    |
| PolicyEntropy   | 2.53225    |
| PolicyLoss      | -0.0170363 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0364     |
| _MeanReward     | 2.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82028    |
| _max_adv        | 5.24       |
| _max_discrew    | 2.89       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0629324 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 2.08       |
| _mean_obs       | 0.0408     |
| _min_adv        | -7.25      |
| _min_discrew    | 0.000606   |
| _min_obs        | -1.35      |
| _std_act        | 0.57797    |
| _std_adv        | 1          |
| _std_discrew    | 0.438      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.937       |
| ExplainedVarOld | 0.935       |
| KL              | 0.00210743  |
| Phi_loss        | 191.685     |
| PolicyEntropy   | 2.51748     |
| PolicyLoss      | -0.00916807 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0276      |
| _MeanReward     | 2.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87733     |
| _max_adv        | 3.3         |
| _max_discrew    | 3.09        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0648316  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 2.15        |
| _mean_obs       | 0.0417      |
| _min_adv        | -7.71       |
| _min_discrew    | 0.00818     |
| _min_obs        | -1.44       |
| _std_act        | 0.582695    |
| _std_adv        | 1           |
| _std_discrew    | 0.457       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00195884 |
| Phi_loss        | 160.777    |
| PolicyEntropy   | 2.50553    |
| PolicyLoss      | -0.022206  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0481     |
| _MeanReward     | 2.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75826    |
| _max_adv        | 7.69       |
| _max_discrew    | 3.16       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0635872 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 2.21       |
| _mean_obs       | 0.0417     |
| _min_adv        | -7.28      |
| _min_discrew    | 0.00943    |
| _min_obs        | -1.33      |
| _std_act        | 0.583255   |
| _std_adv        | 1          |
| _std_discrew    | 0.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.941       |
| ExplainedVarOld | 0.94        |
| KL              | 0.00370172  |
| Phi_loss        | 201.68      |
| PolicyEntropy   | 2.48438     |
| PolicyLoss      | -0.00859091 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0279      |
| _MeanReward     | 2.72e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.87019     |
| _max_adv        | 6.84        |
| _max_discrew    | 3.21        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0613214  |
| _mean_adv       | 0           |
| _mean_discrew   | 2.23        |
| _mean_obs       | 0.0426      |
| _min_adv        | -7.74       |
| _min_discrew    | 0.00258     |
| _min_obs        | -1.4        |
| _std_act        | 0.583762    |
| _std_adv        | 1           |
| _std_discrew    | 0.494       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.943      |
| ExplainedVarOld | 0.936      |
| KL              | 0.00195611 |
| Phi_loss        | 188.132    |
| PolicyEntropy   | 2.47403    |
| PolicyLoss      | -0.0127556 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0286     |
| _MeanReward     | 2.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.82086    |
| _max_adv        | 2.22       |
| _max_discrew    | 3.14       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0450759 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.02       |
| _mean_obs       | 0.0422     |
| _min_adv        | -13.2      |
| _min_discrew    | -1.87      |
| _min_obs        | -1.31      |
| _std_act        | 0.700264   |
| _std_adv        | 1          |
| _std_discrew    | 1.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.853      |
| ExplainedVarOld | 0.816      |
| KL              | 0.0138591  |
| Phi_loss        | 131.937    |
| PolicyEntropy   | 2.48194    |
| PolicyLoss      | -0.0228815 |
| Steps           | 10000      |
| VarFuncLoss     | 0.17       |
| _MeanReward     | 2.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.11307    |
| _max_adv        | 11.8       |
| _max_discrew    | 3.33       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0614431 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.23       |
| _mean_obs       | 0.0417     |
| _min_adv        | -7.08      |
| _min_discrew    | 0.00384    |
| _min_obs        | -1.43      |
| _std_act        | 0.584113   |
| _std_adv        | 1          |
| _std_discrew    | 0.513      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.938      |
| KL              | 0.00185782 |
| Phi_loss        | 195.185    |
| PolicyEntropy   | 2.46781    |
| PolicyLoss      | 0.00823082 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0331     |
| _MeanReward     | 2.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82885    |
| _max_adv        | 20.1       |
| _max_discrew    | 3.07       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0603458 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.15       |
| _mean_obs       | 0.042      |
| _min_adv        | -6.23      |
| _min_discrew    | -0.00278   |
| _min_obs        | -1.41      |
| _std_act        | 0.584975   |
| _std_adv        | 1          |
| _std_discrew    | 0.552      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00180334 |
| Phi_loss        | 146.887    |
| PolicyEntropy   | 2.45896    |
| PolicyLoss      | 0.00779357 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0431     |
| _MeanReward     | 2.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.21326    |
| _max_adv        | 13.6       |
| _max_discrew    | 3.05       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0624976 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 2.19       |
| _mean_obs       | 0.0413     |
| _min_adv        | -6.93      |
| _min_discrew    | 0.00139    |
| _min_obs        | -1.29      |
| _std_act        | 0.585906   |
| _std_adv        | 1          |
| _std_discrew    | 0.452      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.936      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00093278 |
| Phi_loss        | 189.19     |
| PolicyEntropy   | 2.45081    |
| PolicyLoss      | -0.0219352 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0289     |
| _MeanReward     | 2.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.49346    |
| _max_adv        | 2.6        |
| _max_discrew    | 3.09       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0456733 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.97       |
| _mean_obs       | 0.0418     |
| _min_adv        | -15.7      |
| _min_discrew    | -2.16      |
| _min_obs        | -1.29      |
| _std_act        | 0.767165   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.853      |
| ExplainedVarOld | 0.822      |
| KL              | 0.00749287 |
| Phi_loss        | 151.643    |
| PolicyEntropy   | 2.45539    |
| PolicyLoss      | 0.0195824  |
| Steps           | 10000      |
| VarFuncLoss     | 0.217      |
| _MeanReward     | 2.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.09867    |
| _max_adv        | 7.45       |
| _max_discrew    | 3.09       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0652474 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.0411     |
| _min_adv        | -6.3       |
| _min_discrew    | 0.00782    |
| _min_obs        | -1.58      |
| _std_act        | 0.57528    |
| _std_adv        | 1          |
| _std_discrew    | 0.484      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.954       |
| ExplainedVarOld | 0.947       |
| KL              | 0.000966748 |
| Phi_loss        | 194.041     |
| PolicyEntropy   | 2.44094     |
| PolicyLoss      | -0.00878685 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 2.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6235      |
| _max_adv        | 21.8        |
| _max_discrew    | 3.06        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0610314  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.21        |
| _mean_obs       | 0.0419      |
| _min_adv        | -8.57       |
| _min_discrew    | 0.0039      |
| _min_obs        | -1.54       |
| _std_act        | 0.589535    |
| _std_adv        | 1           |
| _std_discrew    | 0.529       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.899      |
| ExplainedVarOld | 0.892      |
| KL              | 0.00210965 |
| Phi_loss        | 174.995    |
| PolicyEntropy   | 2.43951    |
| PolicyLoss      | -0.0177675 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0535     |
| _MeanReward     | 2.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76988    |
| _max_adv        | 4.36       |
| _max_discrew    | 3.27       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0624698 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 2.22       |
| _mean_obs       | 0.041      |
| _min_adv        | -7.08      |
| _min_discrew    | 0.00711    |
| _min_obs        | -1.34      |
| _std_act        | 0.580229   |
| _std_adv        | 1          |
| _std_discrew    | 0.548      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.906      |
| ExplainedVarOld | 0.901      |
| KL              | 0.00203179 |
| Phi_loss        | 201.277    |
| PolicyEntropy   | 2.4305     |
| PolicyLoss      | -0.0176374 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0517     |
| _MeanReward     | 2.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68953    |
| _max_adv        | 9.39       |
| _max_discrew    | 3.34       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0600759 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.08       |
| _mean_obs       | 0.041      |
| _min_adv        | -7.74      |
| _min_discrew    | 0.00904    |
| _min_obs        | -1.38      |
| _std_act        | 0.593299   |
| _std_adv        | 1          |
| _std_discrew    | 0.603      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.841       |
| ExplainedVarOld | 0.82        |
| KL              | 0.00179748  |
| Phi_loss        | 196.238     |
| PolicyEntropy   | 2.41641     |
| PolicyLoss      | -0.00187892 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0999      |
| _MeanReward     | 2.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74633     |
| _max_adv        | 7.18        |
| _max_discrew    | 3.06        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0645228  |
| _mean_adv       | 1.85e-17    |
| _mean_discrew   | 2.24        |
| _mean_obs       | 0.0415      |
| _min_adv        | -7.37       |
| _min_discrew    | 0.00565     |
| _min_obs        | -1.47       |
| _std_act        | 0.598441    |
| _std_adv        | 1           |
| _std_discrew    | 0.561       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.942       |
| KL              | 0.00206286  |
| Phi_loss        | 202.965     |
| PolicyEntropy   | 2.38885     |
| PolicyLoss      | -0.00973484 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0322      |
| _MeanReward     | 2.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.80592     |
| _max_adv        | 11.8        |
| _max_discrew    | 3.18        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0654074  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.3         |
| _mean_obs       | 0.0416      |
| _min_adv        | -11.5       |
| _min_discrew    | 0.00409     |
| _min_obs        | -1.4        |
| _std_act        | 0.590342    |
| _std_adv        | 1           |
| _std_discrew    | 0.536       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.923      |
| KL              | 0.00211666 |
| Phi_loss        | 218.126    |
| PolicyEntropy   | 2.37045    |
| PolicyLoss      | -0.0147561 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0377     |
| _MeanReward     | 2.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.70521    |
| _max_adv        | 2.67       |
| _max_discrew    | 3.24       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0396866 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.94       |
| _mean_obs       | 0.0415     |
| _min_adv        | -14.7      |
| _min_discrew    | -2.15      |
| _min_obs        | -1.27      |
| _std_act        | 0.833963   |
| _std_adv        | 1          |
| _std_discrew    | 1.92       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.842      |
| KL              | 0.00586932 |
| Phi_loss        | 157.732    |
| PolicyEntropy   | 2.3884     |
| PolicyLoss      | 0.0226576  |
| Steps           | 10000      |
| VarFuncLoss     | 0.166      |
| _MeanReward     | 2.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.20119    |
| _max_adv        | 17.7       |
| _max_discrew    | 3.2        |
| _max_obs        | 1.26       |
| _mean_act       | -0.0613379 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.041      |
| _min_adv        | -7.77      |
| _min_discrew    | -0.00118   |
| _min_obs        | -1.44      |
| _std_act        | 0.596744   |
| _std_adv        | 1          |
| _std_discrew    | 0.541      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.901      |
| ExplainedVarOld | 0.88       |
| KL              | 0.0139977  |
| Phi_loss        | 137.226    |
| PolicyEntropy   | 2.3775     |
| PolicyLoss      | 0.0576964  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0538     |
| _MeanReward     | 2.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.41908    |
| _max_adv        | 3.11       |
| _max_discrew    | 3.26       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0457452 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.09       |
| _mean_obs       | 0.0415     |
| _min_adv        | -16        |
| _min_discrew    | -2.01      |
| _min_obs        | -1.44      |
| _std_act        | 0.750208   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.845      |
| ExplainedVarOld | 0.833      |
| KL              | 0.00311076 |
| Phi_loss        | 191.371    |
| PolicyEntropy   | 2.36442    |
| PolicyLoss      | 0.0220673  |
| Steps           | 10000      |
| VarFuncLoss     | 0.22       |
| _MeanReward     | 2.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71376    |
| _max_adv        | 6.76       |
| _max_discrew    | 3.35       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0646307 |
| _mean_adv       | 5.76e-17   |
| _mean_discrew   | 2.36       |
| _mean_obs       | 0.0415     |
| _min_adv        | -7.3       |
| _min_discrew    | 0.00478    |
| _min_obs        | -1.26      |
| _std_act        | 0.599403   |
| _std_adv        | 1          |
| _std_discrew    | 0.586      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.945       |
| ExplainedVarOld | 0.941       |
| KL              | 0.000979094 |
| Phi_loss        | 231.869     |
| PolicyEntropy   | 2.35331     |
| PolicyLoss      | -0.00535266 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0334      |
| _MeanReward     | 2.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.36796     |
| _max_adv        | 16.5        |
| _max_discrew    | 3.36        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0579209  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 2.25        |
| _mean_obs       | 0.0416      |
| _min_adv        | -15.2       |
| _min_discrew    | -1.37       |
| _min_obs        | -1.3        |
| _std_act        | 0.651218    |
| _std_adv        | 1           |
| _std_discrew    | 0.838       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.835      |
| ExplainedVarOld | 0.826      |
| KL              | 0.00552593 |
| Phi_loss        | 226.188    |
| PolicyEntropy   | 2.34429    |
| PolicyLoss      | -0.003449  |
| Steps           | 10000      |
| VarFuncLoss     | 0.139      |
| _MeanReward     | 2.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88187    |
| _max_adv        | 7.88       |
| _max_discrew    | 3.31       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0656444 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.37       |
| _mean_obs       | 0.0413     |
| _min_adv        | -5.31      |
| _min_discrew    | 0.00443    |
| _min_obs        | -1.3       |
| _std_act        | 0.597478   |
| _std_adv        | 1          |
| _std_discrew    | 0.588      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00209601 |
| Phi_loss        | 234.389    |
| PolicyEntropy   | 2.30534    |
| PolicyLoss      | -0.0052579 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0221     |
| _MeanReward     | 2.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77869    |
| _max_adv        | 4.79       |
| _max_discrew    | 3.29       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0638351 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.34       |
| _mean_obs       | 0.041      |
| _min_adv        | -7.24      |
| _min_discrew    | 0.00657    |
| _min_obs        | -1.3       |
| _std_act        | 0.594144   |
| _std_adv        | 1          |
| _std_discrew    | 0.547      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.958       |
| ExplainedVarOld | 0.953       |
| KL              | 0.00220911  |
| Phi_loss        | 230.089     |
| PolicyEntropy   | 2.27552     |
| PolicyLoss      | -0.00284795 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 2.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84772     |
| _max_adv        | 9.19        |
| _max_discrew    | 3.09        |
| _max_obs        | 1.25        |
| _mean_act       | -0.062017   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 2.27        |
| _mean_obs       | 0.0407      |
| _min_adv        | -8.64       |
| _min_discrew    | 0.00572     |
| _min_obs        | -1.29       |
| _std_act        | 0.590204    |
| _std_adv        | 1           |
| _std_discrew    | 0.536       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.892      |
| KL              | 0.00223903 |
| Phi_loss        | 209.112    |
| PolicyEntropy   | 2.26898    |
| PolicyLoss      | -0.0263672 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0484     |
| _MeanReward     | 2.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.46518    |
| _max_adv        | 3.68       |
| _max_discrew    | 3.25       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0436583 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 1.97       |
| _mean_obs       | 0.0404     |
| _min_adv        | -16.5      |
| _min_discrew    | -2         |
| _min_obs        | -1.39      |
| _std_act        | 0.824214   |
| _std_adv        | 1          |
| _std_discrew    | 1.9        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00401359 |
| Phi_loss        | 174.427    |
| PolicyEntropy   | 2.29348    |
| PolicyLoss      | 0.00635478 |
| Steps           | 10000      |
| VarFuncLoss     | 0.146      |
| _MeanReward     | 2.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.22621    |
| _max_adv        | 7.66       |
| _max_discrew    | 3.34       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0607282 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.37       |
| _mean_obs       | 0.0415     |
| _min_adv        | -16.1      |
| _min_discrew    | -0.963     |
| _min_obs        | -1.34      |
| _std_act        | 0.632663   |
| _std_adv        | 1          |
| _std_discrew    | 0.736      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.891      |
| ExplainedVarOld | 0.879      |
| KL              | 0.001608   |
| Phi_loss        | 198.885    |
| PolicyEntropy   | 2.2798     |
| PolicyLoss      | -0.0115387 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0806     |
| _MeanReward     | 2.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.59391    |
| _max_adv        | 4.33       |
| _max_discrew    | 3.27       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0519978 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.11       |
| _mean_obs       | 0.0409     |
| _min_adv        | -17.2      |
| _min_discrew    | -1.93      |
| _min_obs        | -1.42      |
| _std_act        | 0.745799   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.84       |
| ExplainedVarOld | 0.835      |
| KL              | 0.00178009 |
| Phi_loss        | 236.108    |
| PolicyEntropy   | 2.27909    |
| PolicyLoss      | 0.00139573 |
| Steps           | 10000      |
| VarFuncLoss     | 0.218      |
| _MeanReward     | 2.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95218    |
| _max_adv        | 21.2       |
| _max_discrew    | 3.33       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0657848 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.41       |
| _mean_obs       | 0.0416     |
| _min_adv        | -9.22      |
| _min_discrew    | 0.00664    |
| _min_obs        | -1.31      |
| _std_act        | 0.602507   |
| _std_adv        | 1          |
| _std_discrew    | 0.595      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.936      |
| KL              | 0.0149537  |
| Phi_loss        | 218.313    |
| PolicyEntropy   | 2.27816    |
| PolicyLoss      | -0.284223  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0374     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90378    |
| _max_adv        | 17.2       |
| _max_discrew    | 3.32       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0652656 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0419     |
| _min_adv        | -7.63      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.44      |
| _std_act        | 0.606598   |
| _std_adv        | 1          |
| _std_discrew    | 0.577      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.959       |
| ExplainedVarOld | 0.946       |
| KL              | 0.0018205   |
| Phi_loss        | 209.389     |
| PolicyEntropy   | 2.27727     |
| PolicyLoss      | 0.000684639 |
| Steps           | 10000       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 2.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72726     |
| _max_adv        | 8.88        |
| _max_discrew    | 3.45        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0598143  |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 2.42        |
| _mean_obs       | 0.042       |
| _min_adv        | -8.67       |
| _min_discrew    | 0.00892     |
| _min_obs        | -1.22       |
| _std_act        | 0.600198    |
| _std_adv        | 1           |
| _std_discrew    | 0.694       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.891       |
| KL              | 0.00105325  |
| Phi_loss        | 233.743     |
| PolicyEntropy   | 2.27059     |
| PolicyLoss      | -0.00613563 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0667      |
| _MeanReward     | 2.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.073       |
| _max_adv        | 8.76        |
| _max_discrew    | 3.42        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0645992  |
| _mean_adv       | 2.42e-17    |
| _mean_discrew   | 2.39        |
| _mean_obs       | 0.0411      |
| _min_adv        | -9.11       |
| _min_discrew    | 0.00382     |
| _min_obs        | -1.34       |
| _std_act        | 0.606325    |
| _std_adv        | 1           |
| _std_discrew    | 0.572       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.902      |
| KL              | 0.00211158 |
| Phi_loss        | 232.816    |
| PolicyEntropy   | 2.26524    |
| PolicyLoss      | -0.0169201 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0531     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87145    |
| _max_adv        | 5.85       |
| _max_discrew    | 3.5        |
| _max_obs        | 1.25       |
| _mean_act       | -0.0638464 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.44       |
| _mean_obs       | 0.0421     |
| _min_adv        | -9.98      |
| _min_discrew    | 0.0065     |
| _min_obs        | -1.39      |
| _std_act        | 0.612723   |
| _std_adv        | 1          |
| _std_discrew    | 0.609      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.919      |
| KL              | 0.00145362 |
| Phi_loss        | 238.247    |
| PolicyEntropy   | 2.26103    |
| PolicyLoss      | 0.00124151 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0452     |
| _MeanReward     | 2.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.35995    |
| _max_adv        | 7.03       |
| _max_discrew    | 3.33       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0495131 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 2.05       |
| _mean_obs       | 0.0409     |
| _min_adv        | -14.3      |
| _min_discrew    | -2.02      |
| _min_obs        | -1.34      |
| _std_act        | 0.812378   |
| _std_adv        | 1          |
| _std_discrew    | 1.8        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.84       |
| ExplainedVarOld | 0.823      |
| KL              | 0.00460905 |
| Phi_loss        | 215.088    |
| PolicyEntropy   | 2.23514    |
| PolicyLoss      | -0.0124779 |
| Steps           | 10000      |
| VarFuncLoss     | 0.292      |
| _MeanReward     | 2.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.38488    |
| _max_adv        | 2.84       |
| _max_discrew    | 3.44       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0542736 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.2        |
| _mean_obs       | 0.0406     |
| _min_adv        | -19.2      |
| _min_discrew    | -2.05      |
| _min_obs        | -1.3       |
| _std_act        | 0.784707   |
| _std_adv        | 1          |
| _std_discrew    | 1.78       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.873      |
| ExplainedVarOld | 0.869      |
| KL              | 0.00263528 |
| Phi_loss        | 204.469    |
| PolicyEntropy   | 2.22125    |
| PolicyLoss      | 0.0144399  |
| Steps           | 10000      |
| VarFuncLoss     | 0.23       |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82932    |
| _max_adv        | 20.6       |
| _max_discrew    | 3.5        |
| _max_obs        | 1.22       |
| _mean_act       | -0.0653376 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.0416     |
| _min_adv        | -9.65      |
| _min_discrew    | 0.00423    |
| _min_obs        | -1.41      |
| _std_act        | 0.606317   |
| _std_adv        | 1          |
| _std_discrew    | 0.613      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.929      |
| KL              | 0.00470336 |
| Phi_loss        | 216.522    |
| PolicyEntropy   | 2.20462    |
| PolicyLoss      | -0.010002  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0422     |
| _MeanReward     | 3.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.02521    |
| _max_adv        | 25.1       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0708476 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.53       |
| _mean_obs       | 0.0412     |
| _min_adv        | -6.61      |
| _min_discrew    | 0.0107     |
| _min_obs        | -1.39      |
| _std_act        | 0.604357   |
| _std_adv        | 1          |
| _std_discrew    | 0.644      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00317588 |
| Phi_loss        | 217.143    |
| PolicyEntropy   | 2.17319    |
| PolicyLoss      | -0.0127016 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0201     |
| _MeanReward     | 3.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83381    |
| _max_adv        | 9.91       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0682719 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.51       |
| _mean_obs       | 0.0417     |
| _min_adv        | -8.24      |
| _min_discrew    | 0.00583    |
| _min_obs        | -1.37      |
| _std_act        | 0.607304   |
| _std_adv        | 1          |
| _std_discrew    | 0.659      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00645022 |
| Phi_loss        | 267.132    |
| PolicyEntropy   | 2.13798    |
| PolicyLoss      | 0.0231444  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0271     |
| _MeanReward     | 3e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.76563    |
| _max_adv        | 4.61       |
| _max_discrew    | 3.45       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0672992 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.45       |
| _mean_obs       | 0.0413     |
| _min_adv        | -6.88      |
| _min_discrew    | -0.0439    |
| _min_obs        | -1.49      |
| _std_act        | 0.608065   |
| _std_adv        | 1          |
| _std_discrew    | 0.706      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.929      |
| KL              | 0.00149355 |
| Phi_loss        | 286.614    |
| PolicyEntropy   | 2.13145    |
| PolicyLoss      | 0.00335978 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0494     |
| _MeanReward     | 3.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13526    |
| _max_adv        | 3.43       |
| _max_discrew    | 3.34       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0702204 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.0407     |
| _min_adv        | -10.1      |
| _min_discrew    | -0.0124    |
| _min_obs        | -1.29      |
| _std_act        | 0.611827   |
| _std_adv        | 1          |
| _std_discrew    | 0.621      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.943      |
| KL              | 0.00368145 |
| Phi_loss        | 253.172    |
| PolicyEntropy   | 2.10486    |
| PolicyLoss      | -0.0246969 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0318     |
| _MeanReward     | 2.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.26308    |
| _max_adv        | 3.09       |
| _max_discrew    | 3.55       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0600867 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 2.39       |
| _mean_obs       | 0.0418     |
| _min_adv        | -15.7      |
| _min_discrew    | -1.88      |
| _min_obs        | -1.22      |
| _std_act        | 0.735559   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.854       |
| ExplainedVarOld | 0.827       |
| KL              | 0.00271378  |
| Phi_loss        | 186.384     |
| PolicyEntropy   | 2.10975     |
| PolicyLoss      | -0.00234714 |
| Steps           | 10000       |
| VarFuncLoss     | 0.208       |
| _MeanReward     | 2.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 4.475       |
| _max_adv        | 12.3        |
| _max_discrew    | 3.59        |
| _max_obs        | 1.25        |
| _mean_act       | -0.05242    |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 2.07        |
| _mean_obs       | 0.0407      |
| _min_adv        | -14.6       |
| _min_discrew    | -2.01       |
| _min_obs        | -1.3        |
| _std_act        | 0.867618    |
| _std_adv        | 1           |
| _std_discrew    | 2.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.821      |
| ExplainedVarOld | 0.818      |
| KL              | 0.0082704  |
| Phi_loss        | 322.57     |
| PolicyEntropy   | 2.09623    |
| PolicyLoss      | 0.0212044  |
| Steps           | 10000      |
| VarFuncLoss     | 0.401      |
| _MeanReward     | 3.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.75294    |
| _max_adv        | 18.4       |
| _max_discrew    | 3.53       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0631794 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 2.53       |
| _mean_obs       | 0.0418     |
| _min_adv        | -6.7       |
| _min_discrew    | 0.00622    |
| _min_obs        | -1.28      |
| _std_act        | 0.618068   |
| _std_adv        | 1          |
| _std_discrew    | 0.702      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00236179 |
| Phi_loss        | 155.085    |
| PolicyEntropy   | 2.08061    |
| PolicyLoss      | -0.0159483 |
| Steps           | 10000      |
| VarFuncLoss     | 0.044      |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.09827    |
| _max_adv        | 6.39       |
| _max_discrew    | 3.57       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0646204 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.45       |
| _mean_obs       | 0.0416     |
| _min_adv        | -14.3      |
| _min_discrew    | -1.12      |
| _min_obs        | -1.34      |
| _std_act        | 0.664565   |
| _std_adv        | 1          |
| _std_discrew    | 0.904      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.881      |
| ExplainedVarOld | 0.864      |
| KL              | 0.00240372 |
| Phi_loss        | 225.347    |
| PolicyEntropy   | 2.06068    |
| PolicyLoss      | -0.0103758 |
| Steps           | 10000      |
| VarFuncLoss     | 0.109      |
| _MeanReward     | 3.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65879    |
| _max_adv        | 14.9       |
| _max_discrew    | 3.71       |
| _max_obs        | 1.27       |
| _mean_act       | -0.060504  |
| _mean_adv       | -4.19e-17  |
| _mean_discrew   | 2.55       |
| _mean_obs       | 0.0423     |
| _min_adv        | -8.4       |
| _min_discrew    | 0.00377    |
| _min_obs        | -1.22      |
| _std_act        | 0.614391   |
| _std_adv        | 1          |
| _std_discrew    | 0.667      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.905      |
| ExplainedVarOld | 0.895      |
| KL              | 0.0022203  |
| Phi_loss        | 208.248    |
| PolicyEntropy   | 2.03947    |
| PolicyLoss      | -0.0139488 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0653     |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.3926     |
| _max_adv        | 5.85       |
| _max_discrew    | 3.64       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0574843 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.2        |
| _mean_obs       | 0.0407     |
| _min_adv        | -16.1      |
| _min_discrew    | -2.07      |
| _min_obs        | -1.42      |
| _std_act        | 0.822369   |
| _std_adv        | 1          |
| _std_discrew    | 1.91       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.859      |
| ExplainedVarOld | 0.853      |
| KL              | 0.00298095 |
| Phi_loss        | 270.311    |
| PolicyEntropy   | 2.05469    |
| PolicyLoss      | -0.0126873 |
| Steps           | 10000      |
| VarFuncLoss     | 0.271      |
| _MeanReward     | 3.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.751      |
| _max_adv        | 17.9       |
| _max_discrew    | 3.73       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0627377 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 2.66       |
| _mean_obs       | 0.0421     |
| _min_adv        | -9.22      |
| _min_discrew    | 0.00512    |
| _min_obs        | -1.27      |
| _std_act        | 0.620246   |
| _std_adv        | 1          |
| _std_discrew    | 0.705      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.949      |
| KL              | 0.00306759 |
| Phi_loss        | 220.301    |
| PolicyEntropy   | 2.05039    |
| PolicyLoss      | -0.0102694 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0361     |
| _MeanReward     | 2.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.55285    |
| _max_adv        | 8.08       |
| _max_discrew    | 3.44       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0561409 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.33       |
| _mean_obs       | 0.0412     |
| _min_adv        | -18.4      |
| _min_discrew    | -2.03      |
| _min_obs        | -1.35      |
| _std_act        | 0.75167    |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.862      |
| ExplainedVarOld | 0.855      |
| KL              | 0.00244533 |
| Phi_loss        | 276.327    |
| PolicyEntropy   | 2.0379     |
| PolicyLoss      | 0.0213057  |
| Steps           | 10000      |
| VarFuncLoss     | 0.213      |
| _MeanReward     | 3.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.77241    |
| _max_adv        | 26.1       |
| _max_discrew    | 3.54       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0600084 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.62       |
| _mean_obs       | 0.0419     |
| _min_adv        | -8.37      |
| _min_discrew    | 0.0102     |
| _min_obs        | -1.19      |
| _std_act        | 0.6087     |
| _std_adv        | 1          |
| _std_discrew    | 0.702      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00188197 |
| Phi_loss        | 231.4      |
| PolicyEntropy   | 2.01047    |
| PolicyLoss      | -0.0209583 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0223     |
| _MeanReward     | 3.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75336    |
| _max_adv        | 16.6       |
| _max_discrew    | 3.52       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0585659 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.62       |
| _mean_obs       | 0.0419     |
| _min_adv        | -8.41      |
| _min_discrew    | 0.00751    |
| _min_obs        | -1.28      |
| _std_act        | 0.610219   |
| _std_adv        | 1          |
| _std_discrew    | 0.676      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.959       |
| KL              | 0.00150369  |
| Phi_loss        | 255.71      |
| PolicyEntropy   | 1.99583     |
| PolicyLoss      | -0.00193716 |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 3.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.36203     |
| _max_adv        | 7.12        |
| _max_discrew    | 3.67        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0572759  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.48        |
| _mean_obs       | 0.0419      |
| _min_adv        | -16.2       |
| _min_discrew    | -1.53       |
| _min_obs        | -1.31       |
| _std_act        | 0.678923    |
| _std_adv        | 1           |
| _std_discrew    | 1.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.869      |
| KL              | 0.00763838 |
| Phi_loss        | 237.483    |
| PolicyEntropy   | 1.99976    |
| PolicyLoss      | 0.0632846  |
| Steps           | 10000      |
| VarFuncLoss     | 0.13       |
| _MeanReward     | 2.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.59124    |
| _max_adv        | 1.52       |
| _max_discrew    | 3.53       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0418513 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 1.84       |
| _mean_obs       | 0.0386     |
| _min_adv        | -12.9      |
| _min_discrew    | -2.08      |
| _min_obs        | -1.22      |
| _std_act        | 0.996607   |
| _std_adv        | 1          |
| _std_discrew    | 3.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.887      |
| KL              | 0.00237837 |
| Phi_loss        | 222.139    |
| PolicyEntropy   | 1.98428    |
| PolicyLoss      | -0.039043  |
| Steps           | 10000      |
| VarFuncLoss     | 0.324      |
| _MeanReward     | 2.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.46748    |
| _max_adv        | 13.8       |
| _max_discrew    | 3.56       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0529308 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.27       |
| _mean_obs       | 0.0408     |
| _min_adv        | -18.8      |
| _min_discrew    | -2.07      |
| _min_obs        | -1.26      |
| _std_act        | 0.796185   |
| _std_adv        | 1          |
| _std_discrew    | 1.92       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.871       |
| ExplainedVarOld | 0.868       |
| KL              | 0.000994132 |
| Phi_loss        | 327.007     |
| PolicyEntropy   | 1.97513     |
| PolicyLoss      | 0.0145484   |
| Steps           | 10000       |
| VarFuncLoss     | 0.247       |
| _MeanReward     | 3.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73995     |
| _max_adv        | 22.8        |
| _max_discrew    | 3.65        |
| _max_obs        | 1.18        |
| _mean_act       | -0.059117   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0421      |
| _min_adv        | -6.78       |
| _min_discrew    | 0.0114      |
| _min_obs        | -1.36       |
| _std_act        | 0.612794    |
| _std_adv        | 1           |
| _std_discrew    | 0.703       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.917       |
| KL              | 0.00187904  |
| Phi_loss        | 160.069     |
| PolicyEntropy   | 1.95854     |
| PolicyLoss      | -0.00225294 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0367      |
| _MeanReward     | 3.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.10131     |
| _max_adv        | 14.1        |
| _max_discrew    | 3.57        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0596511  |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 2.66        |
| _mean_obs       | 0.0421      |
| _min_adv        | -8.64       |
| _min_discrew    | 0.00967     |
| _min_obs        | -1.36       |
| _std_act        | 0.617656    |
| _std_adv        | 1           |
| _std_discrew    | 0.744       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.953      |
| KL              | 0.00123209 |
| Phi_loss        | 286.329    |
| PolicyEntropy   | 1.94688    |
| PolicyLoss      | -0.0126139 |
| Steps           | 10000      |
| VarFuncLoss     | 0.03       |
| _MeanReward     | 3.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82715    |
| _max_adv        | 8.87       |
| _max_discrew    | 3.63       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0580845 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.57       |
| _mean_obs       | 0.042      |
| _min_adv        | -8.44      |
| _min_discrew    | 0.00911    |
| _min_obs        | -1.26      |
| _std_act        | 0.610904   |
| _std_adv        | 1          |
| _std_discrew    | 0.811      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.904      |
| KL              | 0.00439912 |
| Phi_loss        | 267.121    |
| PolicyEntropy   | 1.93786    |
| PolicyLoss      | -0.0206257 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0765     |
| _MeanReward     | 3.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.73147    |
| _max_adv        | 10.3       |
| _max_discrew    | 3.58       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0575377 |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 2.61       |
| _mean_obs       | 0.0417     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.00247    |
| _min_obs        | -1.24      |
| _std_act        | 0.606781   |
| _std_adv        | 1          |
| _std_discrew    | 0.741      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.944      |
| ExplainedVarOld | 0.941      |
| KL              | 0.00434419 |
| Phi_loss        | 278.779    |
| PolicyEntropy   | 1.92176    |
| PolicyLoss      | -0.0241775 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0421     |
| _MeanReward     | 3.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72639    |
| _max_adv        | 6.04       |
| _max_discrew    | 3.68       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0598206 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.74       |
| _mean_obs       | 0.0418     |
| _min_adv        | -6.61      |
| _min_discrew    | 0.00704    |
| _min_obs        | -1.24      |
| _std_act        | 0.610276   |
| _std_adv        | 1          |
| _std_discrew    | 0.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00368992 |
| Phi_loss        | 305.204    |
| PolicyEntropy   | 1.87685    |
| PolicyLoss      | -0.0145577 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0172     |
| _MeanReward     | 3.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.73501    |
| _max_adv        | 4.03       |
| _max_discrew    | 3.77       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0640697 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.66       |
| _mean_obs       | 0.042      |
| _min_adv        | -11.3      |
| _min_discrew    | -0.0993    |
| _min_obs        | -1.3       |
| _std_act        | 0.627197   |
| _std_adv        | 1          |
| _std_discrew    | 0.808      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.868       |
| ExplainedVarOld | 0.859       |
| KL              | 0.00411334  |
| Phi_loss        | 282.094     |
| PolicyEntropy   | 1.86404     |
| PolicyLoss      | -0.00357881 |
| Steps           | 10000       |
| VarFuncLoss     | 0.107       |
| _MeanReward     | 3.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7527      |
| _max_adv        | 9.38        |
| _max_discrew    | 3.76        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0626198  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.61        |
| _mean_obs       | 0.0416      |
| _min_adv        | -10.5       |
| _min_discrew    | 0.00209     |
| _min_obs        | -1.32       |
| _std_act        | 0.623512    |
| _std_adv        | 1           |
| _std_discrew    | 0.819       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.856       |
| ExplainedVarOld | 0.849       |
| KL              | 0.00419161  |
| Phi_loss        | 306.924     |
| PolicyEntropy   | 1.84896     |
| PolicyLoss      | -0.00370973 |
| Steps           | 10000       |
| VarFuncLoss     | 0.117       |
| _MeanReward     | 3.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6711      |
| _max_adv        | 9.22        |
| _max_discrew    | 3.85        |
| _max_obs        | 1.27        |
| _mean_act       | -0.0615824  |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 2.62        |
| _mean_obs       | 0.0412      |
| _min_adv        | -11.1       |
| _min_discrew    | 0.012       |
| _min_obs        | -1.17       |
| _std_act        | 0.616712    |
| _std_adv        | 1           |
| _std_discrew    | 0.744       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00395003 |
| Phi_loss        | 344.615    |
| PolicyEntropy   | 1.8286     |
| PolicyLoss      | 0.00915742 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0862     |
| _MeanReward     | 3.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74841    |
| _max_adv        | 7.48       |
| _max_discrew    | 3.8        |
| _max_obs        | 1.18       |
| _mean_act       | -0.063129  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.71       |
| _mean_obs       | 0.042      |
| _min_adv        | -8.04      |
| _min_discrew    | 0.0075     |
| _min_obs        | -1.31      |
| _std_act        | 0.620226   |
| _std_adv        | 1          |
| _std_discrew    | 0.762      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.93       |
| KL              | 0.00513673 |
| Phi_loss        | 294.116    |
| PolicyEntropy   | 1.82693    |
| PolicyLoss      | -0.0101616 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0484     |
| _MeanReward     | 2.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.4196     |
| _max_adv        | 1.98       |
| _max_discrew    | 3.68       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0536908 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.11       |
| _mean_obs       | 0.0386     |
| _min_adv        | -11.2      |
| _min_discrew    | -2.14      |
| _min_obs        | -1.31      |
| _std_act        | 0.915275   |
| _std_adv        | 1          |
| _std_discrew    | 2.79       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.888       |
| ExplainedVarOld | 0.808       |
| KL              | 0.00904501  |
| Phi_loss        | 211.413     |
| PolicyEntropy   | 1.81704     |
| PolicyLoss      | -0.00819077 |
| Steps           | 10000       |
| VarFuncLoss     | 0.318       |
| _MeanReward     | 3.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58685     |
| _max_adv        | 8.07        |
| _max_discrew    | 3.74        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0616299  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.81        |
| _mean_obs       | 0.0423      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.0115      |
| _min_obs        | -1.28       |
| _std_act        | 0.620423    |
| _std_adv        | 1           |
| _std_discrew    | 0.75        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.953       |
| KL              | 0.0014535   |
| Phi_loss        | 302.114     |
| PolicyEntropy   | 1.80295     |
| PolicyLoss      | -0.00565318 |
| Steps           | 10000       |
| VarFuncLoss     | 0.041       |
| _MeanReward     | 3.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.30645     |
| _max_adv        | 20.4        |
| _max_discrew    | 3.67        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0616571  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 2.81        |
| _mean_obs       | 0.0422      |
| _min_adv        | -8.35       |
| _min_discrew    | 0.00759     |
| _min_obs        | -1.25       |
| _std_act        | 0.619635    |
| _std_adv        | 1           |
| _std_discrew    | 0.75        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.944      |
| KL              | 0.0162615  |
| Phi_loss        | 373.382    |
| PolicyEntropy   | 1.80503    |
| PolicyLoss      | -0.0810122 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 3.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5381     |
| _max_adv        | 3.51       |
| _max_discrew    | 3.67       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0656966 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.82       |
| _mean_obs       | 0.0414     |
| _min_adv        | -3.45      |
| _min_discrew    | 0.0068     |
| _min_obs        | -1.32      |
| _std_act        | 0.618131   |
| _std_adv        | 1          |
| _std_discrew    | 0.757      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00453049 |
| Phi_loss        | 469.163    |
| PolicyEntropy   | 1.7921     |
| PolicyLoss      | 0.00646381 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 3.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61688    |
| _max_adv        | 7.33       |
| _max_discrew    | 3.78       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0652464 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 2.72       |
| _mean_obs       | 0.0414     |
| _min_adv        | -10.2      |
| _min_discrew    | -0.0417    |
| _min_obs        | -1.3       |
| _std_act        | 0.620417   |
| _std_adv        | 1          |
| _std_discrew    | 0.924      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.932       |
| KL              | 0.00437327  |
| Phi_loss        | 455.606     |
| PolicyEntropy   | 1.77338     |
| PolicyLoss      | -0.00796731 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0547      |
| _MeanReward     | 3.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.17587     |
| _max_adv        | 3.27        |
| _max_discrew    | 3.72        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0612653  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.61        |
| _mean_obs       | 0.0409      |
| _min_adv        | -15.6       |
| _min_discrew    | -1.4        |
| _min_obs        | -1.33       |
| _std_act        | 0.681906    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.866      |
| ExplainedVarOld | 0.843      |
| KL              | 0.00674062 |
| Phi_loss        | 373.949    |
| PolicyEntropy   | 1.76853    |
| PolicyLoss      | -0.0735968 |
| Steps           | 10000      |
| VarFuncLoss     | 0.155      |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.05909    |
| _max_adv        | 6.04       |
| _max_discrew    | 3.84       |
| _max_obs        | 1.18       |
| _mean_act       | -0.064156  |
| _mean_adv       | 0          |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.0407     |
| _min_adv        | -15.2      |
| _min_discrew    | -1.23      |
| _min_obs        | -1.33      |
| _std_act        | 0.670029   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.887      |
| ExplainedVarOld | 0.883      |
| KL              | 0.00080907 |
| Phi_loss        | 358.909    |
| PolicyEntropy   | 1.76256    |
| PolicyLoss      | -0.0135037 |
| Steps           | 10000      |
| VarFuncLoss     | 0.125      |
| _MeanReward     | 3.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64518    |
| _max_adv        | 10.5       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0643575 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.81       |
| _mean_obs       | 0.0412     |
| _min_adv        | -3.85      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.25      |
| _std_act        | 0.622832   |
| _std_adv        | 1          |
| _std_discrew    | 0.724      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00178621 |
| Phi_loss        | 317.807    |
| PolicyEntropy   | 1.73915    |
| PolicyLoss      | -0.0330704 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 3.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.0347     |
| _max_adv        | 6.87       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0646865 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.0414     |
| _min_adv        | -17.3      |
| _min_discrew    | -1.28      |
| _min_obs        | -1.25      |
| _std_act        | 0.679912   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.887      |
| ExplainedVarOld | 0.882      |
| KL              | 0.00252612 |
| Phi_loss        | 379.841    |
| PolicyEntropy   | 1.73755    |
| PolicyLoss      | 0.0148731  |
| Steps           | 10000      |
| VarFuncLoss     | 0.137      |
| _MeanReward     | 3.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60436    |
| _max_adv        | 10.4       |
| _max_discrew    | 3.84       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0650628 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.79       |
| _mean_obs       | 0.0412     |
| _min_adv        | -8.15      |
| _min_discrew    | 0.00967    |
| _min_obs        | -1.26      |
| _std_act        | 0.617601   |
| _std_adv        | 1          |
| _std_discrew    | 0.834      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.95        |
| ExplainedVarOld | 0.948       |
| KL              | 0.00130834  |
| Phi_loss        | 409.968     |
| PolicyEntropy   | 1.73085     |
| PolicyLoss      | -0.00652185 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0422      |
| _MeanReward     | 3.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01474     |
| _max_adv        | 12.4        |
| _max_discrew    | 3.79        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0656883  |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 2.8         |
| _mean_obs       | 0.0419      |
| _min_adv        | -7.1        |
| _min_discrew    | 0.00967     |
| _min_obs        | -1.37       |
| _std_act        | 0.621049    |
| _std_adv        | 1           |
| _std_discrew    | 0.786       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.929      |
| KL              | 0.00660652 |
| Phi_loss        | 311.659    |
| PolicyEntropy   | 1.72342    |
| PolicyLoss      | 0.00271338 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0479     |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78254    |
| _max_adv        | 9.2        |
| _max_discrew    | 3.85       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0630802 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.8        |
| _mean_obs       | 0.0415     |
| _min_adv        | -9.1       |
| _min_discrew    | 0.00991    |
| _min_obs        | -1.35      |
| _std_act        | 0.626163   |
| _std_adv        | 1          |
| _std_discrew    | 0.777      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.939      |
| KL              | 0.00207361 |
| Phi_loss        | 405.267    |
| PolicyEntropy   | 1.70911    |
| PolicyLoss      | -0.0057553 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0457     |
| _MeanReward     | 3.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66484    |
| _max_adv        | 5.57       |
| _max_discrew    | 3.77       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0657573 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.83       |
| _mean_obs       | 0.0419     |
| _min_adv        | -9.67      |
| _min_discrew    | -0.00515   |
| _min_obs        | -1.26      |
| _std_act        | 0.631418   |
| _std_adv        | 1          |
| _std_discrew    | 0.777      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.946        |
| ExplainedVarOld | 0.945        |
| KL              | 0.00181268   |
| Phi_loss        | 388.603      |
| PolicyEntropy   | 1.69141      |
| PolicyLoss      | -0.000807311 |
| Steps           | 10000        |
| VarFuncLoss     | 0.042        |
| _MeanReward     | 3.46e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.73508      |
| _max_adv        | 7.97         |
| _max_discrew    | 3.85         |
| _max_obs        | 1.18         |
| _mean_act       | -0.0658657   |
| _mean_adv       | 8.53e-18     |
| _mean_discrew   | 2.87         |
| _mean_obs       | 0.0412       |
| _min_adv        | -11.4        |
| _min_discrew    | 0.0102       |
| _min_obs        | -1.36        |
| _std_act        | 0.629523     |
| _std_adv        | 1            |
| _std_discrew    | 0.805        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00210958  |
| Phi_loss        | 355.191     |
| PolicyEntropy   | 1.6667      |
| PolicyLoss      | -0.00953949 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0151      |
| _MeanReward     | 3.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68825     |
| _max_adv        | 4.97        |
| _max_discrew    | 3.89        |
| _max_obs        | 1.17        |
| _mean_act       | -0.0648048  |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 2.93        |
| _mean_obs       | 0.0426      |
| _min_adv        | -12.1       |
| _min_discrew    | 0.0106      |
| _min_obs        | -1.25       |
| _std_act        | 0.627766    |
| _std_adv        | 1           |
| _std_discrew    | 0.844       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.969       |
| ExplainedVarOld | 0.966       |
| KL              | 0.00219059  |
| Phi_loss        | 392.943     |
| PolicyEntropy   | 1.65219     |
| PolicyLoss      | -0.00737229 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0272      |
| _MeanReward     | 3.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.09839     |
| _max_adv        | 2.81        |
| _max_discrew    | 3.93        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0680207  |
| _mean_adv       | 5.68e-17    |
| _mean_discrew   | 2.56        |
| _mean_obs       | 0.0397      |
| _min_adv        | -14.2       |
| _min_discrew    | -1.64       |
| _min_obs        | -1.32       |
| _std_act        | 0.750589    |
| _std_adv        | 1           |
| _std_discrew    | 1.78        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.857      |
| ExplainedVarOld | 0.837      |
| KL              | 0.00421432 |
| Phi_loss        | 272.425    |
| PolicyEntropy   | 1.66695    |
| PolicyLoss      | 0.0411634  |
| Steps           | 10000      |
| VarFuncLoss     | 0.259      |
| _MeanReward     | 3.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62579    |
| _max_adv        | 21.7       |
| _max_discrew    | 3.87       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0664135 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.91       |
| _mean_obs       | 0.0417     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.24      |
| _std_act        | 0.632438   |
| _std_adv        | 1          |
| _std_discrew    | 0.848      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.0152114  |
| Phi_loss        | 413.879    |
| PolicyEntropy   | 1.65624    |
| PolicyLoss      | -0.0172449 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0306     |
| _MeanReward     | 3.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.92407    |
| _max_adv        | 14.5       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0656302 |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.0408     |
| _min_adv        | -17.5      |
| _min_discrew    | -1.5       |
| _min_obs        | -1.35      |
| _std_act        | 0.724548   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.86       |
| KL              | 0.00386168 |
| Phi_loss        | 332.133    |
| PolicyEntropy   | 1.65482    |
| PolicyLoss      | 0.0586032  |
| Steps           | 10000      |
| VarFuncLoss     | 0.182      |
| _MeanReward     | 3.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.92102    |
| _max_adv        | 6.56       |
| _max_discrew    | 4          |
| _max_obs        | 1.16       |
| _mean_act       | -0.0682289 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.47       |
| _mean_obs       | 0.0391     |
| _min_adv        | -15.2      |
| _min_discrew    | -1.55      |
| _min_obs        | -1.27      |
| _std_act        | 0.804463   |
| _std_adv        | 1          |
| _std_discrew    | 2.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.847      |
| ExplainedVarOld | 0.841      |
| KL              | 0.00104964 |
| Phi_loss        | 374.9      |
| PolicyEntropy   | 1.65316    |
| PolicyLoss      | 0.0127064  |
| Steps           | 10000      |
| VarFuncLoss     | 0.332      |
| _MeanReward     | 3.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.94229    |
| _max_adv        | 4.88       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0677811 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 2.56       |
| _mean_obs       | 0.0396     |
| _min_adv        | -15.5      |
| _min_discrew    | -1.48      |
| _min_obs        | -1.19      |
| _std_act        | 0.762154   |
| _std_adv        | 1          |
| _std_discrew    | 1.85       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.837       |
| ExplainedVarOld | 0.833       |
| KL              | 0.0011791   |
| Phi_loss        | 418.11      |
| PolicyEntropy   | 1.65859     |
| PolicyLoss      | -0.00974457 |
| Steps           | 10000       |
| VarFuncLoss     | 0.301       |
| _MeanReward     | 3.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64491     |
| _max_adv        | 19.2        |
| _max_discrew    | 3.82        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0669716  |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 2.9         |
| _mean_obs       | 0.0411      |
| _min_adv        | -3.97       |
| _min_discrew    | -0.000964   |
| _min_obs        | -1.26       |
| _std_act        | 0.630409    |
| _std_adv        | 1           |
| _std_discrew    | 0.831       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.941      |
| KL              | 0.011255   |
| Phi_loss        | 315.658    |
| PolicyEntropy   | 1.65983    |
| PolicyLoss      | -0.0774779 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0323     |
| _MeanReward     | 2.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.94675    |
| _max_adv        | 4.78       |
| _max_discrew    | 3.93       |
| _max_obs        | 1.09       |
| _mean_act       | -0.069982  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.12       |
| _mean_obs       | 0.0363     |
| _min_adv        | -13.4      |
| _min_discrew    | -1.55      |
| _min_obs        | -1.3       |
| _std_act        | 0.889234   |
| _std_adv        | 1          |
| _std_discrew    | 2.9        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.849      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00799767 |
| Phi_loss        | 441.517    |
| PolicyEntropy   | 1.64042    |
| PolicyLoss      | -0.196855  |
| Steps           | 10000      |
| VarFuncLoss     | 0.449      |
| _MeanReward     | 3.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.83714    |
| _max_adv        | 11.6       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0667003 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.83       |
| _mean_obs       | 0.0412     |
| _min_adv        | -14.6      |
| _min_discrew    | -0.844     |
| _min_obs        | -1.21      |
| _std_act        | 0.679672   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00110017 |
| Phi_loss        | 326.507    |
| PolicyEntropy   | 1.64712    |
| PolicyLoss      | -0.0192742 |
| Steps           | 10000      |
| VarFuncLoss     | 0.122      |
| _MeanReward     | 3.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5693     |
| _max_adv        | 11.5       |
| _max_discrew    | 3.89       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0664895 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.91       |
| _mean_obs       | 0.0413     |
| _min_adv        | -9.02      |
| _min_discrew    | -0.0091    |
| _min_obs        | -1.25      |
| _std_act        | 0.637273   |
| _std_adv        | 1          |
| _std_discrew    | 0.848      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00146034 |
| Phi_loss        | 406.932    |
| PolicyEntropy   | 1.63147    |
| PolicyLoss      | -0.0175768 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0268     |
| _MeanReward     | 3.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.7581     |
| _max_adv        | 18.7       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0666991 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.87       |
| _mean_obs       | 0.0417     |
| _min_adv        | -8.66      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.26      |
| _std_act        | 0.639663   |
| _std_adv        | 1          |
| _std_discrew    | 0.844      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.928       |
| ExplainedVarOld | 0.922       |
| KL              | 0.00361584  |
| Phi_loss        | 426.637     |
| PolicyEntropy   | 1.5896      |
| PolicyLoss      | -0.00745777 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0609      |
| _MeanReward     | 2.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.03692     |
| _max_adv        | 9.05        |
| _max_discrew    | 4.01        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0623474  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.12        |
| _mean_obs       | 0.0356      |
| _min_adv        | -14.8       |
| _min_discrew    | -1.59       |
| _min_obs        | -1.21       |
| _std_act        | 0.922654    |
| _std_adv        | 1           |
| _std_discrew    | 3.47        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.924      |
| KL              | 0.00586091 |
| Phi_loss        | 345.088    |
| PolicyEntropy   | 1.58991    |
| PolicyLoss      | -0.0109601 |
| Steps           | 10000      |
| VarFuncLoss     | 0.23       |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.07497    |
| _max_adv        | 7.67       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0656556 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.44       |
| _mean_obs       | 0.0374     |
| _min_adv        | -16.8      |
| _min_discrew    | -1.59      |
| _min_obs        | -1.21      |
| _std_act        | 0.829572   |
| _std_adv        | 1          |
| _std_discrew    | 2.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.903      |
| ExplainedVarOld | 0.899      |
| KL              | 0.00317508 |
| Phi_loss        | 418.166    |
| PolicyEntropy   | 1.59334    |
| PolicyLoss      | 0.0155936  |
| Steps           | 10000      |
| VarFuncLoss     | 0.251      |
| _MeanReward     | 3.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.11971    |
| _max_adv        | 10.1       |
| _max_discrew    | 3.91       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0664875 |
| _mean_adv       | -3.34e-17  |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.038      |
| _min_adv        | -18        |
| _min_discrew    | -1.57      |
| _min_obs        | -1.24      |
| _std_act        | 0.79568    |
| _std_adv        | 1          |
| _std_discrew    | 2.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.937        |
| ExplainedVarOld | 0.934        |
| KL              | 0.00256462   |
| Phi_loss        | 427.631      |
| PolicyEntropy   | 1.58496      |
| PolicyLoss      | -0.000696499 |
| Steps           | 10000        |
| VarFuncLoss     | 0.144        |
| _MeanReward     | 3.4e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 4.10036      |
| _max_adv        | 10.1         |
| _max_discrew    | 3.98         |
| _max_obs        | 1.18         |
| _mean_act       | -0.0671906   |
| _mean_adv       | 7.11e-18     |
| _mean_discrew   | 2.77         |
| _mean_obs       | 0.04         |
| _min_adv        | -19.2        |
| _min_discrew    | -1.48        |
| _min_obs        | -1.24        |
| _std_act        | 0.721108     |
| _std_adv        | 1            |
| _std_discrew    | 1.66         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.878        |
| ExplainedVarOld | 0.866        |
| KL              | 0.00215728   |
| Phi_loss        | 374.138      |
| PolicyEntropy   | 1.5732       |
| PolicyLoss      | -0.000476143 |
| Steps           | 10000        |
| VarFuncLoss     | 0.203        |
| _MeanReward     | 3.51e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.77128      |
| _max_adv        | 7.6          |
| _max_discrew    | 3.97         |
| _max_obs        | 1.17         |
| _mean_act       | -0.0666878   |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 2.86         |
| _mean_obs       | 0.0411       |
| _min_adv        | -17.3        |
| _min_discrew    | -1.04        |
| _min_obs        | -1.29        |
| _std_act        | 0.677411     |
| _std_adv        | 1            |
| _std_discrew    | 1.19         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.884       |
| KL              | 0.00263358  |
| Phi_loss        | 327.616     |
| PolicyEntropy   | 1.55698     |
| PolicyLoss      | 0.000415724 |
| Steps           | 10000       |
| VarFuncLoss     | 0.126       |
| _MeanReward     | 3.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.85756     |
| _max_adv        | 2.61        |
| _max_discrew    | 3.98        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0660956  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 2.75        |
| _mean_obs       | 0.0396      |
| _min_adv        | -20.8       |
| _min_discrew    | -1.45       |
| _min_obs        | -1.23       |
| _std_act        | 0.720385    |
| _std_adv        | 1           |
| _std_discrew    | 1.61        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.886      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00272894 |
| Phi_loss        | 544.931    |
| PolicyEntropy   | 1.53117    |
| PolicyLoss      | 0.0120957  |
| Steps           | 10000      |
| VarFuncLoss     | 0.183      |
| _MeanReward     | 3.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.93602    |
| _max_adv        | 5.4        |
| _max_discrew    | 3.93       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0654095 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.038      |
| _min_adv        | -17.5      |
| _min_discrew    | -1.57      |
| _min_obs        | -1.21      |
| _std_act        | 0.813689   |
| _std_adv        | 1          |
| _std_discrew    | 2.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.881      |
| ExplainedVarOld | 0.876      |
| KL              | 0.00230087 |
| Phi_loss        | 309.837    |
| PolicyEntropy   | 1.54125    |
| PolicyLoss      | 0.010613   |
| Steps           | 10000      |
| VarFuncLoss     | 0.291      |
| _MeanReward     | 3.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.88232    |
| _max_adv        | 10         |
| _max_discrew    | 4          |
| _max_obs        | 1.15       |
| _mean_act       | -0.0635705 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.73       |
| _mean_obs       | 0.0397     |
| _min_adv        | -18.7      |
| _min_discrew    | -1.43      |
| _min_obs        | -1.31      |
| _std_act        | 0.716686   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.865      |
| ExplainedVarOld | 0.863      |
| KL              | 0.00208068 |
| Phi_loss        | 298.834    |
| PolicyEntropy   | 1.54509    |
| PolicyLoss      | 0.00243424 |
| Steps           | 10000      |
| VarFuncLoss     | 0.211      |
| _MeanReward     | 3.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.91969    |
| _max_adv        | 11         |
| _max_discrew    | 4          |
| _max_obs        | 1.15       |
| _mean_act       | -0.0654078 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.7        |
| _mean_obs       | 0.04       |
| _min_adv        | -14.2      |
| _min_discrew    | -1.36      |
| _min_obs        | -1.32      |
| _std_act        | 0.751513   |
| _std_adv        | 1          |
| _std_discrew    | 1.82       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.834      |
| ExplainedVarOld | 0.824      |
| KL              | 0.00327636 |
| Phi_loss        | 385.258    |
| PolicyEntropy   | 1.5121     |
| PolicyLoss      | 0.0170233  |
| Steps           | 10000      |
| VarFuncLoss     | 0.301      |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.91398    |
| _max_adv        | 7.59       |
| _max_discrew    | 4          |
| _max_obs        | 1.19       |
| _mean_act       | -0.0670879 |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 2.66       |
| _mean_obs       | 0.0384     |
| _min_adv        | -19.6      |
| _min_discrew    | -1.55      |
| _min_obs        | -1.39      |
| _std_act        | 0.748213   |
| _std_adv        | 1          |
| _std_discrew    | 1.95       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.879      |
| KL              | 0.0022372  |
| Phi_loss        | 474.028    |
| PolicyEntropy   | 1.50667    |
| PolicyLoss      | -0.003642  |
| Steps           | 10000      |
| VarFuncLoss     | 0.229      |
| _MeanReward     | 3.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.77262    |
| _max_adv        | 3.43       |
| _max_discrew    | 3.88       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0661923 |
| _mean_adv       | -1.28e-17  |
| _mean_discrew   | 2.83       |
| _mean_obs       | 0.0398     |
| _min_adv        | -18.8      |
| _min_discrew    | -1.36      |
| _min_obs        | -1.33      |
| _std_act        | 0.698697   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.878      |
| KL              | 0.00199128 |
| Phi_loss        | 384.691    |
| PolicyEntropy   | 1.50644    |
| PolicyLoss      | -0.0119878 |
| Steps           | 10000      |
| VarFuncLoss     | 0.171      |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85205    |
| _max_adv        | 15.7       |
| _max_discrew    | 3.97       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0672626 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0405     |
| _min_adv        | -5.69      |
| _min_discrew    | 0.0111     |
| _min_obs        | -1.13      |
| _std_act        | 0.625805   |
| _std_adv        | 1          |
| _std_discrew    | 0.872      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00285339 |
| Phi_loss        | 365.512    |
| PolicyEntropy   | 1.50374    |
| PolicyLoss      | -0.0016897 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0175     |
| _MeanReward     | 3.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55506    |
| _max_adv        | 27.9       |
| _max_discrew    | 3.99       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0699583 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0405     |
| _min_adv        | -9.7       |
| _min_discrew    | 0.00393    |
| _min_obs        | -1.28      |
| _std_act        | 0.627165   |
| _std_adv        | 1          |
| _std_discrew    | 0.914      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.969       |
| ExplainedVarOld | 0.963       |
| KL              | 0.00453634  |
| Phi_loss        | 315.356     |
| PolicyEntropy   | 1.4749      |
| PolicyLoss      | -0.00363778 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0287      |
| _MeanReward     | 3.66e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.70013     |
| _max_adv        | 34          |
| _max_discrew    | 3.96        |
| _max_obs        | 1.16        |
| _mean_act       | -0.0663341  |
| _mean_adv       | -2.42e-17   |
| _mean_discrew   | 3.02        |
| _mean_obs       | 0.0404      |
| _min_adv        | -6.52       |
| _min_discrew    | 0.00679     |
| _min_obs        | -1.17       |
| _std_act        | 0.629976    |
| _std_adv        | 1           |
| _std_discrew    | 0.872       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00422794 |
| Phi_loss        | 410.667    |
| PolicyEntropy   | 1.43574    |
| PolicyLoss      | 0.0152095  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0126     |
| _MeanReward     | 3.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.88445    |
| _max_adv        | 13.6       |
| _max_discrew    | 4          |
| _max_obs        | 1.22       |
| _mean_act       | -0.0659411 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.66       |
| _mean_obs       | 0.0384     |
| _min_adv        | -19.1      |
| _min_discrew    | -1.47      |
| _min_obs        | -1.29      |
| _std_act        | 0.753739   |
| _std_adv        | 1          |
| _std_discrew    | 1.96       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.868       |
| KL              | 0.0250893   |
| Phi_loss        | 603.026     |
| PolicyEntropy   | 1.42779     |
| PolicyLoss      | -0.00342237 |
| Steps           | 10000       |
| VarFuncLoss     | 0.228       |
| _MeanReward     | 3.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69084     |
| _max_adv        | 14          |
| _max_discrew    | 4.01        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0631134  |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0415      |
| _min_adv        | -11.9       |
| _min_discrew    | 0.00758     |
| _min_obs        | -1.31       |
| _std_act        | 0.629332    |
| _std_adv        | 1           |
| _std_discrew    | 0.888       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00363168 |
| Phi_loss        | 412.885    |
| PolicyEntropy   | 1.41906    |
| PolicyLoss      | -0.0116894 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0337     |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.93584    |
| _max_adv        | 2.21       |
| _max_discrew    | 3.97       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0548705 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.66       |
| _mean_obs       | 0.0382     |
| _min_adv        | -19.2      |
| _min_discrew    | -1.33      |
| _min_obs        | -1.27      |
| _std_act        | 0.757231   |
| _std_adv        | 1          |
| _std_discrew    | 2.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.933       |
| ExplainedVarOld | 0.928       |
| KL              | 0.00172256  |
| Phi_loss        | 339.68      |
| PolicyEntropy   | 1.42375     |
| PolicyLoss      | -0.00427395 |
| Steps           | 10000       |
| VarFuncLoss     | 0.152       |
| _MeanReward     | 3.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66042     |
| _max_adv        | 6.9         |
| _max_discrew    | 4.06        |
| _max_obs        | 1.12        |
| _mean_act       | -0.0643485  |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 3.04        |
| _mean_obs       | 0.0408      |
| _min_adv        | -3.8        |
| _min_discrew    | 0.00671     |
| _min_obs        | -1.33       |
| _std_act        | 0.623086    |
| _std_adv        | 1           |
| _std_discrew    | 0.907       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00225904 |
| Phi_loss        | 405.215    |
| PolicyEntropy   | 1.40255    |
| PolicyLoss      | -0.0152359 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 3.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50313    |
| _max_adv        | 22.6       |
| _max_discrew    | 4.15       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0680371 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0407     |
| _min_adv        | -7.16      |
| _min_discrew    | 0.00753    |
| _min_obs        | -1.27      |
| _std_act        | 0.621152   |
| _std_adv        | 1          |
| _std_discrew    | 0.891      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.969       |
| KL              | 0.00232394  |
| Phi_loss        | 445.326     |
| PolicyEntropy   | 1.38607     |
| PolicyLoss      | -0.00930762 |
| Steps           | 10000       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 3.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.86508     |
| _max_adv        | 3.43        |
| _max_discrew    | 4.04        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0637356  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 2.81        |
| _mean_obs       | 0.0397      |
| _min_adv        | -13.8       |
| _min_discrew    | -0.983      |
| _min_obs        | -1.36       |
| _std_act        | 0.701467    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.864      |
| ExplainedVarOld | 0.851      |
| KL              | 0.00272492 |
| Phi_loss        | 429.318    |
| PolicyEntropy   | 1.37916    |
| PolicyLoss      | -0.0222024 |
| Steps           | 10000      |
| VarFuncLoss     | 0.22       |
| _MeanReward     | 2.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.89467    |
| _max_adv        | 4.59       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0458402 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.0362     |
| _min_adv        | -12.6      |
| _min_discrew    | -1.27      |
| _min_obs        | -1.26      |
| _std_act        | 0.830734   |
| _std_adv        | 1          |
| _std_discrew    | 2.92       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.829      |
| ExplainedVarOld | 0.82       |
| KL              | 0.00151213 |
| Phi_loss        | 435.393    |
| PolicyEntropy   | 1.37784    |
| PolicyLoss      | 0.0109592  |
| Steps           | 10000      |
| VarFuncLoss     | 0.505      |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81477    |
| _max_adv        | 26         |
| _max_discrew    | 4.2        |
| _max_obs        | 1.13       |
| _mean_act       | -0.0658504 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.11       |
| _mean_obs       | 0.0406     |
| _min_adv        | -4.62      |
| _min_discrew    | 0.0124     |
| _min_obs        | -1.26      |
| _std_act        | 0.625571   |
| _std_adv        | 1          |
| _std_discrew    | 0.934      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00163479 |
| Phi_loss        | 491.648    |
| PolicyEntropy   | 1.36584    |
| PolicyLoss      | 0.00652167 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0484     |
| _MeanReward     | 3.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.63756    |
| _max_adv        | 16.2       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0634353 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 2.94       |
| _mean_obs       | 0.0397     |
| _min_adv        | -16.4      |
| _min_discrew    | -0.765     |
| _min_obs        | -1.22      |
| _std_act        | 0.651481   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00212146 |
| Phi_loss        | 415.8      |
| PolicyEntropy   | 1.36899    |
| PolicyLoss      | 0.00919921 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0992     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.76014    |
| _max_adv        | 3.52       |
| _max_discrew    | 4.18       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0635945 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.88       |
| _mean_obs       | 0.0399     |
| _min_adv        | -16.3      |
| _min_discrew    | -1.13      |
| _min_obs        | -1.18      |
| _std_act        | 0.686082   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.873       |
| KL              | 0.00236905  |
| Phi_loss        | 399.596     |
| PolicyEntropy   | 1.36112     |
| PolicyLoss      | -0.00590578 |
| Steps           | 10000       |
| VarFuncLoss     | 0.178       |
| _MeanReward     | 3.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.63465     |
| _max_adv        | 12          |
| _max_discrew    | 4.08        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0689149  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.04        |
| _mean_obs       | 0.0405      |
| _min_adv        | -11.4       |
| _min_discrew    | 0.0148      |
| _min_obs        | -1.25       |
| _std_act        | 0.628394    |
| _std_adv        | 1           |
| _std_discrew    | 0.924       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00162239 |
| Phi_loss        | 430.849    |
| PolicyEntropy   | 1.34369    |
| PolicyLoss      | -0.0194612 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0306     |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64383    |
| _max_adv        | 17.1       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0654903 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.11       |
| _mean_obs       | 0.041      |
| _min_adv        | -10.9      |
| _min_discrew    | 0.00838    |
| _min_obs        | -1.36      |
| _std_act        | 0.617825   |
| _std_adv        | 1          |
| _std_discrew    | 0.907      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00161263  |
| Phi_loss        | 398.033     |
| PolicyEntropy   | 1.3371      |
| PolicyLoss      | -0.00861205 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0244      |
| _MeanReward     | 2.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.12087     |
| _max_adv        | 1.44        |
| _max_discrew    | 4.07        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0388081  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.86        |
| _mean_obs       | 0.0332      |
| _min_adv        | -11         |
| _min_discrew    | -1.33       |
| _min_obs        | -1.34       |
| _std_act        | 0.920219    |
| _std_adv        | 1           |
| _std_discrew    | 3.92        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.844      |
| ExplainedVarOld | 0.828      |
| KL              | 0.00738843 |
| Phi_loss        | 431.353    |
| PolicyEntropy   | 1.34871    |
| PolicyLoss      | -0.0835138 |
| Steps           | 10000      |
| VarFuncLoss     | 0.63       |
| _MeanReward     | 3.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61346    |
| _max_adv        | 19.1       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0689296 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.05       |
| _mean_obs       | 0.0401     |
| _min_adv        | -9.06      |
| _min_discrew    | 0.00996    |
| _min_obs        | -1.24      |
| _std_act        | 0.624481   |
| _std_adv        | 1          |
| _std_discrew    | 0.961      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00428833 |
| Phi_loss        | 319.885    |
| PolicyEntropy   | 1.35986    |
| PolicyLoss      | 0.00890333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0653     |
| _MeanReward     | 3.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.77044    |
| _max_adv        | 15.6       |
| _max_discrew    | 4.14       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0649302 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0399     |
| _min_adv        | -17.3      |
| _min_discrew    | -0.699     |
| _min_obs        | -1.14      |
| _std_act        | 0.650233   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.933      |
| ExplainedVarOld | 0.909      |
| KL              | 0.00277145 |
| Phi_loss        | 467.839    |
| PolicyEntropy   | 1.35654    |
| PolicyLoss      | -0.0280776 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0791     |
| _MeanReward     | 3.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72874    |
| _max_adv        | 5.45       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0649238 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.0401     |
| _min_adv        | -4.89      |
| _min_discrew    | 0.00895    |
| _min_obs        | -1.16      |
| _std_act        | 0.617005   |
| _std_adv        | 1          |
| _std_discrew    | 0.961      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.000988155 |
| Phi_loss        | 434.931     |
| PolicyEntropy   | 1.33434     |
| PolicyLoss      | -0.0194297  |
| Steps           | 10000       |
| VarFuncLoss     | 0.016       |
| _MeanReward     | 3.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.70918     |
| _max_adv        | 11.9        |
| _max_discrew    | 4.15        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0658745  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.1         |
| _mean_obs       | 0.0406      |
| _min_adv        | -12.6       |
| _min_discrew    | 0.0104      |
| _min_obs        | -1.19       |
| _std_act        | 0.626229    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00182342 |
| Phi_loss        | 455.306    |
| PolicyEntropy   | 1.30074    |
| PolicyLoss      | 0.0074294  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0283     |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60577    |
| _max_adv        | 4.18       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0666328 |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.0408     |
| _min_adv        | -4.72      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.28      |
| _std_act        | 0.626108   |
| _std_adv        | 1          |
| _std_discrew    | 0.934      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00175366 |
| Phi_loss        | 483.819    |
| PolicyEntropy   | 1.2841     |
| PolicyLoss      | -0.025492  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0141     |
| _MeanReward     | 3.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72294    |
| _max_adv        | 5.95       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0692004 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0413     |
| _min_adv        | -4.77      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.25      |
| _std_act        | 0.622832   |
| _std_adv        | 1          |
| _std_discrew    | 0.946      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00150433 |
| Phi_loss        | 512.122    |
| PolicyEntropy   | 1.26442    |
| PolicyLoss      | -0.0222662 |
| Steps           | 10000      |
| VarFuncLoss     | 0.015      |
| _MeanReward     | 3.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.86607    |
| _max_adv        | 4.03       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0690381 |
| _mean_adv       | -4.69e-17  |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.0409     |
| _min_adv        | -4.82      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.19      |
| _std_act        | 0.624706   |
| _std_adv        | 1          |
| _std_discrew    | 0.957      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00161851 |
| Phi_loss        | 524.404    |
| PolicyEntropy   | 1.24047    |
| PolicyLoss      | -0.0219205 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00918    |
| _MeanReward     | 3.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92364    |
| _max_adv        | 14.3       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0707553 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0407     |
| _min_adv        | -9.19      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.33      |
| _std_act        | 0.632987   |
| _std_adv        | 1          |
| _std_discrew    | 0.968      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00186271 |
| Phi_loss        | 536.902    |
| PolicyEntropy   | 1.22298    |
| PolicyLoss      | -0.0127793 |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.46678    |
| _max_adv        | 20.1       |
| _max_discrew    | 4.19       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0703176 |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.0407     |
| _min_adv        | -10.3      |
| _min_discrew    | -0.0593    |
| _min_obs        | -1.37      |
| _std_act        | 0.63441    |
| _std_adv        | 1          |
| _std_discrew    | 0.923      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.967       |
| KL              | 0.00385718  |
| Phi_loss        | 521.964     |
| PolicyEntropy   | 1.20585     |
| PolicyLoss      | -0.00864041 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0267      |
| _MeanReward     | 3.66e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.0287      |
| _max_adv        | 0.993       |
| _max_discrew    | 4.38        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0639375  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 2.98        |
| _mean_obs       | 0.0396      |
| _min_adv        | -17.2       |
| _min_discrew    | -1.23       |
| _min_obs        | -1.35       |
| _std_act        | 0.700329    |
| _std_adv        | 1           |
| _std_discrew    | 1.7         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.891      |
| ExplainedVarOld | 0.882      |
| KL              | 0.00152838 |
| Phi_loss        | 314.986    |
| PolicyEntropy   | 1.21152    |
| PolicyLoss      | -0.0336622 |
| Steps           | 10000      |
| VarFuncLoss     | 0.186      |
| _MeanReward     | 3.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76407    |
| _max_adv        | 14.3       |
| _max_discrew    | 4.36       |
| _max_obs        | 1.23       |
| _mean_act       | -0.071686  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0405     |
| _min_adv        | -4.35      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.32      |
| _std_act        | 0.625228   |
| _std_adv        | 1          |
| _std_discrew    | 0.973      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00263533 |
| Phi_loss        | 461.114    |
| PolicyEntropy   | 1.19432    |
| PolicyLoss      | -0.0122883 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0178     |
| _MeanReward     | 3.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.59305    |
| _max_adv        | 7.67       |
| _max_discrew    | 4.35       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0717969 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0403     |
| _min_adv        | -5.03      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.17      |
| _std_act        | 0.623428   |
| _std_adv        | 1          |
| _std_discrew    | 0.991      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.978       |
| KL              | 0.0021834   |
| Phi_loss        | 489.298     |
| PolicyEntropy   | 1.18        |
| PolicyLoss      | -0.00735526 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0175      |
| _MeanReward     | 3.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.95387     |
| _max_adv        | 1.53        |
| _max_discrew    | 4.37        |
| _max_obs        | 1.13        |
| _mean_act       | -0.0633791  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.93        |
| _mean_obs       | 0.0393      |
| _min_adv        | -19.3       |
| _min_discrew    | -1.37       |
| _min_obs        | -1.25       |
| _std_act        | 0.735148    |
| _std_adv        | 1           |
| _std_discrew    | 2.18        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.893       |
| ExplainedVarOld | 0.888       |
| KL              | 0.00213248  |
| Phi_loss        | 470.706     |
| PolicyEntropy   | 1.18043     |
| PolicyLoss      | -0.00708203 |
| Steps           | 10000       |
| VarFuncLoss     | 0.234       |
| _MeanReward     | 3.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.96725     |
| _max_adv        | 9.2         |
| _max_discrew    | 4.22        |
| _max_obs        | 1.12        |
| _mean_act       | -0.0552284  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.46        |
| _mean_obs       | 0.0358      |
| _min_adv        | -14.1       |
| _min_discrew    | -1.4        |
| _min_obs        | -1.18       |
| _std_act        | 0.842347    |
| _std_adv        | 1           |
| _std_discrew    | 3.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.871      |
| KL              | 0.00140996 |
| Phi_loss        | 474.331    |
| PolicyEntropy   | 1.18052    |
| PolicyLoss      | 0.0105102  |
| Steps           | 10000      |
| VarFuncLoss     | 0.383      |
| _MeanReward     | 3.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.12045    |
| _max_adv        | 20.7       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0724886 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.27       |
| _mean_obs       | 0.0411     |
| _min_adv        | -9.16      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.32      |
| _std_act        | 0.624884   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.925      |
| KL              | 0.0130312  |
| Phi_loss        | 333.765    |
| PolicyEntropy   | 1.19433    |
| PolicyLoss      | -0.195959  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0536     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56206    |
| _max_adv        | 42.7       |
| _max_discrew    | 4.37       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0694633 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.0411     |
| _min_adv        | -6.91      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.21      |
| _std_act        | 0.624853   |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.968       |
| KL              | 0.00438745  |
| Phi_loss        | 562.137     |
| PolicyEntropy   | 1.18765     |
| PolicyLoss      | -0.00502117 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0194      |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56978     |
| _max_adv        | 22.3        |
| _max_discrew    | 4.36        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0721452  |
| _mean_adv       | -3.27e-17   |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0412      |
| _min_adv        | -11.3       |
| _min_discrew    | 0.0144      |
| _min_obs        | -1.15       |
| _std_act        | 0.628169    |
| _std_adv        | 1           |
| _std_discrew    | 1.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00211246 |
| Phi_loss        | 516.792    |
| PolicyEntropy   | 1.18124    |
| PolicyLoss      | 0.00835788 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0339     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57509    |
| _max_adv        | 2.93       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0691811 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.041      |
| _min_adv        | -9.96      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.33      |
| _std_act        | 0.623932   |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00173415 |
| Phi_loss        | 556.908    |
| PolicyEntropy   | 1.16186    |
| PolicyLoss      | -0.0135537 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0186     |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.47864    |
| _max_adv        | 5.55       |
| _max_discrew    | 4.3        |
| _max_obs        | 1.11       |
| _mean_act       | -0.0688345 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.31       |
| _mean_obs       | 0.0412     |
| _min_adv        | -5.07      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.24      |
| _std_act        | 0.623624   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00160169  |
| Phi_loss        | 587.327     |
| PolicyEntropy   | 1.13183     |
| PolicyLoss      | -0.00895276 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 3.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.88137     |
| _max_adv        | 14.3        |
| _max_discrew    | 4.38        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0681739  |
| _mean_adv       | 5.68e-17    |
| _mean_discrew   | 3.11        |
| _mean_obs       | 0.0402      |
| _min_adv        | -14.6       |
| _min_discrew    | -1.16       |
| _min_obs        | -1.34       |
| _std_act        | 0.688837    |
| _std_adv        | 1           |
| _std_discrew    | 1.61        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.88       |
| ExplainedVarOld | 0.845      |
| KL              | 0.0030369  |
| Phi_loss        | 528.357    |
| PolicyEntropy   | 1.11989    |
| PolicyLoss      | 0.01546    |
| Steps           | 10000      |
| VarFuncLoss     | 0.197      |
| _MeanReward     | 4.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63179    |
| _max_adv        | 19.2       |
| _max_discrew    | 4.44       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0696396 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0411     |
| _min_adv        | -6.13      |
| _min_discrew    | 0.00956    |
| _min_obs        | -1.23      |
| _std_act        | 0.621342   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00183004 |
| Phi_loss        | 548.461    |
| PolicyEntropy   | 1.10186    |
| PolicyLoss      | 0.00993971 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0196     |
| _MeanReward     | 3.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.03535    |
| _max_adv        | 4.83       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0667953 |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.03       |
| _mean_obs       | 0.0397     |
| _min_adv        | -19.4      |
| _min_discrew    | -1.29      |
| _min_obs        | -1.28      |
| _std_act        | 0.706783   |
| _std_adv        | 1          |
| _std_discrew    | 1.91       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.881      |
| KL              | 0.00161909 |
| Phi_loss        | 496.8      |
| PolicyEntropy   | 1.10596    |
| PolicyLoss      | -0.0220877 |
| Steps           | 10000      |
| VarFuncLoss     | 0.217      |
| _MeanReward     | 3.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.06508    |
| _max_adv        | 6.96       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.15       |
| _mean_act       | -0.066339  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.82       |
| _mean_obs       | 0.0388     |
| _min_adv        | -15.8      |
| _min_discrew    | -1.31      |
| _min_obs        | -1.27      |
| _std_act        | 0.746156   |
| _std_adv        | 1          |
| _std_discrew    | 2.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.857      |
| ExplainedVarOld | 0.849      |
| KL              | 0.00326821 |
| Phi_loss        | 540.021    |
| PolicyEntropy   | 1.11105    |
| PolicyLoss      | 0.00264599 |
| Steps           | 10000      |
| VarFuncLoss     | 0.341      |
| _MeanReward     | 3.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.93149    |
| _max_adv        | 9.27       |
| _max_discrew    | 4.24       |
| _max_obs        | 1.11       |
| _mean_act       | -0.061085  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.86       |
| _mean_obs       | 0.0382     |
| _min_adv        | -18.8      |
| _min_discrew    | -1.42      |
| _min_obs        | -1.2       |
| _std_act        | 0.754186   |
| _std_adv        | 1          |
| _std_discrew    | 2.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.9        |
| KL              | 0.00165679 |
| Phi_loss        | 372.381    |
| PolicyEntropy   | 1.11164    |
| PolicyLoss      | 0.00136177 |
| Steps           | 10000      |
| VarFuncLoss     | 0.227      |
| _MeanReward     | 3.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.77434    |
| _max_adv        | 18.1       |
| _max_discrew    | 4.35       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0729284 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0406     |
| _min_adv        | -11.8      |
| _min_discrew    | -0.631     |
| _min_obs        | -1.27      |
| _std_act        | 0.649972   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.926       |
| ExplainedVarOld | 0.907       |
| KL              | 0.00377578  |
| Phi_loss        | 436.274     |
| PolicyEntropy   | 1.10279     |
| PolicyLoss      | -0.00757076 |
| Steps           | 10000       |
| VarFuncLoss     | 0.105       |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79787     |
| _max_adv        | 15.6        |
| _max_discrew    | 4.38        |
| _max_obs        | 1.16        |
| _mean_act       | -0.0711918  |
| _mean_adv       | -7.96e-17   |
| _mean_discrew   | 3.34        |
| _mean_obs       | 0.0413      |
| _min_adv        | -4.82       |
| _min_discrew    | 0.0136      |
| _min_obs        | -1.21       |
| _std_act        | 0.625159    |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00181169  |
| Phi_loss        | 449.117     |
| PolicyEntropy   | 1.08748     |
| PolicyLoss      | -0.00860359 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0264      |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71015     |
| _max_adv        | 5           |
| _max_discrew    | 4.39        |
| _max_obs        | 1.15        |
| _mean_act       | -0.0721417  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.35        |
| _mean_obs       | 0.0409      |
| _min_adv        | -4.19       |
| _min_discrew    | 0.00814     |
| _min_obs        | -1.3        |
| _std_act        | 0.624603    |
| _std_adv        | 1           |
| _std_discrew    | 1.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00146356 |
| Phi_loss        | 519.861    |
| PolicyEntropy   | 1.07837    |
| PolicyLoss      | -0.0230674 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0148     |
| _MeanReward     | 3.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.94637    |
| _max_adv        | 1.72       |
| _max_discrew    | 4.4        |
| _max_obs        | 1.22       |
| _mean_act       | -0.0644359 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3          |
| _mean_obs       | 0.039      |
| _min_adv        | -19.9      |
| _min_discrew    | -1.37      |
| _min_obs        | -1.25      |
| _std_act        | 0.736314   |
| _std_adv        | 1          |
| _std_discrew    | 2.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.894      |
| ExplainedVarOld | 0.888      |
| KL              | 0.00504063 |
| Phi_loss        | 465.393    |
| PolicyEntropy   | 1.08133    |
| PolicyLoss      | -0.0101436 |
| Steps           | 10000      |
| VarFuncLoss     | 0.24       |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59256    |
| _max_adv        | 30.9       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.14       |
| _mean_act       | -0.073564  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.32       |
| _mean_obs       | 0.0409     |
| _min_adv        | -7.19      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.29      |
| _std_act        | 0.626365   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.979     |
| ExplainedVarOld | 0.978     |
| KL              | 0.0150089 |
| Phi_loss        | 616.329   |
| PolicyEntropy   | 1.08214   |
| PolicyLoss      | 0.166851  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0231    |
| _MeanReward     | 3.57e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.9831    |
| _max_adv        | 1.6       |
| _max_discrew    | 4.59      |
| _max_obs        | 1.16      |
| _mean_act       | -0.070825 |
| _mean_adv       | 0         |
| _mean_discrew   | 2.9       |
| _mean_obs       | 0.0374    |
| _min_adv        | -18.4     |
| _min_discrew    | -1.34     |
| _min_obs        | -1.23     |
| _std_act        | 0.749669  |
| _std_adv        | 1         |
| _std_discrew    | 2.6       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.917      |
| KL              | 0.0188232  |
| Phi_loss        | 945.234    |
| PolicyEntropy   | 1.08465    |
| PolicyLoss      | 0.0232287  |
| Steps           | 10000      |
| VarFuncLoss     | 0.199      |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80409    |
| _max_adv        | 15.7       |
| _max_discrew    | 4.34       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0783931 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.31       |
| _mean_obs       | 0.0401     |
| _min_adv        | -14        |
| _min_discrew    | 0.0104     |
| _min_obs        | -1.17      |
| _std_act        | 0.625275   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00234536 |
| Phi_loss        | 676.326    |
| PolicyEntropy   | 1.06711    |
| PolicyLoss      | -0.0113527 |
| Steps           | 10000      |
| VarFuncLoss     | 0.029      |
| _MeanReward     | 3.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.98537    |
| _max_adv        | 1.92       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0618483 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0388     |
| _min_adv        | -19.8      |
| _min_discrew    | -1.35      |
| _min_obs        | -1.26      |
| _std_act        | 0.724076   |
| _std_adv        | 1          |
| _std_discrew    | 2.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.89        |
| KL              | 0.000879619 |
| Phi_loss        | 438.817     |
| PolicyEntropy   | 1.06185     |
| PolicyLoss      | -0.0118053  |
| Steps           | 10000       |
| VarFuncLoss     | 0.234       |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78015     |
| _max_adv        | 24.1        |
| _max_discrew    | 4.6         |
| _max_obs        | 1.14        |
| _mean_act       | -0.0793357  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0401      |
| _min_adv        | -9.65       |
| _min_discrew    | -0.00404    |
| _min_obs        | -1.17       |
| _std_act        | 0.626176    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.949      |
| KL              | 0.00536049 |
| Phi_loss        | 397.464    |
| PolicyEntropy   | 1.05197    |
| PolicyLoss      | 0.0016992  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0372     |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68977    |
| _max_adv        | 22.7       |
| _max_discrew    | 4.38       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0788537 |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.0401     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.19      |
| _std_act        | 0.625894   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00212088  |
| Phi_loss        | 442.809     |
| PolicyEntropy   | 1.03029     |
| PolicyLoss      | -0.00953541 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0211      |
| _MeanReward     | 3.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 4.13242     |
| _max_adv        | 2.28        |
| _max_discrew    | 4.44        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0672187  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.07        |
| _mean_obs       | 0.0389      |
| _min_adv        | -19         |
| _min_discrew    | -1.22       |
| _min_obs        | -1.15       |
| _std_act        | 0.703841    |
| _std_adv        | 1           |
| _std_discrew    | 1.89        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.882      |
| ExplainedVarOld | 0.877      |
| KL              | 0.00618651 |
| Phi_loss        | 538.363    |
| PolicyEntropy   | 1.01195    |
| PolicyLoss      | 0.0640037  |
| Steps           | 10000      |
| VarFuncLoss     | 0.226      |
| _MeanReward     | 4.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.15989    |
| _max_adv        | 5.11       |
| _max_discrew    | 4.5        |
| _max_obs        | 1.07       |
| _mean_act       | -0.0768567 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0402     |
| _min_adv        | -14.7      |
| _min_discrew    | -0.63      |
| _min_obs        | -1.15      |
| _std_act        | 0.645867   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.906       |
| KL              | 0.000802255 |
| Phi_loss        | 571.036     |
| PolicyEntropy   | 1.00853     |
| PolicyLoss      | 0.00540101  |
| Steps           | 10000       |
| VarFuncLoss     | 0.114       |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.97128     |
| _max_adv        | 21          |
| _max_discrew    | 4.44        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0764855  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.32        |
| _mean_obs       | 0.0402      |
| _min_adv        | -8.5        |
| _min_discrew    | -0.0492     |
| _min_obs        | -1.23       |
| _std_act        | 0.627271    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00332578 |
| Phi_loss        | 452.008    |
| PolicyEntropy   | 0.99762    |
| PolicyLoss      | 0.00822986 |
| Steps           | 10000      |
| VarFuncLoss     | 0.026      |
| _MeanReward     | 3.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.20042    |
| _max_adv        | 10.3       |
| _max_discrew    | 4.33       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0709122 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0393     |
| _min_adv        | -14.5      |
| _min_discrew    | -0.961     |
| _min_obs        | -1.24      |
| _std_act        | 0.666214   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.892      |
| ExplainedVarOld | 0.885      |
| KL              | 0.00321327 |
| Phi_loss        | 553.422    |
| PolicyEntropy   | 0.982879   |
| PolicyLoss      | -0.036441  |
| Steps           | 10000      |
| VarFuncLoss     | 0.161      |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.19605    |
| _max_adv        | 6.28       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0651855 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.08       |
| _mean_obs       | 0.0389     |
| _min_adv        | -18.6      |
| _min_discrew    | -1.25      |
| _min_obs        | -1.25      |
| _std_act        | 0.691175   |
| _std_adv        | 1          |
| _std_discrew    | 1.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.886      |
| ExplainedVarOld | 0.878      |
| KL              | 0.00164078 |
| Phi_loss        | 586.16     |
| PolicyEntropy   | 0.978577   |
| PolicyLoss      | 0.00113916 |
| Steps           | 10000      |
| VarFuncLoss     | 0.199      |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.71058    |
| _max_adv        | 20.8       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0788364 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0393     |
| _min_adv        | -11        |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.19      |
| _std_act        | 0.617267   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00211386 |
| Phi_loss        | 609.992    |
| PolicyEntropy   | 0.954842   |
| PolicyLoss      | -0.0091218 |
| Steps           | 10000      |
| VarFuncLoss     | 0.026      |
| _MeanReward     | 4.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.40804    |
| _max_adv        | 7.01       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0791716 |
| _mean_adv       | -9.38e-17  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0401     |
| _min_adv        | -4.56      |
| _min_discrew    | -0.00183   |
| _min_obs        | -1.19      |
| _std_act        | 0.622182   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.985      |
| KL              | 0.00206592 |
| Phi_loss        | 609.956    |
| PolicyEntropy   | 0.943699   |
| PolicyLoss      | -0.0177083 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.42109    |
| _max_adv        | 3.96       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0555346 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.94       |
| _mean_obs       | 0.039      |
| _min_adv        | -18.4      |
| _min_discrew    | -1.46      |
| _min_obs        | -1.27      |
| _std_act        | 0.756439   |
| _std_adv        | 1          |
| _std_discrew    | 2.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.896      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00359997 |
| Phi_loss        | 767.655    |
| PolicyEntropy   | 0.927665   |
| PolicyLoss      | -0.0113222 |
| Steps           | 10000      |
| VarFuncLoss     | 0.257      |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59487    |
| _max_adv        | 26.8       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0781516 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0402     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.16      |
| _std_act        | 0.625544   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00539801 |
| Phi_loss        | 491.74     |
| PolicyEntropy   | 0.91575    |
| PolicyLoss      | 0.0289982  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0373     |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66636    |
| _max_adv        | 11.3       |
| _max_discrew    | 4.47       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0780724 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0403     |
| _min_adv        | -9.73      |
| _min_discrew    | 0.011      |
| _min_obs        | -1.23      |
| _std_act        | 0.622678   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.96        |
| KL              | 0.00194667  |
| Phi_loss        | 743.136     |
| PolicyEntropy   | 0.896245    |
| PolicyLoss      | -0.00803708 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0411      |
| _MeanReward     | 4.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5146      |
| _max_adv        | 22.5        |
| _max_discrew    | 4.52        |
| _max_obs        | 1.15        |
| _mean_act       | -0.0778479  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.41        |
| _mean_obs       | 0.0406      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.27       |
| _std_act        | 0.625291    |
| _std_adv        | 1           |
| _std_discrew    | 1.09        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00200268 |
| Phi_loss        | 613.965    |
| PolicyEntropy   | 0.892584   |
| PolicyLoss      | -0.0109895 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0354     |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.669      |
| _max_adv        | 9.7        |
| _max_discrew    | 4.52       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0823245 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0396     |
| _min_adv        | -7.3       |
| _min_discrew    | 0.00679    |
| _min_obs        | -1.22      |
| _std_act        | 0.620395   |
| _std_adv        | 1          |
| _std_discrew    | 1.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.987      |
| KL              | 0.0013985  |
| Phi_loss        | 675.6      |
| PolicyEntropy   | 0.866178   |
| PolicyLoss      | -0.0071979 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79705    |
| _max_adv        | 6.43       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0820857 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0401     |
| _min_adv        | -13.7      |
| _min_discrew    | 0.00932    |
| _min_obs        | -1.19      |
| _std_act        | 0.620986   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00514752 |
| Phi_loss        | 761.923    |
| PolicyEntropy   | 0.826512   |
| PolicyLoss      | -0.0138706 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52995    |
| _max_adv        | 2.97       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0811584 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.0404     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0212     |
| _min_obs        | -1.22      |
| _std_act        | 0.630196   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00359601 |
| Phi_loss        | 701.147    |
| PolicyEntropy   | 0.802944   |
| PolicyLoss      | -0.0117145 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0342     |
| _MeanReward     | 4.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81583    |
| _max_adv        | 7.33       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0843049 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0396     |
| _min_adv        | -11.6      |
| _min_discrew    | 0.00853    |
| _min_obs        | -1.26      |
| _std_act        | 0.626794   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00303607 |
| Phi_loss        | 619.598    |
| PolicyEntropy   | 0.779478   |
| PolicyLoss      | -0.0207424 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0415     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53094    |
| _max_adv        | 13.2       |
| _max_discrew    | 4.61       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0859519 |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.0397     |
| _min_adv        | -12.5      |
| _min_discrew    | 0.013      |
| _min_obs        | -1.13      |
| _std_act        | 0.632447   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00465294 |
| Phi_loss        | 646.071    |
| PolicyEntropy   | 0.750991   |
| PolicyLoss      | 0.00167918 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0403     |
| _MeanReward     | 4.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.24282    |
| _max_adv        | 6.51       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0767411 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0394     |
| _min_adv        | -17.1      |
| _min_discrew    | -1.16      |
| _min_obs        | -1.12      |
| _std_act        | 0.686105   |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.876      |
| ExplainedVarOld | 0.863      |
| KL              | 0.00567507 |
| Phi_loss        | 808.53     |
| PolicyEntropy   | 0.726664   |
| PolicyLoss      | 0.0161364  |
| Steps           | 10000      |
| VarFuncLoss     | 0.215      |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66847    |
| _max_adv        | 13.2       |
| _max_discrew    | 4.57       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0850315 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.04       |
| _min_adv        | -13.4      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.35      |
| _std_act        | 0.627601   |
| _std_adv        | 1          |
| _std_discrew    | 1.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.953     |
| ExplainedVarOld | 0.948     |
| KL              | 0.0130001 |
| Phi_loss        | 715.361   |
| PolicyEntropy   | 0.728468  |
| PolicyLoss      | -0.127726 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0552    |
| _MeanReward     | 4.16e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.52402   |
| _max_adv        | 9.21      |
| _max_discrew    | 4.55      |
| _max_obs        | 1.11      |
| _mean_act       | -0.086245 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.41      |
| _mean_obs       | 0.0393    |
| _min_adv        | -11.3     |
| _min_discrew    | -0.0659   |
| _min_obs        | -1.22     |
| _std_act        | 0.629051  |
| _std_adv        | 1         |
| _std_discrew    | 1.24      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00250987 |
| Phi_loss        | 774.835    |
| PolicyEntropy   | 0.720417   |
| PolicyLoss      | -0.0342394 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0274     |
| _MeanReward     | 4.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47944    |
| _max_adv        | 21.6       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0856289 |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0401     |
| _min_adv        | -8.49      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.34      |
| _std_act        | 0.630586   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00689759  |
| Phi_loss        | 674.529     |
| PolicyEntropy   | 0.690164    |
| PolicyLoss      | -0.00341305 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0156      |
| _MeanReward     | 4.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.60951     |
| _max_adv        | 3.67        |
| _max_discrew    | 4.56        |
| _max_obs        | 1.13        |
| _mean_act       | -0.0842855  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.45        |
| _mean_obs       | 0.0396      |
| _min_adv        | -4.42       |
| _min_discrew    | 0.00695     |
| _min_obs        | -1.17       |
| _std_act        | 0.629609    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00138664 |
| Phi_loss        | 830.177    |
| PolicyEntropy   | 0.679865   |
| PolicyLoss      | -0.0207164 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0153     |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48907    |
| _max_adv        | 3.46       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0830798 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0398     |
| _min_adv        | -13.1      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.13      |
| _std_act        | 0.630343   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00251326  |
| Phi_loss        | 771.422     |
| PolicyEntropy   | 0.661508    |
| PolicyLoss      | -0.00611575 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0224      |
| _MeanReward     | 3.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 4.48642     |
| _max_adv        | 2.49        |
| _max_discrew    | 4.59        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0708085  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0388      |
| _min_adv        | -18.5       |
| _min_discrew    | -1.45       |
| _min_obs        | -1.22       |
| _std_act        | 0.733921    |
| _std_adv        | 1           |
| _std_discrew    | 2.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.886      |
| ExplainedVarOld | 0.876      |
| KL              | 0.00196066 |
| Phi_loss        | 1225.0     |
| PolicyEntropy   | 0.652067   |
| PolicyLoss      | -0.0168055 |
| Steps           | 10000      |
| VarFuncLoss     | 0.249      |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51666    |
| _max_adv        | 15.7       |
| _max_discrew    | 4.5        |
| _max_obs        | 1.21       |
| _mean_act       | -0.0861104 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.04       |
| _min_adv        | -13.9      |
| _min_discrew    | 0.012      |
| _min_obs        | -1.19      |
| _std_act        | 0.633456   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.967      |
| KL              | 0.00198117 |
| Phi_loss        | 596.665    |
| PolicyEntropy   | 0.650922   |
| PolicyLoss      | -0.0167091 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0383     |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75982    |
| _max_adv        | 4.17       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0831195 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0402     |
| _min_adv        | -4.98      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.2       |
| _std_act        | 0.629386   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00182253 |
| Phi_loss        | 726.965    |
| PolicyEntropy   | 0.641337   |
| PolicyLoss      | -0.0114564 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4795     |
| _max_adv        | 15         |
| _max_discrew    | 4.71       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0840729 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0399     |
| _min_adv        | -11.5      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.26      |
| _std_act        | 0.632888   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00246241 |
| Phi_loss        | 677.445    |
| PolicyEntropy   | 0.640382   |
| PolicyLoss      | -0.0208788 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0392     |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85538    |
| _max_adv        | 5.83       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0868254 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.04       |
| _min_adv        | -3.84      |
| _min_discrew    | 0.01       |
| _min_obs        | -1.41      |
| _std_act        | 0.628801   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00152729 |
| Phi_loss        | 869.659    |
| PolicyEntropy   | 0.623281   |
| PolicyLoss      | 0.00307621 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0176     |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71341    |
| _max_adv        | 6.7        |
| _max_discrew    | 4.65       |
| _max_obs        | 1.16       |
| _mean_act       | -0.088798  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.04       |
| _min_adv        | -5.81      |
| _min_discrew    | 0.00627    |
| _min_obs        | -1.2       |
| _std_act        | 0.633656   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.988      |
| KL              | 0.00165836 |
| Phi_loss        | 830.021    |
| PolicyEntropy   | 0.599135   |
| PolicyLoss      | -0.0118332 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0121     |
| _MeanReward     | 3.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.28084    |
| _max_adv        | 2.13       |
| _max_discrew    | 4.74       |
| _max_obs        | 1.1        |
| _mean_act       | -0.075862  |
| _mean_adv       | 5.9e-17    |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.0392     |
| _min_adv        | -15.9      |
| _min_discrew    | -1.31      |
| _min_obs        | -1.25      |
| _std_act        | 0.705368   |
| _std_adv        | 1          |
| _std_discrew    | 1.93       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.875      |
| ExplainedVarOld | 0.86       |
| KL              | 0.00413793 |
| Phi_loss        | 639.606    |
| PolicyEntropy   | 0.618949   |
| PolicyLoss      | -0.0385277 |
| Steps           | 10000      |
| VarFuncLoss     | 0.248      |
| _MeanReward     | 4.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54116    |
| _max_adv        | 23.5       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0891679 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.51       |
| _mean_obs       | 0.0403     |
| _min_adv        | -11        |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.21      |
| _std_act        | 0.635171   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.975       |
| KL              | 0.00895721  |
| Phi_loss        | 726.32      |
| PolicyEntropy   | 0.605355    |
| PolicyLoss      | -0.00260336 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0368      |
| _MeanReward     | 4.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.43088     |
| _max_adv        | 22.3        |
| _max_discrew    | 4.67        |
| _max_obs        | 1.12        |
| _mean_act       | -0.0839145  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.51        |
| _mean_obs       | 0.0401      |
| _min_adv        | -10.7       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.3        |
| _std_act        | 0.631808    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.966       |
| KL              | 0.00185736  |
| Phi_loss        | 690.443     |
| PolicyEntropy   | 0.605392    |
| PolicyLoss      | -0.00408453 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0312      |
| _MeanReward     | 4.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57458     |
| _max_adv        | 13.5        |
| _max_discrew    | 4.56        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0841904  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.53        |
| _mean_obs       | 0.0404      |
| _min_adv        | -7.69       |
| _min_discrew    | -0.0206     |
| _min_obs        | -1.11       |
| _std_act        | 0.629536    |
| _std_adv        | 1           |
| _std_discrew    | 1.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00106651 |
| Phi_loss        | 888.543    |
| PolicyEntropy   | 0.584368   |
| PolicyLoss      | -0.0386592 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0201     |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48745    |
| _max_adv        | 15.4       |
| _max_discrew    | 4.75       |
| _max_obs        | 1.05       |
| _mean_act       | -0.08422   |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.51       |
| _mean_obs       | 0.0404     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0103     |
| _min_obs        | -1.19      |
| _std_act        | 0.633418   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00244829 |
| Phi_loss        | 763.177    |
| PolicyEntropy   | 0.57151    |
| PolicyLoss      | 0.0115494  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0236     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47133    |
| _max_adv        | 7.79       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0823538 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.52      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.13      |
| _std_act        | 0.631869   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0015527  |
| Phi_loss        | 899.489    |
| PolicyEntropy   | 0.548803   |
| PolicyLoss      | -0.0126381 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0205     |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51331    |
| _max_adv        | 5.1        |
| _max_discrew    | 4.81       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0835463 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0407     |
| _min_adv        | -9.49      |
| _min_discrew    | 0.0185     |
| _min_obs        | -1.17      |
| _std_act        | 0.63177    |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00216786  |
| Phi_loss        | 728.669     |
| PolicyEntropy   | 0.546225    |
| PolicyLoss      | -0.00140512 |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 4.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.59022     |
| _max_adv        | 9.14        |
| _max_discrew    | 4.57        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0836936  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0399      |
| _min_adv        | -7.3        |
| _min_discrew    | 0.015       |
| _min_obs        | -1.14       |
| _std_act        | 0.630712    |
| _std_adv        | 1           |
| _std_discrew    | 1.18        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00166848 |
| Phi_loss        | 897.427    |
| PolicyEntropy   | 0.532737   |
| PolicyLoss      | -0.0072165 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0143     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56958    |
| _max_adv        | 2.39       |
| _max_discrew    | 4.75       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0839364 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0403     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.2       |
| _std_act        | 0.634379   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00189881  |
| Phi_loss        | 768.199     |
| PolicyEntropy   | 0.515872    |
| PolicyLoss      | -0.00300582 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0307      |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.40534     |
| _max_adv        | 15.8        |
| _max_discrew    | 4.86        |
| _max_obs        | 1.14        |
| _mean_act       | -0.0868336  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.57        |
| _mean_obs       | 0.0401      |
| _min_adv        | -7.67       |
| _min_discrew    | 0.0117      |
| _min_obs        | -1.26       |
| _std_act        | 0.630681    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00220323 |
| Phi_loss        | 849.028    |
| PolicyEntropy   | 0.510736   |
| PolicyLoss      | -0.0280259 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0176     |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.41009    |
| _max_adv        | 1.55       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0749513 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.04       |
| _min_adv        | -16.7      |
| _min_discrew    | -1.16      |
| _min_obs        | -1.12      |
| _std_act        | 0.687557   |
| _std_adv        | 1          |
| _std_discrew    | 1.88       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00377883 |
| Phi_loss        | 982.127    |
| PolicyEntropy   | 0.497306   |
| PolicyLoss      | 0.0520078  |
| Steps           | 10000      |
| VarFuncLoss     | 0.192      |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74109    |
| _max_adv        | 9.94       |
| _max_discrew    | 4.74       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0832533 |
| _mean_adv       | -1.42e-18  |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0408     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.14      |
| _std_act        | 0.635195   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.952      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00270457 |
| Phi_loss        | 895.8      |
| PolicyEntropy   | 0.482353   |
| PolicyLoss      | 0.0245028  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0604     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64112    |
| _max_adv        | 6.09       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0830569 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0406     |
| _min_adv        | -11.1      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.26      |
| _std_act        | 0.64064    |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.934      |
| KL              | 0.00230217 |
| Phi_loss        | 763.69     |
| PolicyEntropy   | 0.472636   |
| PolicyLoss      | 0.00833302 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0842     |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44456    |
| _max_adv        | 14.3       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0820082 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0404     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.26      |
| _std_act        | 0.635361   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00278565  |
| Phi_loss        | 766.749     |
| PolicyEntropy   | 0.464739    |
| PolicyLoss      | -0.00491271 |
| Steps           | 10000       |
| VarFuncLoss     | 0.038       |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52476     |
| _max_adv        | 15          |
| _max_discrew    | 4.78        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0828596  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.62        |
| _mean_obs       | 0.0405      |
| _min_adv        | -10.5       |
| _min_discrew    | 0.0142      |
| _min_obs        | -1.15       |
| _std_act        | 0.631484    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.977      |
| KL              | 0.00240286 |
| Phi_loss        | 715.632    |
| PolicyEntropy   | 0.449142   |
| PolicyLoss      | 0.00405323 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0258     |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63366    |
| _max_adv        | 6.73       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.17       |
| _mean_act       | -0.0834478 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0408     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.0213     |
| _min_obs        | -1.23      |
| _std_act        | 0.630493   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00187782 |
| Phi_loss        | 975.821    |
| PolicyEntropy   | 0.438409   |
| PolicyLoss      | -0.0252631 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 4.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.585      |
| _max_adv        | 5.28       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0830975 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0408     |
| _min_adv        | -14.7      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.17      |
| _std_act        | 0.629969   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00176662 |
| Phi_loss        | 1111.15    |
| PolicyEntropy   | 0.414899   |
| PolicyLoss      | 0.0147112  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3291     |
| _max_adv        | 10.6       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.09       |
| _mean_act       | -0.081631  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.041      |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0126     |
| _min_obs        | -1.17      |
| _std_act        | 0.626248   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00210273 |
| Phi_loss        | 905.377    |
| PolicyEntropy   | 0.394676   |
| PolicyLoss      | -0.0204563 |
| Steps           | 10000      |
| VarFuncLoss     | 0.028      |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35967    |
| _max_adv        | 19.3       |
| _max_discrew    | 5.02       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0778769 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.041      |
| _min_adv        | -14.9      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.17      |
| _std_act        | 0.637835   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.953      |
| KL              | 0.00474435 |
| Phi_loss        | 1011.36    |
| PolicyEntropy   | 0.392596   |
| PolicyLoss      | -0.0327293 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0612     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.6717     |
| _max_adv        | 15.6       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0815983 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0406     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.19      |
| _std_act        | 0.628995   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00249138  |
| Phi_loss        | 1140.97     |
| PolicyEntropy   | 0.376545    |
| PolicyLoss      | -0.00479117 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0216      |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56664     |
| _max_adv        | 10.2        |
| _max_discrew    | 4.88        |
| _max_obs        | 1.15        |
| _mean_act       | -0.0819567  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0407      |
| _min_adv        | -9.72       |
| _min_discrew    | 0.0127      |
| _min_obs        | -1.15       |
| _std_act        | 0.631786    |
| _std_adv        | 1           |
| _std_discrew    | 1.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00319664 |
| Phi_loss        | 922.633    |
| PolicyEntropy   | 0.367326   |
| PolicyLoss      | -0.0297474 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 4.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5395     |
| _max_adv        | 3.67       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0825389 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.041      |
| _min_adv        | -11.4      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.42      |
| _std_act        | 0.635532   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00204674 |
| Phi_loss        | 989.179    |
| PolicyEntropy   | 0.357253   |
| PolicyLoss      | 0.00571542 |
| Steps           | 10000      |
| VarFuncLoss     | 0.032      |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.37034    |
| _max_adv        | 8.02       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0828951 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0405     |
| _min_adv        | -6.17      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.13      |
| _std_act        | 0.629759   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00177409 |
| Phi_loss        | 1026.88    |
| PolicyEntropy   | 0.336408   |
| PolicyLoss      | -0.0240011 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 4.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51742    |
| _max_adv        | 5.94       |
| _max_discrew    | 5          |
| _max_obs        | 1.13       |
| _mean_act       | -0.0846177 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0404     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.22      |
| _std_act        | 0.632381   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00217035  |
| Phi_loss        | 938.192     |
| PolicyEntropy   | 0.316113    |
| PolicyLoss      | -0.00917719 |
| Steps           | 10000       |
| VarFuncLoss     | 0.034       |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.39869     |
| _max_adv        | 2.04        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0591256  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.26        |
| _mean_obs       | 0.0393      |
| _min_adv        | -16.9       |
| _min_discrew    | -1.42       |
| _min_obs        | -1.31       |
| _std_act        | 0.758878    |
| _std_adv        | 1           |
| _std_discrew    | 2.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.887      |
| KL              | 0.0025989  |
| Phi_loss        | 642.862    |
| PolicyEntropy   | 0.315773   |
| PolicyLoss      | -0.0187237 |
| Steps           | 10000      |
| VarFuncLoss     | 0.276      |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.31571    |
| _max_adv        | 11.2       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0525682 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0391     |
| _min_adv        | -18.8      |
| _min_discrew    | -1.44      |
| _min_obs        | -1.18      |
| _std_act        | 0.789626   |
| _std_adv        | 1          |
| _std_discrew    | 3.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.943      |
| ExplainedVarOld | 0.938      |
| KL              | 0.0153496  |
| Phi_loss        | 1129.71    |
| PolicyEntropy   | 0.333578   |
| PolicyLoss      | 0.16204    |
| Steps           | 10000      |
| VarFuncLoss     | 0.19       |
| _MeanReward     | 3.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.29457    |
| _max_adv        | 9.78       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0580958 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.039      |
| _min_adv        | -18.2      |
| _min_discrew    | -1.42      |
| _min_obs        | -1.24      |
| _std_act        | 0.782441   |
| _std_adv        | 1          |
| _std_discrew    | 3.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.925      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00271724 |
| Phi_loss        | 905.872    |
| PolicyEntropy   | 0.343615   |
| PolicyLoss      | -0.0208749 |
| Steps           | 10000      |
| VarFuncLoss     | 0.242      |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.33279    |
| _max_adv        | 5.35       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0680124 |
| _mean_adv       | -2.7e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0395     |
| _min_adv        | -19.9      |
| _min_discrew    | -1.33      |
| _min_obs        | -1.18      |
| _std_act        | 0.717094   |
| _std_adv        | 1          |
| _std_discrew    | 2.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.869       |
| KL              | 0.000900085 |
| Phi_loss        | 938.558     |
| PolicyEntropy   | 0.340425    |
| PolicyLoss      | -0.00105057 |
| Steps           | 10000       |
| VarFuncLoss     | 0.272       |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54512     |
| _max_adv        | 18.9        |
| _max_discrew    | 4.85        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0864415  |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.04        |
| _min_adv        | -9.76       |
| _min_discrew    | 0.0124      |
| _min_obs        | -1.11       |
| _std_act        | 0.63433     |
| _std_adv        | 1           |
| _std_discrew    | 1.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.968       |
| KL              | 0.00221933  |
| Phi_loss        | 1059.18     |
| PolicyEntropy   | 0.324208    |
| PolicyLoss      | -0.00285711 |
| Steps           | 10000       |
| VarFuncLoss     | 0.037       |
| _MeanReward     | 4.55e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.45796     |
| _max_adv        | 13.5        |
| _max_discrew    | 4.94        |
| _max_obs        | 1.13        |
| _mean_act       | -0.0874536  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0405      |
| _min_adv        | -9.84       |
| _min_discrew    | 0.0149      |
| _min_obs        | -1.31       |
| _std_act        | 0.634597    |
| _std_adv        | 1           |
| _std_discrew    | 1.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00182314 |
| Phi_loss        | 1000.25    |
| PolicyEntropy   | 0.311792   |
| PolicyLoss      | 0.0172738  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0202     |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.24603    |
| _max_adv        | 1.88       |
| _max_discrew    | 4.94       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0474041 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0386     |
| _min_adv        | -15.1      |
| _min_discrew    | -1.39      |
| _min_obs        | -1.22      |
| _std_act        | 0.823846   |
| _std_adv        | 1          |
| _std_discrew    | 3.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.87       |
| ExplainedVarOld | 0.862      |
| KL              | 0.00306728 |
| Phi_loss        | 1419.01    |
| PolicyEntropy   | 0.294394   |
| PolicyLoss      | 0.0837117  |
| Steps           | 10000      |
| VarFuncLoss     | 0.484      |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.47227    |
| _max_adv        | 23.2       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0885428 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0407     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.33      |
| _std_act        | 0.636748   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.959      |
| KL              | 0.0128205  |
| Phi_loss        | 700.802    |
| PolicyEntropy   | 0.298171   |
| PolicyLoss      | -0.0652452 |
| Steps           | 10000      |
| VarFuncLoss     | 0.048      |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46599    |
| _max_adv        | 11.7       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0883218 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0406     |
| _min_adv        | -3.71      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.23      |
| _std_act        | 0.635981   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00132579 |
| Phi_loss        | 1042.05    |
| PolicyEntropy   | 0.289613   |
| PolicyLoss      | -0.027677  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0151     |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86479    |
| _max_adv        | 4.86       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0859967 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0404     |
| _min_adv        | -11.9      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.16      |
| _std_act        | 0.634634   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00272684 |
| Phi_loss        | 1092.46    |
| PolicyEntropy   | 0.280553   |
| PolicyLoss      | -0.0186261 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0466     |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53089    |
| _max_adv        | 6.32       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0854528 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0406     |
| _min_adv        | -4.52      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.13      |
| _std_act        | 0.635898   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00192798 |
| Phi_loss        | 1252.42    |
| PolicyEntropy   | 0.268279   |
| PolicyLoss      | -0.0109892 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4569     |
| _max_adv        | 16.1       |
| _max_discrew    | 4.87       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0872314 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0407     |
| _min_adv        | -13.7      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.18      |
| _std_act        | 0.635956   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00220753 |
| Phi_loss        | 1065.96    |
| PolicyEntropy   | 0.257049   |
| PolicyLoss      | -0.0181502 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0269     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.29558    |
| _max_adv        | 1.33       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0714149 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.41       |
| _mean_obs       | 0.0394     |
| _min_adv        | -17.7      |
| _min_discrew    | -1.33      |
| _min_obs        | -1.28      |
| _std_act        | 0.723022   |
| _std_adv        | 1          |
| _std_discrew    | 2.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.866      |
| KL              | 0.00765472 |
| Phi_loss        | 930.695    |
| PolicyEntropy   | 0.258032   |
| PolicyLoss      | -0.135574  |
| Steps           | 10000      |
| VarFuncLoss     | 0.294      |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6695     |
| _max_adv        | 17.3       |
| _max_discrew    | 5.11       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0893414 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0408     |
| _min_adv        | -6.31      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.29      |
| _std_act        | 0.63982    |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00120023  |
| Phi_loss        | 1121.66     |
| PolicyEntropy   | 0.236757    |
| PolicyLoss      | -0.00107294 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0377      |
| _MeanReward     | 4.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.39563     |
| _max_adv        | 3.74        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.16        |
| _mean_act       | -0.072975   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.52        |
| _mean_obs       | 0.0394      |
| _min_adv        | -20.9       |
| _min_discrew    | -1.36       |
| _min_obs        | -1.27       |
| _std_act        | 0.716726    |
| _std_adv        | 1           |
| _std_discrew    | 2.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.902      |
| KL              | 0.00136104 |
| Phi_loss        | 721.799    |
| PolicyEntropy   | 0.229782   |
| PolicyLoss      | 0.011169   |
| Steps           | 10000      |
| VarFuncLoss     | 0.229      |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44417    |
| _max_adv        | 20.8       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.13       |
| _mean_act       | -0.085971  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.04       |
| _min_adv        | -11.3      |
| _min_discrew    | -0.0231    |
| _min_obs        | -1.27      |
| _std_act        | 0.634111   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00376044  |
| Phi_loss        | 1056.05     |
| PolicyEntropy   | 0.22801     |
| PolicyLoss      | -0.00072678 |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 4.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52717     |
| _max_adv        | 26.2        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.08        |
| _mean_act       | -0.0853227  |
| _mean_adv       | -1.42e-18   |
| _mean_discrew   | 3.72        |
| _mean_obs       | 0.0402      |
| _min_adv        | -8.66       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.16       |
| _std_act        | 0.635463    |
| _std_adv        | 1           |
| _std_discrew    | 1.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.975       |
| KL              | 0.00673922  |
| Phi_loss        | 766.201     |
| PolicyEntropy   | 0.22401     |
| PolicyLoss      | -0.00954767 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0223      |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.53154     |
| _max_adv        | 12.2        |
| _max_discrew    | 4.96        |
| _max_obs        | 1.13        |
| _mean_act       | -0.0824401  |
| _mean_adv       | -7.46e-17   |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0407      |
| _min_adv        | -9.87       |
| _min_discrew    | 0.00889     |
| _min_obs        | -1.32       |
| _std_act        | 0.634757    |
| _std_adv        | 1           |
| _std_discrew    | 1.41        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00212996 |
| Phi_loss        | 1437.26    |
| PolicyEntropy   | 0.208234   |
| PolicyLoss      | -0.0252659 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35326    |
| _max_adv        | 3.26       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0847616 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0406     |
| _min_adv        | -3.86      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.13      |
| _std_act        | 0.630048   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00186956 |
| Phi_loss        | 1200.31    |
| PolicyEntropy   | 0.191396   |
| PolicyLoss      | -0.0592362 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0145     |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69281    |
| _max_adv        | 7.03       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0818166 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0407     |
| _min_adv        | -12.5      |
| _min_discrew    | 0.000477   |
| _min_obs        | -1.24      |
| _std_act        | 0.632348   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.96       |
| KL              | 0.00324998 |
| Phi_loss        | 1226.08    |
| PolicyEntropy   | 0.197356   |
| PolicyLoss      | -0.0324396 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0561     |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42061    |
| _max_adv        | 5.53       |
| _max_discrew    | 5          |
| _max_obs        | 1.07       |
| _mean_act       | -0.085309  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.041      |
| _min_adv        | -15.2      |
| _min_discrew    | 0.0118     |
| _min_obs        | -1.16      |
| _std_act        | 0.634666   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00169637 |
| Phi_loss        | 1188.13    |
| PolicyEntropy   | 0.191072   |
| PolicyLoss      | -0.0169582 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0487     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46454    |
| _max_adv        | 10.7       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0841617 |
| _mean_adv       | -3.55e-18  |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0409     |
| _min_adv        | -4.5       |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.16      |
| _std_act        | 0.631477   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.991       |
| KL              | 0.0020988   |
| Phi_loss        | 1234.72     |
| PolicyEntropy   | 0.182082    |
| PolicyLoss      | -0.00983492 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0121      |
| _MeanReward     | 4.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.4697      |
| _max_adv        | 9.3         |
| _max_discrew    | 4.93        |
| _max_obs        | 1.09        |
| _mean_act       | -0.0840615  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.81        |
| _mean_obs       | 0.041       |
| _min_adv        | -7.45       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.18       |
| _std_act        | 0.630795    |
| _std_adv        | 1           |
| _std_discrew    | 1.4         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00199227 |
| Phi_loss        | 1354.36    |
| PolicyEntropy   | 0.172602   |
| PolicyLoss      | -0.017686  |
| Steps           | 10000      |
| VarFuncLoss     | 0.015      |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53354    |
| _max_adv        | 11.1       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0850357 |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.0409     |
| _min_adv        | -9.81      |
| _min_discrew    | 0.0123     |
| _min_obs        | -1.15      |
| _std_act        | 0.638437   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00184488 |
| Phi_loss        | 1179.45    |
| PolicyEntropy   | 0.165716   |
| PolicyLoss      | -0.0238903 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0202     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54414    |
| _max_adv        | 5.81       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0822279 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0408     |
| _min_adv        | -13.1      |
| _min_discrew    | -0.282     |
| _min_obs        | -1.25      |
| _std_act        | 0.643268   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.929      |
| ExplainedVarOld | 0.907      |
| KL              | 0.00672612 |
| Phi_loss        | 1423.22    |
| PolicyEntropy   | 0.180145   |
| PolicyLoss      | -0.024837  |
| Steps           | 10000      |
| VarFuncLoss     | 0.122      |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.55356    |
| _max_adv        | 1.48       |
| _max_discrew    | 5.07       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0615765 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0389     |
| _min_adv        | -17        |
| _min_discrew    | -1.61      |
| _min_obs        | -1.12      |
| _std_act        | 0.802234   |
| _std_adv        | 1          |
| _std_discrew    | 3.53       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.933       |
| ExplainedVarOld | 0.917       |
| KL              | 0.0026548   |
| Phi_loss        | 689.098     |
| PolicyEntropy   | 0.174317    |
| PolicyLoss      | -0.00838378 |
| Steps           | 10000       |
| VarFuncLoss     | 0.236       |
| _MeanReward     | 4.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82047     |
| _max_adv        | 18          |
| _max_discrew    | 5           |
| _max_obs        | 1.09        |
| _mean_act       | -0.0867576  |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.78        |
| _mean_obs       | 0.0404      |
| _min_adv        | -9.2        |
| _min_discrew    | 0.00689     |
| _min_obs        | -1.21       |
| _std_act        | 0.640838    |
| _std_adv        | 1           |
| _std_discrew    | 1.45        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.971      |
| KL              | 0.0197922  |
| Phi_loss        | 873.32     |
| PolicyEntropy   | 0.157327   |
| PolicyLoss      | 0.0391413  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0266     |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01601    |
| _max_adv        | 11.8       |
| _max_discrew    | 5.08       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0850422 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0412     |
| _min_adv        | -11.9      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.16      |
| _std_act        | 0.637273   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
--------------------------------
| Beta            | 1.5        |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.974      |
| KL              | 0.0126306  |
| Phi_loss        | 1152.58    |
| PolicyEntropy   | 0.15637    |
| PolicyLoss      | 0.0037567  |
| Steps           | 10000      |
| VarFuncLoss     | 0.034      |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42859    |
| _max_adv        | 8.11       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0825923 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0413     |
| _min_adv        | -3.93      |
| _min_discrew    | 0.013      |
| _min_obs        | -1.19      |
| _std_act        | 0.638375   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 2.25       |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.988      |
| KL              | 0.0868352  |
| Phi_loss        | 1203.52    |
| PolicyEntropy   | 0.155435   |
| PolicyLoss      | 0.424501   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0137     |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63875    |
| _max_adv        | 6.72       |
| _max_discrew    | 5.09       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0848915 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0404     |
| _min_adv        | -13.3      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.21      |
| _std_act        | 0.630392   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
--------------------------------
| Beta            | 3.38       |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.119017   |
| Phi_loss        | 1273.1     |
| PolicyEntropy   | 0.155185   |
| PolicyLoss      | 0.873128   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0238     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39638    |
| _max_adv        | 3.42       |
| _max_discrew    | 5.06       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0851379 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0394     |
| _min_adv        | -3.52      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.14      |
| _std_act        | 0.628922   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
-------------------------------
| Beta            | 5.06      |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.987     |
| KL              | 0.0938314 |
| Phi_loss        | 1481.0    |
| PolicyEntropy   | 0.154265  |
| PolicyLoss      | 0.675657  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0165    |
| _MeanReward     | 4.53e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.84606   |
| _max_adv        | 10.3      |
| _max_discrew    | 5         |
| _max_obs        | 1.1       |
| _mean_act       | -0.08836  |
| _mean_adv       | -1.99e-17 |
| _mean_discrew   | 3.71      |
| _mean_obs       | 0.0384    |
| _min_adv        | -9.67     |
| _min_discrew    | -0.00103  |
| _min_obs        | -1.11     |
| _std_act        | 0.621722  |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 7.59       |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.0714278  |
| Phi_loss        | 1455.47    |
| PolicyEntropy   | 0.153251   |
| PolicyLoss      | 0.547026   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0116     |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7421     |
| _max_adv        | 3.52       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.11       |
| _mean_act       | -0.0882133 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0372     |
| _min_adv        | -13.3      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.2       |
| _std_act        | 0.621141   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
--------------------------------
| Beta            | 11.4       |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.0505596  |
| Phi_loss        | 1508.79    |
| PolicyEntropy   | 0.152236   |
| PolicyLoss      | 0.463841   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0283     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48403    |
| _max_adv        | 4.58       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0892882 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0367     |
| _min_adv        | -4.36      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.23      |
| _std_act        | 0.624916   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
--------------------------------
| Beta            | 17.1       |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.989      |
| KL              | 0.0350105  |
| Phi_loss        | 1337.71    |
| PolicyEntropy   | 0.151344   |
| PolicyLoss      | 0.422708   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0115     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61964    |
| _max_adv        | 8.54       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0889878 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0355     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.21      |
| _std_act        | 0.626427   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
--------------------------------
| Beta            | 25.6       |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.958      |
| KL              | 0.0256625  |
| Phi_loss        | 1586.15    |
| PolicyEntropy   | 0.150233   |
| PolicyLoss      | 0.42898    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0499     |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56207    |
| _max_adv        | 2.79       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.11       |
| _mean_act       | -0.0910432 |
| _mean_adv       | 3.84e-17   |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0354     |
| _min_adv        | -11.9      |
| _min_discrew    | 0.0103     |
| _min_obs        | -1.19      |
| _std_act        | 0.630772   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.973      |
| KL              | 0.019432   |
| Phi_loss        | 1406.63    |
| PolicyEntropy   | 0.149084   |
| PolicyLoss      | 0.483309   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0328     |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35932    |
| _max_adv        | 4.33       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0907105 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0354     |
| _min_adv        | -4.19      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.21      |
| _std_act        | 0.626509   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0141217  |
| Phi_loss        | 1284.65    |
| PolicyEntropy   | 0.147733   |
| PolicyLoss      | 0.50649    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0204     |
| _MeanReward     | 4.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32483    |
| _max_adv        | 15.5       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0930452 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0343     |
| _min_adv        | -9.17      |
| _min_discrew    | 0.00958    |
| _min_obs        | -1.17      |
| _std_act        | 0.629864   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.188188   |
| Phi_loss        | 1278.17    |
| PolicyEntropy   | 0.151436   |
| PolicyLoss      | 8.25361    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0253     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56426    |
| _max_adv        | 21.9       |
| _max_discrew    | 4.61       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0923858 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0355     |
| _min_adv        | -13.4      |
| _min_discrew    | 0.0156     |
| _min_obs        | -1.24      |
| _std_act        | 0.628915   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.963      |
| KL              | 0.232938   |
| Phi_loss        | 1417.62    |
| PolicyEntropy   | 0.155749   |
| PolicyLoss      | 10.6991    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0435     |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52224    |
| _max_adv        | 6.33       |
| _max_discrew    | 4.71       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0908935 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0363     |
| _min_adv        | -4.3       |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.16      |
| _std_act        | 0.617851   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.194476   |
| Phi_loss        | 1533.6     |
| PolicyEntropy   | 0.159266   |
| PolicyLoss      | 8.55027    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0171     |
| _MeanReward     | 4.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39394    |
| _max_adv        | 4.44       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0889375 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0374     |
| _min_adv        | -14.7      |
| _min_discrew    | 0.00853    |
| _min_obs        | -1.31      |
| _std_act        | 0.618488   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.979     |
| ExplainedVarOld | 0.978     |
| KL              | 0.157474  |
| Phi_loss        | 1533.52   |
| PolicyEntropy   | 0.162463  |
| PolicyLoss      | 6.68112   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0281    |
| _MeanReward     | 4.55e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.44999   |
| _max_adv        | 9.56      |
| _max_discrew    | 4.92      |
| _max_obs        | 1.19      |
| _mean_act       | -0.089564 |
| _mean_adv       | -8.53e-18 |
| _mean_discrew   | 3.73      |
| _mean_obs       | 0.0384    |
| _min_adv        | -4.98     |
| _min_discrew    | 0.00417   |
| _min_obs        | -1.23     |
| _std_act        | 0.615739  |
| _std_adv        | 1         |
| _std_discrew    | 1.36      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.129428   |
| Phi_loss        | 1514.09    |
| PolicyEntropy   | 0.165158   |
| PolicyLoss      | 5.27472    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49147    |
| _max_adv        | 7.18       |
| _max_discrew    | 4.98       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0880075 |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0393     |
| _min_adv        | -14.4      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.23      |
| _std_act        | 0.613694   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.973      |
| KL              | 0.10432    |
| Phi_loss        | 2588.31    |
| PolicyEntropy   | 0.167275   |
| PolicyLoss      | 4.14145    |
| Steps           | 10000      |
| VarFuncLoss     | 0.036      |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67806    |
| _max_adv        | 12.4       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0892741 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.0397     |
| _min_adv        | -5.41      |
| _min_discrew    | 0.0227     |
| _min_obs        | -1.23      |
| _std_act        | 0.618831   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.0846428  |
| Phi_loss        | 1381.56    |
| PolicyEntropy   | 0.169031   |
| PolicyLoss      | 3.23691    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00947    |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66438    |
| _max_adv        | 2.04       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.09       |
| _mean_act       | -0.0868034 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0405     |
| _min_adv        | -15.5      |
| _min_discrew    | -0.0111    |
| _min_obs        | -1.14      |
| _std_act        | 0.636034   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.966      |
| KL              | 0.0666902  |
| Phi_loss        | 1948.47    |
| PolicyEntropy   | 0.170408   |
| PolicyLoss      | 2.52201    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0467     |
| _MeanReward     | 4.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82225    |
| _max_adv        | 13.8       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0872378 |
| _mean_adv       | -4.12e-17  |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0402     |
| _min_adv        | -15        |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.19      |
| _std_act        | 0.638502   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.964      |
| KL              | 0.0519784  |
| Phi_loss        | 1107.6     |
| PolicyEntropy   | 0.171359   |
| PolicyLoss      | 1.92275    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0408     |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32547    |
| _max_adv        | 20.2       |
| _max_discrew    | 4.63       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0819154 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0402     |
| _min_adv        | -7.95      |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.2       |
| _std_act        | 0.636491   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.981      |
| KL              | 0.0413646  |
| Phi_loss        | 943.357    |
| PolicyEntropy   | 0.172111   |
| PolicyLoss      | 1.49692    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0137     |
| _MeanReward     | 4.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77875    |
| _max_adv        | 7.99       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0855349 |
| _mean_adv       | -7.96e-17  |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.0389     |
| _min_adv        | -9.25      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.14      |
| _std_act        | 0.643425   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.948      |
| KL              | 0.0313682  |
| Phi_loss        | 1559.78    |
| PolicyEntropy   | 0.172761   |
| PolicyLoss      | 1.11382    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0631     |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92854    |
| _max_adv        | 6.26       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0869135 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0394     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.00792    |
| _min_obs        | -1.36      |
| _std_act        | 0.644776   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.951     |
| ExplainedVarOld | 0.948     |
| KL              | 0.0248974 |
| Phi_loss        | 1571.86   |
| PolicyEntropy   | 0.172925  |
| PolicyLoss      | 0.888112  |
| Steps           | 10000     |
| VarFuncLoss     | 0.054     |
| _MeanReward     | 3.89e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.83169   |
| _max_adv        | 5.45      |
| _max_discrew    | 4.34      |
| _max_obs        | 1.07      |
| _mean_act       | -0.084332 |
| _mean_adv       | -2.84e-18 |
| _mean_discrew   | 3.19      |
| _mean_obs       | 0.0388    |
| _min_adv        | -9.06     |
| _min_discrew    | 0.00929   |
| _min_obs        | -1.25     |
| _std_act        | 0.651891  |
| _std_adv        | 1         |
| _std_discrew    | 1.05      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.913      |
| KL              | 0.0192787  |
| Phi_loss        | 1236.72    |
| PolicyEntropy   | 0.173269   |
| PolicyLoss      | 0.671686   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0894     |
| _MeanReward     | 3.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.50176    |
| _max_adv        | 3.05       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0524604 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.5        |
| _mean_obs       | 0.035      |
| _min_adv        | -12.8      |
| _min_discrew    | -1.47      |
| _min_obs        | -1.21      |
| _std_act        | 0.861231   |
| _std_adv        | 1          |
| _std_discrew    | 3.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.86       |
| ExplainedVarOld | 0.844      |
| KL              | 0.0132924  |
| Phi_loss        | 978.428    |
| PolicyEntropy   | 0.173731   |
| PolicyLoss      | 0.431888   |
| Steps           | 10000      |
| VarFuncLoss     | 0.449      |
| _MeanReward     | 3.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.33907    |
| _max_adv        | 12.8       |
| _max_discrew    | 4.29       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0596761 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.61       |
| _mean_obs       | 0.0359     |
| _min_adv        | -13.2      |
| _min_discrew    | -1.48      |
| _min_obs        | -1.15      |
| _std_act        | 0.818441   |
| _std_adv        | 1          |
| _std_discrew    | 2.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.874      |
| ExplainedVarOld | 0.866      |
| KL              | 0.0443681  |
| Phi_loss        | 1051.52    |
| PolicyEntropy   | 0.177931   |
| PolicyLoss      | 1.60337    |
| Steps           | 10000      |
| VarFuncLoss     | 0.325      |
| _MeanReward     | 3.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.94666    |
| _max_adv        | 13.9       |
| _max_discrew    | 4.33       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0819128 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0388     |
| _min_adv        | -6.85      |
| _min_discrew    | -0.0484    |
| _min_obs        | -1.17      |
| _std_act        | 0.649121   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.935      |
| ExplainedVarOld | 0.921      |
| KL              | 0.0845724  |
| Phi_loss        | 1181.96    |
| PolicyEntropy   | 0.181179   |
| PolicyLoss      | 3.24727    |
| Steps           | 10000      |
| VarFuncLoss     | 0.079      |
| _MeanReward     | 4e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 3.0602     |
| _max_adv        | 13.6       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0755564 |
| _mean_adv       | -4.83e-17  |
| _mean_discrew   | 3.28       |
| _mean_obs       | 0.0396     |
| _min_adv        | -6.69      |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.23      |
| _std_act        | 0.643453   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.891      |
| KL              | 0.0695908  |
| Phi_loss        | 1107.33    |
| PolicyEntropy   | 0.184175   |
| PolicyLoss      | 2.61264    |
| Steps           | 10000      |
| VarFuncLoss     | 0.113      |
| _MeanReward     | 4.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60816    |
| _max_adv        | 6.73       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0722634 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.52       |
| _mean_obs       | 0.04       |
| _min_adv        | -7.93      |
| _min_discrew    | 0.00602    |
| _min_obs        | -1.2       |
| _std_act        | 0.626682   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.962      |
| KL              | 0.0580711  |
| Phi_loss        | 1123.83    |
| PolicyEntropy   | 0.186797   |
| PolicyLoss      | 2.15184    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0466     |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.25125    |
| _max_adv        | 2.69       |
| _max_discrew    | 4.62       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0636767 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.38       |
| _mean_obs       | 0.0388     |
| _min_adv        | -18.1      |
| _min_discrew    | -1.21      |
| _min_obs        | -1.19      |
| _std_act        | 0.681371   |
| _std_adv        | 1          |
| _std_discrew    | 1.92       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.885     |
| ExplainedVarOld | 0.879     |
| KL              | 0.0455889 |
| Phi_loss        | 1053.79   |
| PolicyEntropy   | 0.189149  |
| PolicyLoss      | 1.657     |
| Steps           | 10000     |
| VarFuncLoss     | 0.221     |
| _MeanReward     | 4.4e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.3612    |
| _max_adv        | 7.63      |
| _max_discrew    | 4.66      |
| _max_obs        | 1.09      |
| _mean_act       | -0.070834 |
| _mean_adv       | -6.82e-17 |
| _mean_discrew   | 3.63      |
| _mean_obs       | 0.039     |
| _min_adv        | -4.76     |
| _min_discrew    | 0.0143    |
| _min_obs        | -1.2      |
| _std_act        | 0.605545  |
| _std_adv        | 1         |
| _std_discrew    | 1.25      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.0378644  |
| Phi_loss        | 1198.75    |
| PolicyEntropy   | 0.191201   |
| PolicyLoss      | 1.323      |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39989    |
| _max_adv        | 30.2       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.05       |
| _mean_act       | -0.0657721 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0388     |
| _min_adv        | -9.69      |
| _min_discrew    | 0.0138     |
| _min_obs        | -1.12      |
| _std_act        | 0.601485   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.989      |
| KL              | 0.0297037  |
| Phi_loss        | 887.023    |
| PolicyEntropy   | 0.192958   |
| PolicyLoss      | 1.06637    |
| Steps           | 10000      |
| VarFuncLoss     | 0.00972    |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42179    |
| _max_adv        | 14.9       |
| _max_discrew    | 4.71       |
| _max_obs        | 1.02       |
| _mean_act       | -0.0651254 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0384     |
| _min_adv        | -12.8      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.22      |
| _std_act        | 0.593524   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.0234039  |
| Phi_loss        | 1310.52    |
| PolicyEntropy   | 0.19428    |
| PolicyLoss      | 0.796964   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0243     |
| _MeanReward     | 4.36e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62424    |
| _max_adv        | 4.44       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.04       |
| _mean_act       | -0.0640606 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0382     |
| _min_adv        | -6.86      |
| _min_discrew    | 0.00987    |
| _min_obs        | -1.2       |
| _std_act        | 0.585264   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.0185693  |
| Phi_loss        | 1288.27    |
| PolicyEntropy   | 0.19522    |
| PolicyLoss      | 0.617453   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00898    |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.23327    |
| _max_adv        | 8.73       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0615011 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0379     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.21      |
| _std_act        | 0.582364   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.0144904  |
| Phi_loss        | 1199.97    |
| PolicyEntropy   | 0.195937   |
| PolicyLoss      | 0.474315   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00922    |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.33711    |
| _max_adv        | 10.7       |
| _max_discrew    | 4.63       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0565078 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0379     |
| _min_adv        | -6.07      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.09      |
| _std_act        | 0.570479   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.0299924  |
| Phi_loss        | 1233.5     |
| PolicyEntropy   | 0.199891   |
| PolicyLoss      | 1.04088    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0117     |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.34783    |
| _max_adv        | 10.6       |
| _max_discrew    | 4.76       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0642355 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0383     |
| _min_adv        | -9.96      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.18      |
| _std_act        | 0.587142   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.989      |
| KL              | 0.0607737  |
| Phi_loss        | 1176.08    |
| PolicyEntropy   | 0.202916   |
| PolicyLoss      | 2.23095    |
| Steps           | 10000      |
| VarFuncLoss     | 0.014      |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.73944    |
| _max_adv        | 2.26       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0689837 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.0385     |
| _min_adv        | -12        |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.08      |
| _std_act        | 0.60634    |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.971      |
| KL              | 0.0498766  |
| Phi_loss        | 1198.18    |
| PolicyEntropy   | 0.205344   |
| PolicyLoss      | 1.85194    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0353     |
| _MeanReward     | 4.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95713    |
| _max_adv        | 5.18       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0764638 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0391     |
| _min_adv        | -14.7      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.21      |
| _std_act        | 0.617707   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.0409474  |
| Phi_loss        | 934.982    |
| PolicyEntropy   | 0.207404   |
| PolicyLoss      | 1.46507    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0327     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.28499    |
| _max_adv        | 4.91       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0818074 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0398     |
| _min_adv        | -5         |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.22      |
| _std_act        | 0.628241   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.0332238  |
| Phi_loss        | 1214.81    |
| PolicyEntropy   | 0.208979   |
| PolicyLoss      | 1.16493    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0124     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.03248    |
| _max_adv        | 19.7       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0856625 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0392     |
| _min_adv        | -8.21      |
| _min_discrew    | -0.0487    |
| _min_obs        | -1.21      |
| _std_act        | 0.637397   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.026433   |
| Phi_loss        | 1009.38    |
| PolicyEntropy   | 0.209836   |
| PolicyLoss      | 0.958734   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0188     |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49217    |
| _max_adv        | 13.2       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0876231 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0393     |
| _min_adv        | -9.86      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.14      |
| _std_act        | 0.647388   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.020979   |
| Phi_loss        | 1292.33    |
| PolicyEntropy   | 0.210545   |
| PolicyLoss      | 0.731483   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0273     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.03896    |
| _max_adv        | 4.81       |
| _max_discrew    | 4.73       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0908461 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0396     |
| _min_adv        | -8.73      |
| _min_discrew    | 0.0111     |
| _min_obs        | -1.19      |
| _std_act        | 0.658941   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.928      |
| KL              | 0.01652    |
| Phi_loss        | 1172.46    |
| PolicyEntropy   | 0.211167   |
| PolicyLoss      | 0.558699   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0874     |
| _MeanReward     | 3.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 4.41106    |
| _max_adv        | 2.73       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0625499 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 2.74       |
| _mean_obs       | 0.0351     |
| _min_adv        | -12.9      |
| _min_discrew    | -1.44      |
| _min_obs        | -1.15      |
| _std_act        | 0.860853   |
| _std_adv        | 1          |
| _std_discrew    | 3.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.861      |
| KL              | 0.00173804 |
| Phi_loss        | 760.48     |
| PolicyEntropy   | 0.211533   |
| PolicyLoss      | 0.0233862  |
| Steps           | 10000      |
| VarFuncLoss     | 0.467      |
| _MeanReward     | 4.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.14726    |
| _max_adv        | 12.6       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0851608 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.31       |
| _mean_obs       | 0.0383     |
| _min_adv        | -17.5      |
| _min_discrew    | -1.3       |
| _min_obs        | -1.33      |
| _std_act        | 0.733284   |
| _std_adv        | 1          |
| _std_discrew    | 2.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
---------------------------------
| Beta            | 23.3        |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.88        |
| KL              | 0.000156582 |
| Phi_loss        | 802.587     |
| PolicyEntropy   | 0.211876    |
| PolicyLoss      | 0.0103939   |
| Steps           | 10000       |
| VarFuncLoss     | 0.253       |
| _MeanReward     | 4.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94717     |
| _max_adv        | 19.8        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.08        |
| _mean_act       | -0.0954598  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.5         |
| _mean_obs       | 0.0391      |
| _min_adv        | -7.08       |
| _min_discrew    | 0.0134      |
| _min_obs        | -1.17       |
| _std_act        | 0.660977    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
---------------------------------
| Beta            | 15.6        |
| ExplainedVarNew | 0.959       |
| ExplainedVarOld | 0.945       |
| KL              | 1.71851e-05 |
| Phi_loss        | 988.405     |
| PolicyEntropy   | 0.211551    |
| PolicyLoss      | -0.0123867  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0489      |
| _MeanReward     | 4.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.7165      |
| _max_adv        | 17.9        |
| _max_discrew    | 4.63        |
| _max_obs        | 1.3         |
| _mean_act       | -0.096146   |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 3.52        |
| _mean_obs       | 0.0396      |
| _min_adv        | -9.88       |
| _min_discrew    | 0.00285     |
| _min_obs        | -1.23       |
| _std_act        | 0.662862    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.941       |
| KL              | 1.66602e-06 |
| Phi_loss        | 668.893     |
| PolicyEntropy   | 0.21153     |
| PolicyLoss      | 0.00276412  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0469      |
| _MeanReward     | 4.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.29665     |
| _max_adv        | 6.48        |
| _max_discrew    | 4.69        |
| _max_obs        | 1.09        |
| _mean_act       | -0.0932132  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.4         |
| _mean_obs       | 0.0389      |
| _min_adv        | -8.05       |
| _min_discrew    | -0.00461    |
| _min_obs        | -1.23       |
| _std_act        | 0.666344    |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
---------------------------------
| Beta            | 6.91        |
| ExplainedVarNew | 0.94        |
| ExplainedVarOld | 0.934       |
| KL              | 4.75597e-06 |
| Phi_loss        | 1080.67     |
| PolicyEntropy   | 0.210937    |
| PolicyLoss      | 0.016673    |
| Steps           | 10000       |
| VarFuncLoss     | 0.0818      |
| _MeanReward     | 3.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.26534     |
| _max_adv        | 2.6         |
| _max_discrew    | 4.74        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0767148  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.14        |
| _mean_obs       | 0.0375      |
| _min_adv        | -17.3       |
| _min_discrew    | -1.46       |
| _min_obs        | -1.22       |
| _std_act        | 0.78533     |
| _std_adv        | 1           |
| _std_discrew    | 2.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.897       |
| ExplainedVarOld | 0.881       |
| KL              | 1.54045e-05 |
| Phi_loss        | 1186.92     |
| PolicyEntropy   | 0.209598    |
| PolicyLoss      | -0.108228   |
| Steps           | 10000       |
| VarFuncLoss     | 0.295       |
| _MeanReward     | 4.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.2669      |
| _max_adv        | 25.6        |
| _max_discrew    | 4.55        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0956088  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.5         |
| _mean_obs       | 0.0389      |
| _min_adv        | -8.03       |
| _min_discrew    | 0.00324     |
| _min_obs        | -1.17       |
| _std_act        | 0.65859     |
| _std_adv        | 1           |
| _std_discrew    | 1.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.944       |
| ExplainedVarOld | 0.937       |
| KL              | 8.96137e-06 |
| Phi_loss        | 849.922     |
| PolicyEntropy   | 0.209599    |
| PolicyLoss      | -0.00969295 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0661      |
| _MeanReward     | 4.21e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.16837     |
| _max_adv        | 18.7        |
| _max_discrew    | 4.62        |
| _max_obs        | 1.11        |
| _mean_act       | -0.0946431  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.48        |
| _mean_obs       | 0.0389      |
| _min_adv        | -8.43       |
| _min_discrew    | 0.00971     |
| _min_obs        | -1.28       |
| _std_act        | 0.664539    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
---------------------------------
| Beta            | 2.05        |
| ExplainedVarNew | 0.946       |
| ExplainedVarOld | 0.938       |
| KL              | 2.08698e-05 |
| Phi_loss        | 1106.52     |
| PolicyEntropy   | 0.208328    |
| PolicyLoss      | -0.015711   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0641      |
| _MeanReward     | 4.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 3.01214     |
| _max_adv        | 6.11        |
| _max_discrew    | 4.81        |
| _max_obs        | 1.04        |
| _mean_act       | -0.0956959  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.38        |
| _mean_obs       | 0.0385      |
| _min_adv        | -8.43       |
| _min_discrew    | 0.00602     |
| _min_obs        | -1.19       |
| _std_act        | 0.661381    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.938       |
| ExplainedVarOld | 0.932       |
| KL              | 2.6059e-05  |
| Phi_loss        | 1139.6      |
| PolicyEntropy   | 0.2089      |
| PolicyLoss      | -0.00311482 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0718      |
| _MeanReward     | 4.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.23534     |
| _max_adv        | 19.3        |
| _max_discrew    | 4.61        |
| _max_obs        | 1.08        |
| _mean_act       | -0.0927811  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.34        |
| _mean_obs       | 0.0386      |
| _min_adv        | -8.31       |
| _min_discrew    | 0.0163      |
| _min_obs        | -1.17       |
| _std_act        | 0.668144    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.872       |
| KL              | 6.51399e-05 |
| Phi_loss        | 1007.63     |
| PolicyEntropy   | 0.205638    |
| PolicyLoss      | 0.0244377   |
| Steps           | 10000       |
| VarFuncLoss     | 0.132       |
| _MeanReward     | 4.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.39758     |
| _max_adv        | 10          |
| _max_discrew    | 4.66        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0975272  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.45        |
| _mean_obs       | 0.0389      |
| _min_adv        | -7.91       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.23       |
| _std_act        | 0.668373    |
| _std_adv        | 1           |
| _std_discrew    | 1.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.946       |
| ExplainedVarOld | 0.942       |
| KL              | 0.000132863 |
| Phi_loss        | 1057.33     |
| PolicyEntropy   | 0.199397    |
| PolicyLoss      | -0.0244678  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0619      |
| _MeanReward     | 4.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07927     |
| _max_adv        | 7.23        |
| _max_discrew    | 4.67        |
| _max_obs        | 1.13        |
| _mean_act       | -0.0966926  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0392      |
| _min_adv        | -11         |
| _min_discrew    | 0.00777     |
| _min_obs        | -1.11       |
| _std_act        | 0.659998    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
--------------------------------
| Beta            | 0.405      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00027369 |
| Phi_loss        | 968.502    |
| PolicyEntropy   | 0.198855   |
| PolicyLoss      | -0.0250141 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0446     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.91322    |
| _max_adv        | 7.06       |
| _max_discrew    | 4.71       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0945384 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0391     |
| _min_adv        | -8.19      |
| _min_discrew    | -0.268     |
| _min_obs        | -1.18      |
| _std_act        | 0.666645   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.955       |
| KL              | 0.000501644 |
| Phi_loss        | 1106.5      |
| PolicyEntropy   | 0.204836    |
| PolicyLoss      | -0.00792272 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0503      |
| _MeanReward     | 4.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54062     |
| _max_adv        | 4.45        |
| _max_discrew    | 4.87        |
| _max_obs        | 1.08        |
| _mean_act       | -0.0978438  |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 3.58        |
| _mean_obs       | 0.039       |
| _min_adv        | -9.28       |
| _min_discrew    | 0.0183      |
| _min_obs        | -1.19       |
| _std_act        | 0.65806     |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.972       |
| KL              | 0.000700886 |
| Phi_loss        | 1088.88     |
| PolicyEntropy   | 0.198823    |
| PolicyLoss      | -0.0247902  |
| Steps           | 10000       |
| VarFuncLoss     | 0.035       |
| _MeanReward     | 4.29e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79658     |
| _max_adv        | 7.02        |
| _max_discrew    | 4.76        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0982448  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.55        |
| _mean_obs       | 0.0387      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0155      |
| _min_obs        | -1.27       |
| _std_act        | 0.657716    |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.968       |
| ExplainedVarOld | 0.967       |
| KL              | 0.000804589 |
| Phi_loss        | 1000.59     |
| PolicyEntropy   | 0.191311    |
| PolicyLoss      | -0.00960793 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0382      |
| _MeanReward     | 4.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.52434     |
| _max_adv        | 7.64        |
| _max_discrew    | 4.66        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0970617  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.0387      |
| _min_adv        | -8.14       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.14       |
| _std_act        | 0.659458    |
| _std_adv        | 1           |
| _std_discrew    | 1.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
---------------------------------
| Beta            | 0.0799      |
| ExplainedVarNew | 0.966       |
| ExplainedVarOld | 0.962       |
| KL              | 0.000760278 |
| Phi_loss        | 1179.01     |
| PolicyEntropy   | 0.167575    |
| PolicyLoss      | -0.0167549  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0397      |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85546     |
| _max_adv        | 5.3         |
| _max_discrew    | 4.64        |
| _max_obs        | 1.07        |
| _mean_act       | -0.0977125  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.62        |
| _mean_obs       | 0.0393      |
| _min_adv        | -7.68       |
| _min_discrew    | 0.0142      |
| _min_obs        | -1.14       |
| _std_act        | 0.661407    |
| _std_adv        | 1           |
| _std_discrew    | 1.16        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00174738 |
| Phi_loss        | 1266.01    |
| PolicyEntropy   | 0.145618   |
| PolicyLoss      | 0.0132704  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0337     |
| _MeanReward     | 3.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.17959    |
| _max_adv        | 2.52       |
| _max_discrew    | 4.87       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0856042 |
| _mean_adv       | 2.49e-17   |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0377     |
| _min_adv        | -16        |
| _min_discrew    | -1.39      |
| _min_obs        | -1.22      |
| _std_act        | 0.758984   |
| _std_adv        | 1          |
| _std_discrew    | 2.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.865       |
| ExplainedVarOld | 0.855       |
| KL              | 0.000865387 |
| Phi_loss        | 870.29      |
| PolicyEntropy   | 0.139308    |
| PolicyLoss      | 0.0197078   |
| Steps           | 10000       |
| VarFuncLoss     | 0.312       |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80468     |
| _max_adv        | 6.55        |
| _max_discrew    | 4.81        |
| _max_obs        | 1.09        |
| _mean_act       | -0.094928   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.59        |
| _mean_obs       | 0.0392      |
| _min_adv        | -10.5       |
| _min_discrew    | -0.000928   |
| _min_obs        | -1.27       |
| _std_act        | 0.665313    |
| _std_adv        | 1           |
| _std_discrew    | 1.32        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.949      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00170886 |
| Phi_loss        | 1032.61    |
| PolicyEntropy   | 0.126426   |
| PolicyLoss      | -0.0356044 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0702     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.26218    |
| _max_adv        | 18.7       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0970153 |
| _mean_adv       | -7.39e-17  |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0396     |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.19      |
| _std_act        | 0.663109   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00219006 |
| Phi_loss        | 977.263    |
| PolicyEntropy   | 0.0995474  |
| PolicyLoss      | -0.0129536 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0321     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.98473    |
| _max_adv        | 15.7       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.03       |
| _mean_act       | -0.0973198 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0394     |
| _min_adv        | -8.38      |
| _min_discrew    | 0.0145     |
| _min_obs        | -1.15      |
| _std_act        | 0.667769   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.941       |
| ExplainedVarOld | 0.935       |
| KL              | 0.00214356  |
| Phi_loss        | 1114.18     |
| PolicyEntropy   | 0.0826483   |
| PolicyLoss      | -0.00715248 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0813      |
| _MeanReward     | 4.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9084      |
| _max_adv        | 14.4        |
| _max_discrew    | 4.98        |
| _max_obs        | 1.07        |
| _mean_act       | -0.0999996  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0391      |
| _min_adv        | -11.4       |
| _min_discrew    | 0.0108      |
| _min_obs        | -1.34       |
| _std_act        | 0.670538    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.972      |
| KL              | 0.0015955  |
| Phi_loss        | 1009.63    |
| PolicyEntropy   | 0.0722933  |
| PolicyLoss      | 0.00736187 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0348     |
| _MeanReward     | 4.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.31398    |
| _max_adv        | 5.06       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0929114 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0389     |
| _min_adv        | -13.9      |
| _min_discrew    | -1.12      |
| _min_obs        | -1.18      |
| _std_act        | 0.726758   |
| _std_adv        | 1          |
| _std_discrew    | 1.91       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.855      |
| ExplainedVarOld | 0.836      |
| KL              | 0.00169947 |
| Phi_loss        | 1189.61    |
| PolicyEntropy   | 0.044034   |
| PolicyLoss      | 0.0290687  |
| Steps           | 10000      |
| VarFuncLoss     | 0.279      |
| _MeanReward     | 4.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.42577    |
| _max_adv        | 5.14       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0855233 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0374     |
| _min_adv        | -15.7      |
| _min_discrew    | -1.39      |
| _min_obs        | -1.3       |
| _std_act        | 0.757483   |
| _std_adv        | 1          |
| _std_discrew    | 2.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.854      |
| ExplainedVarOld | 0.842      |
| KL              | 0.00163019 |
| Phi_loss        | 1383.78    |
| PolicyEntropy   | 0.0233774  |
| PolicyLoss      | -0.0226317 |
| Steps           | 10000      |
| VarFuncLoss     | 0.392      |
| _MeanReward     | 4.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.46106    |
| _max_adv        | 7.46       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0804369 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0372     |
| _min_adv        | -18.7      |
| _min_discrew    | -1.47      |
| _min_obs        | -1.26      |
| _std_act        | 0.793876   |
| _std_adv        | 1          |
| _std_discrew    | 3.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.911      |
| ExplainedVarOld | 0.904      |
| KL              | 0.0016201  |
| Phi_loss        | 1318.74    |
| PolicyEntropy   | 0.0054636  |
| PolicyLoss      | -0.0200821 |
| Steps           | 10000      |
| VarFuncLoss     | 0.294      |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.37748    |
| _max_adv        | 15.6       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.11       |
| _mean_act       | -0.102171  |
| _mean_adv       | -6.39e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0398     |
| _min_adv        | -10.6      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.11      |
| _std_act        | 0.661606   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.975       |
| KL              | 0.00122927  |
| Phi_loss        | 1072.58     |
| PolicyEntropy   | -0.0270805  |
| PolicyLoss      | -0.00792086 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0262      |
| _MeanReward     | 4.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52902     |
| _max_adv        | 10.8        |
| _max_discrew    | 5.03        |
| _max_obs        | 1.06        |
| _mean_act       | -0.106623   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.78        |
| _mean_obs       | 0.039       |
| _min_adv        | -5.73       |
| _min_discrew    | 0.0146      |
| _min_obs        | -1.1        |
| _std_act        | 0.658265    |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.966       |
| KL              | 0.00152516  |
| Phi_loss        | 915.255     |
| PolicyEntropy   | -0.0309916  |
| PolicyLoss      | -0.00218532 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0331      |
| _MeanReward     | 4.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84159     |
| _max_adv        | 3.27        |
| _max_discrew    | 5           |
| _max_obs        | 1.13        |
| _mean_act       | -0.103284   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.71        |
| _mean_obs       | 0.0395      |
| _min_adv        | -10.9       |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.13       |
| _std_act        | 0.669783    |
| _std_adv        | 1           |
| _std_discrew    | 1.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.939      |
| ExplainedVarOld | 0.935      |
| KL              | 0.00357556 |
| Phi_loss        | 1168.01    |
| PolicyEntropy   | -0.0544453 |
| PolicyLoss      | -0.0136439 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0868     |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.22454    |
| _max_adv        | 9.21       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.13       |
| _mean_act       | -0.11003   |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 3.83       |
| _mean_obs       | 0.0395     |
| _min_adv        | -5.2       |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.17      |
| _std_act        | 0.662177   |
| _std_adv        | 1          |
| _std_discrew    | 1.38       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00583131 |
| Phi_loss        | 1201.86    |
| PolicyEntropy   | -0.111538  |
| PolicyLoss      | 0.0192985  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0209     |
| _MeanReward     | 4.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.14109    |
| _max_adv        | 9.24       |
| _max_discrew    | 5.18       |
| _max_obs        | 1.17       |
| _mean_act       | -0.113612  |
| _mean_adv       | 2.7e-17    |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.0399     |
| _min_adv        | -13.6      |
| _min_discrew    | 0.0134     |
| _min_obs        | -1.19      |
| _std_act        | 0.666526   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.00559162 |
| Phi_loss        | 1223.77    |
| PolicyEntropy   | -0.147168  |
| PolicyLoss      | 0.00333231 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0441     |
| _MeanReward     | 4.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42173    |
| _max_adv        | 25.6       |
| _max_discrew    | 5.17       |
| _max_obs        | 1.24       |
| _mean_act       | -0.116006  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.0396     |
| _min_adv        | -13.2      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.17      |
| _std_act        | 0.66076    |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00224648  |
| Phi_loss        | 930.521     |
| PolicyEntropy   | -0.158416   |
| PolicyLoss      | -0.00575765 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0321      |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.20187     |
| _max_adv        | 2.52        |
| _max_discrew    | 5.02        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0907338  |
| _mean_adv       | -8.53e-17   |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0358      |
| _min_adv        | -19.5       |
| _min_discrew    | -1.49       |
| _min_obs        | -1.14       |
| _std_act        | 0.819516    |
| _std_adv        | 1           |
| _std_discrew    | 3.44        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.95       |
| ExplainedVarOld | 0.945      |
| KL              | 0.00508865 |
| Phi_loss        | 1365.42    |
| PolicyEntropy   | -0.21721   |
| PolicyLoss      | -0.0314759 |
| Steps           | 10000      |
| VarFuncLoss     | 0.176      |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.7193     |
| _max_adv        | 2.29       |
| _max_discrew    | 5.09       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0970538 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.41       |
| _mean_obs       | 0.037      |
| _min_adv        | -18.4      |
| _min_discrew    | -1.47      |
| _min_obs        | -1.17      |
| _std_act        | 0.777499   |
| _std_adv        | 1          |
| _std_discrew    | 2.97       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.879      |
| KL              | 0.00235056 |
| Phi_loss        | 1202.75    |
| PolicyEntropy   | -0.261971  |
| PolicyLoss      | 0.0115904  |
| Steps           | 10000      |
| VarFuncLoss     | 0.349      |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.25328    |
| _max_adv        | 2.81       |
| _max_discrew    | 5.2        |
| _max_obs        | 1.24       |
| _mean_act       | -0.0932296 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.37       |
| _mean_obs       | 0.036      |
| _min_adv        | -17.5      |
| _min_discrew    | -1.48      |
| _min_obs        | -1.23      |
| _std_act        | 0.807528   |
| _std_adv        | 1          |
| _std_discrew    | 3.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.882      |
| ExplainedVarOld | 0.879      |
| KL              | 0.00274956 |
| Phi_loss        | 1506.34    |
| PolicyEntropy   | -0.281127  |
| PolicyLoss      | 0.00383686 |
| Steps           | 10000      |
| VarFuncLoss     | 0.407      |
| _MeanReward     | 4.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15208    |
| _max_adv        | 4.98       |
| _max_discrew    | 5.06       |
| _max_obs        | 1.07       |
| _mean_act       | -0.117243  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.039      |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.26      |
| _std_act        | 0.64705    |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 477
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00118473 |
| Phi_loss        | 1109.06    |
| PolicyEntropy   | -0.289915  |
| PolicyLoss      | 0.00223789 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0409     |
| _MeanReward     | 4.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.20472    |
| _max_adv        | 16.8       |
| _max_discrew    | 5.22       |
| _max_obs        | 1.24       |
| _mean_act       | -0.112616  |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 3.81       |
| _mean_obs       | 0.0388     |
| _min_adv        | -18.6      |
| _min_discrew    | -1.07      |
| _min_obs        | -1.1       |
| _std_act        | 0.701006   |
| _std_adv        | 1          |
| _std_discrew    | 2.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 478
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.903      |
| KL              | 0.00267235 |
| Phi_loss        | 996.905    |
| PolicyEntropy   | -0.271049  |
| PolicyLoss      | -0.0452751 |
| Steps           | 10000      |
| VarFuncLoss     | 0.183      |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.38228    |
| _max_adv        | 9.65       |
| _max_discrew    | 5.13       |
| _max_obs        | 1.31       |
| _mean_act       | -0.101622  |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0372     |
| _min_adv        | -18.9      |
| _min_discrew    | -1.46      |
| _min_obs        | -1.32      |
| _std_act        | 0.770649   |
| _std_adv        | 1          |
| _std_discrew    | 2.93       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 479
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.892      |
| ExplainedVarOld | 0.885      |
| KL              | 0.00168784 |
| Phi_loss        | 1117.1     |
| PolicyEntropy   | -0.250268  |
| PolicyLoss      | 0.0142914  |
| Steps           | 10000      |
| VarFuncLoss     | 0.318      |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.41983    |
| _max_adv        | 11.1       |
| _max_discrew    | 5.1        |
| _max_obs        | 1.3        |
| _mean_act       | -0.107394  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0383     |
| _min_adv        | -17        |
| _min_discrew    | -1.32      |
| _min_obs        | -1.16      |
| _std_act        | 0.746136   |
| _std_adv        | 1          |
| _std_discrew    | 2.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 480
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.88       |
| KL              | 0.00334488 |
| Phi_loss        | 1216.82    |
| PolicyEntropy   | -0.240836  |
| PolicyLoss      | -0.0276151 |
| Steps           | 10000      |
| VarFuncLoss     | 0.29       |
| _MeanReward     | 4.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76873    |
| _max_adv        | 17.3       |
| _max_discrew    | 5.18       |
| _max_obs        | 1.08       |
| _mean_act       | -0.11943   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0386     |
| _min_adv        | -9.73      |
| _min_discrew    | 0.00991    |
| _min_obs        | -1.14      |
| _std_act        | 0.666039   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 481
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.95       |
| KL              | 0.00143571 |
| Phi_loss        | 1040.03    |
| PolicyEntropy   | -0.253688  |
| PolicyLoss      | 0.0171556  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0621     |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 3.21378    |
| _max_adv        | 15.1       |
| _max_discrew    | 5.16       |
| _max_obs        | 1.1        |
| _mean_act       | -0.119732  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.0387     |
| _min_adv        | -9.81      |
| _min_discrew    | 0.00395    |
| _min_obs        | -1.17      |
| _std_act        | 0.658993   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 482
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.952      |
| KL              | 0.00294151 |
| Phi_loss        | 1007.78    |
| PolicyEntropy   | -0.278863  |
| PolicyLoss      | -0.0121746 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0603     |
| _MeanReward     | 4.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.22715    |
| _max_adv        | 24.3       |
| _max_discrew    | 5.17       |
| _max_obs        | 1.07       |
| _mean_act       | -0.120462  |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.0387     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.0102     |
| _min_obs        | -1.13      |
| _std_act        | 0.656392   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
