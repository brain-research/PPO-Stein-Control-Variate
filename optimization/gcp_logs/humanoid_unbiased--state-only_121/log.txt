Logging to humanoid_unbiased--state-only_121
using small structure
Policy Params -- h1: 377, h2: 80,                     h3: 17, lr: 0.000101, logvar_speed: 3
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
--------------------------------
| Steps         | 10016        |
| _MeanReward   | 106          |
| _max_act      | 3.15237      |
| _max_adv      | 4.18         |
| _max_discrew  | 1.21         |
| _max_obs      | 1.13e+03     |
| _mean_act     | -1.22904e-05 |
| _mean_adv     | 2.98e-17     |
| _mean_discrew | 0.295        |
| _mean_obs     | 0.00266      |
| _min_adv      | -4.26        |
| _min_discrew  | 0.0126       |
| _min_obs      | -550         |
| _std_act      | 0.405047     |
| _std_adv      | 1            |
| _std_discrew  | 0.0363       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
----------------------------------
| Beta            | 1            |
| ExplainedVarNew | 0.675        |
| ExplainedVarOld | -3.03        |
| KL              | 0.00188803   |
| Phi_loss        | 4.7757       |
| PolicyEntropy   | 15.6177      |
| PolicyLoss      | 0.00469744   |
| Steps           | 10010        |
| VarFuncLoss     | 0.0118       |
| _MeanReward     | 105          |
| _lr_multiplier  | 1            |
| _max_act        | 3.08768      |
| _max_adv        | 6.15         |
| _max_discrew    | 1.1          |
| _max_obs        | 57.3         |
| _mean_act       | -0.000942306 |
| _mean_adv       | 2.27e-17     |
| _mean_discrew   | 0.289        |
| _mean_obs       | -0.000924    |
| _min_adv        | -8.37        |
| _min_discrew    | 0.00956      |
| _min_obs        | -24.1        |
| _std_act        | 0.400961     |
| _std_adv        | 1            |
| _std_discrew    | 0.0328       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
---------------------------------
| Beta            | 1           |
| ExplainedVarNew | 0.691       |
| ExplainedVarOld | 0.629       |
| KL              | 0.00188727  |
| Phi_loss        | 68.4302     |
| PolicyEntropy   | 15.6131     |
| PolicyLoss      | -0.00898012 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0101      |
| _MeanReward     | 111         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19997     |
| _max_adv        | 4.82        |
| _max_discrew    | 1.2         |
| _max_obs        | 39.3        |
| _mean_act       | 0.00132418  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.305       |
| _mean_obs       | 0.000664    |
| _min_adv        | -3.68       |
| _min_discrew    | 0.00244     |
| _min_obs        | -36.2       |
| _std_act        | 0.401735    |
| _std_adv        | 1           |
| _std_discrew    | 0.0374      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
----------------------------------
| Beta            | 1            |
| ExplainedVarNew | 0.669        |
| ExplainedVarOld | 0.636        |
| KL              | 0.00188844   |
| Phi_loss        | 84.618       |
| PolicyEntropy   | 15.6064      |
| PolicyLoss      | -0.0722819   |
| Steps           | 10018        |
| VarFuncLoss     | 0.0124       |
| _MeanReward     | 112          |
| _lr_multiplier  | 1            |
| _max_act        | 2.72035      |
| _max_adv        | 5.65         |
| _max_discrew    | 1.06         |
| _max_obs        | 72.4         |
| _mean_act       | -0.000325636 |
| _mean_adv       | 5.67e-18     |
| _mean_discrew   | 0.307        |
| _mean_obs       | 0.000594     |
| _min_adv        | -4.75        |
| _min_discrew    | -0.000989    |
| _min_obs        | -84.8        |
| _std_act        | 0.400055     |
| _std_adv        | 1            |
| _std_discrew    | 0.0364       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.707       |
| ExplainedVarOld | 0.652       |
| KL              | 0.000920877 |
| Phi_loss        | 88.1231     |
| PolicyEntropy   | 15.6088     |
| PolicyLoss      | 0.00128652  |
| Steps           | 10003       |
| VarFuncLoss     | 0.0107      |
| _MeanReward     | 109         |
| _lr_multiplier  | 1           |
| _max_act        | 2.74626     |
| _max_adv        | 5.5         |
| _max_discrew    | 1.23        |
| _max_obs        | 20.1        |
| _mean_act       | 0.00101199  |
| _mean_adv       | -9.23e-18   |
| _mean_discrew   | 0.304       |
| _mean_obs       | -0.000114   |
| _min_adv        | -3.2        |
| _min_discrew    | 0.0123      |
| _min_obs        | -16.7       |
| _std_act        | 0.398585    |
| _std_adv        | 1           |
| _std_discrew    | 0.0397      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.679      |
| ExplainedVarOld | 0.622      |
| KL              | 0.00181359 |
| Phi_loss        | 93.5624    |
| PolicyEntropy   | 15.6092    |
| PolicyLoss      | 0.0191011  |
| Steps           | 10001      |
| VarFuncLoss     | 0.0128     |
| _MeanReward     | 113        |
| _lr_multiplier  | 1          |
| _max_act        | 2.93074    |
| _max_adv        | 6.21       |
| _max_discrew    | 1.3        |
| _max_obs        | 36.6       |
| _mean_act       | 0.00300665 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 0.313      |
| _mean_obs       | -2.97e-06  |
| _min_adv        | -4.28      |
| _min_discrew    | 0.000232   |
| _min_obs        | -32        |
| _std_act        | 0.403263   |
| _std_adv        | 1          |
| _std_discrew    | 0.0401     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.691       |
| ExplainedVarOld | 0.611       |
| KL              | 0.00133459  |
| Phi_loss        | 94.4538     |
| PolicyEntropy   | 15.6041     |
| PolicyLoss      | 0.000644148 |
| Steps           | 10010       |
| VarFuncLoss     | 0.0124      |
| _MeanReward     | 117         |
| _lr_multiplier  | 1           |
| _max_act        | 2.75877     |
| _max_adv        | 5.33        |
| _max_discrew    | 1.31        |
| _max_obs        | 73.8        |
| _mean_act       | 0.00329485  |
| _mean_adv       | -1.56e-17   |
| _mean_discrew   | 0.325       |
| _mean_obs       | -0.000206   |
| _min_adv        | -3.57       |
| _min_discrew    | 0.00948     |
| _min_obs        | -48         |
| _std_act        | 0.401788    |
| _std_adv        | 1           |
| _std_discrew    | 0.0431      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.7        |
| ExplainedVarOld | 0.64       |
| KL              | 0.00338664 |
| Phi_loss        | 102.616    |
| PolicyEntropy   | 15.5991    |
| PolicyLoss      | 0.0212154  |
| Steps           | 10023      |
| VarFuncLoss     | 0.0129     |
| _MeanReward     | 118        |
| _lr_multiplier  | 1          |
| _max_act        | 2.65782    |
| _max_adv        | 6.27       |
| _max_discrew    | 1.27       |
| _max_obs        | 71.9       |
| _mean_act       | 0.00175078 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.328      |
| _mean_obs       | 0.00117    |
| _min_adv        | -4.06      |
| _min_discrew    | 0.00716    |
| _min_obs        | -65.3      |
| _std_act        | 0.40189    |
| _std_adv        | 1          |
| _std_discrew    | 0.0437     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.702      |
| ExplainedVarOld | 0.638      |
| KL              | 0.00297322 |
| Phi_loss        | 100.199    |
| PolicyEntropy   | 15.5906    |
| PolicyLoss      | 0.0019981  |
| Steps           | 10014      |
| VarFuncLoss     | 0.013      |
| _MeanReward     | 124        |
| _lr_multiplier  | 1          |
| _max_act        | 2.81788    |
| _max_adv        | 5.74       |
| _max_discrew    | 1.26       |
| _max_obs        | 98.2       |
| _mean_act       | 0.00555038 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.341      |
| _mean_obs       | 0.000974   |
| _min_adv        | -3.61      |
| _min_discrew    | -0.0228    |
| _min_obs        | -29.3      |
| _std_act        | 0.398057   |
| _std_adv        | 1          |
| _std_discrew    | 0.0464     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.696      |
| ExplainedVarOld | 0.637      |
| KL              | 0.00167164 |
| Phi_loss        | 93.884     |
| PolicyEntropy   | 15.5873    |
| PolicyLoss      | -0.0010814 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0143     |
| _MeanReward     | 129        |
| _lr_multiplier  | 1          |
| _max_act        | 2.58054    |
| _max_adv        | 5.16       |
| _max_discrew    | 1.23       |
| _max_obs        | 50.3       |
| _mean_act       | 0.00440732 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.354      |
| _mean_obs       | 0.000986   |
| _min_adv        | -7         |
| _min_discrew    | 0.0161     |
| _min_obs        | -25.4      |
| _std_act        | 0.404479   |
| _std_adv        | 1          |
| _std_discrew    | 0.0488     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.737      |
| ExplainedVarOld | 0.646      |
| KL              | 0.0120218  |
| Phi_loss        | 107.71     |
| PolicyEntropy   | 15.5869    |
| PolicyLoss      | -0.71525   |
| Steps           | 10052      |
| VarFuncLoss     | 0.0129     |
| _MeanReward     | 129        |
| _lr_multiplier  | 1          |
| _max_act        | 3.14327    |
| _max_adv        | 5.28       |
| _max_discrew    | 1.49       |
| _max_obs        | 60.2       |
| _mean_act       | 0.00506166 |
| _mean_adv       | 8.48e-18   |
| _mean_discrew   | 0.358      |
| _mean_obs       | 0.0012     |
| _min_adv        | -3.32      |
| _min_discrew    | 0.0122     |
| _min_obs        | -47.3      |
| _std_act        | 0.406338   |
| _std_adv        | 1          |
| _std_discrew    | 0.0551     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.682      |
| ExplainedVarOld | 0.577      |
| KL              | 0.00524382 |
| Phi_loss        | 99.0448    |
| PolicyEntropy   | 15.5729    |
| PolicyLoss      | 0.023819   |
| Steps           | 10012      |
| VarFuncLoss     | 0.0176     |
| _MeanReward     | 132        |
| _lr_multiplier  | 1          |
| _max_act        | 2.75846    |
| _max_adv        | 5.64       |
| _max_discrew    | 1.46       |
| _max_obs        | 65.1       |
| _mean_act       | 0.00513443 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 0.362      |
| _mean_obs       | 0.00118    |
| _min_adv        | -6.35      |
| _min_discrew    | 0.0129     |
| _min_obs        | -27.6      |
| _std_act        | 0.403368   |
| _std_adv        | 1          |
| _std_discrew    | 0.0529     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.719       |
| ExplainedVarOld | 0.639       |
| KL              | 0.000903574 |
| Phi_loss        | 95.2822     |
| PolicyEntropy   | 15.5685     |
| PolicyLoss      | 0.00182868  |
| Steps           | 10033       |
| VarFuncLoss     | 0.0149      |
| _MeanReward     | 138         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87887     |
| _max_adv        | 6.67        |
| _max_discrew    | 2.26        |
| _max_obs        | 49.5        |
| _mean_act       | 0.00954635  |
| _mean_adv       | -5.67e-18   |
| _mean_discrew   | 0.385       |
| _mean_obs       | 0.00141     |
| _min_adv        | -4.08       |
| _min_discrew    | 0.00126     |
| _min_obs        | -38         |
| _std_act        | 0.406209    |
| _std_adv        | 1           |
| _std_discrew    | 0.0727      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.71        |
| ExplainedVarOld | 0.524       |
| KL              | 0.0016103   |
| Phi_loss        | 80.3835     |
| PolicyEntropy   | 15.5671     |
| PolicyLoss      | -0.00194202 |
| Steps           | 10034       |
| VarFuncLoss     | 0.0214      |
| _MeanReward     | 134         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95109     |
| _max_adv        | 5.99        |
| _max_discrew    | 1.86        |
| _max_obs        | 33.9        |
| _mean_act       | 0.00692093  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.375       |
| _mean_obs       | 0.000608    |
| _min_adv        | -5.79       |
| _min_discrew    | 0.0102      |
| _min_obs        | -23.2       |
| _std_act        | 0.404555    |
| _std_adv        | 1           |
| _std_discrew    | 0.0618      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.69        |
| ExplainedVarOld | 0.548       |
| KL              | 0.00144686  |
| Phi_loss        | 86.0809     |
| PolicyEntropy   | 15.5668     |
| PolicyLoss      | -0.00440419 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0192      |
| _MeanReward     | 139         |
| _lr_multiplier  | 1           |
| _max_act        | 3.37484     |
| _max_adv        | 4.98        |
| _max_discrew    | 1.38        |
| _max_obs        | 50.7        |
| _mean_act       | 0.00690896  |
| _mean_adv       | -1.07e-18   |
| _mean_discrew   | 0.381       |
| _mean_obs       | 0.000662    |
| _min_adv        | -6.64       |
| _min_discrew    | 0.0116      |
| _min_obs        | -27.2       |
| _std_act        | 0.403857    |
| _std_adv        | 1           |
| _std_discrew    | 0.0584      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.707        |
| ExplainedVarOld | 0.56         |
| KL              | 0.00249828   |
| Phi_loss        | 77.3387      |
| PolicyEntropy   | 15.5661      |
| PolicyLoss      | -0.000678688 |
| Steps           | 10013        |
| VarFuncLoss     | 0.0172       |
| _MeanReward     | 146          |
| _lr_multiplier  | 1            |
| _max_act        | 2.88555      |
| _max_adv        | 4.91         |
| _max_discrew    | 1.51         |
| _max_obs        | 62.3         |
| _mean_act       | 0.0113802    |
| _mean_adv       | -2.34e-17    |
| _mean_discrew   | 0.406        |
| _mean_obs       | 0.00166      |
| _min_adv        | -5.84        |
| _min_discrew    | 0.00183      |
| _min_obs        | -27.2        |
| _std_act        | 0.40762      |
| _std_adv        | 1            |
| _std_discrew    | 0.0694       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.7        |
| ExplainedVarOld | 0.582      |
| KL              | 0.00511185 |
| Phi_loss        | 87.4396    |
| PolicyEntropy   | 15.5651    |
| PolicyLoss      | 0.0280251  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0209     |
| _MeanReward     | 154        |
| _lr_multiplier  | 1          |
| _max_act        | 2.62205    |
| _max_adv        | 5.65       |
| _max_discrew    | 1.51       |
| _max_obs        | 53.5       |
| _mean_act       | 0.0101403  |
| _mean_adv       | -1.56e-17  |
| _mean_discrew   | 0.421      |
| _mean_obs       | 0.00187    |
| _min_adv        | -3.8       |
| _min_discrew    | 0.00814    |
| _min_obs        | -47.8      |
| _std_act        | 0.404697   |
| _std_adv        | 1          |
| _std_discrew    | 0.0715     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.722        |
| ExplainedVarOld | 0.621        |
| KL              | 0.00316456   |
| Phi_loss        | 83.1671      |
| PolicyEntropy   | 15.56        |
| PolicyLoss      | -0.000515002 |
| Steps           | 10008        |
| VarFuncLoss     | 0.02         |
| _MeanReward     | 154          |
| _lr_multiplier  | 1            |
| _max_act        | 2.78398      |
| _max_adv        | 5.14         |
| _max_discrew    | 1.63         |
| _max_obs        | 61           |
| _mean_act       | 0.00987408   |
| _mean_adv       | 1.42e-18     |
| _mean_discrew   | 0.422        |
| _mean_obs       | 0.00252      |
| _min_adv        | -3.9         |
| _min_discrew    | 0.0109       |
| _min_obs        | -51.1        |
| _std_act        | 0.405976     |
| _std_adv        | 1            |
| _std_discrew    | 0.074        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.721      |
| ExplainedVarOld | 0.613      |
| KL              | 0.0035226  |
| Phi_loss        | 82.4418    |
| PolicyEntropy   | 15.5563    |
| PolicyLoss      | 0.00161448 |
| Steps           | 10008      |
| VarFuncLoss     | 0.0207     |
| _MeanReward     | 167        |
| _lr_multiplier  | 1          |
| _max_act        | 3.03713    |
| _max_adv        | 4.78       |
| _max_discrew    | 1.7        |
| _max_obs        | 98.5       |
| _mean_act       | 0.00961641 |
| _mean_adv       | 9.23e-18   |
| _mean_discrew   | 0.454      |
| _mean_obs       | 0.0021     |
| _min_adv        | -3.64      |
| _min_discrew    | 0.0107     |
| _min_obs        | -40.9      |
| _std_act        | 0.405431   |
| _std_adv        | 1          |
| _std_discrew    | 0.0825     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.72        |
| ExplainedVarOld | 0.587       |
| KL              | 0.00279553  |
| Phi_loss        | 76.813      |
| PolicyEntropy   | 15.5537     |
| PolicyLoss      | -0.00164044 |
| Steps           | 10008       |
| VarFuncLoss     | 0.0235      |
| _MeanReward     | 167         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06743     |
| _max_adv        | 5.22        |
| _max_discrew    | 1.65        |
| _max_obs        | 40.3        |
| _mean_act       | 0.0120478   |
| _mean_adv       | 4.54e-17    |
| _mean_discrew   | 0.457       |
| _mean_obs       | 0.00215     |
| _min_adv        | -3.7        |
| _min_discrew    | 0.0148      |
| _min_obs        | -30.9       |
| _std_act        | 0.40436     |
| _std_adv        | 1           |
| _std_discrew    | 0.0845      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.7         |
| ExplainedVarOld | 0.597       |
| KL              | 0.00232151  |
| Phi_loss        | 72.85       |
| PolicyEntropy   | 15.55       |
| PolicyLoss      | 0.000915154 |
| Steps           | 10021       |
| VarFuncLoss     | 0.0254      |
| _MeanReward     | 177         |
| _lr_multiplier  | 1           |
| _max_act        | 2.67619     |
| _max_adv        | 4.5         |
| _max_discrew    | 1.49        |
| _max_obs        | 23.6        |
| _mean_act       | 0.0130984   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 0.477       |
| _mean_obs       | 0.00216     |
| _min_adv        | -4.39       |
| _min_discrew    | 0.0136      |
| _min_obs        | -20.7       |
| _std_act        | 0.406112    |
| _std_adv        | 1           |
| _std_discrew    | 0.086       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.724        |
| ExplainedVarOld | 0.603        |
| KL              | 0.0028183    |
| Phi_loss        | 73.8364      |
| PolicyEntropy   | 15.5478      |
| PolicyLoss      | -0.000953643 |
| Steps           | 10031        |
| VarFuncLoss     | 0.0238       |
| _MeanReward     | 178          |
| _lr_multiplier  | 1            |
| _max_act        | 3.27704      |
| _max_adv        | 4.69         |
| _max_discrew    | 1.95         |
| _max_obs        | 26           |
| _mean_act       | 0.0140204    |
| _mean_adv       | -1.7e-17     |
| _mean_discrew   | 0.49         |
| _mean_obs       | 0.002        |
| _min_adv        | -3.76        |
| _min_discrew    | 0.0145       |
| _min_obs        | -33          |
| _std_act        | 0.406871     |
| _std_adv        | 1            |
| _std_discrew    | 0.102        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.705       |
| ExplainedVarOld | 0.55        |
| KL              | 0.00296551  |
| Phi_loss        | 70.5887     |
| PolicyEntropy   | 15.5449     |
| PolicyLoss      | -0.00425303 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0302      |
| _MeanReward     | 179         |
| _lr_multiplier  | 1           |
| _max_act        | 2.81645     |
| _max_adv        | 4.43        |
| _max_discrew    | 1.95        |
| _max_obs        | 31          |
| _mean_act       | 0.016948    |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 0.491       |
| _mean_obs       | 0.00264     |
| _min_adv        | -3.9        |
| _min_discrew    | 0.00386     |
| _min_obs        | -29.6       |
| _std_act        | 0.409334    |
| _std_adv        | 1           |
| _std_discrew    | 0.104       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.693      |
| ExplainedVarOld | 0.553      |
| KL              | 0.00295437 |
| Phi_loss        | 70.0754    |
| PolicyEntropy   | 15.5396    |
| PolicyLoss      | 0.00156864 |
| Steps           | 10028      |
| VarFuncLoss     | 0.0322     |
| _MeanReward     | 191        |
| _lr_multiplier  | 1          |
| _max_act        | 3.60138    |
| _max_adv        | 5.54       |
| _max_discrew    | 1.57       |
| _max_obs        | 32.7       |
| _mean_act       | 0.0183309  |
| _mean_adv       | -1.13e-17  |
| _mean_discrew   | 0.505      |
| _mean_obs       | 0.00321    |
| _min_adv        | -3.75      |
| _min_discrew    | 0.0114     |
| _min_obs        | -22.5      |
| _std_act        | 0.410458   |
| _std_adv        | 1          |
| _std_discrew    | 0.0959     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.746      |
| ExplainedVarOld | 0.599      |
| KL              | 0.00338853 |
| Phi_loss        | 70.0334    |
| PolicyEntropy   | 15.535     |
| PolicyLoss      | 0.00067615 |
| Steps           | 10020      |
| VarFuncLoss     | 0.0244     |
| _MeanReward     | 201        |
| _lr_multiplier  | 1          |
| _max_act        | 2.83915    |
| _max_adv        | 4.53       |
| _max_discrew    | 1.72       |
| _max_obs        | 27.7       |
| _mean_act       | 0.0198888  |
| _mean_adv       | -1.7e-17   |
| _mean_discrew   | 0.538      |
| _mean_obs       | 0.00316    |
| _min_adv        | -3.56      |
| _min_discrew    | -0.0169    |
| _min_obs        | -24.7      |
| _std_act        | 0.407277   |
| _std_adv        | 1          |
| _std_discrew    | 0.113      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.738      |
| ExplainedVarOld | 0.597      |
| KL              | 0.00411911 |
| Phi_loss        | 88.9864    |
| PolicyEntropy   | 15.5325    |
| PolicyLoss      | 0.00584803 |
| Steps           | 10003      |
| VarFuncLoss     | 0.0298     |
| _MeanReward     | 194        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8933     |
| _max_adv        | 4.07       |
| _max_discrew    | 1.72       |
| _max_obs        | 42.4       |
| _mean_act       | 0.018737   |
| _mean_adv       | 3.09e-17   |
| _mean_discrew   | 0.52       |
| _mean_obs       | 0.00297    |
| _min_adv        | -3.53      |
| _min_discrew    | 0.0137     |
| _min_obs        | -43.4      |
| _std_act        | 0.407116   |
| _std_adv        | 1          |
| _std_discrew    | 0.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.732       |
| ExplainedVarOld | 0.6         |
| KL              | 0.00300442  |
| Phi_loss        | 89.3148     |
| PolicyEntropy   | 15.5279     |
| PolicyLoss      | 7.47505e-05 |
| Steps           | 10023       |
| VarFuncLoss     | 0.0295      |
| _MeanReward     | 205         |
| _lr_multiplier  | 1           |
| _max_act        | 2.8978      |
| _max_adv        | 5.25        |
| _max_discrew    | 1.91        |
| _max_obs        | 38.5        |
| _mean_act       | 0.0219764   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 0.54        |
| _mean_obs       | 0.00366     |
| _min_adv        | -3.44       |
| _min_discrew    | 0.00612     |
| _min_obs        | -26         |
| _std_act        | 0.407047    |
| _std_adv        | 1           |
| _std_discrew    | 0.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.77        |
| ExplainedVarOld | 0.618       |
| KL              | 0.00282826  |
| Phi_loss        | 87.3696     |
| PolicyEntropy   | 15.5246     |
| PolicyLoss      | -0.00725574 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0253      |
| _MeanReward     | 212         |
| _lr_multiplier  | 1           |
| _max_act        | 2.94496     |
| _max_adv        | 6.43        |
| _max_discrew    | 2.44        |
| _max_obs        | 46.7        |
| _mean_act       | 0.0257627   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.563       |
| _mean_obs       | 0.00331     |
| _min_adv        | -3.73       |
| _min_discrew    | 0.00994     |
| _min_obs        | -27.8       |
| _std_act        | 0.408626    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.757      |
| ExplainedVarOld | 0.564      |
| KL              | 0.00306739 |
| Phi_loss        | 85.76      |
| PolicyEntropy   | 15.5229    |
| PolicyLoss      | -0.0048369 |
| Steps           | 10009      |
| VarFuncLoss     | 0.0318     |
| _MeanReward     | 216        |
| _lr_multiplier  | 1          |
| _max_act        | 2.92781    |
| _max_adv        | 4.93       |
| _max_discrew    | 1.72       |
| _max_obs        | 23.3       |
| _mean_act       | 0.023948   |
| _mean_adv       | 1.06e-17   |
| _mean_discrew   | 0.572      |
| _mean_obs       | 0.00289    |
| _min_adv        | -3.85      |
| _min_discrew    | 0.00984    |
| _min_obs        | -27.7      |
| _std_act        | 0.407671   |
| _std_adv        | 1          |
| _std_discrew    | 0.126      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.757        |
| ExplainedVarOld | 0.597        |
| KL              | 0.00268049   |
| Phi_loss        | 86.6097      |
| PolicyEntropy   | 15.5208      |
| PolicyLoss      | -0.000712599 |
| Steps           | 10042        |
| VarFuncLoss     | 0.0307       |
| _MeanReward     | 231          |
| _lr_multiplier  | 1            |
| _max_act        | 2.70621      |
| _max_adv        | 4            |
| _max_discrew    | 2.05         |
| _max_obs        | 32.7         |
| _mean_act       | 0.0261054    |
| _mean_adv       | 8.49e-18     |
| _mean_discrew   | 0.606        |
| _mean_obs       | 0.00192      |
| _min_adv        | -4.1         |
| _min_discrew    | 0.00981      |
| _min_obs        | -26.7        |
| _std_act        | 0.407899     |
| _std_adv        | 1            |
| _std_discrew    | 0.146        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.768      |
| ExplainedVarOld | 0.588      |
| KL              | 0.00264853 |
| Phi_loss        | 76.724     |
| PolicyEntropy   | 15.5162    |
| PolicyLoss      | 0.00172366 |
| Steps           | 10014      |
| VarFuncLoss     | 0.0342     |
| _MeanReward     | 241        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0237     |
| _max_adv        | 4.69       |
| _max_discrew    | 2.06       |
| _max_obs        | 28.4       |
| _mean_act       | 0.0277932  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.626      |
| _mean_obs       | 0.00254    |
| _min_adv        | -4.48      |
| _min_discrew    | 0.00239    |
| _min_obs        | -26.4      |
| _std_act        | 0.410281   |
| _std_adv        | 1          |
| _std_discrew    | 0.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.77        |
| ExplainedVarOld | 0.551       |
| KL              | 0.00326062  |
| Phi_loss        | 74.4053     |
| PolicyEntropy   | 15.5134     |
| PolicyLoss      | -0.00712309 |
| Steps           | 10037       |
| VarFuncLoss     | 0.0346      |
| _MeanReward     | 240         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13965     |
| _max_adv        | 5.97        |
| _max_discrew    | 2.1         |
| _max_obs        | 22.4        |
| _mean_act       | 0.025444    |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.617       |
| _mean_obs       | 0.0037      |
| _min_adv        | -4.38       |
| _min_discrew    | 0.00883     |
| _min_obs        | -20.2       |
| _std_act        | 0.409346    |
| _std_adv        | 1           |
| _std_discrew    | 0.142       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.781        |
| ExplainedVarOld | 0.592        |
| KL              | 0.00255097   |
| Phi_loss        | 76.8981      |
| PolicyEntropy   | 15.5111      |
| PolicyLoss      | -0.000593533 |
| Steps           | 10069        |
| VarFuncLoss     | 0.0311       |
| _MeanReward     | 231          |
| _lr_multiplier  | 1            |
| _max_act        | 2.85301      |
| _max_adv        | 4.45         |
| _max_discrew    | 2.06         |
| _max_obs        | 50.8         |
| _mean_act       | 0.025147     |
| _mean_adv       | 2.82e-18     |
| _mean_discrew   | 0.607        |
| _mean_obs       | 0.00255      |
| _min_adv        | -4.16        |
| _min_discrew    | 0.0141       |
| _min_obs        | -23.9        |
| _std_act        | 0.405975     |
| _std_adv        | 1            |
| _std_discrew    | 0.144        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.773       |
| ExplainedVarOld | 0.576       |
| KL              | 0.00273154  |
| Phi_loss        | 76.3028     |
| PolicyEntropy   | 15.5082     |
| PolicyLoss      | -0.00110878 |
| Steps           | 10005       |
| VarFuncLoss     | 0.0326      |
| _MeanReward     | 246         |
| _lr_multiplier  | 1           |
| _max_act        | 2.71695     |
| _max_adv        | 4.89        |
| _max_discrew    | 2.05        |
| _max_obs        | 32.1        |
| _mean_act       | 0.0265299   |
| _mean_adv       | -7.1e-19    |
| _mean_discrew   | 0.633       |
| _mean_obs       | 0.00381     |
| _min_adv        | -3.96       |
| _min_discrew    | 0.0128      |
| _min_obs        | -23.8       |
| _std_act        | 0.410041    |
| _std_adv        | 1           |
| _std_discrew    | 0.152       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.794       |
| ExplainedVarOld | 0.573       |
| KL              | 0.00308775  |
| Phi_loss        | 75.5664     |
| PolicyEntropy   | 15.506      |
| PolicyLoss      | -0.00272641 |
| Steps           | 10076       |
| VarFuncLoss     | 0.0313      |
| _MeanReward     | 257         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93896     |
| _max_adv        | 4.59        |
| _max_discrew    | 2.11        |
| _max_obs        | 36.1        |
| _mean_act       | 0.0306139   |
| _mean_adv       | -2.61e-17   |
| _mean_discrew   | 0.663       |
| _mean_obs       | 0.00372     |
| _min_adv        | -4.64       |
| _min_discrew    | 0.00964     |
| _min_obs        | -30.8       |
| _std_act        | 0.406868    |
| _std_adv        | 1           |
| _std_discrew    | 0.166       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.79        |
| ExplainedVarOld | 0.604       |
| KL              | 0.00271148  |
| Phi_loss        | 73.1355     |
| PolicyEntropy   | 15.5032     |
| PolicyLoss      | -0.00201621 |
| Steps           | 10024       |
| VarFuncLoss     | 0.0349      |
| _MeanReward     | 255         |
| _lr_multiplier  | 1           |
| _max_act        | 3.49559     |
| _max_adv        | 4.02        |
| _max_discrew    | 2.09        |
| _max_obs        | 27.8        |
| _mean_act       | 0.0266752   |
| _mean_adv       | -8.51e-18   |
| _mean_discrew   | 0.657       |
| _mean_obs       | 0.00315     |
| _min_adv        | -5.16       |
| _min_discrew    | 0.0094      |
| _min_obs        | -17         |
| _std_act        | 0.409479    |
| _std_adv        | 1           |
| _std_discrew    | 0.164       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.794      |
| ExplainedVarOld | 0.617      |
| KL              | 0.00430984 |
| Phi_loss        | 81.7913    |
| PolicyEntropy   | 15.5001    |
| PolicyLoss      | -0.0274211 |
| Steps           | 10025      |
| VarFuncLoss     | 0.0338     |
| _MeanReward     | 264        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8979     |
| _max_adv        | 4.26       |
| _max_discrew    | 2.08       |
| _max_obs        | 47.6       |
| _mean_act       | 0.032752   |
| _mean_adv       | -5.67e-18  |
| _mean_discrew   | 0.677      |
| _mean_obs       | 0.00359    |
| _min_adv        | -4.35      |
| _min_discrew    | 0.0139     |
| _min_obs        | -40.9      |
| _std_act        | 0.410022   |
| _std_adv        | 1          |
| _std_discrew    | 0.169      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.799       |
| ExplainedVarOld | 0.603       |
| KL              | 0.00370904  |
| Phi_loss        | 77.5406     |
| PolicyEntropy   | 15.4985     |
| PolicyLoss      | -0.00207013 |
| Steps           | 10009       |
| VarFuncLoss     | 0.0344      |
| _MeanReward     | 276         |
| _lr_multiplier  | 1           |
| _max_act        | 2.82561     |
| _max_adv        | 4.7         |
| _max_discrew    | 2.3         |
| _max_obs        | 30.9        |
| _mean_act       | 0.0352481   |
| _mean_adv       | -1.63e-17   |
| _mean_discrew   | 0.694       |
| _mean_obs       | 0.00359     |
| _min_adv        | -3.9        |
| _min_discrew    | 0.013       |
| _min_obs        | -24.5       |
| _std_act        | 0.408382    |
| _std_adv        | 1           |
| _std_discrew    | 0.173       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.811       |
| ExplainedVarOld | 0.601       |
| KL              | 0.00263019  |
| Phi_loss        | 77.6473     |
| PolicyEntropy   | 15.499      |
| PolicyLoss      | -0.00507015 |
| Steps           | 10026       |
| VarFuncLoss     | 0.033       |
| _MeanReward     | 274         |
| _lr_multiplier  | 1           |
| _max_act        | 3.13765     |
| _max_adv        | 4.72        |
| _max_discrew    | 1.94        |
| _max_obs        | 58.9        |
| _mean_act       | 0.0315376   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.692       |
| _mean_obs       | 0.00328     |
| _min_adv        | -4.09       |
| _min_discrew    | 0.0091      |
| _min_obs        | -38.1       |
| _std_act        | 0.407999    |
| _std_adv        | 1           |
| _std_discrew    | 0.174       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.818      |
| ExplainedVarOld | 0.61       |
| KL              | 0.00414861 |
| Phi_loss        | 81.5316    |
| PolicyEntropy   | 15.5001    |
| PolicyLoss      | -0.0499424 |
| Steps           | 10052      |
| VarFuncLoss     | 0.0316     |
| _MeanReward     | 276        |
| _lr_multiplier  | 1          |
| _max_act        | 2.95261    |
| _max_adv        | 4.57       |
| _max_discrew    | 2.01       |
| _max_obs        | 40.7       |
| _mean_act       | 0.0336312  |
| _mean_adv       | -5.65e-18  |
| _mean_discrew   | 0.69       |
| _mean_obs       | 0.00295    |
| _min_adv        | -4.36      |
| _min_discrew    | 0.0145     |
| _min_obs        | -50.7      |
| _std_act        | 0.41265    |
| _std_adv        | 1          |
| _std_discrew    | 0.169      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.827      |
| ExplainedVarOld | 0.63       |
| KL              | 0.00462007 |
| Phi_loss        | 95.5928    |
| PolicyEntropy   | 15.5003    |
| PolicyLoss      | -0.0221197 |
| Steps           | 10047      |
| VarFuncLoss     | 0.0293     |
| _MeanReward     | 285        |
| _lr_multiplier  | 1          |
| _max_act        | 2.93312    |
| _max_adv        | 5.13       |
| _max_discrew    | 2.61       |
| _max_obs        | 43         |
| _mean_act       | 0.0340826  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.736      |
| _mean_obs       | 0.00319    |
| _min_adv        | -3.81      |
| _min_discrew    | 0.0066     |
| _min_obs        | -31.3      |
| _std_act        | 0.41242    |
| _std_adv        | 1          |
| _std_discrew    | 0.209      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.795        |
| ExplainedVarOld | 0.532        |
| KL              | 0.0038824    |
| Phi_loss        | 91.2265      |
| PolicyEntropy   | 15.4986      |
| PolicyLoss      | -0.000492246 |
| Steps           | 10056        |
| VarFuncLoss     | 0.0429       |
| _MeanReward     | 282          |
| _lr_multiplier  | 1            |
| _max_act        | 2.85356      |
| _max_adv        | 4.7          |
| _max_discrew    | 2.02         |
| _max_obs        | 38.1         |
| _mean_act       | 0.0333415    |
| _mean_adv       | 1.7e-17      |
| _mean_discrew   | 0.704        |
| _mean_obs       | 0.00331      |
| _min_adv        | -5.47        |
| _min_discrew    | 0.00448      |
| _min_obs        | -20.6        |
| _std_act        | 0.409476     |
| _std_adv        | 1            |
| _std_discrew    | 0.175        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.812      |
| ExplainedVarOld | 0.608      |
| KL              | 0.00346471 |
| Phi_loss        | 92.8507    |
| PolicyEntropy   | 15.4954    |
| PolicyLoss      | -0.0691485 |
| Steps           | 10009      |
| VarFuncLoss     | 0.033      |
| _MeanReward     | 297        |
| _lr_multiplier  | 1          |
| _max_act        | 2.65937    |
| _max_adv        | 5.31       |
| _max_discrew    | 2.19       |
| _max_obs        | 40.8       |
| _mean_act       | 0.0349029  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.746      |
| _mean_obs       | 0.00421    |
| _min_adv        | -4.37      |
| _min_discrew    | 0.0152     |
| _min_obs        | -33.6      |
| _std_act        | 0.411311   |
| _std_adv        | 1          |
| _std_discrew    | 0.198      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.833      |
| ExplainedVarOld | 0.608      |
| KL              | 0.00515018 |
| Phi_loss        | 91.9105    |
| PolicyEntropy   | 15.4907    |
| PolicyLoss      | 0.007447   |
| Steps           | 10052      |
| VarFuncLoss     | 0.0332     |
| _MeanReward     | 296        |
| _lr_multiplier  | 1          |
| _max_act        | 3.73062    |
| _max_adv        | 4.21       |
| _max_discrew    | 2.27       |
| _max_obs        | 67.4       |
| _mean_act       | 0.0360095  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.747      |
| _mean_obs       | 0.00413    |
| _min_adv        | -4.47      |
| _min_discrew    | 0.0145     |
| _min_obs        | -20.9      |
| _std_act        | 0.412694   |
| _std_adv        | 1          |
| _std_discrew    | 0.202      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.825      |
| ExplainedVarOld | 0.605      |
| KL              | 0.00462191 |
| Phi_loss        | 92.192     |
| PolicyEntropy   | 15.4848    |
| PolicyLoss      | -0.0128434 |
| Steps           | 10057      |
| VarFuncLoss     | 0.0354     |
| _MeanReward     | 292        |
| _lr_multiplier  | 1          |
| _max_act        | 2.97121    |
| _max_adv        | 3.9        |
| _max_discrew    | 2.23       |
| _max_obs        | 29.3       |
| _mean_act       | 0.0368286  |
| _mean_adv       | -1.41e-17  |
| _mean_discrew   | 0.739      |
| _mean_obs       | 0.00316    |
| _min_adv        | -4.73      |
| _min_discrew    | 0.0072     |
| _min_obs        | -32.9      |
| _std_act        | 0.414713   |
| _std_adv        | 1          |
| _std_discrew    | 0.202      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.828       |
| ExplainedVarOld | 0.628       |
| KL              | 0.00296131  |
| Phi_loss        | 93.1837     |
| PolicyEntropy   | 15.4825     |
| PolicyLoss      | -0.00226175 |
| Steps           | 10006       |
| VarFuncLoss     | 0.0349      |
| _MeanReward     | 313         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97513     |
| _max_adv        | 4.99        |
| _max_discrew    | 2.17        |
| _max_obs        | 39.6        |
| _mean_act       | 0.0367774   |
| _mean_adv       | -1.63e-17   |
| _mean_discrew   | 0.771       |
| _mean_obs       | 0.00402     |
| _min_adv        | -3.97       |
| _min_discrew    | 0.0146      |
| _min_obs        | -52.2       |
| _std_act        | 0.413582    |
| _std_adv        | 1           |
| _std_discrew    | 0.208       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.843       |
| ExplainedVarOld | 0.636       |
| KL              | 0.00249066  |
| Phi_loss        | 89.4536     |
| PolicyEntropy   | 15.4787     |
| PolicyLoss      | 0.000420995 |
| Steps           | 10008       |
| VarFuncLoss     | 0.0327      |
| _MeanReward     | 299         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03471     |
| _max_adv        | 5.6         |
| _max_discrew    | 2.21        |
| _max_obs        | 21.7        |
| _mean_act       | 0.0366451   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.754       |
| _mean_obs       | 0.00341     |
| _min_adv        | -4.46       |
| _min_discrew    | 0.016       |
| _min_obs        | -31.6       |
| _std_act        | 0.412342    |
| _std_adv        | 1           |
| _std_discrew    | 0.208       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.829       |
| ExplainedVarOld | 0.603       |
| KL              | 0.00287651  |
| Phi_loss        | 90.5791     |
| PolicyEntropy   | 15.4758     |
| PolicyLoss      | -0.00331703 |
| Steps           | 10038       |
| VarFuncLoss     | 0.0358      |
| _MeanReward     | 316         |
| _lr_multiplier  | 1           |
| _max_act        | 2.91069     |
| _max_adv        | 4.5         |
| _max_discrew    | 2.51        |
| _max_obs        | 26.4        |
| _mean_act       | 0.0386826   |
| _mean_adv       | -5.66e-18   |
| _mean_discrew   | 0.779       |
| _mean_obs       | 0.00378     |
| _min_adv        | -5          |
| _min_discrew    | 0.0168      |
| _min_obs        | -27.7       |
| _std_act        | 0.41198     |
| _std_adv        | 1           |
| _std_discrew    | 0.215       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.839      |
| ExplainedVarOld | 0.639      |
| KL              | 0.00283331 |
| Phi_loss        | 81.8614    |
| PolicyEntropy   | 15.4776    |
| PolicyLoss      | -0.0069654 |
| Steps           | 10009      |
| VarFuncLoss     | 0.0346     |
| _MeanReward     | 314        |
| _lr_multiplier  | 1          |
| _max_act        | 2.82823    |
| _max_adv        | 4.73       |
| _max_discrew    | 2.23       |
| _max_obs        | 40.8       |
| _mean_act       | 0.0393045  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.788      |
| _mean_obs       | 0.00294    |
| _min_adv        | -5.84      |
| _min_discrew    | 0.011      |
| _min_obs        | -35.6      |
| _std_act        | 0.41221    |
| _std_adv        | 1          |
| _std_discrew    | 0.221      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.84        |
| ExplainedVarOld | 0.64        |
| KL              | 0.00320575  |
| Phi_loss        | 78.2476     |
| PolicyEntropy   | 15.4786     |
| PolicyLoss      | -0.00491654 |
| Steps           | 10021       |
| VarFuncLoss     | 0.0355      |
| _MeanReward     | 336         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03251     |
| _max_adv        | 3.71        |
| _max_discrew    | 2.25        |
| _max_obs        | 29.1        |
| _mean_act       | 0.0406878   |
| _mean_adv       | 8.51e-18    |
| _mean_discrew   | 0.828       |
| _mean_obs       | 0.00447     |
| _min_adv        | -4.64       |
| _min_discrew    | 0.012       |
| _min_obs        | -21.7       |
| _std_act        | 0.412285    |
| _std_adv        | 1           |
| _std_discrew    | 0.245       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.845      |
| ExplainedVarOld | 0.619      |
| KL              | 0.00283452 |
| Phi_loss        | 83.1943    |
| PolicyEntropy   | 15.4779    |
| PolicyLoss      | -0.0061491 |
| Steps           | 10010      |
| VarFuncLoss     | 0.038      |
| _MeanReward     | 324        |
| _lr_multiplier  | 1          |
| _max_act        | 3.1715     |
| _max_adv        | 3.99       |
| _max_discrew    | 2.2        |
| _max_obs        | 23.4       |
| _mean_act       | 0.0364684  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.791      |
| _mean_obs       | 0.00404    |
| _min_adv        | -5.78      |
| _min_discrew    | 0.0107     |
| _min_obs        | -23.5      |
| _std_act        | 0.414415   |
| _std_adv        | 1          |
| _std_discrew    | 0.217      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.844       |
| ExplainedVarOld | 0.648       |
| KL              | 0.00290395  |
| Phi_loss        | 81.1535     |
| PolicyEntropy   | 15.4789     |
| PolicyLoss      | -0.00390469 |
| Steps           | 10064       |
| VarFuncLoss     | 0.0339      |
| _MeanReward     | 332         |
| _lr_multiplier  | 1           |
| _max_act        | 2.85217     |
| _max_adv        | 4.63        |
| _max_discrew    | 2.48        |
| _max_obs        | 29.8        |
| _mean_act       | 0.038493    |
| _mean_adv       | 1.69e-17    |
| _mean_discrew   | 0.806       |
| _mean_obs       | 0.00371     |
| _min_adv        | -4.28       |
| _min_discrew    | 0.0149      |
| _min_obs        | -21.9       |
| _std_act        | 0.411627    |
| _std_adv        | 1           |
| _std_discrew    | 0.224       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.858       |
| ExplainedVarOld | 0.635       |
| KL              | 0.00327785  |
| Phi_loss        | 79.8702     |
| PolicyEntropy   | 15.4799     |
| PolicyLoss      | -0.00585034 |
| Steps           | 10043       |
| VarFuncLoss     | 0.0319      |
| _MeanReward     | 331         |
| _lr_multiplier  | 1           |
| _max_act        | 2.98468     |
| _max_adv        | 4.55        |
| _max_discrew    | 2.55        |
| _max_obs        | 48.8        |
| _mean_act       | 0.0409522   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.811       |
| _mean_obs       | 0.0037      |
| _min_adv        | -4.7        |
| _min_discrew    | 0.00986     |
| _min_obs        | -39.7       |
| _std_act        | 0.412554    |
| _std_adv        | 1           |
| _std_discrew    | 0.235       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.855       |
| ExplainedVarOld | 0.645       |
| KL              | 0.00301157  |
| Phi_loss        | 68.7619     |
| PolicyEntropy   | 15.4745     |
| PolicyLoss      | 0.000129812 |
| Steps           | 10001       |
| VarFuncLoss     | 0.0341      |
| _MeanReward     | 346         |
| _lr_multiplier  | 1           |
| _max_act        | 3.39447     |
| _max_adv        | 4.45        |
| _max_discrew    | 2.27        |
| _max_obs        | 39.1        |
| _mean_act       | 0.0423302   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.821       |
| _mean_obs       | 0.00412     |
| _min_adv        | -4.8        |
| _min_discrew    | 0.0113      |
| _min_obs        | -30.8       |
| _std_act        | 0.414736    |
| _std_adv        | 1           |
| _std_discrew    | 0.224       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.734       |
| KL              | 0.00315358  |
| Phi_loss        | 71.9656     |
| PolicyEntropy   | 15.4729     |
| PolicyLoss      | -0.00358613 |
| Steps           | 10033       |
| VarFuncLoss     | 0.0245      |
| _MeanReward     | 331         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93536     |
| _max_adv        | 5.1         |
| _max_discrew    | 2.43        |
| _max_obs        | 44.3        |
| _mean_act       | 0.0445885   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 0.806       |
| _mean_obs       | 0.00362     |
| _min_adv        | -4.93       |
| _min_discrew    | 0.00928     |
| _min_obs        | -25.7       |
| _std_act        | 0.41152     |
| _std_adv        | 1           |
| _std_discrew    | 0.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.862      |
| ExplainedVarOld | 0.655      |
| KL              | 0.00409537 |
| Phi_loss        | 72.7747    |
| PolicyEntropy   | 15.4747    |
| PolicyLoss      | 0.0242871  |
| Steps           | 10055      |
| VarFuncLoss     | 0.0318     |
| _MeanReward     | 349        |
| _lr_multiplier  | 1          |
| _max_act        | 3.07984    |
| _max_adv        | 4.7        |
| _max_discrew    | 3.03       |
| _max_obs        | 22.8       |
| _mean_act       | 0.0430256  |
| _mean_adv       | 8.48e-18   |
| _mean_discrew   | 0.863      |
| _mean_obs       | 0.00245    |
| _min_adv        | -7.33      |
| _min_discrew    | 0.0116     |
| _min_obs        | -25.1      |
| _std_act        | 0.414395   |
| _std_adv        | 1          |
| _std_discrew    | 0.288      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.855     |
| ExplainedVarOld | 0.58      |
| KL              | 0.0111198 |
| Phi_loss        | 87.8247   |
| PolicyEntropy   | 15.4692   |
| PolicyLoss      | -0.873831 |
| Steps           | 10049     |
| VarFuncLoss     | 0.0417    |
| _MeanReward     | 344       |
| _lr_multiplier  | 1         |
| _max_act        | 3.0352    |
| _max_adv        | 4.62      |
| _max_discrew    | 2.46      |
| _max_obs        | 26.8      |
| _mean_act       | 0.0415699 |
| _mean_adv       | 8.48e-18  |
| _mean_discrew   | 0.845     |
| _mean_obs       | 0.00387   |
| _min_adv        | -6.13     |
| _min_discrew    | 0.0172    |
| _min_obs        | -25.1     |
| _std_act        | 0.415852  |
| _std_adv        | 1         |
| _std_discrew    | 0.249     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.87        |
| ExplainedVarOld | 0.638       |
| KL              | 0.00596077  |
| Phi_loss        | 86.0244     |
| PolicyEntropy   | 15.4627     |
| PolicyLoss      | -0.00254289 |
| Steps           | 10060       |
| VarFuncLoss     | 0.0325      |
| _MeanReward     | 350         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04298     |
| _max_adv        | 4.87        |
| _max_discrew    | 2.92        |
| _max_obs        | 76.5        |
| _mean_act       | 0.0408606   |
| _mean_adv       | -1.98e-17   |
| _mean_discrew   | 0.851       |
| _mean_obs       | 0.00418     |
| _min_adv        | -5.52       |
| _min_discrew    | 0.0132      |
| _min_obs        | -25.6       |
| _std_act        | 0.414674    |
| _std_adv        | 1           |
| _std_discrew    | 0.256       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.865       |
| ExplainedVarOld | 0.621       |
| KL              | 0.00150342  |
| Phi_loss        | 89.6779     |
| PolicyEntropy   | 15.4657     |
| PolicyLoss      | -0.00667107 |
| Steps           | 10023       |
| VarFuncLoss     | 0.0347      |
| _MeanReward     | 348         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86573     |
| _max_adv        | 5.32        |
| _max_discrew    | 2.3         |
| _max_obs        | 26.5        |
| _mean_act       | 0.041897    |
| _mean_adv       | 8.51e-18    |
| _mean_discrew   | 0.837       |
| _mean_obs       | 0.00303     |
| _min_adv        | -4.79       |
| _min_discrew    | 0.0117      |
| _min_obs        | -22.5       |
| _std_act        | 0.415185    |
| _std_adv        | 1           |
| _std_discrew    | 0.238       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.863      |
| ExplainedVarOld | 0.659      |
| KL              | 0.00147943 |
| Phi_loss        | 95.205     |
| PolicyEntropy   | 15.4634    |
| PolicyLoss      | 0.00349655 |
| Steps           | 10030      |
| VarFuncLoss     | 0.0326     |
| _MeanReward     | 343        |
| _lr_multiplier  | 1          |
| _max_act        | 3.03144    |
| _max_adv        | 4.54       |
| _max_discrew    | 2.51       |
| _max_obs        | 37.6       |
| _mean_act       | 0.0415655  |
| _mean_adv       | 1.7e-17    |
| _mean_discrew   | 0.832      |
| _mean_obs       | 0.00316    |
| _min_adv        | -5.81      |
| _min_discrew    | 0.0165     |
| _min_obs        | -37.3      |
| _std_act        | 0.412591   |
| _std_adv        | 1          |
| _std_discrew    | 0.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.624       |
| KL              | 0.00251957  |
| Phi_loss        | 89.4692     |
| PolicyEntropy   | 15.4607     |
| PolicyLoss      | -0.00104935 |
| Steps           | 10085       |
| VarFuncLoss     | 0.0358      |
| _MeanReward     | 336         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03863     |
| _max_adv        | 5.01        |
| _max_discrew    | 2.48        |
| _max_obs        | 67.5        |
| _mean_act       | 0.0424226   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.818       |
| _mean_obs       | 0.00345     |
| _min_adv        | -5.14       |
| _min_discrew    | 0.0114      |
| _min_obs        | -28.6       |
| _std_act        | 0.415047    |
| _std_adv        | 1           |
| _std_discrew    | 0.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.863      |
| ExplainedVarOld | 0.665      |
| KL              | 0.00733874 |
| Phi_loss        | 95.6991    |
| PolicyEntropy   | 15.4465    |
| PolicyLoss      | 0.336446   |
| Steps           | 10036      |
| VarFuncLoss     | 0.0328     |
| _MeanReward     | 360        |
| _lr_multiplier  | 1          |
| _max_act        | 3.00375    |
| _max_adv        | 4.39       |
| _max_discrew    | 2.94       |
| _max_obs        | 61.1       |
| _mean_act       | 0.0419398  |
| _mean_adv       | -1.7e-17   |
| _mean_discrew   | 0.878      |
| _mean_obs       | 0.00349    |
| _min_adv        | -4.29      |
| _min_discrew    | 0.00799    |
| _min_obs        | -27.6      |
| _std_act        | 0.414839   |
| _std_adv        | 1          |
| _std_discrew    | 0.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.866       |
| ExplainedVarOld | 0.614       |
| KL              | 0.00206347  |
| Phi_loss        | 81.4771     |
| PolicyEntropy   | 15.4151     |
| PolicyLoss      | -0.00285333 |
| Steps           | 10044       |
| VarFuncLoss     | 0.0393      |
| _MeanReward     | 346         |
| _lr_multiplier  | 1           |
| _max_act        | 3.10443     |
| _max_adv        | 4.81        |
| _max_discrew    | 2.19        |
| _max_obs        | 25.7        |
| _mean_act       | 0.0392138   |
| _mean_adv       | -9.2e-18    |
| _mean_discrew   | 0.834       |
| _mean_obs       | 0.00396     |
| _min_adv        | -5.06       |
| _min_discrew    | 0.0147      |
| _min_obs        | -22.8       |
| _std_act        | 0.412915    |
| _std_adv        | 1           |
| _std_discrew    | 0.236       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.864       |
| ExplainedVarOld | 0.652       |
| KL              | 0.00147871  |
| Phi_loss        | 79.9119     |
| PolicyEntropy   | 15.4165     |
| PolicyLoss      | -0.00231278 |
| Steps           | 10069       |
| VarFuncLoss     | 0.0322      |
| _MeanReward     | 356         |
| _lr_multiplier  | 1           |
| _max_act        | 3.21237     |
| _max_adv        | 4.51        |
| _max_discrew    | 2.36        |
| _max_obs        | 25.1        |
| _mean_act       | 0.0432519   |
| _mean_adv       | 8.47e-18    |
| _mean_discrew   | 0.867       |
| _mean_obs       | 0.00311     |
| _min_adv        | -4.72       |
| _min_discrew    | 0.00506     |
| _min_obs        | -26.1       |
| _std_act        | 0.4145      |
| _std_adv        | 1           |
| _std_discrew    | 0.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.864       |
| ExplainedVarOld | 0.628       |
| KL              | 0.00263259  |
| Phi_loss        | 75.7697     |
| PolicyEntropy   | 15.4169     |
| PolicyLoss      | -0.00176667 |
| Steps           | 10046       |
| VarFuncLoss     | 0.0356      |
| _MeanReward     | 348         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04512     |
| _max_adv        | 5.07        |
| _max_discrew    | 2.35        |
| _max_obs        | 39.8        |
| _mean_act       | 0.0407375   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.847       |
| _mean_obs       | 0.00368     |
| _min_adv        | -5.43       |
| _min_discrew    | 0.0179      |
| _min_obs        | -34.3       |
| _std_act        | 0.411499    |
| _std_adv        | 1           |
| _std_discrew    | 0.244       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.869      |
| ExplainedVarOld | 0.635      |
| KL              | 0.00318955 |
| Phi_loss        | 86.0278    |
| PolicyEntropy   | 15.4161    |
| PolicyLoss      | -0.0144112 |
| Steps           | 10006      |
| VarFuncLoss     | 0.0318     |
| _MeanReward     | 373        |
| _lr_multiplier  | 1          |
| _max_act        | 2.94162    |
| _max_adv        | 6.44       |
| _max_discrew    | 2.77       |
| _max_obs        | 26.1       |
| _mean_act       | 0.0417291  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.905      |
| _mean_obs       | 0.00332    |
| _min_adv        | -4.64      |
| _min_discrew    | 0.0134     |
| _min_obs        | -20        |
| _std_act        | 0.414143   |
| _std_adv        | 1          |
| _std_discrew    | 0.294      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.863       |
| ExplainedVarOld | 0.624       |
| KL              | 0.00257648  |
| Phi_loss        | 82.7546     |
| PolicyEntropy   | 15.414      |
| PolicyLoss      | -0.00137298 |
| Steps           | 10019       |
| VarFuncLoss     | 0.0407      |
| _MeanReward     | 358         |
| _lr_multiplier  | 1           |
| _max_act        | 2.96161     |
| _max_adv        | 4.31        |
| _max_discrew    | 2.7         |
| _max_obs        | 30.5        |
| _mean_act       | 0.0427943   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.871       |
| _mean_obs       | 0.00331     |
| _min_adv        | -5.1        |
| _min_discrew    | -0.00114    |
| _min_obs        | -22.5       |
| _std_act        | 0.413236    |
| _std_adv        | 1           |
| _std_discrew    | 0.271       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.6         |
| KL              | 0.00258678  |
| Phi_loss        | 80.1085     |
| PolicyEntropy   | 15.4119     |
| PolicyLoss      | -0.00206995 |
| Steps           | 10012       |
| VarFuncLoss     | 0.0404      |
| _MeanReward     | 378         |
| _lr_multiplier  | 1           |
| _max_act        | 3.31531     |
| _max_adv        | 4.87        |
| _max_discrew    | 2.65        |
| _max_obs        | 27.4        |
| _mean_act       | 0.0431935   |
| _mean_adv       | -7.1e-18    |
| _mean_discrew   | 0.905       |
| _mean_obs       | 0.00337     |
| _min_adv        | -4.51       |
| _min_discrew    | 0.0149      |
| _min_obs        | -49.2       |
| _std_act        | 0.411786    |
| _std_adv        | 1           |
| _std_discrew    | 0.286       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.872       |
| ExplainedVarOld | 0.681       |
| KL              | 0.00232972  |
| Phi_loss        | 81.4853     |
| PolicyEntropy   | 15.4091     |
| PolicyLoss      | -0.00103221 |
| Steps           | 10016       |
| VarFuncLoss     | 0.0368      |
| _MeanReward     | 371         |
| _lr_multiplier  | 1           |
| _max_act        | 2.81376     |
| _max_adv        | 4.18        |
| _max_discrew    | 2.74        |
| _max_obs        | 29.2        |
| _mean_act       | 0.0435911   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.898       |
| _mean_obs       | 0.00324     |
| _min_adv        | -4.85       |
| _min_discrew    | 0.00188     |
| _min_obs        | -24.1       |
| _std_act        | 0.413605    |
| _std_adv        | 1           |
| _std_discrew    | 0.293       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.873       |
| ExplainedVarOld | 0.628       |
| KL              | 0.00250625  |
| Phi_loss        | 76.4834     |
| PolicyEntropy   | 15.4098     |
| PolicyLoss      | -0.00295099 |
| Steps           | 10065       |
| VarFuncLoss     | 0.0373      |
| _MeanReward     | 358         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14458     |
| _max_adv        | 4.88        |
| _max_discrew    | 2.51        |
| _max_obs        | 25.5        |
| _mean_act       | 0.0421263   |
| _mean_adv       | -9.88e-18   |
| _mean_discrew   | 0.859       |
| _mean_obs       | 0.0026      |
| _min_adv        | -4.92       |
| _min_discrew    | 0.0161      |
| _min_obs        | -18         |
| _std_act        | 0.414161    |
| _std_adv        | 1           |
| _std_discrew    | 0.255       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.859      |
| ExplainedVarOld | 0.665      |
| KL              | 0.00263885 |
| Phi_loss        | 84.9867    |
| PolicyEntropy   | 15.4108    |
| PolicyLoss      | -0.0040976 |
| Steps           | 10007      |
| VarFuncLoss     | 0.0362     |
| _MeanReward     | 374        |
| _lr_multiplier  | 1          |
| _max_act        | 2.99453    |
| _max_adv        | 5.02       |
| _max_discrew    | 2.72       |
| _max_obs        | 75.4       |
| _mean_act       | 0.0395236  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.893      |
| _mean_obs       | 0.00209    |
| _min_adv        | -4.3       |
| _min_discrew    | 0.014      |
| _min_obs        | -86.1      |
| _std_act        | 0.415616   |
| _std_adv        | 1          |
| _std_discrew    | 0.274      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.885     |
| ExplainedVarOld | 0.696     |
| KL              | 0.0142706 |
| Phi_loss        | 89.6153   |
| PolicyEntropy   | 15.4055   |
| PolicyLoss      | 0.544449  |
| Steps           | 10035     |
| VarFuncLoss     | 0.032     |
| _MeanReward     | 383       |
| _lr_multiplier  | 1         |
| _max_act        | 3.16026   |
| _max_adv        | 5.06      |
| _max_discrew    | 2.46      |
| _max_obs        | 20.4      |
| _mean_act       | 0.0444554 |
| _mean_adv       | 9.91e-18  |
| _mean_discrew   | 0.905     |
| _mean_obs       | 0.00367   |
| _min_adv        | -6.27     |
| _min_discrew    | 0.0151    |
| _min_obs        | -21.9     |
| _std_act        | 0.415873  |
| _std_adv        | 1         |
| _std_discrew    | 0.275     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.895      |
| ExplainedVarOld | 0.707      |
| KL              | 0.00601497 |
| Phi_loss        | 89.574     |
| PolicyEntropy   | 15.3934    |
| PolicyLoss      | 0.00171177 |
| Steps           | 10018      |
| VarFuncLoss     | 0.0289     |
| _MeanReward     | 374        |
| _lr_multiplier  | 1          |
| _max_act        | 3.05363    |
| _max_adv        | 3.75       |
| _max_discrew    | 2.93       |
| _max_obs        | 27.9       |
| _mean_act       | 0.0446205  |
| _mean_adv       | 1.7e-17    |
| _mean_discrew   | 0.897      |
| _mean_obs       | 0.00288    |
| _min_adv        | -5.01      |
| _min_discrew    | 0.0109     |
| _min_obs        | -18.8      |
| _std_act        | 0.417969   |
| _std_adv        | 1          |
| _std_discrew    | 0.288      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.874       |
| ExplainedVarOld | 0.628       |
| KL              | 0.000904301 |
| Phi_loss        | 87.2513     |
| PolicyEntropy   | 15.3942     |
| PolicyLoss      | -0.00125099 |
| Steps           | 10047       |
| VarFuncLoss     | 0.0364      |
| _MeanReward     | 384         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01866     |
| _max_adv        | 4.34        |
| _max_discrew    | 2.66        |
| _max_obs        | 23.5        |
| _mean_act       | 0.0426964   |
| _mean_adv       | 8.49e-18    |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.00324     |
| _min_adv        | -4.67       |
| _min_discrew    | 0.0181      |
| _min_obs        | -21.7       |
| _std_act        | 0.413411    |
| _std_adv        | 1           |
| _std_discrew    | 0.286       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.881       |
| ExplainedVarOld | 0.706       |
| KL              | 0.00120067  |
| Phi_loss        | 88.6383     |
| PolicyEntropy   | 15.3941     |
| PolicyLoss      | -0.00237261 |
| Steps           | 10019       |
| VarFuncLoss     | 0.0341      |
| _MeanReward     | 379         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95744     |
| _max_adv        | 3.85        |
| _max_discrew    | 2.83        |
| _max_obs        | 25.5        |
| _mean_act       | 0.0474857   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.921       |
| _mean_obs       | 0.00307     |
| _min_adv        | -4.58       |
| _min_discrew    | 0.0181      |
| _min_obs        | -25.5       |
| _std_act        | 0.414364    |
| _std_adv        | 1           |
| _std_discrew    | 0.306       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.874       |
| ExplainedVarOld | 0.644       |
| KL              | 0.00226768  |
| Phi_loss        | 86.5112     |
| PolicyEntropy   | 15.3938     |
| PolicyLoss      | -0.00334189 |
| Steps           | 10118       |
| VarFuncLoss     | 0.0386      |
| _MeanReward     | 373         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95093     |
| _max_adv        | 5.19        |
| _max_discrew    | 2.82        |
| _max_obs        | 66.4        |
| _mean_act       | 0.0474985   |
| _mean_adv       | -2.53e-17   |
| _mean_discrew   | 0.888       |
| _mean_obs       | 0.00281     |
| _min_adv        | -4.87       |
| _min_discrew    | 0.0171      |
| _min_obs        | -60.9       |
| _std_act        | 0.417257    |
| _std_adv        | 1           |
| _std_discrew    | 0.268       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.889       |
| ExplainedVarOld | 0.656       |
| KL              | 0.00229629  |
| Phi_loss        | 86.7471     |
| PolicyEntropy   | 15.393      |
| PolicyLoss      | -0.00295283 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0301      |
| _MeanReward     | 382         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93286     |
| _max_adv        | 4.23        |
| _max_discrew    | 2.89        |
| _max_obs        | 42.6        |
| _mean_act       | 0.0460884   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 0.912       |
| _mean_obs       | 0.0021      |
| _min_adv        | -7.1        |
| _min_discrew    | 0.0146      |
| _min_obs        | -37.9       |
| _std_act        | 0.418925    |
| _std_adv        | 1           |
| _std_discrew    | 0.296       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.669      |
| KL              | 0.00249479 |
| Phi_loss        | 81.9704    |
| PolicyEntropy   | 15.3931    |
| PolicyLoss      | -0.0056102 |
| Steps           | 10025      |
| VarFuncLoss     | 0.035      |
| _MeanReward     | 372        |
| _lr_multiplier  | 1          |
| _max_act        | 3.04152    |
| _max_adv        | 4.23       |
| _max_discrew    | 2.49       |
| _max_obs        | 15.8       |
| _mean_act       | 0.0452381  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.881      |
| _mean_obs       | 0.0035     |
| _min_adv        | -5.88      |
| _min_discrew    | 0.0178     |
| _min_obs        | -20.9      |
| _std_act        | 0.416894   |
| _std_adv        | 1          |
| _std_discrew    | 0.252      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.896       |
| ExplainedVarOld | 0.733       |
| KL              | 0.00233771  |
| Phi_loss        | 94.3867     |
| PolicyEntropy   | 15.3948     |
| PolicyLoss      | -0.00405763 |
| Steps           | 10033       |
| VarFuncLoss     | 0.0263      |
| _MeanReward     | 376         |
| _lr_multiplier  | 1           |
| _max_act        | 2.9381      |
| _max_adv        | 4.42        |
| _max_discrew    | 2.96        |
| _max_obs        | 19.7        |
| _mean_act       | 0.0439891   |
| _mean_adv       | -1.98e-17   |
| _mean_discrew   | 0.901       |
| _mean_obs       | 0.00288     |
| _min_adv        | -5.32       |
| _min_discrew    | 0.0134      |
| _min_obs        | -20         |
| _std_act        | 0.418502    |
| _std_adv        | 1           |
| _std_discrew    | 0.285       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.679       |
| KL              | 0.00201326  |
| Phi_loss        | 80.9186     |
| PolicyEntropy   | 15.3953     |
| PolicyLoss      | -0.00150015 |
| Steps           | 10012       |
| VarFuncLoss     | 0.0312      |
| _MeanReward     | 383         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1056      |
| _max_adv        | 5.56        |
| _max_discrew    | 2.47        |
| _max_obs        | 24.7        |
| _mean_act       | 0.0471177   |
| _mean_adv       | -1.28e-17   |
| _mean_discrew   | 0.905       |
| _mean_obs       | 0.00309     |
| _min_adv        | -5.41       |
| _min_discrew    | 0.0159      |
| _min_obs        | -25.2       |
| _std_act        | 0.417827    |
| _std_adv        | 1           |
| _std_discrew    | 0.278       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.908        |
| ExplainedVarOld | 0.732        |
| KL              | 0.00206324   |
| Phi_loss        | 77.5523      |
| PolicyEntropy   | 15.3943      |
| PolicyLoss      | -0.000373389 |
| Steps           | 10022        |
| VarFuncLoss     | 0.0258       |
| _MeanReward     | 389          |
| _lr_multiplier  | 1            |
| _max_act        | 2.77003      |
| _max_adv        | 4.53         |
| _max_discrew    | 2.48         |
| _max_obs        | 25.1         |
| _mean_act       | 0.0492657    |
| _mean_adv       | -1.99e-17    |
| _mean_discrew   | 0.912        |
| _mean_obs       | 0.00318      |
| _min_adv        | -5.81        |
| _min_discrew    | 0.0118       |
| _min_obs        | -23.5        |
| _std_act        | 0.414004     |
| _std_adv        | 1            |
| _std_discrew    | 0.275        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.909       |
| ExplainedVarOld | 0.742       |
| KL              | 0.00218378  |
| Phi_loss        | 76.6802     |
| PolicyEntropy   | 15.3917     |
| PolicyLoss      | -0.00120518 |
| Steps           | 10043       |
| VarFuncLoss     | 0.0252      |
| _MeanReward     | 392         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06799     |
| _max_adv        | 5.01        |
| _max_discrew    | 2.66        |
| _max_obs        | 25.7        |
| _mean_act       | 0.0441733   |
| _mean_adv       | 5.66e-18    |
| _mean_discrew   | 0.92        |
| _mean_obs       | 0.0028      |
| _min_adv        | -5.67       |
| _min_discrew    | 0.0142      |
| _min_obs        | -17.4       |
| _std_act        | 0.417788    |
| _std_adv        | 1           |
| _std_discrew    | 0.282       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.749       |
| KL              | 0.00264988  |
| Phi_loss        | 87.633      |
| PolicyEntropy   | 15.3906     |
| PolicyLoss      | -0.00495013 |
| Steps           | 10062       |
| VarFuncLoss     | 0.0272      |
| _MeanReward     | 388         |
| _lr_multiplier  | 1           |
| _max_act        | 2.77681     |
| _max_adv        | 4.73        |
| _max_discrew    | 3.38        |
| _max_obs        | 48.7        |
| _mean_act       | 0.0475615   |
| _mean_adv       | -1.69e-17   |
| _mean_discrew   | 0.935       |
| _mean_obs       | 0.00256     |
| _min_adv        | -7.57       |
| _min_discrew    | 0.0166      |
| _min_obs        | -49         |
| _std_act        | 0.415772    |
| _std_adv        | 1           |
| _std_discrew    | 0.331       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.887       |
| ExplainedVarOld | 0.665       |
| KL              | 0.00232251  |
| Phi_loss        | 80.1041     |
| PolicyEntropy   | 15.388      |
| PolicyLoss      | -0.00054157 |
| Steps           | 10042       |
| VarFuncLoss     | 0.0373      |
| _MeanReward     | 382         |
| _lr_multiplier  | 1           |
| _max_act        | 3.20808     |
| _max_adv        | 6.12        |
| _max_discrew    | 2.35        |
| _max_obs        | 42.7        |
| _mean_act       | 0.0468538   |
| _mean_adv       | 2.83e-18    |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.00266     |
| _min_adv        | -5.34       |
| _min_discrew    | 0.00797     |
| _min_obs        | -22.3       |
| _std_act        | 0.414828    |
| _std_adv        | 1           |
| _std_discrew    | 0.28        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.882      |
| ExplainedVarOld | 0.66       |
| KL              | 0.00312908 |
| Phi_loss        | 74.6863    |
| PolicyEntropy   | 15.3859    |
| PolicyLoss      | 0.00543743 |
| Steps           | 10019      |
| VarFuncLoss     | 0.033      |
| _MeanReward     | 373        |
| _lr_multiplier  | 1          |
| _max_act        | 3.4703     |
| _max_adv        | 4.42       |
| _max_discrew    | 2.49       |
| _max_obs        | 23         |
| _mean_act       | 0.0447544  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 0.89       |
| _mean_obs       | 0.00273    |
| _min_adv        | -6.15      |
| _min_discrew    | 0.0153     |
| _min_obs        | -28.5      |
| _std_act        | 0.418208   |
| _std_adv        | 1          |
| _std_discrew    | 0.271      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.892       |
| ExplainedVarOld | 0.692       |
| KL              | 0.00238218  |
| Phi_loss        | 78.3748     |
| PolicyEntropy   | 15.3824     |
| PolicyLoss      | -0.00183136 |
| Steps           | 10116       |
| VarFuncLoss     | 0.0292      |
| _MeanReward     | 412         |
| _lr_multiplier  | 1           |
| _max_act        | 2.91715     |
| _max_adv        | 5.16        |
| _max_discrew    | 2.61        |
| _max_obs        | 29.9        |
| _mean_act       | 0.0483944   |
| _mean_adv       | -2.25e-17   |
| _mean_discrew   | 0.966       |
| _mean_obs       | 0.00258     |
| _min_adv        | -4.69       |
| _min_discrew    | 0.00176     |
| _min_obs        | -16.4       |
| _std_act        | 0.419379    |
| _std_adv        | 1           |
| _std_discrew    | 0.306       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.907        |
| ExplainedVarOld | 0.723        |
| KL              | 0.00244735   |
| Phi_loss        | 84.98        |
| PolicyEntropy   | 15.3781      |
| PolicyLoss      | -0.000519763 |
| Steps           | 10040        |
| VarFuncLoss     | 0.0289       |
| _MeanReward     | 410          |
| _lr_multiplier  | 1            |
| _max_act        | 3.13184      |
| _max_adv        | 3.91         |
| _max_discrew    | 2.93         |
| _max_obs        | 47.2         |
| _mean_act       | 0.0452192    |
| _mean_adv       | -1.98e-17    |
| _mean_discrew   | 0.965        |
| _mean_obs       | 0.00202      |
| _min_adv        | -5.8         |
| _min_discrew    | 0.0131       |
| _min_obs        | -25          |
| _std_act        | 0.414487     |
| _std_adv        | 1            |
| _std_discrew    | 0.329        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.888       |
| ExplainedVarOld | 0.673       |
| KL              | 0.00258347  |
| Phi_loss        | 86.6865     |
| PolicyEntropy   | 15.3739     |
| PolicyLoss      | -0.00132704 |
| Steps           | 10052       |
| VarFuncLoss     | 0.0369      |
| _MeanReward     | 409         |
| _lr_multiplier  | 1           |
| _max_act        | 3.14482     |
| _max_adv        | 4.35        |
| _max_discrew    | 2.84        |
| _max_obs        | 20          |
| _mean_act       | 0.0488499   |
| _mean_adv       | 2.26e-17    |
| _mean_discrew   | 0.962       |
| _mean_obs       | 0.00258     |
| _min_adv        | -5.06       |
| _min_discrew    | 0.0135      |
| _min_obs        | -23.9       |
| _std_act        | 0.418664    |
| _std_adv        | 1           |
| _std_discrew    | 0.317       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.899     |
| ExplainedVarOld | 0.717     |
| KL              | 0.0124077 |
| Phi_loss        | 92.9611   |
| PolicyEntropy   | 15.3681   |
| PolicyLoss      | -7.12718  |
| Steps           | 10065     |
| VarFuncLoss     | 0.0319    |
| _MeanReward     | 404       |
| _lr_multiplier  | 1         |
| _max_act        | 3.17441   |
| _max_adv        | 5.09      |
| _max_discrew    | 2.78      |
| _max_obs        | 59.4      |
| _mean_act       | 0.0469053 |
| _mean_adv       | -2.12e-17 |
| _mean_discrew   | 0.954     |
| _mean_obs       | 0.00289   |
| _min_adv        | -4.88     |
| _min_discrew    | 0.0172    |
| _min_obs        | -47.8     |
| _std_act        | 0.42005   |
| _std_adv        | 1         |
| _std_discrew    | 0.309     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.709       |
| KL              | 0.00772995  |
| Phi_loss        | 83.1358     |
| PolicyEntropy   | 15.3417     |
| PolicyLoss      | 0.000566826 |
| Steps           | 10056       |
| VarFuncLoss     | 0.0289      |
| _MeanReward     | 411         |
| _lr_multiplier  | 1           |
| _max_act        | 2.85486     |
| _max_adv        | 5.28        |
| _max_discrew    | 3.58        |
| _max_obs        | 27          |
| _mean_act       | 0.0495586   |
| _mean_adv       | 5.65e-18    |
| _mean_discrew   | 0.974       |
| _mean_obs       | 0.00349     |
| _min_adv        | -5.22       |
| _min_discrew    | 0.0157      |
| _min_obs        | -27.9       |
| _std_act        | 0.417161    |
| _std_adv        | 1           |
| _std_discrew    | 0.347       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.896        |
| ExplainedVarOld | 0.668        |
| KL              | 0.000683488  |
| Phi_loss        | 72.5146      |
| PolicyEntropy   | 15.3402      |
| PolicyLoss      | -0.000958219 |
| Steps           | 10057        |
| VarFuncLoss     | 0.0363       |
| _MeanReward     | 405          |
| _lr_multiplier  | 1            |
| _max_act        | 3.05892      |
| _max_adv        | 4.65         |
| _max_discrew    | 2.83         |
| _max_obs        | 34           |
| _mean_act       | 0.051938     |
| _mean_adv       | 5.65e-18     |
| _mean_discrew   | 0.954        |
| _mean_obs       | 0.00404      |
| _min_adv        | -6.12        |
| _min_discrew    | 0.0153       |
| _min_obs        | -29.8        |
| _std_act        | 0.419769     |
| _std_adv        | 1            |
| _std_discrew    | 0.309        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.674       |
| KL              | 0.00101624  |
| Phi_loss        | 94.921      |
| PolicyEntropy   | 15.3384     |
| PolicyLoss      | 0.000925419 |
| Steps           | 10075       |
| VarFuncLoss     | 0.0357      |
| _MeanReward     | 388         |
| _lr_multiplier  | 1           |
| _max_act        | 3.39768     |
| _max_adv        | 3.63        |
| _max_discrew    | 2.46        |
| _max_obs        | 24.8        |
| _mean_act       | 0.049375    |
| _mean_adv       | -5.64e-18   |
| _mean_discrew   | 0.939       |
| _mean_obs       | 0.00353     |
| _min_adv        | -8.15       |
| _min_discrew    | 0.0129      |
| _min_obs        | -52.9       |
| _std_act        | 0.417746    |
| _std_adv        | 1           |
| _std_discrew    | 0.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.869        |
| ExplainedVarOld | 0.642        |
| KL              | 0.00172546   |
| Phi_loss        | 84.286       |
| PolicyEntropy   | 15.3367      |
| PolicyLoss      | -0.000403475 |
| Steps           | 10012        |
| VarFuncLoss     | 0.0394       |
| _MeanReward     | 394          |
| _lr_multiplier  | 1            |
| _max_act        | 2.86887      |
| _max_adv        | 4.89         |
| _max_discrew    | 2.56         |
| _max_obs        | 61           |
| _mean_act       | 0.0467891    |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 0.931        |
| _mean_obs       | 0.00305      |
| _min_adv        | -5.34        |
| _min_discrew    | 0.0109       |
| _min_obs        | -44.3        |
| _std_act        | 0.420121     |
| _std_adv        | 1            |
| _std_discrew    | 0.284        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.733      |
| KL              | 0.00244283 |
| Phi_loss        | 95.5833    |
| PolicyEntropy   | 15.3356    |
| PolicyLoss      | 0.107621   |
| Steps           | 10033      |
| VarFuncLoss     | 0.0292     |
| _MeanReward     | 416        |
| _lr_multiplier  | 1          |
| _max_act        | 3.15892    |
| _max_adv        | 6.32       |
| _max_discrew    | 2.58       |
| _max_obs        | 44         |
| _mean_act       | 0.0479257  |
| _mean_adv       | 2.55e-17   |
| _mean_discrew   | 0.964      |
| _mean_obs       | 0.00304    |
| _min_adv        | -4.53      |
| _min_discrew    | 0.0162     |
| _min_obs        | -28.3      |
| _std_act        | 0.414072   |
| _std_adv        | 1          |
| _std_discrew    | 0.298      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.901       |
| ExplainedVarOld | 0.714       |
| KL              | 0.00193537  |
| Phi_loss        | 93.5729     |
| PolicyEntropy   | 15.332      |
| PolicyLoss      | -0.00347068 |
| Steps           | 10022       |
| VarFuncLoss     | 0.0293      |
| _MeanReward     | 415         |
| _lr_multiplier  | 1           |
| _max_act        | 3.12571     |
| _max_adv        | 4.26        |
| _max_discrew    | 2.79        |
| _max_obs        | 37          |
| _mean_act       | 0.0480119   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.958       |
| _mean_obs       | 0.00266     |
| _min_adv        | -5.13       |
| _min_discrew    | 0.016       |
| _min_obs        | -21.7       |
| _std_act        | 0.415291    |
| _std_adv        | 1           |
| _std_discrew    | 0.306       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.908       |
| ExplainedVarOld | 0.729       |
| KL              | 0.00150988  |
| Phi_loss        | 93.5153     |
| PolicyEntropy   | 15.3328     |
| PolicyLoss      | -0.00749411 |
| Steps           | 10009       |
| VarFuncLoss     | 0.0282      |
| _MeanReward     | 403         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04892     |
| _max_adv        | 4.37        |
| _max_discrew    | 2.44        |
| _max_obs        | 33.3        |
| _mean_act       | 0.0490074   |
| _mean_adv       | 7.1e-18     |
| _mean_discrew   | 0.934       |
| _mean_obs       | 0.00279     |
| _min_adv        | -6.46       |
| _min_discrew    | 0.0163      |
| _min_obs        | -44.4       |
| _std_act        | 0.418184    |
| _std_adv        | 1           |
| _std_discrew    | 0.282       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.752      |
| KL              | 0.00214543 |
| Phi_loss        | 90.5469    |
| PolicyEntropy   | 15.3329    |
| PolicyLoss      | -0.0467331 |
| Steps           | 10020      |
| VarFuncLoss     | 0.026      |
| _MeanReward     | 419        |
| _lr_multiplier  | 1          |
| _max_act        | 3.2201     |
| _max_adv        | 4.14       |
| _max_discrew    | 2.86       |
| _max_obs        | 24.6       |
| _mean_act       | 0.0501713  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 0.991      |
| _mean_obs       | 0.00398    |
| _min_adv        | -5.23      |
| _min_discrew    | 0.0142     |
| _min_obs        | -21.4      |
| _std_act        | 0.417253   |
| _std_adv        | 1          |
| _std_discrew    | 0.338      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.721      |
| KL              | 0.00169751 |
| Phi_loss        | 93.877     |
| PolicyEntropy   | 15.3319    |
| PolicyLoss      | 0.00086898 |
| Steps           | 10074      |
| VarFuncLoss     | 0.035      |
| _MeanReward     | 423        |
| _lr_multiplier  | 1          |
| _max_act        | 2.85924    |
| _max_adv        | 4.52       |
| _max_discrew    | 2.9        |
| _max_obs        | 55.1       |
| _mean_act       | 0.0476636  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.989      |
| _mean_obs       | 0.00233    |
| _min_adv        | -4.83      |
| _min_discrew    | 0.0151     |
| _min_obs        | -63.9      |
| _std_act        | 0.42278    |
| _std_adv        | 1          |
| _std_discrew    | 0.331      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.901      |
| ExplainedVarOld | 0.723      |
| KL              | 0.00163706 |
| Phi_loss        | 94.4807    |
| PolicyEntropy   | 15.3302    |
| PolicyLoss      | 0.00129897 |
| Steps           | 10037      |
| VarFuncLoss     | 0.0327     |
| _MeanReward     | 406        |
| _lr_multiplier  | 1          |
| _max_act        | 2.9805     |
| _max_adv        | 4.13       |
| _max_discrew    | 2.51       |
| _max_obs        | 50         |
| _mean_act       | 0.0508404  |
| _mean_adv       | -2.83e-18  |
| _mean_discrew   | 0.961      |
| _mean_obs       | 0.00375    |
| _min_adv        | -5.44      |
| _min_discrew    | 0.00929    |
| _min_obs        | -24        |
| _std_act        | 0.416172   |
| _std_adv        | 1          |
| _std_discrew    | 0.309      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.709       |
| KL              | 0.00142615  |
| Phi_loss        | 93.5354     |
| PolicyEntropy   | 15.3292     |
| PolicyLoss      | -0.00143672 |
| Steps           | 10027       |
| VarFuncLoss     | 0.0328      |
| _MeanReward     | 418         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01853     |
| _max_adv        | 4.91        |
| _max_discrew    | 2.88        |
| _max_obs        | 33.3        |
| _mean_act       | 0.0482109   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.977       |
| _mean_obs       | 0.00356     |
| _min_adv        | -4.69       |
| _min_discrew    | 0.0175      |
| _min_obs        | -30.7       |
| _std_act        | 0.417747    |
| _std_adv        | 1           |
| _std_discrew    | 0.317       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.696       |
| KL              | 0.00323039  |
| Phi_loss        | 96.6957     |
| PolicyEntropy   | 15.328      |
| PolicyLoss      | -0.00777066 |
| Steps           | 10217       |
| VarFuncLoss     | 0.03        |
| _MeanReward     | 431         |
| _lr_multiplier  | 1           |
| _max_act        | 3.49164     |
| _max_adv        | 4.37        |
| _max_discrew    | 3.26        |
| _max_obs        | 17.7        |
| _mean_act       | 0.0487045   |
| _mean_adv       | -2.78e-18   |
| _mean_discrew   | 1           |
| _mean_obs       | 0.00292     |
| _min_adv        | -6.33       |
| _min_discrew    | 0.0121      |
| _min_obs        | -19.7       |
| _std_act        | 0.419472    |
| _std_adv        | 1           |
| _std_discrew    | 0.339       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.739       |
| KL              | 0.00276295  |
| Phi_loss        | 95.8736     |
| PolicyEntropy   | 15.3268     |
| PolicyLoss      | -0.00152314 |
| Steps           | 10016       |
| VarFuncLoss     | 0.0294      |
| _MeanReward     | 425         |
| _lr_multiplier  | 1           |
| _max_act        | 2.74134     |
| _max_adv        | 4.78        |
| _max_discrew    | 3.42        |
| _max_obs        | 29.6        |
| _mean_act       | 0.0541423   |
| _mean_adv       | 2.55e-17    |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.00337     |
| _min_adv        | -5.08       |
| _min_discrew    | 0.0153      |
| _min_obs        | -35.7       |
| _std_act        | 0.419554    |
| _std_adv        | 1           |
| _std_discrew    | 0.396       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.9        |
| ExplainedVarOld | 0.611      |
| KL              | 0.0027665  |
| Phi_loss        | 92.1349    |
| PolicyEntropy   | 15.325     |
| PolicyLoss      | 0.00135539 |
| Steps           | 10038      |
| VarFuncLoss     | 0.0396     |
| _MeanReward     | 420        |
| _lr_multiplier  | 1          |
| _max_act        | 3.05323    |
| _max_adv        | 4.02       |
| _max_discrew    | 2.7        |
| _max_obs        | 34.1       |
| _mean_act       | 0.051773   |
| _mean_adv       | 0          |
| _mean_discrew   | 0.988      |
| _mean_obs       | 0.00289    |
| _min_adv        | -5.57      |
| _min_discrew    | 0.0136     |
| _min_obs        | -31.1      |
| _std_act        | 0.421058   |
| _std_adv        | 1          |
| _std_discrew    | 0.329      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.896       |
| ExplainedVarOld | 0.696       |
| KL              | 0.0034934   |
| Phi_loss        | 96.2181     |
| PolicyEntropy   | 15.3242     |
| PolicyLoss      | -0.00222486 |
| Steps           | 10038       |
| VarFuncLoss     | 0.0344      |
| _MeanReward     | 406         |
| _lr_multiplier  | 1           |
| _max_act        | 3.10455     |
| _max_adv        | 4.5         |
| _max_discrew    | 2.59        |
| _max_obs        | 29.2        |
| _mean_act       | 0.0551195   |
| _mean_adv       | -5.66e-18   |
| _mean_discrew   | 0.954       |
| _mean_obs       | 0.00282     |
| _min_adv        | -5.85       |
| _min_discrew    | 0.0138      |
| _min_obs        | -61.6       |
| _std_act        | 0.41836     |
| _std_adv        | 1           |
| _std_discrew    | 0.304       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.89        |
| ExplainedVarOld | 0.653       |
| KL              | 0.00291933  |
| Phi_loss        | 83.6004     |
| PolicyEntropy   | 15.3236     |
| PolicyLoss      | 0.000290296 |
| Steps           | 10043       |
| VarFuncLoss     | 0.0335      |
| _MeanReward     | 424         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0181      |
| _max_adv        | 5.05        |
| _max_discrew    | 2.82        |
| _max_obs        | 55.6        |
| _mean_act       | 0.050454    |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 0.986       |
| _mean_obs       | 0.00263     |
| _min_adv        | -4.56       |
| _min_discrew    | 0.013       |
| _min_obs        | -29.8       |
| _std_act        | 0.41846     |
| _std_adv        | 1           |
| _std_discrew    | 0.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.909      |
| ExplainedVarOld | 0.741      |
| KL              | 0.00310231 |
| Phi_loss        | 89.4533    |
| PolicyEntropy   | 15.322     |
| PolicyLoss      | 0.00888784 |
| Steps           | 10037      |
| VarFuncLoss     | 0.0303     |
| _MeanReward     | 431        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8869     |
| _max_adv        | 3.96       |
| _max_discrew    | 2.75       |
| _max_obs        | 30.6       |
| _mean_act       | 0.0520187  |
| _mean_adv       | 1.2e-17    |
| _mean_discrew   | 0.996      |
| _mean_obs       | 0.00248    |
| _min_adv        | -5.83      |
| _min_discrew    | 0.0117     |
| _min_obs        | -23.5      |
| _std_act        | 0.420285   |
| _std_adv        | 1          |
| _std_discrew    | 0.326      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.724       |
| KL              | 0.00349607  |
| Phi_loss        | 90.9135     |
| PolicyEntropy   | 15.3194     |
| PolicyLoss      | 0.000841892 |
| Steps           | 10046       |
| VarFuncLoss     | 0.0284      |
| _MeanReward     | 424         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24957     |
| _max_adv        | 4.4         |
| _max_discrew    | 2.76        |
| _max_obs        | 29.8        |
| _mean_act       | 0.0509906   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 0.988       |
| _mean_obs       | 0.00288     |
| _min_adv        | -5.15       |
| _min_discrew    | 0.0151      |
| _min_obs        | -18.5       |
| _std_act        | 0.418667    |
| _std_adv        | 1           |
| _std_discrew    | 0.323       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.897        |
| ExplainedVarOld | 0.696        |
| KL              | 0.00314359   |
| Phi_loss        | 88.6615      |
| PolicyEntropy   | 15.317       |
| PolicyLoss      | -0.000371669 |
| Steps           | 10002        |
| VarFuncLoss     | 0.0332       |
| _MeanReward     | 422          |
| _lr_multiplier  | 1            |
| _max_act        | 3.23397      |
| _max_adv        | 4.5          |
| _max_discrew    | 2.91         |
| _max_obs        | 21.5         |
| _mean_act       | 0.0492249    |
| _mean_adv       | -2.84e-18    |
| _mean_discrew   | 0.974        |
| _mean_obs       | 0.00292      |
| _min_adv        | -4.77        |
| _min_discrew    | 0.015        |
| _min_obs        | -18.7        |
| _std_act        | 0.417974     |
| _std_adv        | 1            |
| _std_discrew    | 0.316        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00309701  |
| Phi_loss        | 89.0709     |
| PolicyEntropy   | 15.3159     |
| PolicyLoss      | -0.00153248 |
| Steps           | 10058       |
| VarFuncLoss     | 0.026       |
| _MeanReward     | 408         |
| _lr_multiplier  | 1           |
| _max_act        | 3.08226     |
| _max_adv        | 4.16        |
| _max_discrew    | 2.36        |
| _max_obs        | 46.9        |
| _mean_act       | 0.0452755   |
| _mean_adv       | 1.98e-17    |
| _mean_discrew   | 0.951       |
| _mean_obs       | 0.00322     |
| _min_adv        | -7.07       |
| _min_discrew    | 0.0145      |
| _min_obs        | -41.9       |
| _std_act        | 0.419287    |
| _std_adv        | 1           |
| _std_discrew    | 0.286       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.901       |
| ExplainedVarOld | 0.728       |
| KL              | 0.00299167  |
| Phi_loss        | 82.3891     |
| PolicyEntropy   | 15.3152     |
| PolicyLoss      | -0.00399305 |
| Steps           | 10005       |
| VarFuncLoss     | 0.0283      |
| _MeanReward     | 426         |
| _lr_multiplier  | 1           |
| _max_act        | 2.7863      |
| _max_adv        | 4.17        |
| _max_discrew    | 2.95        |
| _max_obs        | 21          |
| _mean_act       | 0.049939    |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1           |
| _mean_obs       | 0.00201     |
| _min_adv        | -5.62       |
| _min_discrew    | 0.0156      |
| _min_obs        | -22.8       |
| _std_act        | 0.41993     |
| _std_adv        | 1           |
| _std_discrew    | 0.354       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.714       |
| KL              | 0.00356448  |
| Phi_loss        | 71.5952     |
| PolicyEntropy   | 15.3152     |
| PolicyLoss      | -0.00572512 |
| Steps           | 10008       |
| VarFuncLoss     | 0.0293      |
| _MeanReward     | 432         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97501     |
| _max_adv        | 4.46        |
| _max_discrew    | 2.95        |
| _max_obs        | 25.3        |
| _mean_act       | 0.0543564   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.00307     |
| _min_adv        | -5.43       |
| _min_discrew    | -0.00388    |
| _min_obs        | -22.4       |
| _std_act        | 0.416421    |
| _std_adv        | 1           |
| _std_discrew    | 0.343       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.711       |
| KL              | 0.00384204  |
| Phi_loss        | 77.2449     |
| PolicyEntropy   | 15.3158     |
| PolicyLoss      | -0.00458114 |
| Steps           | 10025       |
| VarFuncLoss     | 0.0309      |
| _MeanReward     | 410         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93818     |
| _max_adv        | 4.24        |
| _max_discrew    | 2.72        |
| _max_obs        | 22.8        |
| _mean_act       | 0.0511327   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.962       |
| _mean_obs       | 0.00266     |
| _min_adv        | -4.93       |
| _min_discrew    | 0.0174      |
| _min_obs        | -22.7       |
| _std_act        | 0.422076    |
| _std_adv        | 1           |
| _std_discrew    | 0.306       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
-------------------------------
| Beta            | 0.296     |
| ExplainedVarNew | 0.905     |
| ExplainedVarOld | 0.72      |
| KL              | 0.0117403 |
| Phi_loss        | 105.685   |
| PolicyEntropy   | 15.3139   |
| PolicyLoss      | 0.792164  |
| Steps           | 10069     |
| VarFuncLoss     | 0.0294    |
| _MeanReward     | 420       |
| _lr_multiplier  | 1         |
| _max_act        | 3.20283   |
| _max_adv        | 3.99      |
| _max_discrew    | 2.77      |
| _max_obs        | 32.8      |
| _mean_act       | 0.0483783 |
| _mean_adv       | -1.13e-17 |
| _mean_discrew   | 0.98      |
| _mean_obs       | 0.0022    |
| _min_adv        | -5.05     |
| _min_discrew    | 0.0165    |
| _min_obs        | -17       |
| _std_act        | 0.41805   |
| _std_adv        | 1         |
| _std_discrew    | 0.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.724       |
| KL              | 0.00655966  |
| Phi_loss        | 99.8082     |
| PolicyEntropy   | 15.3095     |
| PolicyLoss      | -0.00100922 |
| Steps           | 10080       |
| VarFuncLoss     | 0.0303      |
| _MeanReward     | 421         |
| _lr_multiplier  | 1           |
| _max_act        | 3.44051     |
| _max_adv        | 6.34        |
| _max_discrew    | 2.75        |
| _max_obs        | 22.6        |
| _mean_act       | 0.0497106   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.982       |
| _mean_obs       | 0.00256     |
| _min_adv        | -5.08       |
| _min_discrew    | 0.0161      |
| _min_obs        | -32.7       |
| _std_act        | 0.418922    |
| _std_adv        | 1           |
| _std_discrew    | 0.323       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.904        |
| ExplainedVarOld | 0.708        |
| KL              | 0.000978332  |
| Phi_loss        | 91.7481      |
| PolicyEntropy   | 15.3089      |
| PolicyLoss      | -0.000277129 |
| Steps           | 10016        |
| VarFuncLoss     | 0.0311       |
| _MeanReward     | 421          |
| _lr_multiplier  | 1            |
| _max_act        | 3.04241      |
| _max_adv        | 5.41         |
| _max_discrew    | 2.56         |
| _max_obs        | 29.6         |
| _mean_act       | 0.0546038    |
| _mean_adv       | 2.55e-17     |
| _mean_discrew   | 0.983        |
| _mean_obs       | 0.00346      |
| _min_adv        | -6.55        |
| _min_discrew    | 0.0115       |
| _min_obs        | -40.8        |
| _std_act        | 0.422269     |
| _std_adv        | 1            |
| _std_discrew    | 0.309        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.905        |
| ExplainedVarOld | 0.736        |
| KL              | 0.00170537   |
| Phi_loss        | 91.2525      |
| PolicyEntropy   | 15.3078      |
| PolicyLoss      | -0.000678757 |
| Steps           | 10008        |
| VarFuncLoss     | 0.0293       |
| _MeanReward     | 413          |
| _lr_multiplier  | 1            |
| _max_act        | 2.95147      |
| _max_adv        | 4.93         |
| _max_discrew    | 2.42         |
| _max_obs        | 29.1         |
| _mean_act       | 0.0512946    |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 0.961        |
| _mean_obs       | 0.00261      |
| _min_adv        | -5.68        |
| _min_discrew    | 0.0162       |
| _min_obs        | -26.4        |
| _std_act        | 0.420894     |
| _std_adv        | 1            |
| _std_discrew    | 0.296        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.903       |
| ExplainedVarOld | 0.737       |
| KL              | 0.00159813  |
| Phi_loss        | 88.0748     |
| PolicyEntropy   | 15.3075     |
| PolicyLoss      | -0.00347677 |
| Steps           | 10000       |
| VarFuncLoss     | 0.029       |
| _MeanReward     | 409         |
| _lr_multiplier  | 1           |
| _max_act        | 3.00173     |
| _max_adv        | 4.61        |
| _max_discrew    | 2.8         |
| _max_obs        | 40.4        |
| _mean_act       | 0.0510423   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.959       |
| _mean_obs       | 0.00279     |
| _min_adv        | -6.24       |
| _min_discrew    | 0.00573     |
| _min_obs        | -41.6       |
| _std_act        | 0.421588    |
| _std_adv        | 1           |
| _std_discrew    | 0.305       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.915      |
| ExplainedVarOld | 0.782      |
| KL              | 0.0023554  |
| Phi_loss        | 99.9008    |
| PolicyEntropy   | 15.3084    |
| PolicyLoss      | 0.00984354 |
| Steps           | 10006      |
| VarFuncLoss     | 0.0259     |
| _MeanReward     | 432        |
| _lr_multiplier  | 1          |
| _max_act        | 2.89796    |
| _max_adv        | 4.23       |
| _max_discrew    | 2.5        |
| _max_obs        | 40.7       |
| _mean_act       | 0.0564744  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.998      |
| _mean_obs       | 0.00267    |
| _min_adv        | -6.47      |
| _min_discrew    | 0.0109     |
| _min_obs        | -21.1      |
| _std_act        | 0.418734   |
| _std_adv        | 1          |
| _std_discrew    | 0.317      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.767      |
| KL              | 0.00179241 |
| Phi_loss        | 100.794    |
| PolicyEntropy   | 15.3071    |
| PolicyLoss      | 0.00156706 |
| Steps           | 10080      |
| VarFuncLoss     | 0.0285     |
| _MeanReward     | 426        |
| _lr_multiplier  | 1          |
| _max_act        | 2.92502    |
| _max_adv        | 6.66       |
| _max_discrew    | 2.74       |
| _max_obs        | 20.5       |
| _mean_act       | 0.0509367  |
| _mean_adv       | -1.13e-17  |
| _mean_discrew   | 0.986      |
| _mean_obs       | 0.00215    |
| _min_adv        | -6.18      |
| _min_discrew    | 0.0153     |
| _min_obs        | -19.5      |
| _std_act        | 0.420523   |
| _std_adv        | 1          |
| _std_discrew    | 0.307      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.777      |
| KL              | 0.00177871 |
| Phi_loss        | 104.449    |
| PolicyEntropy   | 15.3064    |
| PolicyLoss      | 0.00263316 |
| Steps           | 10060      |
| VarFuncLoss     | 0.0259     |
| _MeanReward     | 436        |
| _lr_multiplier  | 1          |
| _max_act        | 2.95406    |
| _max_adv        | 5.93       |
| _max_discrew    | 3.1        |
| _max_obs        | 25         |
| _mean_act       | 0.0536423  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.00215    |
| _min_adv        | -5.44      |
| _min_discrew    | 0.0175     |
| _min_obs        | -28.2      |
| _std_act        | 0.422106   |
| _std_adv        | 1          |
| _std_discrew    | 0.363      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.737      |
| KL              | 0.00148176 |
| Phi_loss        | 100.697    |
| PolicyEntropy   | 15.3052    |
| PolicyLoss      | 0.00262517 |
| Steps           | 10015      |
| VarFuncLoss     | 0.0295     |
| _MeanReward     | 447        |
| _lr_multiplier  | 1          |
| _max_act        | 3.52431    |
| _max_adv        | 4.69       |
| _max_discrew    | 3.32       |
| _max_obs        | 26.6       |
| _mean_act       | 0.053353   |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.00289    |
| _min_adv        | -5.13      |
| _min_discrew    | 0.0165     |
| _min_obs        | -31.9      |
| _std_act        | 0.421002   |
| _std_adv        | 1          |
| _std_discrew    | 0.367      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.727       |
| KL              | 0.00282838  |
| Phi_loss        | 102.936     |
| PolicyEntropy   | 15.3047     |
| PolicyLoss      | -0.00556343 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0318      |
| _MeanReward     | 432         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24738     |
| _max_adv        | 4.7         |
| _max_discrew    | 2.87        |
| _max_obs        | 31.4        |
| _mean_act       | 0.0516552   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 0.998       |
| _mean_obs       | 0.00193     |
| _min_adv        | -6.04       |
| _min_discrew    | 0.0161      |
| _min_obs        | -28.8       |
| _std_act        | 0.420127    |
| _std_adv        | 1           |
| _std_discrew    | 0.329       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.913        |
| ExplainedVarOld | 0.743        |
| KL              | 0.00264089   |
| Phi_loss        | 100.045      |
| PolicyEntropy   | 15.3042      |
| PolicyLoss      | -6.48487e-05 |
| Steps           | 10060        |
| VarFuncLoss     | 0.0285       |
| _MeanReward     | 422          |
| _lr_multiplier  | 1            |
| _max_act        | 2.75401      |
| _max_adv        | 4.88         |
| _max_discrew    | 3.02         |
| _max_obs        | 19.5         |
| _mean_act       | 0.0515553    |
| _mean_adv       | -9.89e-18    |
| _mean_discrew   | 0.997        |
| _mean_obs       | 0.00228      |
| _min_adv        | -4.25        |
| _min_discrew    | 0.0149       |
| _min_obs        | -19.6        |
| _std_act        | 0.418323     |
| _std_adv        | 1            |
| _std_discrew    | 0.348        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.693      |
| KL              | 0.002731   |
| Phi_loss        | 97.4053    |
| PolicyEntropy   | 15.3048    |
| PolicyLoss      | -0.0035019 |
| Steps           | 10002      |
| VarFuncLoss     | 0.0355     |
| _MeanReward     | 419        |
| _lr_multiplier  | 1          |
| _max_act        | 2.99458    |
| _max_adv        | 5.58       |
| _max_discrew    | 3.05       |
| _max_obs        | 70.4       |
| _mean_act       | 0.0532006  |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 0.988      |
| _mean_obs       | 0.00276    |
| _min_adv        | -6.46      |
| _min_discrew    | 0.00878    |
| _min_obs        | -23.8      |
| _std_act        | 0.423415   |
| _std_adv        | 1          |
| _std_discrew    | 0.346      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.702       |
| KL              | 0.00281462  |
| Phi_loss        | 90.4282     |
| PolicyEntropy   | 15.3051     |
| PolicyLoss      | -0.00327529 |
| Steps           | 10017       |
| VarFuncLoss     | 0.0333      |
| _MeanReward     | 430         |
| _lr_multiplier  | 1           |
| _max_act        | 2.85428     |
| _max_adv        | 4.58        |
| _max_discrew    | 2.62        |
| _max_obs        | 23.4        |
| _mean_act       | 0.0508046   |
| _mean_adv       | 8.51e-18    |
| _mean_discrew   | 0.995       |
| _mean_obs       | 0.00276     |
| _min_adv        | -5.35       |
| _min_discrew    | -0.00711    |
| _min_obs        | -23.7       |
| _std_act        | 0.422233    |
| _std_adv        | 1           |
| _std_discrew    | 0.321       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.73       |
| KL              | 0.00322959 |
| Phi_loss        | 96.349     |
| PolicyEntropy   | 15.3033    |
| PolicyLoss      | 0.00284659 |
| Steps           | 10077      |
| VarFuncLoss     | 0.0276     |
| _MeanReward     | 426        |
| _lr_multiplier  | 1          |
| _max_act        | 2.97607    |
| _max_adv        | 4.75       |
| _max_discrew    | 2.54       |
| _max_obs        | 24         |
| _mean_act       | 0.0523094  |
| _mean_adv       | 0          |
| _mean_discrew   | 0.986      |
| _mean_obs       | 0.00251    |
| _min_adv        | -6.07      |
| _min_discrew    | 0.0165     |
| _min_obs        | -26.2      |
| _std_act        | 0.417892   |
| _std_adv        | 1          |
| _std_discrew    | 0.312      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.779       |
| KL              | 0.00265286  |
| Phi_loss        | 97.247      |
| PolicyEntropy   | 15.302      |
| PolicyLoss      | -0.00167533 |
| Steps           | 10061       |
| VarFuncLoss     | 0.0258      |
| _MeanReward     | 432         |
| _lr_multiplier  | 1           |
| _max_act        | 3.2861      |
| _max_adv        | 5.05        |
| _max_discrew    | 3.14        |
| _max_obs        | 44          |
| _mean_act       | 0.0528441   |
| _mean_adv       | 1.41e-17    |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.00245     |
| _min_adv        | -7.2        |
| _min_discrew    | -0.00104    |
| _min_obs        | -22.4       |
| _std_act        | 0.41913     |
| _std_adv        | 1           |
| _std_discrew    | 0.359       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.905       |
| ExplainedVarOld | 0.712       |
| KL              | 0.00313285  |
| Phi_loss        | 87.3614     |
| PolicyEntropy   | 15.3004     |
| PolicyLoss      | 0.000187872 |
| Steps           | 10030       |
| VarFuncLoss     | 0.0342      |
| _MeanReward     | 433         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90132     |
| _max_adv        | 4.84        |
| _max_discrew    | 2.89        |
| _max_obs        | 52.5        |
| _mean_act       | 0.0551833   |
| _mean_adv       | 1.98e-17    |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.00331     |
| _min_adv        | -6.06       |
| _min_discrew    | 0.0172      |
| _min_obs        | -25.5       |
| _std_act        | 0.419154    |
| _std_adv        | 1           |
| _std_discrew    | 0.336       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.744      |
| KL              | 0.00341173 |
| Phi_loss        | 85.2959    |
| PolicyEntropy   | 15.3015    |
| PolicyLoss      | -0.0038178 |
| Steps           | 10074      |
| VarFuncLoss     | 0.0304     |
| _MeanReward     | 432        |
| _lr_multiplier  | 1          |
| _max_act        | 3.1045     |
| _max_adv        | 4.21       |
| _max_discrew    | 2.92       |
| _max_obs        | 29.3       |
| _mean_act       | 0.0506594  |
| _mean_adv       | -5.64e-18  |
| _mean_discrew   | 1.01       |
| _mean_obs       | 0.0024     |
| _min_adv        | -6.97      |
| _min_discrew    | 0.0145     |
| _min_obs        | -21.5      |
| _std_act        | 0.418602   |
| _std_adv        | 1          |
| _std_discrew    | 0.338      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.912       |
| ExplainedVarOld | 0.715       |
| KL              | 0.00258484  |
| Phi_loss        | 83.8445     |
| PolicyEntropy   | 15.3015     |
| PolicyLoss      | 0.000875783 |
| Steps           | 10001       |
| VarFuncLoss     | 0.0301      |
| _MeanReward     | 446         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87485     |
| _max_adv        | 7.24        |
| _max_discrew    | 2.84        |
| _max_obs        | 39.4        |
| _mean_act       | 0.0512563   |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.00264     |
| _min_adv        | -5.23       |
| _min_discrew    | 0.0144      |
| _min_obs        | -13.1       |
| _std_act        | 0.419642    |
| _std_adv        | 1           |
| _std_discrew    | 0.341       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.733       |
| KL              | 0.00281249  |
| Phi_loss        | 85.1287     |
| PolicyEntropy   | 15.3009     |
| PolicyLoss      | -0.00456752 |
| Steps           | 10055       |
| VarFuncLoss     | 0.0282      |
| _MeanReward     | 431         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01049     |
| _max_adv        | 5.67        |
| _max_discrew    | 3.37        |
| _max_obs        | 17.3        |
| _mean_act       | 0.0538668   |
| _mean_adv       | 5.65e-18    |
| _mean_discrew   | 1           |
| _mean_obs       | 0.0022      |
| _min_adv        | -5.83       |
| _min_discrew    | 0.0166      |
| _min_obs        | -16.6       |
| _std_act        | 0.422358    |
| _std_adv        | 1           |
| _std_discrew    | 0.349       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.71       |
| KL              | 0.00278976 |
| Phi_loss        | 88.2918    |
| PolicyEntropy   | 15.2994    |
| PolicyLoss      | 0.00333586 |
| Steps           | 10030      |
| VarFuncLoss     | 0.0302     |
| _MeanReward     | 435        |
| _lr_multiplier  | 1          |
| _max_act        | 3.00965    |
| _max_adv        | 4.76       |
| _max_discrew    | 3.02       |
| _max_obs        | 31.7       |
| _mean_act       | 0.0538855  |
| _mean_adv       | 1.84e-17   |
| _mean_discrew   | 1.01       |
| _mean_obs       | 0.00217    |
| _min_adv        | -5.02      |
| _min_discrew    | 0.0139     |
| _min_obs        | -16.6      |
| _std_act        | 0.420079   |
| _std_adv        | 1          |
| _std_discrew    | 0.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.917      |
| ExplainedVarOld | 0.744      |
| KL              | 0.00374792 |
| Phi_loss        | 97.993     |
| PolicyEntropy   | 15.3001    |
| PolicyLoss      | 0.00985639 |
| Steps           | 10036      |
| VarFuncLoss     | 0.0283     |
| _MeanReward     | 446        |
| _lr_multiplier  | 1          |
| _max_act        | 3.03816    |
| _max_adv        | 4.46       |
| _max_discrew    | 2.77       |
| _max_obs        | 23.4       |
| _mean_act       | 0.0560373  |
| _mean_adv       | 5.66e-18   |
| _mean_discrew   | 1.03       |
| _mean_obs       | 0.00283    |
| _min_adv        | -4.75      |
| _min_discrew    | 0.0126     |
| _min_obs        | -24.3      |
| _std_act        | 0.420462   |
| _std_adv        | 1          |
| _std_discrew    | 0.347      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
----------------------------------
| Beta            | 0.198        |
| ExplainedVarNew | 0.92         |
| ExplainedVarOld | 0.757        |
| KL              | 0.00419951   |
| Phi_loss        | 98.9824      |
| PolicyEntropy   | 15.2996      |
| PolicyLoss      | -0.000915871 |
| Steps           | 10022        |
| VarFuncLoss     | 0.0279       |
| _MeanReward     | 433          |
| _lr_multiplier  | 1            |
| _max_act        | 2.9341       |
| _max_adv        | 3.98         |
| _max_discrew    | 2.79         |
| _max_obs        | 27.7         |
| _mean_act       | 0.055896     |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 1            |
| _mean_obs       | 0.00247      |
| _min_adv        | -6.54        |
| _min_discrew    | 0.0167       |
| _min_obs        | -26.1        |
| _std_act        | 0.422252     |
| _std_adv        | 1            |
| _std_discrew    | 0.322        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.733       |
| KL              | 0.0030033   |
| Phi_loss        | 94.3206     |
| PolicyEntropy   | 15.2997     |
| PolicyLoss      | -0.00417446 |
| Steps           | 10069       |
| VarFuncLoss     | 0.0305      |
| _MeanReward     | 415         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90465     |
| _max_adv        | 4.56        |
| _max_discrew    | 2.38        |
| _max_obs        | 25.4        |
| _mean_act       | 0.0533367   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.966       |
| _mean_obs       | 0.00148     |
| _min_adv        | -7.3        |
| _min_discrew    | 0.0138      |
| _min_obs        | -25.7       |
| _std_act        | 0.423322    |
| _std_adv        | 1           |
| _std_discrew    | 0.303       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.779       |
| KL              | 0.00271538  |
| Phi_loss        | 91.1041     |
| PolicyEntropy   | 15.2982     |
| PolicyLoss      | -0.00110644 |
| Steps           | 10022       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 440         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01315     |
| _max_adv        | 5.07        |
| _max_discrew    | 3.59        |
| _max_obs        | 42.2        |
| _mean_act       | 0.0548581   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.00256     |
| _min_adv        | -6.43       |
| _min_discrew    | 0.0172      |
| _min_obs        | -44.4       |
| _std_act        | 0.423319    |
| _std_adv        | 1           |
| _std_discrew    | 0.373       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.894       |
| ExplainedVarOld | 0.663       |
| KL              | 0.00332595  |
| Phi_loss        | 92.5353     |
| PolicyEntropy   | 15.2966     |
| PolicyLoss      | -0.00695328 |
| Steps           | 10079       |
| VarFuncLoss     | 0.0397      |
| _MeanReward     | 429         |
| _lr_multiplier  | 1           |
| _max_act        | 3.109       |
| _max_adv        | 4.22        |
| _max_discrew    | 2.9         |
| _max_obs        | 26.3        |
| _mean_act       | 0.0545897   |
| _mean_adv       | -2.26e-17   |
| _mean_discrew   | 0.999       |
| _mean_obs       | 0.00215     |
| _min_adv        | -5.49       |
| _min_discrew    | 0.0161      |
| _min_obs        | -17.1       |
| _std_act        | 0.422857    |
| _std_adv        | 1           |
| _std_discrew    | 0.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.768       |
| KL              | 0.00295268  |
| Phi_loss        | 93.1292     |
| PolicyEntropy   | 15.2968     |
| PolicyLoss      | -0.00479312 |
| Steps           | 10025       |
| VarFuncLoss     | 0.031       |
| _MeanReward     | 456         |
| _lr_multiplier  | 1           |
| _max_act        | 3.12054     |
| _max_adv        | 4.65        |
| _max_discrew    | 2.99        |
| _max_obs        | 22.3        |
| _mean_act       | 0.0537479   |
| _mean_adv       | -2.55e-17   |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00263     |
| _min_adv        | -6.21       |
| _min_discrew    | 0.015       |
| _min_obs        | -42.4       |
| _std_act        | 0.421373    |
| _std_adv        | 1           |
| _std_discrew    | 0.367       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.742       |
| KL              | 0.00307432  |
| Phi_loss        | 84.3668     |
| PolicyEntropy   | 15.2989     |
| PolicyLoss      | -0.00587518 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0329      |
| _MeanReward     | 455         |
| _lr_multiplier  | 1           |
| _max_act        | 2.94704     |
| _max_adv        | 4.19        |
| _max_discrew    | 2.86        |
| _max_obs        | 24.7        |
| _mean_act       | 0.0522604   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.00222     |
| _min_adv        | -4.52       |
| _min_discrew    | 0.0156      |
| _min_obs        | -32.1       |
| _std_act        | 0.420446    |
| _std_adv        | 1           |
| _std_discrew    | 0.353       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
--------------------------------
| Beta            | 0.198      |
| ExplainedVarNew | 0.921      |
| ExplainedVarOld | 0.765      |
| KL              | 0.00302689 |
| Phi_loss        | 92.6741    |
| PolicyEntropy   | 15.2994    |
| PolicyLoss      | 0.00088047 |
| Steps           | 10017      |
| VarFuncLoss     | 0.028      |
| _MeanReward     | 438        |
| _lr_multiplier  | 1          |
| _max_act        | 3.03048    |
| _max_adv        | 3.78       |
| _max_discrew    | 2.74       |
| _max_obs        | 56.1       |
| _mean_act       | 0.0549893  |
| _mean_adv       | -5.67e-18  |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.00187    |
| _min_adv        | -7.72      |
| _min_discrew    | 0.0171     |
| _min_obs        | -35.4      |
| _std_act        | 0.425394   |
| _std_adv        | 1          |
| _std_discrew    | 0.345      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
---------------------------------
| Beta            | 0.198       |
| ExplainedVarNew | 0.905       |
| ExplainedVarOld | 0.725       |
| KL              | 0.00308465  |
| Phi_loss        | 92.0553     |
| PolicyEntropy   | 15.2989     |
| PolicyLoss      | -0.00166102 |
| Steps           | 10025       |
| VarFuncLoss     | 0.0331      |
| _MeanReward     | 434         |
| _lr_multiplier  | 1           |
| _max_act        | 2.95063     |
| _max_adv        | 4.17        |
| _max_discrew    | 2.76        |
| _max_obs        | 33.8        |
| _mean_act       | 0.0556759   |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.00316     |
| _min_adv        | -5.91       |
| _min_discrew    | 0.0176      |
| _min_obs        | -22.2       |
| _std_act        | 0.423009    |
| _std_adv        | 1           |
| _std_discrew    | 0.326       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.775       |
| KL              | 0.00750675  |
| Phi_loss        | 109.301     |
| PolicyEntropy   | 15.297      |
| PolicyLoss      | -0.00313296 |
| Steps           | 10017       |
| VarFuncLoss     | 0.0265      |
| _MeanReward     | 436         |
| _lr_multiplier  | 1           |
| _max_act        | 3.27427     |
| _max_adv        | 4.33        |
| _max_discrew    | 2.8         |
| _max_obs        | 56.4        |
| _mean_act       | 0.0505891   |
| _mean_adv       | 1.84e-17    |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.00185     |
| _min_adv        | -6.19       |
| _min_discrew    | 0.0126      |
| _min_obs        | -64.3       |
| _std_act        | 0.42401     |
| _std_adv        | 1           |
| _std_discrew    | 0.345       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.744      |
| KL              | 0.00314726 |
| Phi_loss        | 104.791    |
| PolicyEntropy   | 15.2939    |
| PolicyLoss      | 0.00156752 |
| Steps           | 10063      |
| VarFuncLoss     | 0.0303     |
| _MeanReward     | 447        |
| _lr_multiplier  | 1          |
| _max_act        | 3.17693    |
| _max_adv        | 4.97       |
| _max_discrew    | 2.86       |
| _max_obs        | 42         |
| _mean_act       | 0.0552997  |
| _mean_adv       | -5.65e-18  |
| _mean_discrew   | 1.03       |
| _mean_obs       | 0.00171    |
| _min_adv        | -5.65      |
| _min_discrew    | 0.0103     |
| _min_obs        | -35.3      |
| _std_act        | 0.420295   |
| _std_adv        | 1          |
| _std_discrew    | 0.352      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.76       |
| KL              | 0.00175581 |
| Phi_loss        | 105.515    |
| PolicyEntropy   | 15.2924    |
| PolicyLoss      | 0.00108631 |
| Steps           | 10046      |
| VarFuncLoss     | 0.0285     |
| _MeanReward     | 435        |
| _lr_multiplier  | 1          |
| _max_act        | 2.97935    |
| _max_adv        | 6          |
| _max_discrew    | 3.01       |
| _max_obs        | 35.6       |
| _mean_act       | 0.0559988  |
| _mean_adv       | 0          |
| _mean_discrew   | 1          |
| _mean_obs       | 0.00257    |
| _min_adv        | -5.64      |
| _min_discrew    | 0.0139     |
| _min_obs        | -31.9      |
| _std_act        | 0.424934   |
| _std_adv        | 1          |
| _std_discrew    | 0.323      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.913       |
| ExplainedVarOld | 0.744       |
| KL              | 0.00186404  |
| Phi_loss        | 95.6505     |
| PolicyEntropy   | 15.2913     |
| PolicyLoss      | -0.00502936 |
| Steps           | 10067       |
| VarFuncLoss     | 0.0281      |
| _MeanReward     | 444         |
| _lr_multiplier  | 1           |
| _max_act        | 3.05724     |
| _max_adv        | 4.13        |
| _max_discrew    | 2.87        |
| _max_obs        | 34.6        |
| _mean_act       | 0.0565985   |
| _mean_adv       | 5.65e-18    |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.00228     |
| _min_adv        | -5.78       |
| _min_discrew    | 0.0143      |
| _min_obs        | -19.5       |
| _std_act        | 0.424151    |
| _std_adv        | 1           |
| _std_discrew    | 0.331       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.791       |
| KL              | 0.00179218  |
| Phi_loss        | 101.325     |
| PolicyEntropy   | 15.2908     |
| PolicyLoss      | -0.00391496 |
| Steps           | 10046       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 456         |
| _lr_multiplier  | 1           |
| _max_act        | 3.272       |
| _max_adv        | 4.28        |
| _max_discrew    | 2.86        |
| _max_obs        | 37.5        |
| _mean_act       | 0.0556289   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.0026      |
| _min_adv        | -4.72       |
| _min_discrew    | 0.0176      |
| _min_obs        | -20.9       |
| _std_act        | 0.424533    |
| _std_adv        | 1           |
| _std_discrew    | 0.368       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.762      |
| KL              | 0.00174767 |
| Phi_loss        | 98.7066    |
| PolicyEntropy   | 15.2889    |
| PolicyLoss      | 0.00211154 |
| Steps           | 10012      |
| VarFuncLoss     | 0.0308     |
| _MeanReward     | 435        |
| _lr_multiplier  | 1          |
| _max_act        | 3.21069    |
| _max_adv        | 5.36       |
| _max_discrew    | 2.71       |
| _max_obs        | 51.9       |
| _mean_act       | 0.0524801  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.01       |
| _mean_obs       | 0.00247    |
| _min_adv        | -6.39      |
| _min_discrew    | 0.0143     |
| _min_obs        | -20        |
| _std_act        | 0.421945   |
| _std_adv        | 1          |
| _std_discrew    | 0.336      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.907      |
| ExplainedVarOld | 0.746      |
| KL              | 0.00166136 |
| Phi_loss        | 92.12      |
| PolicyEntropy   | 15.2868    |
| PolicyLoss      | -0.0010224 |
| Steps           | 10017      |
| VarFuncLoss     | 0.0314     |
| _MeanReward     | 446        |
| _lr_multiplier  | 1          |
| _max_act        | 3.20831    |
| _max_adv        | 4.45       |
| _max_discrew    | 2.89       |
| _max_obs        | 59.7       |
| _mean_act       | 0.0583343  |
| _mean_adv       | -3.55e-18  |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.00261    |
| _min_adv        | -5.16      |
| _min_discrew    | 0.0175     |
| _min_obs        | -62.4      |
| _std_act        | 0.424499   |
| _std_adv        | 1          |
| _std_discrew    | 0.365      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.914        |
| ExplainedVarOld | 0.76         |
| KL              | 0.00177036   |
| Phi_loss        | 88.8838      |
| PolicyEntropy   | 15.2854      |
| PolicyLoss      | -0.000332311 |
| Steps           | 10046        |
| VarFuncLoss     | 0.0316       |
| _MeanReward     | 456          |
| _lr_multiplier  | 1            |
| _max_act        | 2.74007      |
| _max_adv        | 5.69         |
| _max_discrew    | 2.86         |
| _max_obs        | 25           |
| _mean_act       | 0.0565573    |
| _mean_adv       | 1.13e-17     |
| _mean_discrew   | 1.05         |
| _mean_obs       | 0.00305      |
| _min_adv        | -5.08        |
| _min_discrew    | 0.0161       |
| _min_obs        | -20.2        |
| _std_act        | 0.425147     |
| _std_adv        | 1            |
| _std_discrew    | 0.355        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.757       |
| KL              | 0.00243392  |
| Phi_loss        | 101.167     |
| PolicyEntropy   | 15.2863     |
| PolicyLoss      | -0.00172465 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0296      |
| _MeanReward     | 452         |
| _lr_multiplier  | 1           |
| _max_act        | 3.2507      |
| _max_adv        | 5.61        |
| _max_discrew    | 3.07        |
| _max_obs        | 32          |
| _mean_act       | 0.0538769   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.00198     |
| _min_adv        | -5.21       |
| _min_discrew    | 0.0102      |
| _min_obs        | -19.7       |
| _std_act        | 0.423559    |
| _std_adv        | 1           |
| _std_discrew    | 0.364       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.728       |
| KL              | 0.00160763  |
| Phi_loss        | 93.6875     |
| PolicyEntropy   | 15.287      |
| PolicyLoss      | -0.00186976 |
| Steps           | 10046       |
| VarFuncLoss     | 0.0302      |
| _MeanReward     | 446         |
| _lr_multiplier  | 1           |
| _max_act        | 3.12112     |
| _max_adv        | 5.39        |
| _max_discrew    | 2.64        |
| _max_obs        | 22.7        |
| _mean_act       | 0.0567489   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.0021      |
| _min_adv        | -5.82       |
| _min_discrew    | 0.0147      |
| _min_obs        | -21.4       |
| _std_act        | 0.425482    |
| _std_adv        | 1           |
| _std_discrew    | 0.356       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.743      |
| KL              | 0.00181686 |
| Phi_loss        | 98.6151    |
| PolicyEntropy   | 15.2847    |
| PolicyLoss      | 0.00195246 |
| Steps           | 10045      |
| VarFuncLoss     | 0.0308     |
| _MeanReward     | 438        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0358     |
| _max_adv        | 4.14       |
| _max_discrew    | 2.71       |
| _max_obs        | 22         |
| _mean_act       | 0.0534565  |
| _mean_adv       | 1.7e-17    |
| _mean_discrew   | 1.01       |
| _mean_obs       | 0.00155    |
| _min_adv        | -6.08      |
| _min_discrew    | 0.0108     |
| _min_obs        | -19.8      |
| _std_act        | 0.425619   |
| _std_adv        | 1          |
| _std_discrew    | 0.327      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.76        |
| KL              | 0.00158155  |
| Phi_loss        | 107.83      |
| PolicyEntropy   | 15.2825     |
| PolicyLoss      | -0.00212643 |
| Steps           | 10034       |
| VarFuncLoss     | 0.0293      |
| _MeanReward     | 442         |
| _lr_multiplier  | 1           |
| _max_act        | 3.08027     |
| _max_adv        | 4.05        |
| _max_discrew    | 2.7         |
| _max_obs        | 24.8        |
| _mean_act       | 0.0571595   |
| _mean_adv       | 1.7e-17     |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.00199     |
| _min_adv        | -6.77       |
| _min_discrew    | 0.0156      |
| _min_obs        | -22.9       |
| _std_act        | 0.423737    |
| _std_adv        | 1           |
| _std_discrew    | 0.342       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.912      |
| ExplainedVarOld | 0.787      |
| KL              | 0.00166649 |
| Phi_loss        | 105.435    |
| PolicyEntropy   | 15.2812    |
| PolicyLoss      | 0.00287464 |
| Steps           | 10059      |
| VarFuncLoss     | 0.0303     |
| _MeanReward     | 433        |
| _lr_multiplier  | 1          |
| _max_act        | 3.31812    |
| _max_adv        | 4.83       |
| _max_discrew    | 2.8        |
| _max_obs        | 18.4       |
| _mean_act       | 0.051644   |
| _mean_adv       | 0          |
| _mean_discrew   | 1.01       |
| _mean_obs       | 0.00199    |
| _min_adv        | -6.94      |
| _min_discrew    | 0.0132     |
| _min_obs        | -15.1      |
| _std_act        | 0.420392   |
| _std_adv        | 1          |
| _std_discrew    | 0.338      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.73        |
| KL              | 0.00153547  |
| Phi_loss        | 91.4039     |
| PolicyEntropy   | 15.2808     |
| PolicyLoss      | -0.00296257 |
| Steps           | 10077       |
| VarFuncLoss     | 0.0317      |
| _MeanReward     | 442         |
| _lr_multiplier  | 1           |
| _max_act        | 3.0305      |
| _max_adv        | 5.1         |
| _max_discrew    | 3.34        |
| _max_obs        | 29.7        |
| _mean_act       | 0.0546663   |
| _mean_adv       | -1.55e-17   |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.00287     |
| _min_adv        | -5.03       |
| _min_discrew    | 0.0171      |
| _min_obs        | -22.3       |
| _std_act        | 0.421697    |
| _std_adv        | 1           |
| _std_discrew    | 0.355       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.763      |
| KL              | 0.00152502 |
| Phi_loss        | 91.6915    |
| PolicyEntropy   | 15.2813    |
| PolicyLoss      | -0.0021887 |
| Steps           | 10024      |
| VarFuncLoss     | 0.0299     |
| _MeanReward     | 443        |
| _lr_multiplier  | 1          |
| _max_act        | 3.17593    |
| _max_adv        | 4.87       |
| _max_discrew    | 2.66       |
| _max_obs        | 27.1       |
| _mean_act       | 0.0533579  |
| _mean_adv       | -5.67e-18  |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.00174    |
| _min_adv        | -5.82      |
| _min_discrew    | 0.0165     |
| _min_obs        | -21.2      |
| _std_act        | 0.423343   |
| _std_adv        | 1          |
| _std_discrew    | 0.335      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.909       |
| ExplainedVarOld | 0.749       |
| KL              | 0.00179503  |
| Phi_loss        | 89.8091     |
| PolicyEntropy   | 15.2813     |
| PolicyLoss      | -0.00162636 |
| Steps           | 10010       |
| VarFuncLoss     | 0.0306      |
| _MeanReward     | 448         |
| _lr_multiplier  | 1           |
| _max_act        | 3.02215     |
| _max_adv        | 4.85        |
| _max_discrew    | 2.58        |
| _max_obs        | 38.9        |
| _mean_act       | 0.0621343   |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.00344     |
| _min_adv        | -5.5        |
| _min_discrew    | 0.0125      |
| _min_obs        | -35.2       |
| _std_act        | 0.422096    |
| _std_adv        | 1           |
| _std_discrew    | 0.32        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.929      |
| ExplainedVarOld | 0.81       |
| KL              | 0.00181586 |
| Phi_loss        | 90.9542    |
| PolicyEntropy   | 15.2795    |
| PolicyLoss      | 0.00145974 |
| Steps           | 10067      |
| VarFuncLoss     | 0.0226     |
| _MeanReward     | 478        |
| _lr_multiplier  | 1          |
| _max_act        | 2.83571    |
| _max_adv        | 4.35       |
| _max_discrew    | 3.19       |
| _max_obs        | 24.9       |
| _mean_act       | 0.0568323  |
| _mean_adv       | -1.69e-17  |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.00241    |
| _min_adv        | -4.9       |
| _min_discrew    | 0.0163     |
| _min_obs        | -24.2      |
| _std_act        | 0.420352   |
| _std_adv        | 1          |
| _std_discrew    | 0.425      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.699       |
| KL              | 0.0018326   |
| Phi_loss        | 86.8062     |
| PolicyEntropy   | 15.278      |
| PolicyLoss      | -0.00148825 |
| Steps           | 10067       |
| VarFuncLoss     | 0.0367      |
| _MeanReward     | 435         |
| _lr_multiplier  | 1           |
| _max_act        | 3.44559     |
| _max_adv        | 4.03        |
| _max_discrew    | 3.2         |
| _max_obs        | 43.2        |
| _mean_act       | 0.054715    |
| _mean_adv       | -2.54e-17   |
| _mean_discrew   | 1.01        |
| _mean_obs       | 0.00212     |
| _min_adv        | -5.58       |
| _min_discrew    | 0.016       |
| _min_obs        | -25.5       |
| _std_act        | 0.42301     |
| _std_adv        | 1           |
| _std_discrew    | 0.346       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.913        |
| ExplainedVarOld | 0.736        |
| KL              | 0.00180203   |
| Phi_loss        | 76.2378      |
| PolicyEntropy   | 15.2763      |
| PolicyLoss      | -0.000679796 |
| Steps           | 10052        |
| VarFuncLoss     | 0.0304       |
| _MeanReward     | 448          |
| _lr_multiplier  | 1            |
| _max_act        | 2.93284      |
| _max_adv        | 4.29         |
| _max_discrew    | 2.95         |
| _max_obs        | 21.9         |
| _mean_act       | 0.0568103    |
| _mean_adv       | 2.4e-17      |
| _mean_discrew   | 1.03         |
| _mean_obs       | 0.00145      |
| _min_adv        | -5.72        |
| _min_discrew    | 0.00355      |
| _min_obs        | -24.7        |
| _std_act        | 0.422942     |
| _std_adv        | 1            |
| _std_discrew    | 0.358        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.741       |
| KL              | 0.00206797  |
| Phi_loss        | 74.8313     |
| PolicyEntropy   | 15.2773     |
| PolicyLoss      | -0.00362123 |
| Steps           | 10074       |
| VarFuncLoss     | 0.032       |
| _MeanReward     | 457         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90381     |
| _max_adv        | 4.39        |
| _max_discrew    | 2.63        |
| _max_obs        | 25.5        |
| _mean_act       | 0.0564117   |
| _mean_adv       | 7.05e-19    |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.0021      |
| _min_adv        | -5.95       |
| _min_discrew    | 0.0139      |
| _min_obs        | -22.4       |
| _std_act        | 0.422952    |
| _std_adv        | 1           |
| _std_discrew    | 0.347       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.784      |
| KL              | 0.00218371 |
| Phi_loss        | 80.8315    |
| PolicyEntropy   | 15.2774    |
| PolicyLoss      | 0.00116002 |
| Steps           | 10138      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 483        |
| _lr_multiplier  | 1          |
| _max_act        | 2.91341    |
| _max_adv        | 4.72       |
| _max_discrew    | 3.2        |
| _max_obs        | 24.6       |
| _mean_act       | 0.0580732  |
| _mean_adv       | -1.68e-17  |
| _mean_discrew   | 1.11       |
| _mean_obs       | 0.0023     |
| _min_adv        | -4.79      |
| _min_discrew    | 0.0173     |
| _min_obs        | -24.7      |
| _std_act        | 0.423052   |
| _std_adv        | 1          |
| _std_discrew    | 0.404      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.931       |
| ExplainedVarOld | 0.761       |
| KL              | 0.00234036  |
| Phi_loss        | 78.5443     |
| PolicyEntropy   | 15.2759     |
| PolicyLoss      | -0.00161836 |
| Steps           | 10086       |
| VarFuncLoss     | 0.0278      |
| _MeanReward     | 453         |
| _lr_multiplier  | 1           |
| _max_act        | 2.99045     |
| _max_adv        | 5.01        |
| _max_discrew    | 2.6         |
| _max_obs        | 51.4        |
| _mean_act       | 0.0574036   |
| _mean_adv       | -1e-17      |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.00274     |
| _min_adv        | -5.44       |
| _min_discrew    | 0.0149      |
| _min_obs        | -37.2       |
| _std_act        | 0.422198    |
| _std_adv        | 1           |
| _std_discrew    | 0.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.922        |
| ExplainedVarOld | 0.777        |
| KL              | 0.00217842   |
| Phi_loss        | 78.5361      |
| PolicyEntropy   | 15.2756      |
| PolicyLoss      | -0.000463407 |
| Steps           | 10011        |
| VarFuncLoss     | 0.0264       |
| _MeanReward     | 447          |
| _lr_multiplier  | 1            |
| _max_act        | 3.03767      |
| _max_adv        | 4.45         |
| _max_discrew    | 3.06         |
| _max_obs        | 39           |
| _mean_act       | 0.058376     |
| _mean_adv       | -1.35e-17    |
| _mean_discrew   | 1.02         |
| _mean_obs       | 0.0022       |
| _min_adv        | -7.96        |
| _min_discrew    | 0.00675      |
| _min_obs        | -26          |
| _std_act        | 0.42285      |
| _std_adv        | 1            |
| _std_discrew    | 0.335        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.931       |
| ExplainedVarOld | 0.783       |
| KL              | 0.00202727  |
| Phi_loss        | 82.7749     |
| PolicyEntropy   | 15.2752     |
| PolicyLoss      | -0.00150497 |
| Steps           | 10048       |
| VarFuncLoss     | 0.0231      |
| _MeanReward     | 472         |
| _lr_multiplier  | 1           |
| _max_act        | 3.1954      |
| _max_adv        | 4.75        |
| _max_discrew    | 3.08        |
| _max_obs        | 38.3        |
| _mean_act       | 0.0591251   |
| _mean_adv       | 5.66e-18    |
| _mean_discrew   | 1.07        |
| _mean_obs       | 0.00195     |
| _min_adv        | -5.98       |
| _min_discrew    | 0.0104      |
| _min_obs        | -16.6       |
| _std_act        | 0.420653    |
| _std_adv        | 1           |
| _std_discrew    | 0.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.923       |
| ExplainedVarOld | 0.791       |
| KL              | 0.00183898  |
| Phi_loss        | 77.8873     |
| PolicyEntropy   | 15.2758     |
| PolicyLoss      | -0.00560662 |
| Steps           | 10033       |
| VarFuncLoss     | 0.0285      |
| _MeanReward     | 463         |
| _lr_multiplier  | 1           |
| _max_act        | 2.9638      |
| _max_adv        | 5.62        |
| _max_discrew    | 2.82        |
| _max_obs        | 27          |
| _mean_act       | 0.0585926   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00178     |
| _min_adv        | -4.87       |
| _min_discrew    | 0.0164      |
| _min_obs        | -44.9       |
| _std_act        | 0.423139    |
| _std_adv        | 1           |
| _std_discrew    | 0.366       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.915        |
| ExplainedVarOld | 0.763        |
| KL              | 0.00225326   |
| Phi_loss        | 65.2137      |
| PolicyEntropy   | 15.2769      |
| PolicyLoss      | -0.000192258 |
| Steps           | 10024        |
| VarFuncLoss     | 0.0311       |
| _MeanReward     | 455          |
| _lr_multiplier  | 1            |
| _max_act        | 2.90782      |
| _max_adv        | 4.17         |
| _max_discrew    | 2.76         |
| _max_obs        | 34.4         |
| _mean_act       | 0.0568445    |
| _mean_adv       | -5.67e-18    |
| _mean_discrew   | 1.04         |
| _mean_obs       | 0.00231      |
| _min_adv        | -5.7         |
| _min_discrew    | 0.012        |
| _min_obs        | -31          |
| _std_act        | 0.422322     |
| _std_adv        | 1            |
| _std_discrew    | 0.351        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.781       |
| KL              | 0.00178655  |
| Phi_loss        | 61.1965     |
| PolicyEntropy   | 15.2778     |
| PolicyLoss      | -0.00157673 |
| Steps           | 10084       |
| VarFuncLoss     | 0.0282      |
| _MeanReward     | 449         |
| _lr_multiplier  | 1           |
| _max_act        | 2.96237     |
| _max_adv        | 5.38        |
| _max_discrew    | 2.62        |
| _max_obs        | 51.5        |
| _mean_act       | 0.0581605   |
| _mean_adv       | -2.25e-17   |
| _mean_discrew   | 1.03        |
| _mean_obs       | 0.00251     |
| _min_adv        | -5.97       |
| _min_discrew    | 0.0169      |
| _min_obs        | -30.6       |
| _std_act        | 0.422669    |
| _std_adv        | 1           |
| _std_discrew    | 0.327       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.787       |
| KL              | 0.00239508  |
| Phi_loss        | 71.3523     |
| PolicyEntropy   | 15.2784     |
| PolicyLoss      | 7.53743e-06 |
| Steps           | 10093       |
| VarFuncLoss     | 0.024       |
| _MeanReward     | 477         |
| _lr_multiplier  | 1           |
| _max_act        | 3.21425     |
| _max_adv        | 3.48        |
| _max_discrew    | 2.72        |
| _max_obs        | 54.4        |
| _mean_act       | 0.0576453   |
| _mean_adv       | -2.96e-17   |
| _mean_discrew   | 1.09        |
| _mean_obs       | 0.00267     |
| _min_adv        | -4.75       |
| _min_discrew    | 0.0142      |
| _min_obs        | -36         |
| _std_act        | 0.424987    |
| _std_adv        | 1           |
| _std_discrew    | 0.376       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.924       |
| ExplainedVarOld | 0.791       |
| KL              | 0.00200157  |
| Phi_loss        | 76.7271     |
| PolicyEntropy   | 15.2794     |
| PolicyLoss      | -0.00327101 |
| Steps           | 10011       |
| VarFuncLoss     | 0.0286      |
| _MeanReward     | 457         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93461     |
| _max_adv        | 4.15        |
| _max_discrew    | 2.83        |
| _max_obs        | 30.3        |
| _mean_act       | 0.0573513   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00168     |
| _min_adv        | -6.87       |
| _min_discrew    | 0.0171      |
| _min_obs        | -16.9       |
| _std_act        | 0.423847    |
| _std_adv        | 1           |
| _std_discrew    | 0.361       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.92        |
| ExplainedVarOld | 0.773       |
| KL              | 0.00219233  |
| Phi_loss        | 65.0708     |
| PolicyEntropy   | 15.277      |
| PolicyLoss      | -0.00064612 |
| Steps           | 10011       |
| VarFuncLoss     | 0.0288      |
| _MeanReward     | 444         |
| _lr_multiplier  | 1           |
| _max_act        | 3.07497     |
| _max_adv        | 4.38        |
| _max_discrew    | 2.59        |
| _max_obs        | 53.2        |
| _mean_act       | 0.0597201   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.0026      |
| _min_adv        | -5.47       |
| _min_discrew    | 0.016       |
| _min_obs        | -25         |
| _std_act        | 0.426109    |
| _std_adv        | 1           |
| _std_discrew    | 0.336       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.8         |
| KL              | 0.00242582  |
| Phi_loss        | 91.6241     |
| PolicyEntropy   | 15.2745     |
| PolicyLoss      | -0.00389067 |
| Steps           | 10037       |
| VarFuncLoss     | 0.0263      |
| _MeanReward     | 464         |
| _lr_multiplier  | 1           |
| _max_act        | 2.85672     |
| _max_adv        | 4.57        |
| _max_discrew    | 2.69        |
| _max_obs        | 33.5        |
| _mean_act       | 0.0538315   |
| _mean_adv       | 9.91e-18    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00172     |
| _min_adv        | -7.8        |
| _min_discrew    | 0.0167      |
| _min_obs        | -28.9       |
| _std_act        | 0.425473    |
| _std_adv        | 1           |
| _std_discrew    | 0.368       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.74       |
| KL              | 0.00199862 |
| Phi_loss        | 80.0874    |
| PolicyEntropy   | 15.275     |
| PolicyLoss      | -0.0020719 |
| Steps           | 10062      |
| VarFuncLoss     | 0.0316     |
| _MeanReward     | 471        |
| _lr_multiplier  | 1          |
| _max_act        | 3.40287    |
| _max_adv        | 3.99       |
| _max_discrew    | 3.14       |
| _max_obs        | 61.9       |
| _mean_act       | 0.0544551  |
| _mean_adv       | -1.13e-17  |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.00294    |
| _min_adv        | -5.11      |
| _min_discrew    | 0.0165     |
| _min_obs        | -43.5      |
| _std_act        | 0.426554   |
| _std_adv        | 1          |
| _std_discrew    | 0.383      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.758       |
| KL              | 0.00200843  |
| Phi_loss        | 87.0984     |
| PolicyEntropy   | 15.2742     |
| PolicyLoss      | -0.00294401 |
| Steps           | 10030       |
| VarFuncLoss     | 0.0302      |
| _MeanReward     | 464         |
| _lr_multiplier  | 1           |
| _max_act        | 3.07687     |
| _max_adv        | 4.06        |
| _max_discrew    | 2.7         |
| _max_obs        | 60.4        |
| _mean_act       | 0.0585934   |
| _mean_adv       | 5.67e-18    |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00221     |
| _min_adv        | -5.46       |
| _min_discrew    | 0.0119      |
| _min_obs        | -32         |
| _std_act        | 0.424647    |
| _std_adv        | 1           |
| _std_discrew    | 0.366       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.912       |
| ExplainedVarOld | 0.74        |
| KL              | 0.00193858  |
| Phi_loss        | 85.9278     |
| PolicyEntropy   | 15.2723     |
| PolicyLoss      | 0.000974398 |
| Steps           | 10024       |
| VarFuncLoss     | 0.0321      |
| _MeanReward     | 455         |
| _lr_multiplier  | 1           |
| _max_act        | 3.6272      |
| _max_adv        | 4.93        |
| _max_discrew    | 3.28        |
| _max_obs        | 38.1        |
| _mean_act       | 0.0585784   |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00256     |
| _min_adv        | -5.7        |
| _min_discrew    | 0.0157      |
| _min_obs        | -21.1       |
| _std_act        | 0.427706    |
| _std_adv        | 1           |
| _std_discrew    | 0.391       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.701       |
| KL              | 0.00203134  |
| Phi_loss        | 77.0902     |
| PolicyEntropy   | 15.2705     |
| PolicyLoss      | -0.00380286 |
| Steps           | 10081       |
| VarFuncLoss     | 0.0326      |
| _MeanReward     | 463         |
| _lr_multiplier  | 1           |
| _max_act        | 3.72613     |
| _max_adv        | 4.36        |
| _max_discrew    | 2.87        |
| _max_obs        | 28.4        |
| _mean_act       | 0.0577243   |
| _mean_adv       | -1.41e-18   |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00256     |
| _min_adv        | -5.86       |
| _min_discrew    | 0.0125      |
| _min_obs        | -27.6       |
| _std_act        | 0.424883    |
| _std_adv        | 1           |
| _std_discrew    | 0.353       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.772      |
| KL              | 0.00207128 |
| Phi_loss        | 100.692    |
| PolicyEntropy   | 15.2702    |
| PolicyLoss      | 0.00466009 |
| Steps           | 10022      |
| VarFuncLoss     | 0.0275     |
| _MeanReward     | 457        |
| _lr_multiplier  | 1          |
| _max_act        | 3.0493     |
| _max_adv        | 4.93       |
| _max_discrew    | 2.78       |
| _max_obs        | 21.9       |
| _mean_act       | 0.0583144  |
| _mean_adv       | -8.51e-18  |
| _mean_discrew   | 1.03       |
| _mean_obs       | 0.00113    |
| _min_adv        | -5.27      |
| _min_discrew    | 0.0144     |
| _min_obs        | -21.6      |
| _std_act        | 0.426864   |
| _std_adv        | 1          |
| _std_discrew    | 0.336      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.818      |
| KL              | 0.00208952 |
| Phi_loss        | 111.478    |
| PolicyEntropy   | 15.2701    |
| PolicyLoss      | 0.00142931 |
| Steps           | 10017      |
| VarFuncLoss     | 0.0227     |
| _MeanReward     | 464        |
| _lr_multiplier  | 1          |
| _max_act        | 3.24037    |
| _max_adv        | 5.18       |
| _max_discrew    | 2.69       |
| _max_obs        | 26.8       |
| _mean_act       | 0.0560849  |
| _mean_adv       | 1.13e-17   |
| _mean_discrew   | 1.05       |
| _mean_obs       | 0.00197    |
| _min_adv        | -5.71      |
| _min_discrew    | 0.0142     |
| _min_obs        | -25.3      |
| _std_act        | 0.425981   |
| _std_adv        | 1          |
| _std_discrew    | 0.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.931      |
| ExplainedVarOld | 0.806      |
| KL              | 0.00223676 |
| Phi_loss        | 111.093    |
| PolicyEntropy   | 15.2707    |
| PolicyLoss      | -0.0040434 |
| Steps           | 10093      |
| VarFuncLoss     | 0.0243     |
| _MeanReward     | 461        |
| _lr_multiplier  | 1          |
| _max_act        | 3.19229    |
| _max_adv        | 4.3        |
| _max_discrew    | 2.9        |
| _max_obs        | 17.4       |
| _mean_act       | 0.0599127  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.00218    |
| _min_adv        | -5.6       |
| _min_discrew    | 0.0162     |
| _min_obs        | -19.4      |
| _std_act        | 0.425448   |
| _std_adv        | 1          |
| _std_discrew    | 0.361      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.787       |
| KL              | 0.00180669  |
| Phi_loss        | 100.887     |
| PolicyEntropy   | 15.2716     |
| PolicyLoss      | -0.00143532 |
| Steps           | 10073       |
| VarFuncLoss     | 0.0295      |
| _MeanReward     | 488         |
| _lr_multiplier  | 1           |
| _max_act        | 2.85621     |
| _max_adv        | 5.44        |
| _max_discrew    | 3.31        |
| _max_obs        | 31.3        |
| _mean_act       | 0.0597471   |
| _mean_adv       | 5.64e-18    |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.00271     |
| _min_adv        | -5.86       |
| _min_discrew    | 0.0151      |
| _min_obs        | -30.9       |
| _std_act        | 0.424299    |
| _std_adv        | 1           |
| _std_discrew    | 0.402       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.763       |
| KL              | 0.00171765  |
| Phi_loss        | 99.8801     |
| PolicyEntropy   | 15.2717     |
| PolicyLoss      | -0.00089271 |
| Steps           | 10022       |
| VarFuncLoss     | 0.0315      |
| _MeanReward     | 450         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87059     |
| _max_adv        | 3.84        |
| _max_discrew    | 3.05        |
| _max_obs        | 32          |
| _mean_act       | 0.0557965   |
| _mean_adv       | -1.13e-17   |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00199     |
| _min_adv        | -6.95       |
| _min_discrew    | 0.017       |
| _min_obs        | -23.7       |
| _std_act        | 0.424641    |
| _std_adv        | 1           |
| _std_discrew    | 0.376       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.735      |
| KL              | 0.00175133 |
| Phi_loss        | 88.5494    |
| PolicyEntropy   | 15.2701    |
| PolicyLoss      | 0.00103648 |
| Steps           | 10057      |
| VarFuncLoss     | 0.0332     |
| _MeanReward     | 490        |
| _lr_multiplier  | 1          |
| _max_act        | 3.4354     |
| _max_adv        | 4.31       |
| _max_discrew    | 2.93       |
| _max_obs        | 50.4       |
| _mean_act       | 0.0586131  |
| _mean_adv       | -5.65e-18  |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.00324    |
| _min_adv        | -5.87      |
| _min_discrew    | 0.0151     |
| _min_obs        | -39.3      |
| _std_act        | 0.424114   |
| _std_adv        | 1          |
| _std_discrew    | 0.419      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.716       |
| KL              | 0.00207647  |
| Phi_loss        | 98.9537     |
| PolicyEntropy   | 15.2687     |
| PolicyLoss      | 0.000356383 |
| Steps           | 10030       |
| VarFuncLoss     | 0.0401      |
| _MeanReward     | 478         |
| _lr_multiplier  | 1           |
| _max_act        | 3.24407     |
| _max_adv        | 5.27        |
| _max_discrew    | 2.92        |
| _max_obs        | 23          |
| _mean_act       | 0.0582952   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.08        |
| _mean_obs       | 0.00116     |
| _min_adv        | -4.78       |
| _min_discrew    | 0.0164      |
| _min_obs        | -27.4       |
| _std_act        | 0.426286    |
| _std_adv        | 1           |
| _std_discrew    | 0.386       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.926       |
| ExplainedVarOld | 0.773       |
| KL              | 0.00171039  |
| Phi_loss        | 97.4072     |
| PolicyEntropy   | 15.2677     |
| PolicyLoss      | 0.000551097 |
| Steps           | 10024       |
| VarFuncLoss     | 0.0288      |
| _MeanReward     | 461         |
| _lr_multiplier  | 1           |
| _max_act        | 3.07202     |
| _max_adv        | 3.7         |
| _max_discrew    | 2.75        |
| _max_obs        | 23.9        |
| _mean_act       | 0.0584037   |
| _mean_adv       | -1.98e-17   |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00143     |
| _min_adv        | -5.01       |
| _min_discrew    | 0.000334    |
| _min_obs        | -19.3       |
| _std_act        | 0.426557    |
| _std_adv        | 1           |
| _std_discrew    | 0.366       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.753       |
| KL              | 0.00188503  |
| Phi_loss        | 103.087     |
| PolicyEntropy   | 15.2678     |
| PolicyLoss      | -0.00537623 |
| Steps           | 10018       |
| VarFuncLoss     | 0.0301      |
| _MeanReward     | 467         |
| _lr_multiplier  | 1           |
| _max_act        | 2.9475      |
| _max_adv        | 5.26        |
| _max_discrew    | 2.9         |
| _max_obs        | 64.7        |
| _mean_act       | 0.0579889   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00198     |
| _min_adv        | -5.95       |
| _min_discrew    | 0.015       |
| _min_obs        | -29.2       |
| _std_act        | 0.428699    |
| _std_adv        | 1           |
| _std_discrew    | 0.367       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.79       |
| KL              | 0.00480079 |
| Phi_loss        | 27375.8    |
| PolicyEntropy   | 15.2617    |
| PolicyLoss      | 0.0478632  |
| Steps           | 10003      |
| VarFuncLoss     | 0.0286     |
| _MeanReward     | 466        |
| _lr_multiplier  | 1          |
| _max_act        | 2.82233    |
| _max_adv        | 4.96       |
| _max_discrew    | 2.98       |
| _max_obs        | 24.4       |
| _mean_act       | 0.0593593  |
| _mean_adv       | 6.39e-18   |
| _mean_discrew   | 1.07       |
| _mean_obs       | 0.00238    |
| _min_adv        | -4.48      |
| _min_discrew    | 0.0155     |
| _min_obs        | -24.1      |
| _std_act        | 0.427553   |
| _std_adv        | 1          |
| _std_discrew    | 0.377      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.92         |
| ExplainedVarOld | 0.789        |
| KL              | 0.00327662   |
| Phi_loss        | 73.0494      |
| PolicyEntropy   | 15.2497      |
| PolicyLoss      | -0.000946441 |
| Steps           | 10081        |
| VarFuncLoss     | 0.0299       |
| _MeanReward     | 461          |
| _lr_multiplier  | 1            |
| _max_act        | 3.38613      |
| _max_adv        | 4.43         |
| _max_discrew    | 2.91         |
| _max_obs        | 37.7         |
| _mean_act       | 0.0561528    |
| _mean_adv       | -1.41e-18    |
| _mean_discrew   | 1.05         |
| _mean_obs       | 0.00201      |
| _min_adv        | -6.38        |
| _min_discrew    | 0.0153       |
| _min_obs        | -35.7        |
| _std_act        | 0.429068     |
| _std_adv        | 1            |
| _std_discrew    | 0.364        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.914       |
| ExplainedVarOld | 0.761       |
| KL              | 0.00239661  |
| Phi_loss        | 81.807      |
| PolicyEntropy   | 15.2516     |
| PolicyLoss      | -0.00631883 |
| Steps           | 10056       |
| VarFuncLoss     | 0.0312      |
| _MeanReward     | 459         |
| _lr_multiplier  | 1           |
| _max_act        | 2.8769      |
| _max_adv        | 4.2         |
| _max_discrew    | 2.69        |
| _max_obs        | 39.6        |
| _mean_act       | 0.0562913   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00279     |
| _min_adv        | -5.01       |
| _min_discrew    | 0.0152      |
| _min_obs        | -24.8       |
| _std_act        | 0.427723    |
| _std_adv        | 1           |
| _std_discrew    | 0.353       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.73       |
| KL              | 0.00274417 |
| Phi_loss        | 1387.21    |
| PolicyEntropy   | 15.2503    |
| PolicyLoss      | -0.12113   |
| Steps           | 10051      |
| VarFuncLoss     | 0.0304     |
| _MeanReward     | 501        |
| _lr_multiplier  | 1          |
| _max_act        | 3.15442    |
| _max_adv        | 4.59       |
| _max_discrew    | 3.07       |
| _max_obs        | 53.5       |
| _mean_act       | 0.0580609  |
| _mean_adv       | 1.41e-17   |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.00248    |
| _min_adv        | -4.82      |
| _min_discrew    | 0.0164     |
| _min_obs        | -41.9      |
| _std_act        | 0.429886   |
| _std_adv        | 1          |
| _std_discrew    | 0.426      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.912       |
| ExplainedVarOld | 0.734       |
| KL              | 0.00403594  |
| Phi_loss        | 108.576     |
| PolicyEntropy   | 15.2496     |
| PolicyLoss      | -0.00672512 |
| Steps           | 10117       |
| VarFuncLoss     | 0.0379      |
| _MeanReward     | 472         |
| _lr_multiplier  | 1           |
| _max_act        | 2.89757     |
| _max_adv        | 4.06        |
| _max_discrew    | 2.76        |
| _max_obs        | 52.9        |
| _mean_act       | 0.0584608   |
| _mean_adv       | 3.37e-17    |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00155     |
| _min_adv        | -5.42       |
| _min_discrew    | 0.0146      |
| _min_obs        | -29.2       |
| _std_act        | 0.427817    |
| _std_adv        | 1           |
| _std_discrew    | 0.357       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.912       |
| ExplainedVarOld | 0.779       |
| KL              | 0.00248914  |
| Phi_loss        | 102.624     |
| PolicyEntropy   | 15.2501     |
| PolicyLoss      | -0.00252665 |
| Steps           | 10067       |
| VarFuncLoss     | 0.0314      |
| _MeanReward     | 465         |
| _lr_multiplier  | 1           |
| _max_act        | 2.93408     |
| _max_adv        | 4.55        |
| _max_discrew    | 2.85        |
| _max_obs        | 26.2        |
| _mean_act       | 0.0574803   |
| _mean_adv       | -2.26e-17   |
| _mean_discrew   | 1.06        |
| _mean_obs       | 0.00306     |
| _min_adv        | -5.59       |
| _min_discrew    | 0.0162      |
| _min_obs        | -19         |
| _std_act        | 0.429537    |
| _std_adv        | 1           |
| _std_discrew    | 0.364       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.904       |
| ExplainedVarOld | 0.756       |
| KL              | 0.00172594  |
| Phi_loss        | 98.2682     |
| PolicyEntropy   | 15.2495     |
| PolicyLoss      | -0.00278883 |
| Steps           | 10100       |
| VarFuncLoss     | 0.0351      |
| _MeanReward     | 515         |
| _lr_multiplier  | 1           |
| _max_act        | 2.91933     |
| _max_adv        | 4.06        |
| _max_discrew    | 3.35        |
| _max_obs        | 27.3        |
| _mean_act       | 0.0576497   |
| _mean_adv       | -2.25e-17   |
| _mean_discrew   | 1.18        |
| _mean_obs       | 0.0032      |
| _min_adv        | -4.1        |
| _min_discrew    | 0.0171      |
| _min_obs        | -22.1       |
| _std_act        | 0.427449    |
| _std_adv        | 1           |
| _std_discrew    | 0.467       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.707      |
| KL              | 0.00217101 |
| Phi_loss        | 213.347    |
| PolicyEntropy   | 15.2484    |
| PolicyLoss      | 0.00262213 |
| Steps           | 10176      |
| VarFuncLoss     | 0.0363     |
| _MeanReward     | 457        |
| _lr_multiplier  | 1          |
| _max_act        | 3.11409    |
| _max_adv        | 4.84       |
| _max_discrew    | 2.94       |
| _max_obs        | 40.5       |
| _mean_act       | 0.0583807  |
| _mean_adv       | 1.68e-17   |
| _mean_discrew   | 1.05       |
| _mean_obs       | 0.00252    |
| _min_adv        | -6.74      |
| _min_discrew    | 0.0161     |
| _min_obs        | -32.5      |
| _std_act        | 0.428352   |
| _std_adv        | 1          |
| _std_discrew    | 0.356      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.921       |
| ExplainedVarOld | 0.777       |
| KL              | 0.00222664  |
| Phi_loss        | 114.361     |
| PolicyEntropy   | 15.2457     |
| PolicyLoss      | -0.00131822 |
| Steps           | 10055       |
| VarFuncLoss     | 0.028       |
| _MeanReward     | 479         |
| _lr_multiplier  | 1           |
| _max_act        | 3.16567     |
| _max_adv        | 4.35        |
| _max_discrew    | 3.24        |
| _max_obs        | 18.9        |
| _mean_act       | 0.0593444   |
| _mean_adv       | -1.84e-17   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.00211     |
| _min_adv        | -7.09       |
| _min_discrew    | 0.0169      |
| _min_obs        | -22.9       |
| _std_act        | 0.426625    |
| _std_adv        | 1           |
| _std_discrew    | 0.426       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.903       |
| ExplainedVarOld | 0.702       |
| KL              | 0.0018902   |
| Phi_loss        | 106.477     |
| PolicyEntropy   | 15.246      |
| PolicyLoss      | -0.00387474 |
| Steps           | 10036       |
| VarFuncLoss     | 0.0414      |
| _MeanReward     | 486         |
| _lr_multiplier  | 1           |
| _max_act        | 3.06934     |
| _max_adv        | 4.31        |
| _max_discrew    | 2.97        |
| _max_obs        | 28.1        |
| _mean_act       | 0.0611896   |
| _mean_adv       | -6.37e-18   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.00228     |
| _min_adv        | -5.86       |
| _min_discrew    | 0.00663     |
| _min_obs        | -24.2       |
| _std_act        | 0.427086    |
| _std_adv        | 1           |
| _std_discrew    | 0.415       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.731      |
| KL              | 0.00199874 |
| Phi_loss        | 99.3602    |
| PolicyEntropy   | 15.2476    |
| PolicyLoss      | -0.0016543 |
| Steps           | 10001      |
| VarFuncLoss     | 0.0381     |
| _MeanReward     | 464        |
| _lr_multiplier  | 1          |
| _max_act        | 3.09787    |
| _max_adv        | 4.76       |
| _max_discrew    | 2.91       |
| _max_obs        | 30.6       |
| _mean_act       | 0.059881   |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.07       |
| _mean_obs       | 0.00263    |
| _min_adv        | -6.17      |
| _min_discrew    | 0.0173     |
| _min_obs        | -48.5      |
| _std_act        | 0.425975   |
| _std_adv        | 1          |
| _std_discrew    | 0.387      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.898       |
| ExplainedVarOld | 0.738       |
| KL              | 0.00165044  |
| Phi_loss        | 99.4916     |
| PolicyEntropy   | 15.2466     |
| PolicyLoss      | 0.000340884 |
| Steps           | 10035       |
| VarFuncLoss     | 0.0396      |
| _MeanReward     | 459         |
| _lr_multiplier  | 1           |
| _max_act        | 3.17695     |
| _max_adv        | 6.06        |
| _max_discrew    | 2.81        |
| _max_obs        | 34.8        |
| _mean_act       | 0.058649    |
| _mean_adv       | 2.55e-17    |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.00242     |
| _min_adv        | -5.59       |
| _min_discrew    | 0.0172      |
| _min_obs        | -41.8       |
| _std_act        | 0.42947     |
| _std_adv        | 1           |
| _std_discrew    | 0.349       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.773       |
| KL              | 0.00188381  |
| Phi_loss        | 106.252     |
| PolicyEntropy   | 15.244      |
| PolicyLoss      | -0.00074568 |
| Steps           | 10048       |
| VarFuncLoss     | 0.0294      |
| _MeanReward     | 473         |
| _lr_multiplier  | 1           |
| _max_act        | 3.07076     |
| _max_adv        | 4.02        |
| _max_discrew    | 3.03        |
| _max_obs        | 32.6        |
| _mean_act       | 0.0583659   |
| _mean_adv       | -1.7e-17    |
| _mean_discrew   | 1.07        |
| _mean_obs       | 0.00168     |
| _min_adv        | -6.18       |
| _min_discrew    | 0.0113      |
| _min_obs        | -33.1       |
| _std_act        | 0.428076    |
| _std_adv        | 1           |
| _std_discrew    | 0.384       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.746      |
| KL              | 0.00198346 |
| Phi_loss        | 100.605    |
| PolicyEntropy   | 15.2404    |
| PolicyLoss      | 0.00244768 |
| Steps           | 10034      |
| VarFuncLoss     | 0.0348     |
| _MeanReward     | 483        |
| _lr_multiplier  | 1          |
| _max_act        | 2.8079     |
| _max_adv        | 3.59       |
| _max_discrew    | 2.8        |
| _max_obs        | 20.7       |
| _mean_act       | 0.0603532  |
| _mean_adv       | -2.83e-18  |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.00174    |
| _min_adv        | -6.82      |
| _min_discrew    | 0.0162     |
| _min_obs        | -20.1      |
| _std_act        | 0.426693   |
| _std_adv        | 1          |
| _std_discrew    | 0.378      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.918       |
| ExplainedVarOld | 0.81        |
| KL              | 0.00208012  |
| Phi_loss        | 103.173     |
| PolicyEntropy   | 15.2356     |
| PolicyLoss      | -0.00264726 |
| Steps           | 10042       |
| VarFuncLoss     | 0.0309      |
| _MeanReward     | 479         |
| _lr_multiplier  | 1           |
| _max_act        | 3.20115     |
| _max_adv        | 4.49        |
| _max_discrew    | 3.62        |
| _max_obs        | 259         |
| _mean_act       | 0.062774    |
| _mean_adv       | -9.91e-18   |
| _mean_discrew   | 1.12        |
| _mean_obs       | 0.0026      |
| _min_adv        | -7.01       |
| _min_discrew    | 0.0115      |
| _min_obs        | -166        |
| _std_act        | 0.431239    |
| _std_adv        | 1           |
| _std_discrew    | 0.453       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.907       |
| ExplainedVarOld | 0.701       |
| KL              | 0.00230441  |
| Phi_loss        | 88.0467     |
| PolicyEntropy   | 15.2356     |
| PolicyLoss      | -0.00142032 |
| Steps           | 10076       |
| VarFuncLoss     | 0.0423      |
| _MeanReward     | 494         |
| _lr_multiplier  | 1           |
| _max_act        | 3.38887     |
| _max_adv        | 5.09        |
| _max_discrew    | 3.14        |
| _max_obs        | 26.4        |
| _mean_act       | 0.0666345   |
| _mean_adv       | 0           |
| _mean_discrew   | 1.12        |
| _mean_obs       | 0.00228     |
| _min_adv        | -5.74       |
| _min_discrew    | 0.0105      |
| _min_obs        | -23.3       |
| _std_act        | 0.427821    |
| _std_adv        | 1           |
| _std_discrew    | 0.426       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.908       |
| ExplainedVarOld | 0.754       |
| KL              | 0.00231516  |
| Phi_loss        | 167.019     |
| PolicyEntropy   | 15.2358     |
| PolicyLoss      | -0.00274568 |
| Steps           | 10064       |
| VarFuncLoss     | 0.0394      |
| _MeanReward     | 486         |
| _lr_multiplier  | 1           |
| _max_act        | 2.82632     |
| _max_adv        | 4.14        |
| _max_discrew    | 3.05        |
| _max_obs        | 41.3        |
| _mean_act       | 0.0612093   |
| _mean_adv       | 4.94e-18    |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.00211     |
| _min_adv        | -5.54       |
| _min_discrew    | 0.00391     |
| _min_obs        | -42.4       |
| _std_act        | 0.427469    |
| _std_adv        | 1           |
| _std_discrew    | 0.4         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.751      |
| KL              | 0.00187566 |
| Phi_loss        | 100.202    |
| PolicyEntropy   | 15.2344    |
| PolicyLoss      | 0.00184921 |
| Steps           | 10062      |
| VarFuncLoss     | 0.0367     |
| _MeanReward     | 480        |
| _lr_multiplier  | 1          |
| _max_act        | 3.05142    |
| _max_adv        | 4.25       |
| _max_discrew    | 2.84       |
| _max_obs        | 36.9       |
| _mean_act       | 0.0597861  |
| _mean_adv       | -2.54e-17  |
| _mean_discrew   | 1.1        |
| _mean_obs       | 0.00205    |
| _min_adv        | -5.16      |
| _min_discrew    | 0.0175     |
| _min_obs        | -35.5      |
| _std_act        | 0.433481   |
| _std_adv        | 1          |
| _std_discrew    | 0.383      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.908       |
| ExplainedVarOld | 0.765       |
| KL              | 0.0023067   |
| Phi_loss        | 101.561     |
| PolicyEntropy   | 15.2338     |
| PolicyLoss      | 0.000759748 |
| Steps           | 10055       |
| VarFuncLoss     | 0.0352      |
| _MeanReward     | 485         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19422     |
| _max_adv        | 4.95        |
| _max_discrew    | 2.83        |
| _max_obs        | 36.1        |
| _mean_act       | 0.0621675   |
| _mean_adv       | 1.13e-17    |
| _mean_discrew   | 1.09        |
| _mean_obs       | 0.00174     |
| _min_adv        | -6.19       |
| _min_discrew    | 0.0154      |
| _min_obs        | -25.5       |
| _std_act        | 0.428385    |
| _std_adv        | 1           |
| _std_discrew    | 0.392       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
