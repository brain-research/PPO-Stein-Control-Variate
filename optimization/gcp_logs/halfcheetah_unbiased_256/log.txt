Logging to halfcheetah_unbiased_256
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
----------------------------
| Steps         | 10000    |
| _MeanReward   | -225     |
| _max_act      | 2.56595  |
| _max_adv      | 3.45     |
| _max_discrew  | 0.106    |
| _max_obs      | 1.4      |
| _mean_act     | 0.019536 |
| _mean_adv     | 1.14e-17 |
| _mean_discrew | -0.185   |
| _mean_obs     | 0.024    |
| _min_adv      | -3.56    |
| _min_discrew  | -0.545   |
| _min_obs      | -1.39    |
| _std_act      | 0.41507  |
| _std_adv      | 1        |
| _std_discrew  | 0.0131   |
----------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.26        |
| ExplainedVarOld | -2.24       |
| KL              | 0.000178622 |
| Phi_loss        | 4.31067     |
| PolicyEntropy   | 5.51991     |
| PolicyLoss      | -0.00840474 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00966     |
| _MeanReward     | -272        |
| _lr_multiplier  | 1           |
| _max_act        | 2.86827     |
| _max_adv        | 4.17        |
| _max_discrew    | 0.087       |
| _max_obs        | 1.52        |
| _mean_act       | -0.00967049 |
| _mean_adv       | -4.26e-17   |
| _mean_discrew   | -0.212      |
| _mean_obs       | 0.017       |
| _min_adv        | -3.99       |
| _min_discrew    | -0.491      |
| _min_obs        | -1.39       |
| _std_act        | 0.410211    |
| _std_adv        | 1           |
| _std_discrew    | 0.0108      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.248       |
| ExplainedVarOld | 0.217       |
| KL              | 0.000611074 |
| Phi_loss        | 24.1772     |
| PolicyEntropy   | 5.51494     |
| PolicyLoss      | 0.00329951  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00811     |
| _MeanReward     | -265        |
| _lr_multiplier  | 1           |
| _max_act        | 2.4126      |
| _max_adv        | 4.16        |
| _max_discrew    | 0.0568      |
| _max_obs        | 1.32        |
| _mean_act       | -0.0261549  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | -0.214      |
| _mean_obs       | 0.0225      |
| _min_adv        | -4.16       |
| _min_discrew    | -0.53       |
| _min_obs        | -1.31       |
| _std_act        | 0.408137    |
| _std_adv        | 1           |
| _std_discrew    | 0.0112      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.331       |
| ExplainedVarOld | 0.247       |
| KL              | 0.000929663 |
| Phi_loss        | 19.4336     |
| PolicyEntropy   | 5.51254     |
| PolicyLoss      | -0.00139232 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00746     |
| _MeanReward     | -245        |
| _lr_multiplier  | 1           |
| _max_act        | 3.09097     |
| _max_adv        | 3.78        |
| _max_discrew    | 0.089       |
| _max_obs        | 1.33        |
| _mean_act       | -0.0210035  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.202      |
| _mean_obs       | 0.0237      |
| _min_adv        | -5.33       |
| _min_discrew    | -0.519      |
| _min_obs        | -1.42       |
| _std_act        | 0.414197    |
| _std_adv        | 1           |
| _std_discrew    | 0.0128      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.213       |
| ExplainedVarOld | 0.175       |
| KL              | 0.00244194  |
| Phi_loss        | 17.8865     |
| PolicyEntropy   | 5.51173     |
| PolicyLoss      | 0.000420383 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0101      |
| _MeanReward     | -236        |
| _lr_multiplier  | 1           |
| _max_act        | 2.83165     |
| _max_adv        | 3.41        |
| _max_discrew    | 0.0983      |
| _max_obs        | 1.28        |
| _mean_act       | -0.0111584  |
| _mean_adv       | -4.41e-17   |
| _mean_discrew   | -0.188      |
| _mean_obs       | 0.0289      |
| _min_adv        | -4          |
| _min_discrew    | -0.485      |
| _min_obs        | -1.34       |
| _std_act        | 0.414493    |
| _std_adv        | 1           |
| _std_discrew    | 0.00981     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.237      |
| ExplainedVarOld | 0.183      |
| KL              | 0.00290665 |
| Phi_loss        | 18.4257    |
| PolicyEntropy   | 5.50132    |
| PolicyLoss      | 0.00165887 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00749    |
| _MeanReward     | -221       |
| _lr_multiplier  | 1          |
| _max_act        | 2.80331    |
| _max_adv        | 4.02       |
| _max_discrew    | 0.0661     |
| _max_obs        | 1.4        |
| _mean_act       | -0.0179816 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | -0.186     |
| _mean_obs       | 0.031      |
| _min_adv        | -4.53      |
| _min_discrew    | -0.626     |
| _min_obs        | -1.62      |
| _std_act        | 0.410137   |
| _std_adv        | 1          |
| _std_discrew    | 0.0141     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.289       |
| ExplainedVarOld | 0.264       |
| KL              | 0.00249212  |
| Phi_loss        | 17.6203     |
| PolicyEntropy   | 5.47975     |
| PolicyLoss      | 0.00288478  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0101      |
| _MeanReward     | -197        |
| _lr_multiplier  | 1           |
| _max_act        | 3.39279     |
| _max_adv        | 4.1         |
| _max_discrew    | 0.171       |
| _max_obs        | 1.42        |
| _mean_act       | -0.00217482 |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | -0.163      |
| _mean_obs       | 0.0289      |
| _min_adv        | -3.56       |
| _min_discrew    | -0.513      |
| _min_obs        | -1.18       |
| _std_act        | 0.403731    |
| _std_adv        | 1           |
| _std_discrew    | 0.0156      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.259      |
| ExplainedVarOld | 0.244      |
| KL              | 0.00275254 |
| Phi_loss        | 19.3893    |
| PolicyEntropy   | 5.46813    |
| PolicyLoss      | 0.00309216 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0116     |
| _MeanReward     | -210       |
| _lr_multiplier  | 1          |
| _max_act        | 2.8069     |
| _max_adv        | 3.96       |
| _max_discrew    | 0.0944     |
| _max_obs        | 1.33       |
| _mean_act       | -0.0140408 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | -0.174     |
| _mean_obs       | 0.0312     |
| _min_adv        | -4.67      |
| _min_discrew    | -0.56      |
| _min_obs        | -1.6       |
| _std_act        | 0.410373   |
| _std_adv        | 1          |
| _std_discrew    | 0.00864    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.276      |
| ExplainedVarOld | 0.201      |
| KL              | 0.00230386 |
| Phi_loss        | 16.7928    |
| PolicyEntropy   | 5.45451    |
| PolicyLoss      | 0.00414151 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00629    |
| _MeanReward     | -232       |
| _lr_multiplier  | 1          |
| _max_act        | 2.579      |
| _max_adv        | 4.14       |
| _max_discrew    | 0.0169     |
| _max_obs        | 1.32       |
| _mean_act       | -0.0150442 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | -0.193     |
| _mean_obs       | 0.0284     |
| _min_adv        | -4.05      |
| _min_discrew    | -0.499     |
| _min_obs        | -1.29      |
| _std_act        | 0.403249   |
| _std_adv        | 1          |
| _std_discrew    | 0.00863    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.379      |
| ExplainedVarOld | 0.339      |
| KL              | 0.00244078 |
| Phi_loss        | 17.5642    |
| PolicyEntropy   | 5.4385     |
| PolicyLoss      | 0.00366371 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00554    |
| _MeanReward     | -202       |
| _lr_multiplier  | 1          |
| _max_act        | 2.64687    |
| _max_adv        | 3.5        |
| _max_discrew    | 0.0861     |
| _max_obs        | 1.51       |
| _mean_act       | -0.0170019 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | -0.17      |
| _mean_obs       | 0.0353     |
| _min_adv        | -5.44      |
| _min_discrew    | -0.457     |
| _min_obs        | -1.38      |
| _std_act        | 0.407666   |
| _std_adv        | 1          |
| _std_discrew    | 0.00897    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.404      |
| ExplainedVarOld | 0.368      |
| KL              | 0.00295855 |
| Phi_loss        | 18.6588    |
| PolicyEntropy   | 5.42545    |
| PolicyLoss      | 0.00458404 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00553    |
| _MeanReward     | -154       |
| _lr_multiplier  | 1          |
| _max_act        | 2.6183     |
| _max_adv        | 4.26       |
| _max_discrew    | 0.206      |
| _max_obs        | 1.51       |
| _mean_act       | -0.035315  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | -0.132     |
| _mean_obs       | 0.0329     |
| _min_adv        | -4.61      |
| _min_discrew    | -0.332     |
| _min_obs        | -1.34      |
| _std_act        | 0.402239   |
| _std_adv        | 1          |
| _std_discrew    | 0.00883    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.566       |
| ExplainedVarOld | 0.508       |
| KL              | 0.00185856  |
| Phi_loss        | 15.7107     |
| PolicyEntropy   | 5.41562     |
| PolicyLoss      | 0.00232009  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00447     |
| _MeanReward     | -192        |
| _lr_multiplier  | 1           |
| _max_act        | 2.5843      |
| _max_adv        | 4.86        |
| _max_discrew    | 0.127       |
| _max_obs        | 1.52        |
| _mean_act       | -0.00983228 |
| _mean_adv       | 0           |
| _mean_discrew   | -0.157      |
| _mean_obs       | 0.0299      |
| _min_adv        | -4.93       |
| _min_discrew    | -0.365      |
| _min_obs        | -1.4        |
| _std_act        | 0.401607    |
| _std_adv        | 1           |
| _std_discrew    | 0.00781     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.338       |
| ExplainedVarOld | 0.298       |
| KL              | 0.00284031  |
| Phi_loss        | 18.4157     |
| PolicyEntropy   | 5.42298     |
| PolicyLoss      | 0.000133764 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00559     |
| _MeanReward     | -166        |
| _lr_multiplier  | 1           |
| _max_act        | 2.5297      |
| _max_adv        | 3.85        |
| _max_discrew    | 0.0811      |
| _max_obs        | 1.35        |
| _mean_act       | -0.0301593  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | -0.139      |
| _mean_obs       | 0.0342      |
| _min_adv        | -4.75       |
| _min_discrew    | -0.32       |
| _min_obs        | -1.43       |
| _std_act        | 0.406739    |
| _std_adv        | 1           |
| _std_discrew    | 0.00622     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.468       |
| ExplainedVarOld | 0.452       |
| KL              | 0.00218736  |
| Phi_loss        | 16.5301     |
| PolicyEntropy   | 5.40078     |
| PolicyLoss      | 0.00540646  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00361     |
| _MeanReward     | -136        |
| _lr_multiplier  | 1           |
| _max_act        | 2.91908     |
| _max_adv        | 4.34        |
| _max_discrew    | 0.209       |
| _max_obs        | 1.35        |
| _mean_act       | -0.00598217 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.107      |
| _mean_obs       | 0.0381      |
| _min_adv        | -4.76       |
| _min_discrew    | -0.437      |
| _min_obs        | -1.31       |
| _std_act        | 0.405014    |
| _std_adv        | 1           |
| _std_discrew    | 0.00938     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.384      |
| ExplainedVarOld | 0.337      |
| KL              | 0.00308963 |
| Phi_loss        | 17.3641    |
| PolicyEntropy   | 5.38513    |
| PolicyLoss      | 0.0012439  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00579    |
| _MeanReward     | -142       |
| _lr_multiplier  | 1          |
| _max_act        | 2.64964    |
| _max_adv        | 4          |
| _max_discrew    | 0.104      |
| _max_obs        | 1.48       |
| _mean_act       | -0.020852  |
| _mean_adv       | 0          |
| _mean_discrew   | -0.12      |
| _mean_obs       | 0.036      |
| _min_adv        | -4.41      |
| _min_discrew    | -0.41      |
| _min_obs        | -1.28      |
| _std_act        | 0.397596   |
| _std_adv        | 1          |
| _std_discrew    | 0.00891    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.429       |
| ExplainedVarOld | 0.406       |
| KL              | 0.00352442  |
| Phi_loss        | 17.0007     |
| PolicyEntropy   | 5.38356     |
| PolicyLoss      | 0.00490692  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00515     |
| _MeanReward     | -137        |
| _lr_multiplier  | 1           |
| _max_act        | 2.8285      |
| _max_adv        | 3.94        |
| _max_discrew    | 0.103       |
| _max_obs        | 1.28        |
| _mean_act       | -0.00365892 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | -0.114      |
| _mean_obs       | 0.0371      |
| _min_adv        | -4.14       |
| _min_discrew    | -0.414      |
| _min_obs        | -1.41       |
| _std_act        | 0.399038    |
| _std_adv        | 1           |
| _std_discrew    | 0.0069      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.38       |
| ExplainedVarOld | 0.338      |
| KL              | 0.00292319 |
| Phi_loss        | 19.129     |
| PolicyEntropy   | 5.3833     |
| PolicyLoss      | 0.00184533 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00439    |
| _MeanReward     | -111       |
| _lr_multiplier  | 1          |
| _max_act        | 2.51559    |
| _max_adv        | 5.09       |
| _max_discrew    | 0.298      |
| _max_obs        | 1.42       |
| _mean_act       | -0.0103501 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | -0.0886    |
| _mean_obs       | 0.0311     |
| _min_adv        | -3.76      |
| _min_discrew    | -0.351     |
| _min_obs        | -1.36      |
| _std_act        | 0.403063   |
| _std_adv        | 1          |
| _std_discrew    | 0.0104     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.362      |
| ExplainedVarOld | 0.293      |
| KL              | 0.00447056 |
| Phi_loss        | 19.5       |
| PolicyEntropy   | 5.36183    |
| PolicyLoss      | 0.00532025 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00686    |
| _MeanReward     | -116       |
| _lr_multiplier  | 1          |
| _max_act        | 2.88862    |
| _max_adv        | 3.68       |
| _max_discrew    | 0.154      |
| _max_obs        | 1.31       |
| _mean_act       | -0.0116577 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | -0.0998    |
| _mean_obs       | 0.034      |
| _min_adv        | -4.24      |
| _min_discrew    | -0.338     |
| _min_obs        | -1.35      |
| _std_act        | 0.396216   |
| _std_adv        | 1          |
| _std_discrew    | 0.00765    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.276        |
| ExplainedVarOld | 0.267        |
| KL              | 0.00317209   |
| Phi_loss        | 21.9081      |
| PolicyEntropy   | 5.31717      |
| PolicyLoss      | 0.0113676    |
| Steps           | 10000        |
| VarFuncLoss     | 0.00555      |
| _MeanReward     | -80.7        |
| _lr_multiplier  | 1            |
| _max_act        | 2.66576      |
| _max_adv        | 3.1          |
| _max_discrew    | 0.227        |
| _max_obs        | 1.31         |
| _mean_act       | -0.000963617 |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | -0.0537      |
| _mean_obs       | 0.033        |
| _min_adv        | -4.18        |
| _min_discrew    | -0.366       |
| _min_obs        | -1.24        |
| _std_act        | 0.386114     |
| _std_adv        | 1            |
| _std_discrew    | 0.00926      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.19        |
| ExplainedVarOld | 0.124       |
| KL              | 0.0046186   |
| Phi_loss        | 20.3939     |
| PolicyEntropy   | 5.29001     |
| PolicyLoss      | 0.00619432  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0079      |
| _MeanReward     | -65.7       |
| _lr_multiplier  | 1           |
| _max_act        | 2.86547     |
| _max_adv        | 4.47        |
| _max_discrew    | 0.246       |
| _max_obs        | 1.29        |
| _mean_act       | -0.00935492 |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | -0.0456     |
| _mean_obs       | 0.0346      |
| _min_adv        | -4.21       |
| _min_discrew    | -0.292      |
| _min_obs        | -1.31       |
| _std_act        | 0.387717    |
| _std_adv        | 1           |
| _std_discrew    | 0.0067      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.335        |
| ExplainedVarOld | 0.265        |
| KL              | 0.00309587   |
| Phi_loss        | 20.7858      |
| PolicyEntropy   | 5.26409      |
| PolicyLoss      | 0.003222     |
| Steps           | 10000        |
| VarFuncLoss     | 0.00449      |
| _MeanReward     | -42.2        |
| _lr_multiplier  | 1            |
| _max_act        | 2.56405      |
| _max_adv        | 4.91         |
| _max_discrew    | 0.22         |
| _max_obs        | 1.41         |
| _mean_act       | -0.000523843 |
| _mean_adv       | -1.71e-17    |
| _mean_discrew   | -0.0417      |
| _mean_obs       | 0.037        |
| _min_adv        | -4.73        |
| _min_discrew    | -0.27        |
| _min_obs        | -1.32        |
| _std_act        | 0.390684     |
| _std_adv        | 1            |
| _std_discrew    | 0.00631      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.17        |
| ExplainedVarOld | 0.114       |
| KL              | 0.00340574  |
| Phi_loss        | 20.902      |
| PolicyEntropy   | 5.24483     |
| PolicyLoss      | 0.00315412  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00524     |
| _MeanReward     | -40         |
| _lr_multiplier  | 1           |
| _max_act        | 2.81299     |
| _max_adv        | 3.38        |
| _max_discrew    | 0.194       |
| _max_obs        | 1.5         |
| _mean_act       | -0.00561825 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.0262     |
| _mean_obs       | 0.039       |
| _min_adv        | -5.48       |
| _min_discrew    | -0.317      |
| _min_obs        | -1.21       |
| _std_act        | 0.388086    |
| _std_adv        | 1           |
| _std_discrew    | 0.00627     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.132       |
| ExplainedVarOld | 0.134       |
| KL              | 0.00360036  |
| Phi_loss        | 20.8892     |
| PolicyEntropy   | 5.24104     |
| PolicyLoss      | -0.00103467 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00564     |
| _MeanReward     | 9.05        |
| _lr_multiplier  | 1           |
| _max_act        | 2.77865     |
| _max_adv        | 4.25        |
| _max_discrew    | 0.25        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00432201 |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 0.00818     |
| _mean_obs       | 0.0319      |
| _min_adv        | -3.94       |
| _min_discrew    | -0.245      |
| _min_obs        | -1.21       |
| _std_act        | 0.389284    |
| _std_adv        | 1           |
| _std_discrew    | 0.00603     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.162       |
| ExplainedVarOld | 0.086       |
| KL              | 0.00259561  |
| Phi_loss        | 22.1226     |
| PolicyEntropy   | 5.24574     |
| PolicyLoss      | -0.00416495 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00515     |
| _MeanReward     | -35.8       |
| _lr_multiplier  | 1           |
| _max_act        | 2.62039     |
| _max_adv        | 4.33        |
| _max_discrew    | 0.284       |
| _max_obs        | 1.37        |
| _mean_act       | -0.00986719 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.0318     |
| _mean_obs       | 0.0379      |
| _min_adv        | -5.51       |
| _min_discrew    | -0.482      |
| _min_obs        | -1.35       |
| _std_act        | 0.388941    |
| _std_adv        | 1           |
| _std_discrew    | 0.00959     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.172       |
| ExplainedVarOld | 0.145       |
| KL              | 0.00347413  |
| Phi_loss        | 20.0621     |
| PolicyEntropy   | 5.27157     |
| PolicyLoss      | -0.00692522 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00816     |
| _MeanReward     | -36.9       |
| _lr_multiplier  | 1           |
| _max_act        | 2.60692     |
| _max_adv        | 5.51        |
| _max_discrew    | 0.238       |
| _max_obs        | 1.42        |
| _mean_act       | 0.000375265 |
| _mean_adv       | 3.69e-17    |
| _mean_discrew   | -0.0323     |
| _mean_obs       | 0.0367      |
| _min_adv        | -4.17       |
| _min_discrew    | -0.326      |
| _min_obs        | -1.38       |
| _std_act        | 0.394744    |
| _std_adv        | 1           |
| _std_discrew    | 0.00729     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.219       |
| ExplainedVarOld | 0.191       |
| KL              | 0.00361463  |
| Phi_loss        | 21.2534     |
| PolicyEntropy   | 5.24699     |
| PolicyLoss      | 0.00389256  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0057      |
| _MeanReward     | -17.9       |
| _lr_multiplier  | 1           |
| _max_act        | 2.61505     |
| _max_adv        | 5.16        |
| _max_discrew    | 0.207       |
| _max_obs        | 1.4         |
| _mean_act       | -0.00339864 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | -0.0183     |
| _mean_obs       | 0.0397      |
| _min_adv        | -4.36       |
| _min_discrew    | -0.24       |
| _min_obs        | -1.19       |
| _std_act        | 0.388633    |
| _std_adv        | 1           |
| _std_discrew    | 0.00551     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.1         |
| ExplainedVarOld | -0.011      |
| KL              | 0.00330602  |
| Phi_loss        | 19.2818     |
| PolicyEntropy   | 5.20302     |
| PolicyLoss      | 0.00667538  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00503     |
| _MeanReward     | -1.87       |
| _lr_multiplier  | 1           |
| _max_act        | 3.08744     |
| _max_adv        | 3.83        |
| _max_discrew    | 0.231       |
| _max_obs        | 1.28        |
| _mean_act       | -0.00720633 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | -0.00451    |
| _mean_obs       | 0.034       |
| _min_adv        | -4.89       |
| _min_discrew    | -0.225      |
| _min_obs        | -1.28       |
| _std_act        | 0.394468    |
| _std_adv        | 1           |
| _std_discrew    | 0.00566     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.135        |
| ExplainedVarOld | 0.0611       |
| KL              | 0.00398896   |
| Phi_loss        | 22.5994      |
| PolicyEntropy   | 5.1933       |
| PolicyLoss      | 0.00264679   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00491      |
| _MeanReward     | 14.8         |
| _lr_multiplier  | 1            |
| _max_act        | 2.54984      |
| _max_adv        | 4.14         |
| _max_discrew    | 0.29         |
| _max_obs        | 1.34         |
| _mean_act       | -0.000323659 |
| _mean_adv       | -8.53e-18    |
| _mean_discrew   | 0.0183       |
| _mean_obs       | 0.0305       |
| _min_adv        | -4.21        |
| _min_discrew    | -0.192       |
| _min_obs        | -1.32        |
| _std_act        | 0.393169     |
| _std_adv        | 1            |
| _std_discrew    | 0.00681      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.266       |
| ExplainedVarOld | 0.0913      |
| KL              | 0.00440678  |
| Phi_loss        | 25.0711     |
| PolicyEntropy   | 5.17637     |
| PolicyLoss      | 0.00343704  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00509     |
| _MeanReward     | 0.191       |
| _lr_multiplier  | 1           |
| _max_act        | 2.68176     |
| _max_adv        | 4           |
| _max_discrew    | 0.335       |
| _max_obs        | 1.46        |
| _mean_act       | -0.00593285 |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 0.00722     |
| _mean_obs       | 0.0329      |
| _min_adv        | -3.93       |
| _min_discrew    | -0.341      |
| _min_obs        | -1.37       |
| _std_act        | 0.389022    |
| _std_adv        | 1           |
| _std_discrew    | 0.0102      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.212       |
| ExplainedVarOld | 0.181       |
| KL              | 0.00263114  |
| Phi_loss        | 25.3902     |
| PolicyEntropy   | 5.14069     |
| PolicyLoss      | 0.00757601  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00802     |
| _MeanReward     | 8.7         |
| _lr_multiplier  | 1           |
| _max_act        | 2.81056     |
| _max_adv        | 5.4         |
| _max_discrew    | 0.319       |
| _max_obs        | 1.52        |
| _mean_act       | -0.00290172 |
| _mean_adv       | -4.26e-17   |
| _mean_discrew   | 0.00572     |
| _mean_obs       | 0.0373      |
| _min_adv        | -4.08       |
| _min_discrew    | -0.179      |
| _min_obs        | -1.31       |
| _std_act        | 0.382744    |
| _std_adv        | 1           |
| _std_discrew    | 0.00521     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.157       |
| ExplainedVarOld | 0.0672      |
| KL              | 0.00332928  |
| Phi_loss        | 23.9303     |
| PolicyEntropy   | 5.13636     |
| PolicyLoss      | -0.00294869 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00441     |
| _MeanReward     | -30.8       |
| _lr_multiplier  | 1           |
| _max_act        | 2.82046     |
| _max_adv        | 3.64        |
| _max_discrew    | 0.257       |
| _max_obs        | 1.53        |
| _mean_act       | -0.0100711  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | -0.0323     |
| _mean_obs       | 0.022       |
| _min_adv        | -7          |
| _min_discrew    | -0.459      |
| _min_obs        | -1.35       |
| _std_act        | 0.391176    |
| _std_adv        | 1           |
| _std_discrew    | 0.0192      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.467       |
| ExplainedVarOld | 0.175       |
| KL              | 0.00792465  |
| Phi_loss        | 20.931      |
| PolicyEntropy   | 5.12786     |
| PolicyLoss      | 0.00173387  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0102      |
| _MeanReward     | 47.4        |
| _lr_multiplier  | 1           |
| _max_act        | 2.55734     |
| _max_adv        | 4.06        |
| _max_discrew    | 0.373       |
| _max_obs        | 1.54        |
| _mean_act       | -0.00286015 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.0465      |
| _mean_obs       | 0.0321      |
| _min_adv        | -4.08       |
| _min_discrew    | -0.212      |
| _min_obs        | -1.2        |
| _std_act        | 0.387168    |
| _std_adv        | 1           |
| _std_discrew    | 0.00863     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.285      |
| ExplainedVarOld | 0.238      |
| KL              | 0.00125687 |
| Phi_loss        | 29.7592    |
| PolicyEntropy   | 5.10753    |
| PolicyLoss      | 0.0057376  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00655    |
| _MeanReward     | 67         |
| _lr_multiplier  | 1          |
| _max_act        | 2.65477    |
| _max_adv        | 4.8        |
| _max_discrew    | 0.324      |
| _max_obs        | 1.33       |
| _mean_act       | -0.0078489 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.0545     |
| _mean_obs       | 0.0375     |
| _min_adv        | -4.79      |
| _min_discrew    | -0.147     |
| _min_obs        | -1.37      |
| _std_act        | 0.387226   |
| _std_adv        | 1          |
| _std_discrew    | 0.007      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.32        |
| ExplainedVarOld | 0.194       |
| KL              | 0.00278185  |
| Phi_loss        | 28.0888     |
| PolicyEntropy   | 5.08642     |
| PolicyLoss      | 0.00195715  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00492     |
| _MeanReward     | 89.9        |
| _lr_multiplier  | 1           |
| _max_act        | 2.44475     |
| _max_adv        | 3.8         |
| _max_discrew    | 0.377       |
| _max_obs        | 1.42        |
| _mean_act       | -0.00465331 |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 0.0695      |
| _mean_obs       | 0.0312      |
| _min_adv        | -4.69       |
| _min_discrew    | -0.185      |
| _min_obs        | -1.33       |
| _std_act        | 0.392105    |
| _std_adv        | 1           |
| _std_discrew    | 0.0104      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.24         |
| ExplainedVarOld | 0.193        |
| KL              | 0.00327205   |
| Phi_loss        | 30.4131      |
| PolicyEntropy   | 5.07467      |
| PolicyLoss      | -0.000460176 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00787      |
| _MeanReward     | 50.4         |
| _lr_multiplier  | 1            |
| _max_act        | 2.65253      |
| _max_adv        | 4.06         |
| _max_discrew    | 0.259        |
| _max_obs        | 1.44         |
| _mean_act       | -0.0121113   |
| _mean_adv       | 0            |
| _mean_discrew   | 0.0374       |
| _mean_obs       | 0.0289       |
| _min_adv        | -4.03        |
| _min_discrew    | -0.191       |
| _min_obs        | -1.23        |
| _std_act        | 0.382414     |
| _std_adv        | 1            |
| _std_discrew    | 0.00626      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.126      |
| ExplainedVarOld | 0.051      |
| KL              | 0.00294343 |
| Phi_loss        | 29.3913    |
| PolicyEntropy   | 5.05044    |
| PolicyLoss      | 0.00161644 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00575    |
| _MeanReward     | 87.9       |
| _lr_multiplier  | 1          |
| _max_act        | 2.76946    |
| _max_adv        | 3.26       |
| _max_discrew    | 0.336      |
| _max_obs        | 1.38       |
| _mean_act       | -0.0111009 |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 0.0707     |
| _mean_obs       | 0.0301     |
| _min_adv        | -4.02      |
| _min_discrew    | -0.242     |
| _min_obs        | -1.25      |
| _std_act        | 0.385454   |
| _std_adv        | 1          |
| _std_discrew    | 0.00969    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.143      |
| ExplainedVarOld | 0.133      |
| KL              | 0.00363791 |
| Phi_loss        | 29.5878    |
| PolicyEntropy   | 5.03039    |
| PolicyLoss      | 0.00274253 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0086     |
| _MeanReward     | 97.1       |
| _lr_multiplier  | 1          |
| _max_act        | 2.30757    |
| _max_adv        | 4.47       |
| _max_discrew    | 0.428      |
| _max_obs        | 1.43       |
| _mean_act       | -0.0135571 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.0824     |
| _mean_obs       | 0.0299     |
| _min_adv        | -3.36      |
| _min_discrew    | -0.183     |
| _min_obs        | -1.24      |
| _std_act        | 0.382152   |
| _std_adv        | 1          |
| _std_discrew    | 0.00926    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.211       |
| ExplainedVarOld | 0.137       |
| KL              | 0.00286251  |
| Phi_loss        | 27.1107     |
| PolicyEntropy   | 5.03032     |
| PolicyLoss      | -0.00422777 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00731     |
| _MeanReward     | 100         |
| _lr_multiplier  | 1           |
| _max_act        | 2.87968     |
| _max_adv        | 4.88        |
| _max_discrew    | 0.443       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0101834  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.0827      |
| _mean_obs       | 0.0275      |
| _min_adv        | -4          |
| _min_discrew    | -0.169      |
| _min_obs        | -1.46       |
| _std_act        | 0.388958    |
| _std_adv        | 1           |
| _std_discrew    | 0.00828     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.218       |
| ExplainedVarOld | 0.182       |
| KL              | 0.00310795  |
| Phi_loss        | 28.4156     |
| PolicyEntropy   | 5.01747     |
| PolicyLoss      | -0.00175227 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00648     |
| _MeanReward     | 99.6        |
| _lr_multiplier  | 1           |
| _max_act        | 2.81137     |
| _max_adv        | 4.28        |
| _max_discrew    | 0.334       |
| _max_obs        | 1.38        |
| _mean_act       | -0.015145   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.0816      |
| _mean_obs       | 0.0279      |
| _min_adv        | -3.08       |
| _min_discrew    | -0.102      |
| _min_obs        | -1.22       |
| _std_act        | 0.389057    |
| _std_adv        | 1           |
| _std_discrew    | 0.0075      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.384       |
| ExplainedVarOld | 0.292       |
| KL              | 0.00311852  |
| Phi_loss        | 27.4734     |
| PolicyEntropy   | 5.02483     |
| PolicyLoss      | -0.00630671 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00464     |
| _MeanReward     | 103         |
| _lr_multiplier  | 1           |
| _max_act        | 2.41995     |
| _max_adv        | 4.06        |
| _max_discrew    | 0.401       |
| _max_obs        | 1.45        |
| _mean_act       | -0.0201428  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.0822      |
| _mean_obs       | 0.0316      |
| _min_adv        | -5.36       |
| _min_discrew    | -0.212      |
| _min_obs        | -1.21       |
| _std_act        | 0.39741     |
| _std_adv        | 1           |
| _std_discrew    | 0.0081      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.226      |
| ExplainedVarOld | 0.178      |
| KL              | 0.00318697 |
| Phi_loss        | 26.8257    |
| PolicyEntropy   | 5.00142    |
| PolicyLoss      | 0.00169557 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0063     |
| _MeanReward     | 139        |
| _lr_multiplier  | 1          |
| _max_act        | 2.41433    |
| _max_adv        | 4.04       |
| _max_discrew    | 0.421      |
| _max_obs        | 1.37       |
| _mean_act       | -0.0180569 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 0.107      |
| _mean_obs       | 0.0286     |
| _min_adv        | -4.14      |
| _min_discrew    | -0.188     |
| _min_obs        | -1.4       |
| _std_act        | 0.393031   |
| _std_adv        | 1          |
| _std_discrew    | 0.0124     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.219       |
| ExplainedVarOld | 0.154       |
| KL              | 0.0036489   |
| Phi_loss        | 28.5893     |
| PolicyEntropy   | 4.98912     |
| PolicyLoss      | -0.00357772 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00988     |
| _MeanReward     | 145         |
| _lr_multiplier  | 1           |
| _max_act        | 2.76117     |
| _max_adv        | 4.3         |
| _max_discrew    | 0.447       |
| _max_obs        | 1.63        |
| _mean_act       | -0.0205184  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.117       |
| _mean_obs       | 0.0269      |
| _min_adv        | -3.88       |
| _min_discrew    | -0.14       |
| _min_obs        | -1.32       |
| _std_act        | 0.399759    |
| _std_adv        | 1           |
| _std_discrew    | 0.0103      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.327      |
| ExplainedVarOld | 0.271      |
| KL              | 0.0034005  |
| Phi_loss        | 28.7705    |
| PolicyEntropy   | 4.96401    |
| PolicyLoss      | 0.00567941 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00694    |
| _MeanReward     | 178        |
| _lr_multiplier  | 1          |
| _max_act        | 2.48531    |
| _max_adv        | 4.6        |
| _max_discrew    | 0.476      |
| _max_obs        | 1.71       |
| _mean_act       | -0.0207967 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.144      |
| _mean_obs       | 0.0257     |
| _min_adv        | -3.36      |
| _min_discrew    | -0.159     |
| _min_obs        | -1.25      |
| _std_act        | 0.393955   |
| _std_adv        | 1          |
| _std_discrew    | 0.0137     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.236       |
| ExplainedVarOld | 0.207       |
| KL              | 0.00387063  |
| Phi_loss        | 30.4098     |
| PolicyEntropy   | 4.94684     |
| PolicyLoss      | -0.00148983 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0106      |
| _MeanReward     | 205         |
| _lr_multiplier  | 1           |
| _max_act        | 2.74401     |
| _max_adv        | 3.72        |
| _max_discrew    | 0.464       |
| _max_obs        | 1.37        |
| _mean_act       | -0.0201554  |
| _mean_adv       | -1.07e-17   |
| _mean_discrew   | 0.163       |
| _mean_obs       | 0.0229      |
| _min_adv        | -3.76       |
| _min_discrew    | -0.131      |
| _min_obs        | -1.23       |
| _std_act        | 0.396041    |
| _std_adv        | 1           |
| _std_discrew    | 0.0105      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.455       |
| ExplainedVarOld | 0.417       |
| KL              | 0.00296034  |
| Phi_loss        | 30.961      |
| PolicyEntropy   | 4.91685     |
| PolicyLoss      | 0.000473972 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00578     |
| _MeanReward     | 195         |
| _lr_multiplier  | 1           |
| _max_act        | 2.53133     |
| _max_adv        | 4.23        |
| _max_discrew    | 0.552       |
| _max_obs        | 1.46        |
| _mean_act       | -0.0282412  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.158       |
| _mean_obs       | 0.0277      |
| _min_adv        | -3.24       |
| _min_discrew    | -0.259      |
| _min_obs        | -1.28       |
| _std_act        | 0.397148    |
| _std_adv        | 1           |
| _std_discrew    | 0.0173      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.414       |
| ExplainedVarOld | 0.36        |
| KL              | 0.00342153  |
| Phi_loss        | 30.1485     |
| PolicyEntropy   | 4.90512     |
| PolicyLoss      | -0.00592021 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0102      |
| _MeanReward     | 193         |
| _lr_multiplier  | 1           |
| _max_act        | 2.41459     |
| _max_adv        | 3.52        |
| _max_discrew    | 0.438       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0213462  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.16        |
| _mean_obs       | 0.0245      |
| _min_adv        | -4.25       |
| _min_discrew    | -0.145      |
| _min_obs        | -1.2        |
| _std_act        | 0.402274    |
| _std_adv        | 1           |
| _std_discrew    | 0.0102      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.4        |
| ExplainedVarOld | 0.376      |
| KL              | 0.00347771 |
| Phi_loss        | 34.6421    |
| PolicyEntropy   | 4.86185    |
| PolicyLoss      | 0.00802146 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00618    |
| _MeanReward     | 175        |
| _lr_multiplier  | 1          |
| _max_act        | 2.53608    |
| _max_adv        | 3.31       |
| _max_discrew    | 0.422      |
| _max_obs        | 1.39       |
| _mean_act       | -0.0295501 |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 0.146      |
| _mean_obs       | 0.0238     |
| _min_adv        | -4.06      |
| _min_discrew    | -0.0962    |
| _min_obs        | -1.38      |
| _std_act        | 0.396434   |
| _std_adv        | 1          |
| _std_discrew    | 0.00983    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.337      |
| ExplainedVarOld | 0.293      |
| KL              | 0.0028994  |
| Phi_loss        | 33.4012    |
| PolicyEntropy   | 4.83192    |
| PolicyLoss      | 0.00556549 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00652    |
| _MeanReward     | 209        |
| _lr_multiplier  | 1          |
| _max_act        | 2.5191     |
| _max_adv        | 3.78       |
| _max_discrew    | 0.574      |
| _max_obs        | 1.6        |
| _mean_act       | -0.0257167 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.164      |
| _mean_obs       | 0.0262     |
| _min_adv        | -4.01      |
| _min_discrew    | -0.161     |
| _min_obs        | -1.49      |
| _std_act        | 0.397866   |
| _std_adv        | 1          |
| _std_discrew    | 0.0156     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.33       |
| ExplainedVarOld | 0.308      |
| KL              | 0.00346662 |
| Phi_loss        | 35.0501    |
| PolicyEntropy   | 4.82821    |
| PolicyLoss      | -0.003897  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0105     |
| _MeanReward     | 237        |
| _lr_multiplier  | 1          |
| _max_act        | 2.80798    |
| _max_adv        | 3.59       |
| _max_discrew    | 0.543      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0305731 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.185      |
| _mean_obs       | 0.027      |
| _min_adv        | -3.62      |
| _min_discrew    | -0.0683    |
| _min_obs        | -1.33      |
| _std_act        | 0.395111   |
| _std_adv        | 1          |
| _std_discrew    | 0.0148     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.365       |
| ExplainedVarOld | 0.353       |
| KL              | 0.00271885  |
| Phi_loss        | 33.4406     |
| PolicyEntropy   | 4.8169      |
| PolicyLoss      | 0.000685014 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00957     |
| _MeanReward     | 261         |
| _lr_multiplier  | 1           |
| _max_act        | 3.04551     |
| _max_adv        | 3.8         |
| _max_discrew    | 0.507       |
| _max_obs        | 1.4         |
| _mean_act       | -0.0333417  |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 0.207       |
| _mean_obs       | 0.023       |
| _min_adv        | -3.8        |
| _min_discrew    | -0.0808     |
| _min_obs        | -1.42       |
| _std_act        | 0.393986    |
| _std_adv        | 1           |
| _std_discrew    | 0.015       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.367      |
| ExplainedVarOld | 0.348      |
| KL              | 0.0030569  |
| Phi_loss        | 32.5616    |
| PolicyEntropy   | 4.81548    |
| PolicyLoss      | 0.00035175 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00957    |
| _MeanReward     | 233        |
| _lr_multiplier  | 1          |
| _max_act        | 2.90851    |
| _max_adv        | 3.77       |
| _max_discrew    | 0.641      |
| _max_obs        | 1.53       |
| _mean_act       | -0.0493811 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.186      |
| _mean_obs       | 0.0228     |
| _min_adv        | -3.84      |
| _min_discrew    | -0.431     |
| _min_obs        | -1.45      |
| _std_act        | 0.410911   |
| _std_adv        | 1          |
| _std_discrew    | 0.0374     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.761       |
| ExplainedVarOld | 0.503       |
| KL              | 0.00278009  |
| Phi_loss        | 26.8665     |
| PolicyEntropy   | 4.78798     |
| PolicyLoss      | -0.00318856 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00921     |
| _MeanReward     | 229         |
| _lr_multiplier  | 1           |
| _max_act        | 2.46727     |
| _max_adv        | 3.71        |
| _max_discrew    | 0.552       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0374896  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.191       |
| _mean_obs       | 0.0242      |
| _min_adv        | -3.71       |
| _min_discrew    | -0.0737     |
| _min_obs        | -1.22       |
| _std_act        | 0.396145    |
| _std_adv        | 1           |
| _std_discrew    | 0.0124      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.376       |
| ExplainedVarOld | 0.313       |
| KL              | 0.00273593  |
| Phi_loss        | 31.8302     |
| PolicyEntropy   | 4.77455     |
| PolicyLoss      | -0.00188417 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00803     |
| _MeanReward     | 296         |
| _lr_multiplier  | 1           |
| _max_act        | 2.5627      |
| _max_adv        | 4.05        |
| _max_discrew    | 0.746       |
| _max_obs        | 1.56        |
| _mean_act       | -0.0331374  |
| _mean_adv       | -9.95e-18   |
| _mean_discrew   | 0.24        |
| _mean_obs       | 0.0239      |
| _min_adv        | -3.04       |
| _min_discrew    | -0.0401     |
| _min_obs        | -1.31       |
| _std_act        | 0.397545    |
| _std_adv        | 1           |
| _std_discrew    | 0.0188      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.32        |
| ExplainedVarOld | 0.298       |
| KL              | 0.00312634  |
| Phi_loss        | 36.5465     |
| PolicyEntropy   | 4.74072     |
| PolicyLoss      | -0.00134019 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0134      |
| _MeanReward     | 314         |
| _lr_multiplier  | 1           |
| _max_act        | 2.58653     |
| _max_adv        | 3.39        |
| _max_discrew    | 0.614       |
| _max_obs        | 1.55        |
| _mean_act       | -0.0417281  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.256       |
| _mean_obs       | 0.0251      |
| _min_adv        | -3.7        |
| _min_discrew    | -0.12       |
| _min_obs        | -1.4        |
| _std_act        | 0.398141    |
| _std_adv        | 1           |
| _std_discrew    | 0.0204      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.505       |
| ExplainedVarOld | 0.467       |
| KL              | 0.00315138  |
| Phi_loss        | 37.4731     |
| PolicyEntropy   | 4.72106     |
| PolicyLoss      | -0.00191958 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0104      |
| _MeanReward     | 304         |
| _lr_multiplier  | 1           |
| _max_act        | 2.53962     |
| _max_adv        | 3.74        |
| _max_discrew    | 0.57        |
| _max_obs        | 1.49        |
| _mean_act       | -0.037319   |
| _mean_adv       | -2.7e-17    |
| _mean_discrew   | 0.24        |
| _mean_obs       | 0.0251      |
| _min_adv        | -3.93       |
| _min_discrew    | -0.151      |
| _min_obs        | -1.44       |
| _std_act        | 0.400994    |
| _std_adv        | 1           |
| _std_discrew    | 0.018       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.536      |
| ExplainedVarOld | 0.495      |
| KL              | 0.0031483  |
| Phi_loss        | 36.6938    |
| PolicyEntropy   | 4.68455    |
| PolicyLoss      | 0.00353215 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00838    |
| _MeanReward     | 358        |
| _lr_multiplier  | 1          |
| _max_act        | 2.66867    |
| _max_adv        | 4.67       |
| _max_discrew    | 0.772      |
| _max_obs        | 1.62       |
| _mean_act       | -0.0329573 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.287      |
| _mean_obs       | 0.0245     |
| _min_adv        | -4.02      |
| _min_discrew    | -0.142     |
| _min_obs        | -1.45      |
| _std_act        | 0.403691   |
| _std_adv        | 1          |
| _std_discrew    | 0.0204     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.555        |
| ExplainedVarOld | 0.539        |
| KL              | 0.00354716   |
| Phi_loss        | 36.7708      |
| PolicyEntropy   | 4.64017      |
| PolicyLoss      | -0.000851318 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00945      |
| _MeanReward     | 359          |
| _lr_multiplier  | 1            |
| _max_act        | 2.9538       |
| _max_adv        | 3.86         |
| _max_discrew    | 0.758        |
| _max_obs        | 1.46         |
| _mean_act       | -0.0350169   |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 0.287        |
| _mean_obs       | 0.0225       |
| _min_adv        | -3.69        |
| _min_discrew    | -0.0581      |
| _min_obs        | -1.44        |
| _std_act        | 0.403156     |
| _std_adv        | 1            |
| _std_discrew    | 0.0231       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.476       |
| ExplainedVarOld | 0.469       |
| KL              | 0.00291587  |
| Phi_loss        | 42.8051     |
| PolicyEntropy   | 4.61507     |
| PolicyLoss      | 0.000559259 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0121      |
| _MeanReward     | 390         |
| _lr_multiplier  | 1           |
| _max_act        | 2.77136     |
| _max_adv        | 3.59        |
| _max_discrew    | 0.712       |
| _max_obs        | 1.45        |
| _mean_act       | -0.0387129  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.318       |
| _mean_obs       | 0.0254      |
| _min_adv        | -2.92       |
| _min_discrew    | -0.109      |
| _min_obs        | -1.32       |
| _std_act        | 0.399651    |
| _std_adv        | 1           |
| _std_discrew    | 0.0276      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.518       |
| ExplainedVarOld | 0.504       |
| KL              | 0.00297234  |
| Phi_loss        | 41.2717     |
| PolicyEntropy   | 4.605       |
| PolicyLoss      | -0.00722609 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0138      |
| _MeanReward     | 411         |
| _lr_multiplier  | 1           |
| _max_act        | 2.67186     |
| _max_adv        | 3.41        |
| _max_discrew    | 0.737       |
| _max_obs        | 1.52        |
| _mean_act       | -0.033522   |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 0.34        |
| _mean_obs       | 0.0238      |
| _min_adv        | -3.32       |
| _min_discrew    | -0.024      |
| _min_obs        | -1.26       |
| _std_act        | 0.415608    |
| _std_adv        | 1           |
| _std_discrew    | 0.0266      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.421       |
| ExplainedVarOld | 0.411       |
| KL              | 0.00337511  |
| Phi_loss        | 43.943      |
| PolicyEntropy   | 4.59514     |
| PolicyLoss      | 0.000377598 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0155      |
| _MeanReward     | 413         |
| _lr_multiplier  | 1           |
| _max_act        | 2.58122     |
| _max_adv        | 3.79        |
| _max_discrew    | 0.772       |
| _max_obs        | 1.51        |
| _mean_act       | -0.0344339  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.34        |
| _mean_obs       | 0.0246      |
| _min_adv        | -3.4        |
| _min_discrew    | -0.0681     |
| _min_obs        | -1.31       |
| _std_act        | 0.409365    |
| _std_adv        | 1           |
| _std_discrew    | 0.0232      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.519       |
| ExplainedVarOld | 0.499       |
| KL              | 0.00279606  |
| Phi_loss        | 43.4077     |
| PolicyEntropy   | 4.56699     |
| PolicyLoss      | -0.00150939 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0112      |
| _MeanReward     | 403         |
| _lr_multiplier  | 1           |
| _max_act        | 2.62333     |
| _max_adv        | 3.24        |
| _max_discrew    | 0.663       |
| _max_obs        | 1.62        |
| _mean_act       | -0.0357916  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.326       |
| _mean_obs       | 0.0262      |
| _min_adv        | -4.52       |
| _min_discrew    | -0.0867     |
| _min_obs        | -1.2        |
| _std_act        | 0.408879    |
| _std_adv        | 1           |
| _std_discrew    | 0.0271      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.637       |
| ExplainedVarOld | 0.592       |
| KL              | 0.00338135  |
| Phi_loss        | 43.8181     |
| PolicyEntropy   | 4.55745     |
| PolicyLoss      | -0.00786578 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00987     |
| _MeanReward     | 461         |
| _lr_multiplier  | 1           |
| _max_act        | 2.48223     |
| _max_adv        | 3.39        |
| _max_discrew    | 0.875       |
| _max_obs        | 1.53        |
| _mean_act       | -0.034942   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.384       |
| _mean_obs       | 0.0288      |
| _min_adv        | -3.83       |
| _min_discrew    | -0.0682     |
| _min_obs        | -1.3        |
| _std_act        | 0.410855    |
| _std_adv        | 1           |
| _std_discrew    | 0.0266      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.517      |
| ExplainedVarOld | 0.474      |
| KL              | 0.00288868 |
| Phi_loss        | 44.3668    |
| PolicyEntropy   | 4.53332    |
| PolicyLoss      | 0.00367949 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0134     |
| _MeanReward     | 427        |
| _lr_multiplier  | 1          |
| _max_act        | 2.54546    |
| _max_adv        | 3.38       |
| _max_discrew    | 0.764      |
| _max_obs        | 1.86       |
| _mean_act       | -0.044601  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.342      |
| _mean_obs       | 0.0261     |
| _min_adv        | -3.59      |
| _min_discrew    | -0.0875    |
| _min_obs        | -1.32      |
| _std_act        | 0.416046   |
| _std_adv        | 1          |
| _std_discrew    | 0.0334     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.424       |
| ExplainedVarOld | 0.419       |
| KL              | 0.00270747  |
| Phi_loss        | 47.276      |
| PolicyEntropy   | 4.5155      |
| PolicyLoss      | -0.00126089 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0197      |
| _MeanReward     | 486         |
| _lr_multiplier  | 1           |
| _max_act        | 2.69731     |
| _max_adv        | 3.71        |
| _max_discrew    | 0.811       |
| _max_obs        | 1.45        |
| _mean_act       | -0.045012   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 0.398       |
| _mean_obs       | 0.0254      |
| _min_adv        | -3.44       |
| _min_discrew    | -0.156      |
| _min_obs        | -1.26       |
| _std_act        | 0.413285    |
| _std_adv        | 1           |
| _std_discrew    | 0.0281      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.516       |
| ExplainedVarOld | 0.507       |
| KL              | 0.00239414  |
| Phi_loss        | 46.3291     |
| PolicyEntropy   | 4.49419     |
| PolicyLoss      | -0.00287586 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0146      |
| _MeanReward     | 499         |
| _lr_multiplier  | 1           |
| _max_act        | 2.46578     |
| _max_adv        | 3.27        |
| _max_discrew    | 0.773       |
| _max_obs        | 1.49        |
| _mean_act       | -0.0456953  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 0.415       |
| _mean_obs       | 0.0239      |
| _min_adv        | -3.74       |
| _min_discrew    | -0.0373     |
| _min_obs        | -1.35       |
| _std_act        | 0.412358    |
| _std_adv        | 1           |
| _std_discrew    | 0.0324      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.478       |
| ExplainedVarOld | 0.452       |
| KL              | 0.00284503  |
| Phi_loss        | 48.0503     |
| PolicyEntropy   | 4.45966     |
| PolicyLoss      | -0.00228632 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0169      |
| _MeanReward     | 488         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60575     |
| _max_adv        | 3.69        |
| _max_discrew    | 0.845       |
| _max_obs        | 1.59        |
| _mean_act       | -0.0398388  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.398       |
| _mean_obs       | 0.0251      |
| _min_adv        | -3.52       |
| _min_discrew    | -0.0554     |
| _min_obs        | -1.27       |
| _std_act        | 0.418311    |
| _std_adv        | 1           |
| _std_discrew    | 0.0295      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.551      |
| ExplainedVarOld | 0.527      |
| KL              | 0.00268959 |
| Phi_loss        | 46.258     |
| PolicyEntropy   | 4.43345    |
| PolicyLoss      | 0.00173336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0133     |
| _MeanReward     | 526        |
| _lr_multiplier  | 1          |
| _max_act        | 2.73441    |
| _max_adv        | 3.5        |
| _max_discrew    | 0.945      |
| _max_obs        | 1.56       |
| _mean_act       | -0.0409737 |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 0.423      |
| _mean_obs       | 0.0253     |
| _min_adv        | -3.41      |
| _min_discrew    | -0.0333    |
| _min_obs        | -1.39      |
| _std_act        | 0.410715   |
| _std_adv        | 1          |
| _std_discrew    | 0.0315     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.621       |
| ExplainedVarOld | 0.586       |
| KL              | 0.00352175  |
| Phi_loss        | 47.4725     |
| PolicyEntropy   | 4.40903     |
| PolicyLoss      | -0.00377333 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0122      |
| _MeanReward     | 527         |
| _lr_multiplier  | 1           |
| _max_act        | 3.29404     |
| _max_adv        | 3.41        |
| _max_discrew    | 0.968       |
| _max_obs        | 1.67        |
| _mean_act       | -0.0404068  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.431       |
| _mean_obs       | 0.0248      |
| _min_adv        | -3.52       |
| _min_discrew    | -0.0891     |
| _min_obs        | -1.37       |
| _std_act        | 0.422627    |
| _std_adv        | 1           |
| _std_discrew    | 0.0381      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.595      |
| ExplainedVarOld | 0.58       |
| KL              | 0.00238592 |
| Phi_loss        | 49.4682    |
| PolicyEntropy   | 4.38577    |
| PolicyLoss      | 0.00344688 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0154     |
| _MeanReward     | 542        |
| _lr_multiplier  | 1          |
| _max_act        | 2.65328    |
| _max_adv        | 3.41       |
| _max_discrew    | 0.964      |
| _max_obs        | 1.57       |
| _mean_act       | -0.0434267 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 0.429      |
| _mean_obs       | 0.0242     |
| _min_adv        | -3.16      |
| _min_discrew    | -0.0216    |
| _min_obs        | -1.29      |
| _std_act        | 0.411412   |
| _std_adv        | 1          |
| _std_discrew    | 0.0322     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.661      |
| ExplainedVarOld | 0.659      |
| KL              | 0.00311297 |
| Phi_loss        | 53.3097    |
| PolicyEntropy   | 4.34336    |
| PolicyLoss      | 0.00198657 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0109     |
| _MeanReward     | 541        |
| _lr_multiplier  | 1          |
| _max_act        | 2.74953    |
| _max_adv        | 3.83       |
| _max_discrew    | 0.973      |
| _max_obs        | 1.89       |
| _mean_act       | -0.0375293 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.455      |
| _mean_obs       | 0.0273     |
| _min_adv        | -3.39      |
| _min_discrew    | -0.0022    |
| _min_obs        | -1.28      |
| _std_act        | 0.420538   |
| _std_adv        | 1          |
| _std_discrew    | 0.0349     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.586       |
| ExplainedVarOld | 0.544       |
| KL              | 0.00289557  |
| Phi_loss        | 49.4144     |
| PolicyEntropy   | 4.33754     |
| PolicyLoss      | -0.00759224 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0148      |
| _MeanReward     | 527         |
| _lr_multiplier  | 1           |
| _max_act        | 2.56055     |
| _max_adv        | 3.9         |
| _max_discrew    | 0.945       |
| _max_obs        | 1.48        |
| _mean_act       | -0.0366243  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.43        |
| _mean_obs       | 0.0274      |
| _min_adv        | -3.14       |
| _min_discrew    | -0.0633     |
| _min_obs        | -1.35       |
| _std_act        | 0.422591    |
| _std_adv        | 1           |
| _std_discrew    | 0.0402      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.632       |
| ExplainedVarOld | 0.618       |
| KL              | 0.00401287  |
| Phi_loss        | 53.1473     |
| PolicyEntropy   | 4.31977     |
| PolicyLoss      | -0.00479628 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0149      |
| _MeanReward     | 660         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03638     |
| _max_adv        | 3.46        |
| _max_discrew    | 0.999       |
| _max_obs        | 1.53        |
| _mean_act       | -0.0365554  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 0.54        |
| _mean_obs       | 0.0272      |
| _min_adv        | -3.66       |
| _min_discrew    | -0.0204     |
| _min_obs        | -1.38       |
| _std_act        | 0.423905    |
| _std_adv        | 1           |
| _std_discrew    | 0.0523      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.702       |
| ExplainedVarOld | 0.662       |
| KL              | 0.00293811  |
| Phi_loss        | 51.6914     |
| PolicyEntropy   | 4.29191     |
| PolicyLoss      | -0.00733781 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0182      |
| _MeanReward     | 695         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86911     |
| _max_adv        | 3.48        |
| _max_discrew    | 1.05        |
| _max_obs        | 1.62        |
| _mean_act       | -0.0407591  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.567       |
| _mean_obs       | 0.0258      |
| _min_adv        | -3.74       |
| _min_discrew    | -0.0139     |
| _min_obs        | -1.39       |
| _std_act        | 0.429061    |
| _std_adv        | 1           |
| _std_discrew    | 0.042       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.696       |
| ExplainedVarOld | 0.681       |
| KL              | 0.00275939  |
| Phi_loss        | 53.039      |
| PolicyEntropy   | 4.27811     |
| PolicyLoss      | -0.00728069 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0129      |
| _MeanReward     | 657         |
| _lr_multiplier  | 1           |
| _max_act        | 3.19539     |
| _max_adv        | 3.17        |
| _max_discrew    | 1.06        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0380855  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.532       |
| _mean_obs       | 0.0288      |
| _min_adv        | -3.24       |
| _min_discrew    | -0.0156     |
| _min_obs        | -1.28       |
| _std_act        | 0.432851    |
| _std_adv        | 1           |
| _std_discrew    | 0.047       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.719       |
| ExplainedVarOld | 0.714       |
| KL              | 0.00285992  |
| Phi_loss        | 55.104      |
| PolicyEntropy   | 4.26208     |
| PolicyLoss      | -0.00628125 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0133      |
| _MeanReward     | 685         |
| _lr_multiplier  | 1           |
| _max_act        | 2.85251     |
| _max_adv        | 3.44        |
| _max_discrew    | 1.02        |
| _max_obs        | 1.54        |
| _mean_act       | -0.0362076  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 0.553       |
| _mean_obs       | 0.0284      |
| _min_adv        | -4.42       |
| _min_discrew    | -0.0232     |
| _min_obs        | -1.49       |
| _std_act        | 0.440019    |
| _std_adv        | 1           |
| _std_discrew    | 0.0491      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.713       |
| ExplainedVarOld | 0.708       |
| KL              | 0.00410261  |
| Phi_loss        | 55.7004     |
| PolicyEntropy   | 4.22422     |
| PolicyLoss      | -0.00211766 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0141      |
| _MeanReward     | 708         |
| _lr_multiplier  | 1           |
| _max_act        | 2.94202     |
| _max_adv        | 4           |
| _max_discrew    | 1.03        |
| _max_obs        | 1.6         |
| _mean_act       | -0.0323431  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.582       |
| _mean_obs       | 0.0289      |
| _min_adv        | -3.68       |
| _min_discrew    | -0.0307     |
| _min_obs        | -1.32       |
| _std_act        | 0.444118    |
| _std_adv        | 1           |
| _std_discrew    | 0.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.75        |
| ExplainedVarOld | 0.736       |
| KL              | 0.00296939  |
| Phi_loss        | 57.8289     |
| PolicyEntropy   | 4.18109     |
| PolicyLoss      | 0.000830862 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0102      |
| _MeanReward     | 759         |
| _lr_multiplier  | 1           |
| _max_act        | 2.86073     |
| _max_adv        | 3.65        |
| _max_discrew    | 1.12        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0328805  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.623       |
| _mean_obs       | 0.0318      |
| _min_adv        | -3.01       |
| _min_discrew    | -0.0383     |
| _min_obs        | -1.32       |
| _std_act        | 0.454496    |
| _std_adv        | 1           |
| _std_discrew    | 0.0616      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.685      |
| ExplainedVarOld | 0.669      |
| KL              | 0.00346495 |
| Phi_loss        | 58.4249    |
| PolicyEntropy   | 4.12982    |
| PolicyLoss      | 0.00137684 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0198     |
| _MeanReward     | 762        |
| _lr_multiplier  | 1          |
| _max_act        | 3.00932    |
| _max_adv        | 3.14       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.69       |
| _mean_act       | -0.028752  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.635      |
| _mean_obs       | 0.0319     |
| _min_adv        | -4.01      |
| _min_discrew    | -0.0517    |
| _min_obs        | -1.23      |
| _std_act        | 0.452896   |
| _std_adv        | 1          |
| _std_discrew    | 0.0712     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.624       |
| ExplainedVarOld | 0.601       |
| KL              | 0.0027785   |
| Phi_loss        | 59.0964     |
| PolicyEntropy   | 4.10694     |
| PolicyLoss      | -0.00645202 |
| Steps           | 10000       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 751         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01357     |
| _max_adv        | 3.89        |
| _max_discrew    | 1.25        |
| _max_obs        | 1.56        |
| _mean_act       | -0.0335946  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 0.615       |
| _mean_obs       | 0.029       |
| _min_adv        | -3.43       |
| _min_discrew    | -0.00991    |
| _min_obs        | -1.37       |
| _std_act        | 0.446195    |
| _std_adv        | 1           |
| _std_discrew    | 0.0585      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.71       |
| ExplainedVarOld | 0.698      |
| KL              | 0.00318269 |
| Phi_loss        | 56.3512    |
| PolicyEntropy   | 4.07605    |
| PolicyLoss      | -0.0052434 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0172     |
| _MeanReward     | 806        |
| _lr_multiplier  | 1          |
| _max_act        | 2.68606    |
| _max_adv        | 3.38       |
| _max_discrew    | 1.23       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0318157 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.666      |
| _mean_obs       | 0.0306     |
| _min_adv        | -3.63      |
| _min_discrew    | -0.0619    |
| _min_obs        | -1.26      |
| _std_act        | 0.457026   |
| _std_adv        | 1          |
| _std_discrew    | 0.0688     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.739       |
| ExplainedVarOld | 0.725       |
| KL              | 0.00287674  |
| Phi_loss        | 63.4744     |
| PolicyEntropy   | 4.04265     |
| PolicyLoss      | -0.00421216 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0185      |
| _MeanReward     | 784         |
| _lr_multiplier  | 1           |
| _max_act        | 2.59021     |
| _max_adv        | 3.64        |
| _max_discrew    | 1.21        |
| _max_obs        | 1.57        |
| _mean_act       | -0.0291361  |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.643       |
| _mean_obs       | 0.032       |
| _min_adv        | -3.66       |
| _min_discrew    | -0.0151     |
| _min_obs        | -1.31       |
| _std_act        | 0.461959    |
| _std_adv        | 1           |
| _std_discrew    | 0.0621      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.681      |
| ExplainedVarOld | 0.67       |
| KL              | 0.00275368 |
| Phi_loss        | 64.1076    |
| PolicyEntropy   | 4.02985    |
| PolicyLoss      | 0.00737595 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 861        |
| _lr_multiplier  | 1          |
| _max_act        | 2.96976    |
| _max_adv        | 3.32       |
| _max_discrew    | 1.18       |
| _max_obs        | 1.59       |
| _mean_act       | -0.0305336 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.706      |
| _mean_obs       | 0.0315     |
| _min_adv        | -3.97      |
| _min_discrew    | -0.00466   |
| _min_obs        | -1.34      |
| _std_act        | 0.45686    |
| _std_adv        | 1          |
| _std_discrew    | 0.0686     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.78        |
| ExplainedVarOld | 0.774       |
| KL              | 0.00288711  |
| Phi_loss        | 63.3676     |
| PolicyEntropy   | 4.00893     |
| PolicyLoss      | -0.00538231 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0157      |
| _MeanReward     | 886         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60639     |
| _max_adv        | 3.62        |
| _max_discrew    | 1.24        |
| _max_obs        | 1.59        |
| _mean_act       | -0.0344813  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.716       |
| _mean_obs       | 0.0311      |
| _min_adv        | -3.32       |
| _min_discrew    | -0.0214     |
| _min_obs        | -1.26       |
| _std_act        | 0.463531    |
| _std_adv        | 1           |
| _std_discrew    | 0.0698      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.763       |
| ExplainedVarOld | 0.756       |
| KL              | 0.00308134  |
| Phi_loss        | 64.0359     |
| PolicyEntropy   | 3.96892     |
| PolicyLoss      | -0.00219568 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 874         |
| _lr_multiplier  | 1           |
| _max_act        | 2.57165     |
| _max_adv        | 3.22        |
| _max_discrew    | 1.21        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0315905  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.716       |
| _mean_obs       | 0.031       |
| _min_adv        | -3.86       |
| _min_discrew    | -0.00424    |
| _min_obs        | -1.26       |
| _std_act        | 0.452348    |
| _std_adv        | 1           |
| _std_discrew    | 0.0605      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.769       |
| ExplainedVarOld | 0.756       |
| KL              | 0.00386232  |
| Phi_loss        | 67.0272     |
| PolicyEntropy   | 3.94086     |
| PolicyLoss      | -0.00679258 |
| Steps           | 10000       |
| VarFuncLoss     | 0.014       |
| _MeanReward     | 750         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83524     |
| _max_adv        | 3.01        |
| _max_discrew    | 1.26        |
| _max_obs        | 1.57        |
| _mean_act       | -0.0442014  |
| _mean_adv       | 7.96e-17    |
| _mean_discrew   | 0.607       |
| _mean_obs       | 0.0317      |
| _min_adv        | -3.88       |
| _min_discrew    | -0.569      |
| _min_obs        | -1.38       |
| _std_act        | 0.499565    |
| _std_adv        | 1           |
| _std_discrew    | 0.144       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.795       |
| ExplainedVarOld | 0.524       |
| KL              | 0.0032777   |
| Phi_loss        | 42.9453     |
| PolicyEntropy   | 3.9178      |
| PolicyLoss      | -0.00287906 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0296      |
| _MeanReward     | 880         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90076     |
| _max_adv        | 3.13        |
| _max_discrew    | 1.24        |
| _max_obs        | 1.72        |
| _mean_act       | -0.0321043  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.728       |
| _mean_obs       | 0.0328      |
| _min_adv        | -3.85       |
| _min_discrew    | 5.73e-05    |
| _min_obs        | -1.33       |
| _std_act        | 0.471506    |
| _std_adv        | 1           |
| _std_discrew    | 0.0676      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.744      |
| ExplainedVarOld | 0.741      |
| KL              | 0.0029173  |
| Phi_loss        | 63.399     |
| PolicyEntropy   | 3.90167    |
| PolicyLoss      | -0.0029181 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0177     |
| _MeanReward     | 928        |
| _lr_multiplier  | 1          |
| _max_act        | 2.59639    |
| _max_adv        | 4.37       |
| _max_discrew    | 1.38       |
| _max_obs        | 1.56       |
| _mean_act       | -0.0357418 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.767      |
| _mean_obs       | 0.0323     |
| _min_adv        | -3.42      |
| _min_discrew    | -0.00785   |
| _min_obs        | -1.32      |
| _std_act        | 0.466353   |
| _std_adv        | 1          |
| _std_discrew    | 0.0684     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.707       |
| ExplainedVarOld | 0.696       |
| KL              | 0.00328784  |
| Phi_loss        | 68.8736     |
| PolicyEntropy   | 3.87535     |
| PolicyLoss      | -0.00371658 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0202      |
| _MeanReward     | 927         |
| _lr_multiplier  | 1           |
| _max_act        | 3.17002     |
| _max_adv        | 3.61        |
| _max_discrew    | 1.46        |
| _max_obs        | 1.82        |
| _mean_act       | -0.0363038  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.746       |
| _mean_obs       | 0.0323      |
| _min_adv        | -3.93       |
| _min_discrew    | -0.0488     |
| _min_obs        | -1.25       |
| _std_act        | 0.462282    |
| _std_adv        | 1           |
| _std_discrew    | 0.0883      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.795       |
| ExplainedVarOld | 0.768       |
| KL              | 0.00304125  |
| Phi_loss        | 67.5382     |
| PolicyEntropy   | 3.85556     |
| PolicyLoss      | -0.00679635 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0182      |
| _MeanReward     | 930         |
| _lr_multiplier  | 1           |
| _max_act        | 2.69077     |
| _max_adv        | 3.5         |
| _max_discrew    | 1.33        |
| _max_obs        | 1.69        |
| _mean_act       | -0.0360848  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.766       |
| _mean_obs       | 0.0342      |
| _min_adv        | -3.34       |
| _min_discrew    | -0.00486    |
| _min_obs        | -1.32       |
| _std_act        | 0.474523    |
| _std_adv        | 1           |
| _std_discrew    | 0.0718      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.733      |
| ExplainedVarOld | 0.715      |
| KL              | 0.0030748  |
| Phi_loss        | 71.4525    |
| PolicyEntropy   | 3.81649    |
| PolicyLoss      | 0.00267102 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0192     |
| _MeanReward     | 786        |
| _lr_multiplier  | 1          |
| _max_act        | 2.87978    |
| _max_adv        | 3.7        |
| _max_discrew    | 1.3        |
| _max_obs        | 1.58       |
| _mean_act       | -0.0484436 |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 0.637      |
| _mean_obs       | 0.0286     |
| _min_adv        | -9.41      |
| _min_discrew    | -0.563     |
| _min_obs        | -1.26      |
| _std_act        | 0.50201    |
| _std_adv        | 1          |
| _std_discrew    | 0.153      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.793       |
| ExplainedVarOld | 0.759       |
| KL              | 0.00351823  |
| Phi_loss        | 63.2298     |
| PolicyEntropy   | 3.80558     |
| PolicyLoss      | -0.00722484 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0322      |
| _MeanReward     | 933         |
| _lr_multiplier  | 1           |
| _max_act        | 2.65856     |
| _max_adv        | 4.77        |
| _max_discrew    | 1.32        |
| _max_obs        | 1.61        |
| _mean_act       | -0.0418906  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.776       |
| _mean_obs       | 0.0317      |
| _min_adv        | -3.48       |
| _min_discrew    | -0.0814     |
| _min_obs        | -1.28       |
| _std_act        | 0.471185    |
| _std_adv        | 1           |
| _std_discrew    | 0.0832      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.709       |
| ExplainedVarOld | 0.707       |
| KL              | 0.00285084  |
| Phi_loss        | 73.6476     |
| PolicyEntropy   | 3.80667     |
| PolicyLoss      | -0.00896475 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0248      |
| _MeanReward     | 1.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54302     |
| _max_adv        | 4.79        |
| _max_discrew    | 1.48        |
| _max_obs        | 1.61        |
| _mean_act       | -0.0402034  |
| _mean_adv       | 1.85e-17    |
| _mean_discrew   | 0.838       |
| _mean_obs       | 0.0323      |
| _min_adv        | -4.32       |
| _min_discrew    | -0.00118    |
| _min_obs        | -1.3        |
| _std_act        | 0.472051    |
| _std_adv        | 1           |
| _std_discrew    | 0.099       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.771       |
| ExplainedVarOld | 0.717       |
| KL              | 0.00220757  |
| Phi_loss        | 69.8111     |
| PolicyEntropy   | 3.77028     |
| PolicyLoss      | -0.00600988 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 1.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57685     |
| _max_adv        | 3.48        |
| _max_discrew    | 1.46        |
| _max_obs        | 1.52        |
| _mean_act       | -0.036075   |
| _mean_adv       | 0           |
| _mean_discrew   | 0.859       |
| _mean_obs       | 0.0345      |
| _min_adv        | -3.5        |
| _min_discrew    | -0.025      |
| _min_obs        | -1.25       |
| _std_act        | 0.484225    |
| _std_adv        | 1           |
| _std_discrew    | 0.102       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.73        |
| ExplainedVarOld | 0.723       |
| KL              | 0.00325878  |
| Phi_loss        | 74.4331     |
| PolicyEntropy   | 3.73837     |
| PolicyLoss      | -0.00852798 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0276      |
| _MeanReward     | 1.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88229     |
| _max_adv        | 3.16        |
| _max_discrew    | 1.47        |
| _max_obs        | 1.62        |
| _mean_act       | -0.03893    |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.882       |
| _mean_obs       | 0.0327      |
| _min_adv        | -5.03       |
| _min_discrew    | -0.00277    |
| _min_obs        | -1.3        |
| _std_act        | 0.479062    |
| _std_adv        | 1           |
| _std_discrew    | 0.0918      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.754      |
| ExplainedVarOld | 0.742      |
| KL              | 0.0034541  |
| Phi_loss        | 75.9332    |
| PolicyEntropy   | 3.71469    |
| PolicyLoss      | -0.0130219 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0228     |
| _MeanReward     | 1.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65349    |
| _max_adv        | 3.33       |
| _max_discrew    | 1.54       |
| _max_obs        | 1.57       |
| _mean_act       | -0.0397803 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.887      |
| _mean_obs       | 0.0338     |
| _min_adv        | -3.69      |
| _min_discrew    | -0.00481   |
| _min_obs        | -1.22      |
| _std_act        | 0.483615   |
| _std_adv        | 1          |
| _std_discrew    | 0.102      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.782       |
| ExplainedVarOld | 0.777       |
| KL              | 0.00276257  |
| Phi_loss        | 84.2343     |
| PolicyEntropy   | 3.68433     |
| PolicyLoss      | -0.00317918 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0222      |
| _MeanReward     | 1.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6418      |
| _max_adv        | 3.38        |
| _max_discrew    | 1.71        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0431753  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.0331      |
| _min_adv        | -4.27       |
| _min_discrew    | 0.00103     |
| _min_obs        | -1.32       |
| _std_act        | 0.487778    |
| _std_adv        | 1           |
| _std_discrew    | 0.107       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.725       |
| ExplainedVarOld | 0.716       |
| KL              | 0.00292511  |
| Phi_loss        | 77.2914     |
| PolicyEntropy   | 3.65543     |
| PolicyLoss      | 0.000692959 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0296      |
| _MeanReward     | 1.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68932     |
| _max_adv        | 3.92        |
| _max_discrew    | 1.47        |
| _max_obs        | 1.52        |
| _mean_act       | -0.0378018  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.889       |
| _mean_obs       | 0.0346      |
| _min_adv        | -3.82       |
| _min_discrew    | -0.00959    |
| _min_obs        | -1.21       |
| _std_act        | 0.487301    |
| _std_adv        | 1           |
| _std_discrew    | 0.0957      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.831      |
| ExplainedVarOld | 0.824      |
| KL              | 0.00271557 |
| Phi_loss        | 78.7135    |
| PolicyEntropy   | 3.64448    |
| PolicyLoss      | -0.0034654 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0163     |
| _MeanReward     | 1.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.98812    |
| _max_adv        | 3.49       |
| _max_discrew    | 1.4        |
| _max_obs        | 1.6        |
| _mean_act       | -0.0418901 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.881      |
| _mean_obs       | 0.0338     |
| _min_adv        | -3.88      |
| _min_discrew    | -1.41e-05  |
| _min_obs        | -1.24      |
| _std_act        | 0.492112   |
| _std_adv        | 1          |
| _std_discrew    | 0.0901     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.821      |
| ExplainedVarOld | 0.812      |
| KL              | 0.00333918 |
| Phi_loss        | 84.7607    |
| PolicyEntropy   | 3.60128    |
| PolicyLoss      | 0.0075098  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0162     |
| _MeanReward     | 1.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58233    |
| _max_adv        | 3.15       |
| _max_discrew    | 1.6        |
| _max_obs        | 1.38       |
| _mean_act       | -0.0402405 |
| _mean_adv       | -5.97e-17  |
| _mean_discrew   | 0.948      |
| _mean_obs       | 0.0327     |
| _min_adv        | -3.84      |
| _min_discrew    | -0.00964   |
| _min_obs        | -1.23      |
| _std_act        | 0.473683   |
| _std_adv        | 1          |
| _std_discrew    | 0.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.802       |
| ExplainedVarOld | 0.794       |
| KL              | 0.00285873  |
| Phi_loss        | 82.9764     |
| PolicyEntropy   | 3.5918      |
| PolicyLoss      | -0.00744111 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0207      |
| _MeanReward     | 1.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74424     |
| _max_adv        | 3.43        |
| _max_discrew    | 1.42        |
| _max_obs        | 1.51        |
| _mean_act       | -0.0364596  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.939       |
| _mean_obs       | 0.0345      |
| _min_adv        | -3.98       |
| _min_discrew    | -0.00287    |
| _min_obs        | -1.21       |
| _std_act        | 0.480511    |
| _std_adv        | 1           |
| _std_discrew    | 0.101       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.853      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00289703 |
| Phi_loss        | 86.8783    |
| PolicyEntropy   | 3.57019    |
| PolicyLoss      | 0.00285628 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0149     |
| _MeanReward     | 1.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61517    |
| _max_adv        | 2.93       |
| _max_discrew    | 1.55       |
| _max_obs        | 1.57       |
| _mean_act       | -0.0417475 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 0.932      |
| _mean_obs       | 0.0306     |
| _min_adv        | -3.96      |
| _min_discrew    | -0.0293    |
| _min_obs        | -1.35      |
| _std_act        | 0.468598   |
| _std_adv        | 1          |
| _std_discrew    | 0.109      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.796      |
| ExplainedVarOld | 0.793      |
| KL              | 0.00347981 |
| Phi_loss        | 83.9753    |
| PolicyEntropy   | 3.55828    |
| PolicyLoss      | 0.00283076 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0223     |
| _MeanReward     | 1.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55895    |
| _max_adv        | 3.23       |
| _max_discrew    | 1.52       |
| _max_obs        | 1.81       |
| _mean_act       | -0.0361084 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.909      |
| _mean_obs       | 0.0332     |
| _min_adv        | -3.5       |
| _min_discrew    | -0.00204   |
| _min_obs        | -1.38      |
| _std_act        | 0.485299   |
| _std_adv        | 1          |
| _std_discrew    | 0.122      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.785       |
| ExplainedVarOld | 0.776       |
| KL              | 0.00281247  |
| Phi_loss        | 88.0863     |
| PolicyEntropy   | 3.53677     |
| PolicyLoss      | -0.00337853 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0263      |
| _MeanReward     | 1.16e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60232     |
| _max_adv        | 3.44        |
| _max_discrew    | 1.54        |
| _max_obs        | 1.51        |
| _mean_act       | -0.0406897  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.953       |
| _mean_obs       | 0.0324      |
| _min_adv        | -4.06       |
| _min_discrew    | -0.000787   |
| _min_obs        | -1.22       |
| _std_act        | 0.477801    |
| _std_adv        | 1           |
| _std_discrew    | 0.105       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.81        |
| ExplainedVarOld | 0.808       |
| KL              | 0.00332469  |
| Phi_loss        | 89.7003     |
| PolicyEntropy   | 3.53931     |
| PolicyLoss      | -0.00777358 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0203      |
| _MeanReward     | 1.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56281     |
| _max_adv        | 3.44        |
| _max_discrew    | 1.39        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0417171  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.911       |
| _mean_obs       | 0.0329      |
| _min_adv        | -4.06       |
| _min_discrew    | -0.0126     |
| _min_obs        | -1.21       |
| _std_act        | 0.480023    |
| _std_adv        | 1           |
| _std_discrew    | 0.0842      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.812       |
| ExplainedVarOld | 0.771       |
| KL              | 0.00352601  |
| Phi_loss        | 81.9851     |
| PolicyEntropy   | 3.53455     |
| PolicyLoss      | -0.00422196 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62005     |
| _max_adv        | 3.48        |
| _max_discrew    | 1.58        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0424129  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.956       |
| _mean_obs       | 0.0311      |
| _min_adv        | -3.53       |
| _min_discrew    | -0.0391     |
| _min_obs        | -1.21       |
| _std_act        | 0.475029    |
| _std_adv        | 1           |
| _std_discrew    | 0.106       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.847       |
| ExplainedVarOld | 0.839       |
| KL              | 0.00338155  |
| Phi_loss        | 91.0239     |
| PolicyEntropy   | 3.51034     |
| PolicyLoss      | -0.00679858 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0169      |
| _MeanReward     | 1.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95714     |
| _max_adv        | 3.3         |
| _max_discrew    | 1.8         |
| _max_obs        | 1.46        |
| _mean_act       | -0.0432913  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.02        |
| _mean_obs       | 0.0326      |
| _min_adv        | -3.68       |
| _min_discrew    | -0.0122     |
| _min_obs        | -1.28       |
| _std_act        | 0.485921    |
| _std_adv        | 1           |
| _std_discrew    | 0.129       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.774      |
| ExplainedVarOld | 0.759      |
| KL              | 0.00288982 |
| Phi_loss        | 89.1735    |
| PolicyEntropy   | 3.48727    |
| PolicyLoss      | 0.00761433 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0299     |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74077    |
| _max_adv        | 3.54       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.51       |
| _mean_act       | -0.0419011 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.0331     |
| _min_adv        | -4.11      |
| _min_discrew    | -0.00485   |
| _min_obs        | -1.23      |
| _std_act        | 0.47534    |
| _std_adv        | 1          |
| _std_discrew    | 0.132      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.863       |
| ExplainedVarOld | 0.854       |
| KL              | 0.00326693  |
| Phi_loss        | 88.3864     |
| PolicyEntropy   | 3.48535     |
| PolicyLoss      | -0.00647587 |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 1.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.97054     |
| _max_adv        | 4.09        |
| _max_discrew    | 1.71        |
| _max_obs        | 1.55        |
| _mean_act       | -0.0413997  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.0324      |
| _min_adv        | -3.22       |
| _min_discrew    | -0.00747    |
| _min_obs        | -1.18       |
| _std_act        | 0.472387    |
| _std_adv        | 1           |
| _std_discrew    | 0.143       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.869      |
| ExplainedVarOld | 0.861      |
| KL              | 0.00306272 |
| Phi_loss        | 86.7872    |
| PolicyEntropy   | 3.47301    |
| PolicyLoss      | -0.0113964 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 1.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48566    |
| _max_adv        | 3.18       |
| _max_discrew    | 1.67       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0452558 |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0328     |
| _min_adv        | -3.43      |
| _min_discrew    | -0.0314    |
| _min_obs        | -1.26      |
| _std_act        | 0.481106   |
| _std_adv        | 1          |
| _std_discrew    | 0.141      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.812       |
| ExplainedVarOld | 0.804       |
| KL              | 0.00309269  |
| Phi_loss        | 88.7819     |
| PolicyEntropy   | 3.47367     |
| PolicyLoss      | -0.00981307 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0267      |
| _MeanReward     | 1.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88419     |
| _max_adv        | 3.18        |
| _max_discrew    | 1.64        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0443389  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 1.05        |
| _mean_obs       | 0.0322      |
| _min_adv        | -3.86       |
| _min_discrew    | -0.0188     |
| _min_obs        | -1.23       |
| _std_act        | 0.486263    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.836      |
| ExplainedVarOld | 0.832      |
| KL              | 0.00313889 |
| Phi_loss        | 91.3479    |
| PolicyEntropy   | 3.4749     |
| PolicyLoss      | -0.0172013 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 1.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.75303    |
| _max_adv        | 3.19       |
| _max_discrew    | 1.78       |
| _max_obs        | 1.62       |
| _mean_act       | -0.0455779 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.06       |
| _mean_obs       | 0.0328     |
| _min_adv        | -3.62      |
| _min_discrew    | -5.04e-05  |
| _min_obs        | -1.23      |
| _std_act        | 0.48166    |
| _std_adv        | 1          |
| _std_discrew    | 0.138      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.785       |
| ExplainedVarOld | 0.78        |
| KL              | 0.00299884  |
| Phi_loss        | 90.8484     |
| PolicyEntropy   | 3.45478     |
| PolicyLoss      | -0.00519961 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0298      |
| _MeanReward     | 1.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84301     |
| _max_adv        | 3.04        |
| _max_discrew    | 1.68        |
| _max_obs        | 1.57        |
| _mean_act       | -0.0433967  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0335      |
| _min_adv        | -4.22       |
| _min_discrew    | -0.00256    |
| _min_obs        | -1.25       |
| _std_act        | 0.487327    |
| _std_adv        | 1           |
| _std_discrew    | 0.142       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.854       |
| ExplainedVarOld | 0.854       |
| KL              | 0.0037771   |
| Phi_loss        | 92.1919     |
| PolicyEntropy   | 3.43674     |
| PolicyLoss      | -0.00478009 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0211      |
| _MeanReward     | 1.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67083     |
| _max_adv        | 3.11        |
| _max_discrew    | 1.91        |
| _max_obs        | 1.51        |
| _mean_act       | -0.0403002  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.14        |
| _mean_obs       | 0.0343      |
| _min_adv        | -3.72       |
| _min_discrew    | -0.00653    |
| _min_obs        | -1.18       |
| _std_act        | 0.489172    |
| _std_adv        | 1           |
| _std_discrew    | 0.144       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.845       |
| ExplainedVarOld | 0.84        |
| KL              | 0.00333836  |
| Phi_loss        | 95.4555     |
| PolicyEntropy   | 3.41083     |
| PolicyLoss      | -0.00473965 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0226      |
| _MeanReward     | 1.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82418     |
| _max_adv        | 3.25        |
| _max_discrew    | 1.83        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0474466  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.1         |
| _mean_obs       | 0.0334      |
| _min_adv        | -3.92       |
| _min_discrew    | -0.0127     |
| _min_obs        | -1.31       |
| _std_act        | 0.490424    |
| _std_adv        | 1           |
| _std_discrew    | 0.141       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.848      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00359768 |
| Phi_loss        | 101.173    |
| PolicyEntropy   | 3.37211    |
| PolicyLoss      | 0.00689375 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0215     |
| _MeanReward     | 1.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67583    |
| _max_adv        | 3.11       |
| _max_discrew    | 1.88       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0458273 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.11       |
| _mean_obs       | 0.0337     |
| _min_adv        | -4.3       |
| _min_discrew    | 0.000689   |
| _min_obs        | -1.22      |
| _std_act        | 0.493033   |
| _std_adv        | 1          |
| _std_discrew    | 0.139      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.834      |
| ExplainedVarOld | 0.83       |
| KL              | 0.00336458 |
| Phi_loss        | 104.747    |
| PolicyEntropy   | 3.34718    |
| PolicyLoss      | 0.0013449  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 1.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7591     |
| _max_adv        | 2.85       |
| _max_discrew    | 1.88       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0484365 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 1.2        |
| _mean_obs       | 0.0323     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.0247    |
| _min_obs        | -1.18      |
| _std_act        | 0.483539   |
| _std_adv        | 1          |
| _std_discrew    | 0.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.854      |
| ExplainedVarOld | 0.837      |
| KL              | 0.00297134 |
| Phi_loss        | 98.57      |
| PolicyEntropy   | 3.32854    |
| PolicyLoss      | -0.0136321 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0265     |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78779    |
| _max_adv        | 3.71       |
| _max_discrew    | 1.89       |
| _max_obs        | 1.53       |
| _mean_act       | -0.0471643 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.0327     |
| _min_adv        | -3.48      |
| _min_discrew    | -0.00475   |
| _min_obs        | -1.18      |
| _std_act        | 0.491172   |
| _std_adv        | 1          |
| _std_discrew    | 0.159      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.853      |
| ExplainedVarOld | 0.846      |
| KL              | 0.00309048 |
| Phi_loss        | 101.398    |
| PolicyEntropy   | 3.28398    |
| PolicyLoss      | 0.00368469 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0234     |
| _MeanReward     | 1.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.87977    |
| _max_adv        | 2.61       |
| _max_discrew    | 2.06       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0541953 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.14       |
| _mean_obs       | 0.0337     |
| _min_adv        | -8.83      |
| _min_discrew    | -0.48      |
| _min_obs        | -1.21      |
| _std_act        | 0.520224   |
| _std_adv        | 1          |
| _std_discrew    | 0.253      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.832      |
| ExplainedVarOld | 0.814      |
| KL              | 0.00333568 |
| Phi_loss        | 94.5419    |
| PolicyEntropy   | 3.25105    |
| PolicyLoss      | 0.00687895 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0424     |
| _MeanReward     | 1.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50515    |
| _max_adv        | 2.83       |
| _max_discrew    | 1.83       |
| _max_obs        | 1.46       |
| _mean_act       | -0.0582885 |
| _mean_adv       | -2.91e-17  |
| _mean_discrew   | 1.08       |
| _mean_obs       | 0.0309     |
| _min_adv        | -11        |
| _min_discrew    | -0.62      |
| _min_obs        | -1.24      |
| _std_act        | 0.521385   |
| _std_adv        | 1          |
| _std_discrew    | 0.248      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.788      |
| ExplainedVarOld | 0.762      |
| KL              | 0.00320762 |
| Phi_loss        | 101.562    |
| PolicyEntropy   | 3.23026    |
| PolicyLoss      | 0.00402705 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0528     |
| _MeanReward     | 1.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79692    |
| _max_adv        | 4.46       |
| _max_discrew    | 1.74       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0487439 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.2        |
| _mean_obs       | 0.0336     |
| _min_adv        | -3.75      |
| _min_discrew    | 0.000388   |
| _min_obs        | -1.25      |
| _std_act        | 0.491212   |
| _std_adv        | 1          |
| _std_discrew    | 0.145      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.834       |
| ExplainedVarOld | 0.823       |
| KL              | 0.00270353  |
| Phi_loss        | 101.144     |
| PolicyEntropy   | 3.2235      |
| PolicyLoss      | -0.00899438 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0255      |
| _MeanReward     | 1.55e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83008     |
| _max_adv        | 3.93        |
| _max_discrew    | 1.98        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0466218  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.28        |
| _mean_obs       | 0.0323      |
| _min_adv        | -4.93       |
| _min_discrew    | -0.00634    |
| _min_obs        | -1.22       |
| _std_act        | 0.482806    |
| _std_adv        | 1           |
| _std_discrew    | 0.197       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.879       |
| ExplainedVarOld | 0.845       |
| KL              | 0.00331019  |
| Phi_loss        | 98.8627     |
| PolicyEntropy   | 3.20131     |
| PolicyLoss      | -0.00847968 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0247      |
| _MeanReward     | 1.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66058     |
| _max_adv        | 3.51        |
| _max_discrew    | 1.91        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0436789  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.21        |
| _mean_obs       | 0.0339      |
| _min_adv        | -3.73       |
| _min_discrew    | 0.00206     |
| _min_obs        | -1.19       |
| _std_act        | 0.498564    |
| _std_adv        | 1           |
| _std_discrew    | 0.183       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.869      |
| KL              | 0.00345494 |
| Phi_loss        | 113.4      |
| PolicyEntropy   | 3.17279    |
| PolicyLoss      | 0.00282719 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0233     |
| _MeanReward     | 1.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.98333    |
| _max_adv        | 3.43       |
| _max_discrew    | 1.92       |
| _max_obs        | 1.54       |
| _mean_act       | -0.044789  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0333     |
| _min_adv        | -3.46      |
| _min_discrew    | -0.00092   |
| _min_obs        | -1.2       |
| _std_act        | 0.494519   |
| _std_adv        | 1          |
| _std_discrew    | 0.179      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.878      |
| ExplainedVarOld | 0.874      |
| KL              | 0.00378805 |
| Phi_loss        | 115.923    |
| PolicyEntropy   | 3.15585    |
| PolicyLoss      | -0.011824  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0225     |
| _MeanReward     | 1.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67606    |
| _max_adv        | 5.36       |
| _max_discrew    | 2.03       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0413652 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0342     |
| _min_adv        | -3.63      |
| _min_discrew    | -0.000338  |
| _min_obs        | -1.19      |
| _std_act        | 0.489215   |
| _std_adv        | 1          |
| _std_discrew    | 0.202      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.871       |
| ExplainedVarOld | 0.865       |
| KL              | 0.00353286  |
| Phi_loss        | 116.491     |
| PolicyEntropy   | 3.13315     |
| PolicyLoss      | -0.00635053 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0271      |
| _MeanReward     | 1.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.61545     |
| _max_adv        | 3.05        |
| _max_discrew    | 1.98        |
| _max_obs        | 1.46        |
| _mean_act       | -0.0426091  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 1.34        |
| _mean_obs       | 0.0337      |
| _min_adv        | -3.69       |
| _min_discrew    | -0.00458    |
| _min_obs        | -1.34       |
| _std_act        | 0.492611    |
| _std_adv        | 1           |
| _std_discrew    | 0.211       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.888       |
| KL              | 0.00291949  |
| Phi_loss        | 115.834     |
| PolicyEntropy   | 3.10584     |
| PolicyLoss      | -0.00425487 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0229      |
| _MeanReward     | 1.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.45463     |
| _max_adv        | 3.87        |
| _max_discrew    | 2.1         |
| _max_obs        | 1.42        |
| _mean_act       | -0.0398483  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.34        |
| _mean_obs       | 0.035       |
| _min_adv        | -4.2        |
| _min_discrew    | -0.00815    |
| _min_obs        | -1.31       |
| _std_act        | 0.496582    |
| _std_adv        | 1           |
| _std_discrew    | 0.193       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.905      |
| ExplainedVarOld | 0.893      |
| KL              | 0.00340385 |
| Phi_loss        | 105.641    |
| PolicyEntropy   | 3.08683    |
| PolicyLoss      | 0.00679771 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 1.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7644     |
| _max_adv        | 3.22       |
| _max_discrew    | 1.99       |
| _max_obs        | 1.36       |
| _mean_act       | -0.040774  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.33       |
| _mean_obs       | 0.0355     |
| _min_adv        | -4.42      |
| _min_discrew    | -0.00467   |
| _min_obs        | -1.2       |
| _std_act        | 0.49872    |
| _std_adv        | 1          |
| _std_discrew    | 0.208      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.922      |
| ExplainedVarOld | 0.921      |
| KL              | 0.00407332 |
| Phi_loss        | 122.359    |
| PolicyEntropy   | 3.07979    |
| PolicyLoss      | -0.0055178 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0164     |
| _MeanReward     | 1.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70875    |
| _max_adv        | 3.52       |
| _max_discrew    | 2.05       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0433935 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 1.4        |
| _mean_obs       | 0.0347     |
| _min_adv        | -4.53      |
| _min_discrew    | -0.00688   |
| _min_obs        | -1.31      |
| _std_act        | 0.491188   |
| _std_adv        | 1          |
| _std_discrew    | 0.222      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.902       |
| ExplainedVarOld | 0.893       |
| KL              | 0.0041502   |
| Phi_loss        | 115.894     |
| PolicyEntropy   | 3.05674     |
| PolicyLoss      | -0.00710997 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0227      |
| _MeanReward     | 1.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.88514     |
| _max_adv        | 3.22        |
| _max_discrew    | 1.95        |
| _max_obs        | 1.47        |
| _mean_act       | -0.045522   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.33        |
| _mean_obs       | 0.0344      |
| _min_adv        | -4.38       |
| _min_discrew    | 0.00389     |
| _min_obs        | -1.24       |
| _std_act        | 0.495784    |
| _std_adv        | 1           |
| _std_discrew    | 0.167       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.873      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00398314 |
| Phi_loss        | 116.759    |
| PolicyEntropy   | 3.02602    |
| PolicyLoss      | 0.00373798 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0219     |
| _MeanReward     | 1.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.92596    |
| _max_adv        | 3.48       |
| _max_discrew    | 2.23       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0422178 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.41       |
| _mean_obs       | 0.0341     |
| _min_adv        | -4.33      |
| _min_discrew    | 0.0086     |
| _min_obs        | -1.13      |
| _std_act        | 0.495225   |
| _std_adv        | 1          |
| _std_discrew    | 0.222      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.886        |
| ExplainedVarOld | 0.887        |
| KL              | 0.00411478   |
| Phi_loss        | 128.553      |
| PolicyEntropy   | 2.99559      |
| PolicyLoss      | -0.000330567 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0259       |
| _MeanReward     | 1.76e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.70626      |
| _max_adv        | 4.65         |
| _max_discrew    | 2.23         |
| _max_obs        | 1.36         |
| _mean_act       | -0.0403593   |
| _mean_adv       | -1.71e-17    |
| _mean_discrew   | 1.45         |
| _mean_obs       | 0.0343       |
| _min_adv        | -3.98        |
| _min_discrew    | 0.00177      |
| _min_obs        | -1.47        |
| _std_act        | 0.495009     |
| _std_adv        | 1            |
| _std_discrew    | 0.228        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.87        |
| ExplainedVarOld | 0.859       |
| KL              | 0.00333067  |
| Phi_loss        | 128.796     |
| PolicyEntropy   | 2.97699     |
| PolicyLoss      | -0.00337367 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0296      |
| _MeanReward     | 1.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.84442     |
| _max_adv        | 3.38        |
| _max_discrew    | 2.31        |
| _max_obs        | 1.39        |
| _mean_act       | -0.0801188  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.2         |
| _mean_obs       | 0.0315      |
| _min_adv        | -10.7       |
| _min_discrew    | -0.848      |
| _min_obs        | -1.27       |
| _std_act        | 0.576971    |
| _std_adv        | 1           |
| _std_discrew    | 0.585       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.872      |
| KL              | 0.00536932 |
| Phi_loss        | 107.803    |
| PolicyEntropy   | 2.96323    |
| PolicyLoss      | 0.00281342 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0569     |
| _MeanReward     | 1.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44831    |
| _max_adv        | 4.2        |
| _max_discrew    | 2.26       |
| _max_obs        | 1.53       |
| _mean_act       | -0.0710849 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.032      |
| _min_adv        | -14.4      |
| _min_discrew    | -0.813     |
| _min_obs        | -1.17      |
| _std_act        | 0.549764   |
| _std_adv        | 1          |
| _std_discrew    | 0.507      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.877       |
| ExplainedVarOld | 0.873       |
| KL              | 0.00350739  |
| Phi_loss        | 110.855     |
| PolicyEntropy   | 2.94473     |
| PolicyLoss      | -0.00783581 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0625      |
| _MeanReward     | 1.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5377      |
| _max_adv        | 6.4         |
| _max_discrew    | 2.15        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0403852  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.5         |
| _mean_obs       | 0.0347      |
| _min_adv        | -4.61       |
| _min_discrew    | -0.00425    |
| _min_obs        | -1.34       |
| _std_act        | 0.496888    |
| _std_adv        | 1           |
| _std_discrew    | 0.251       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.905      |
| ExplainedVarOld | 0.899      |
| KL              | 0.00329406 |
| Phi_loss        | 134.259    |
| PolicyEntropy   | 2.92347    |
| PolicyLoss      | -0.0123843 |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 1.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84078    |
| _max_adv        | 4.68       |
| _max_discrew    | 2.26       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0437012 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.53       |
| _mean_obs       | 0.0351     |
| _min_adv        | -4.97      |
| _min_discrew    | -0.000366  |
| _min_obs        | -1.22      |
| _std_act        | 0.496994   |
| _std_adv        | 1          |
| _std_discrew    | 0.261      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.92       |
| ExplainedVarOld | 0.912      |
| KL              | 0.00329881 |
| Phi_loss        | 135.042    |
| PolicyEntropy   | 2.89688    |
| PolicyLoss      | -0.0165383 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0213     |
| _MeanReward     | 1.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7573     |
| _max_adv        | 2.96       |
| _max_discrew    | 2.3        |
| _max_obs        | 1.42       |
| _mean_act       | -0.0433825 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 1.52       |
| _mean_obs       | 0.0346     |
| _min_adv        | -4.99      |
| _min_discrew    | 0.000216   |
| _min_obs        | -1.19      |
| _std_act        | 0.502255   |
| _std_adv        | 1          |
| _std_discrew    | 0.254      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.885      |
| KL              | 0.00319702 |
| Phi_loss        | 136.875    |
| PolicyEntropy   | 2.86504    |
| PolicyLoss      | 0.0079554  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0287     |
| _MeanReward     | 1.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78806    |
| _max_adv        | 2.83       |
| _max_discrew    | 2.3        |
| _max_obs        | 1.33       |
| _mean_act       | -0.0421884 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.53       |
| _mean_obs       | 0.0354     |
| _min_adv        | -4.56      |
| _min_discrew    | -0.00471   |
| _min_obs        | -1.14      |
| _std_act        | 0.505552   |
| _std_adv        | 1          |
| _std_discrew    | 0.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.913      |
| ExplainedVarOld | 0.911      |
| KL              | 0.00308862 |
| Phi_loss        | 136.839    |
| PolicyEntropy   | 2.84884    |
| PolicyLoss      | 0.00110173 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0236     |
| _MeanReward     | 1.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.97979    |
| _max_adv        | 3.06       |
| _max_discrew    | 2.28       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0371133 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 1.56       |
| _mean_obs       | 0.0351     |
| _min_adv        | -4.16      |
| _min_discrew    | -0.00473   |
| _min_obs        | -1.16      |
| _std_act        | 0.498169   |
| _std_adv        | 1          |
| _std_discrew    | 0.242      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.913       |
| KL              | 0.00323137  |
| Phi_loss        | 138.748     |
| PolicyEntropy   | 2.81525     |
| PolicyLoss      | -0.00231379 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0202      |
| _MeanReward     | 1.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67428     |
| _max_adv        | 2.89        |
| _max_discrew    | 2.34        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0411418  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 1.55        |
| _mean_obs       | 0.0359      |
| _min_adv        | -4.21       |
| _min_discrew    | 0.00118     |
| _min_obs        | -1.22       |
| _std_act        | 0.511456    |
| _std_adv        | 1           |
| _std_discrew    | 0.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.912      |
| KL              | 0.00398819 |
| Phi_loss        | 139.837    |
| PolicyEntropy   | 2.80271    |
| PolicyLoss      | -0.014674  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0203     |
| _MeanReward     | 1.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64514    |
| _max_adv        | 3.53       |
| _max_discrew    | 2.41       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0406616 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.57       |
| _mean_obs       | 0.0361     |
| _min_adv        | -3.99      |
| _min_discrew    | -0.00321   |
| _min_obs        | -1.19      |
| _std_act        | 0.515713   |
| _std_adv        | 1          |
| _std_discrew    | 0.278      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.91       |
| ExplainedVarOld | 0.904      |
| KL              | 0.00362445 |
| Phi_loss        | 146.253    |
| PolicyEntropy   | 2.7734     |
| PolicyLoss      | 0.00984456 |
| Steps           | 10000      |
| VarFuncLoss     | 0.025      |
| _MeanReward     | 2e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.54839    |
| _max_adv        | 4.12       |
| _max_discrew    | 2.38       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0374845 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.66       |
| _mean_obs       | 0.036      |
| _min_adv        | -3.64      |
| _min_discrew    | 0.00044    |
| _min_obs        | -1.28      |
| _std_act        | 0.507497   |
| _std_adv        | 1          |
| _std_discrew    | 0.292      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.913      |
| KL              | 0.00422588 |
| Phi_loss        | 137.069    |
| PolicyEntropy   | 2.73821    |
| PolicyLoss      | -0.0105728 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0237     |
| _MeanReward     | 1.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86583    |
| _max_adv        | 4.17       |
| _max_discrew    | 2.48       |
| _max_obs        | 1.34       |
| _mean_act       | -0.034365  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.64       |
| _mean_obs       | 0.0358     |
| _min_adv        | -5.56      |
| _min_discrew    | -0.00453   |
| _min_obs        | -1.24      |
| _std_act        | 0.504578   |
| _std_adv        | 1          |
| _std_discrew    | 0.282      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00393948 |
| Phi_loss        | 143.122    |
| PolicyEntropy   | 2.74093    |
| PolicyLoss      | -0.0125217 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0191     |
| _MeanReward     | 2.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67773    |
| _max_adv        | 3.99       |
| _max_discrew    | 2.49       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0330403 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.66       |
| _mean_obs       | 0.0361     |
| _min_adv        | -3.93      |
| _min_discrew    | -0.00272   |
| _min_obs        | -1.27      |
| _std_act        | 0.506021   |
| _std_adv        | 1          |
| _std_discrew    | 0.278      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.921      |
| KL              | 0.00328691 |
| Phi_loss        | 146.944    |
| PolicyEntropy   | 2.72075    |
| PolicyLoss      | -0.0184848 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0211     |
| _MeanReward     | 2.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77837    |
| _max_adv        | 3.06       |
| _max_discrew    | 2.53       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0339123 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.66       |
| _mean_obs       | 0.0364     |
| _min_adv        | -3.97      |
| _min_discrew    | -0.00499   |
| _min_obs        | -1.2       |
| _std_act        | 0.515053   |
| _std_adv        | 1          |
| _std_discrew    | 0.296      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.909       |
| ExplainedVarOld | 0.907       |
| KL              | 0.00325243  |
| Phi_loss        | 151.773     |
| PolicyEntropy   | 2.68974     |
| PolicyLoss      | -0.00266033 |
| Steps           | 10000       |
| VarFuncLoss     | 0.027       |
| _MeanReward     | 1.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66649     |
| _max_adv        | 3.97        |
| _max_discrew    | 2.39        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0332144  |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 1.62        |
| _mean_obs       | 0.0367      |
| _min_adv        | -3.99       |
| _min_discrew    | 0.00389     |
| _min_obs        | -1.16       |
| _std_act        | 0.521579    |
| _std_adv        | 1           |
| _std_discrew    | 0.265       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.921      |
| KL              | 0.00331833 |
| Phi_loss        | 139.534    |
| PolicyEntropy   | 2.67074    |
| PolicyLoss      | 0.00412231 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0205     |
| _MeanReward     | 2.05e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68619    |
| _max_adv        | 2.6        |
| _max_discrew    | 2.72       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0320576 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 1.71       |
| _mean_obs       | 0.0366     |
| _min_adv        | -4.82      |
| _min_discrew    | 0.00361    |
| _min_obs        | -1.17      |
| _std_act        | 0.516357   |
| _std_adv        | 1          |
| _std_discrew    | 0.299      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.891       |
| ExplainedVarOld | 0.889       |
| KL              | 0.0040943   |
| Phi_loss        | 151.958     |
| PolicyEntropy   | 2.62155     |
| PolicyLoss      | -0.00419257 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0342      |
| _MeanReward     | 2.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60902     |
| _max_adv        | 3.97        |
| _max_discrew    | 2.47        |
| _max_obs        | 1.49        |
| _mean_act       | -0.0348884  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.73        |
| _mean_obs       | 0.037       |
| _min_adv        | -4.49       |
| _min_discrew    | 0.00263     |
| _min_obs        | -1.4        |
| _std_act        | 0.518213    |
| _std_adv        | 1           |
| _std_discrew    | 0.286       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.901      |
| ExplainedVarOld | 0.894      |
| KL              | 0.00373867 |
| Phi_loss        | 154.587    |
| PolicyEntropy   | 2.60369    |
| PolicyLoss      | -0.0124688 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0283     |
| _MeanReward     | 2.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85906    |
| _max_adv        | 3.27       |
| _max_discrew    | 2.6        |
| _max_obs        | 1.34       |
| _mean_act       | -0.0324792 |
| _mean_adv       | 5.68e-17   |
| _mean_discrew   | 1.75       |
| _mean_obs       | 0.0369     |
| _min_adv        | -3.55      |
| _min_discrew    | 0.00207    |
| _min_obs        | -1.21      |
| _std_act        | 0.518037   |
| _std_adv        | 1          |
| _std_discrew    | 0.323      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.9         |
| ExplainedVarOld | 0.898       |
| KL              | 0.00385738  |
| Phi_loss        | 168.635     |
| PolicyEntropy   | 2.57629     |
| PolicyLoss      | -0.00813056 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0324      |
| _MeanReward     | 2.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63305     |
| _max_adv        | 3.57        |
| _max_discrew    | 2.51        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0297735  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 1.73        |
| _mean_obs       | 0.0368      |
| _min_adv        | -3.34       |
| _min_discrew    | 0.000674    |
| _min_obs        | -1.25       |
| _std_act        | 0.514833    |
| _std_adv        | 1           |
| _std_discrew    | 0.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.93       |
| ExplainedVarOld | 0.924      |
| KL              | 0.00332077 |
| Phi_loss        | 151.888    |
| PolicyEntropy   | 2.57234    |
| PolicyLoss      | -0.0141967 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0204     |
| _MeanReward     | 2.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54585    |
| _max_adv        | 2.76       |
| _max_discrew    | 2.45       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0309127 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.71       |
| _mean_obs       | 0.0372     |
| _min_adv        | -3.72      |
| _min_discrew    | -0.00157   |
| _min_obs        | -1.15      |
| _std_act        | 0.525628   |
| _std_adv        | 1          |
| _std_discrew    | 0.321      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00439975 |
| Phi_loss        | 155.537    |
| PolicyEntropy   | 2.55918    |
| PolicyLoss      | 0.00342932 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0238     |
| _MeanReward     | 2.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66222    |
| _max_adv        | 3.51       |
| _max_discrew    | 2.48       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0311424 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.76       |
| _mean_obs       | 0.037      |
| _min_adv        | -3.94      |
| _min_discrew    | 0.00654    |
| _min_obs        | -1.29      |
| _std_act        | 0.519897   |
| _std_adv        | 1          |
| _std_discrew    | 0.302      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00412416 |
| Phi_loss        | 170.273    |
| PolicyEntropy   | 2.52443    |
| PolicyLoss      | 0.0011556  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0169     |
| _MeanReward     | 2.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69035    |
| _max_adv        | 3.91       |
| _max_discrew    | 2.59       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0285604 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 1.82       |
| _mean_obs       | 0.0375     |
| _min_adv        | -3.93      |
| _min_discrew    | 0.0023     |
| _min_obs        | -1.17      |
| _std_act        | 0.513894   |
| _std_adv        | 1          |
| _std_discrew    | 0.343      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.93       |
| ExplainedVarOld | 0.928      |
| KL              | 0.00352625 |
| Phi_loss        | 171.879    |
| PolicyEntropy   | 2.49075    |
| PolicyLoss      | 0.00186163 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0246     |
| _MeanReward     | 2.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62608    |
| _max_adv        | 2.48       |
| _max_discrew    | 2.68       |
| _max_obs        | 1.33       |
| _mean_act       | -0.027919  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.83       |
| _mean_obs       | 0.038      |
| _min_adv        | -4.14      |
| _min_discrew    | 0.00403    |
| _min_obs        | -1.17      |
| _std_act        | 0.525994   |
| _std_adv        | 1          |
| _std_discrew    | 0.338      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.915       |
| KL              | 0.00380137  |
| Phi_loss        | 175.547     |
| PolicyEntropy   | 2.45931     |
| PolicyLoss      | -0.00831992 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0281      |
| _MeanReward     | 2.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56827     |
| _max_adv        | 4.44        |
| _max_discrew    | 2.87        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0286612  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 1.86        |
| _mean_obs       | 0.0382      |
| _min_adv        | -4.57       |
| _min_discrew    | -0.00227    |
| _min_obs        | -1.2        |
| _std_act        | 0.524854    |
| _std_adv        | 1           |
| _std_discrew    | 0.365       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.941       |
| KL              | 0.0036502   |
| Phi_loss        | 184.828     |
| PolicyEntropy   | 2.43116     |
| PolicyLoss      | -0.00511091 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0212      |
| _MeanReward     | 2.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71766     |
| _max_adv        | 4.54        |
| _max_discrew    | 2.76        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0273639  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 1.92        |
| _mean_obs       | 0.0391      |
| _min_adv        | -3.59       |
| _min_discrew    | -0.0045     |
| _min_obs        | -1.13       |
| _std_act        | 0.530584    |
| _std_adv        | 1           |
| _std_discrew    | 0.356       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.946       |
| ExplainedVarOld | 0.941       |
| KL              | 0.00420123  |
| Phi_loss        | 179.864     |
| PolicyEntropy   | 2.40393     |
| PolicyLoss      | 0.000792692 |
| Steps           | 10000       |
| VarFuncLoss     | 0.02        |
| _MeanReward     | 2.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76449     |
| _max_adv        | 5.06        |
| _max_discrew    | 2.74        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0311337  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.84        |
| _mean_obs       | 0.0379      |
| _min_adv        | -4.33       |
| _min_discrew    | 0.00573     |
| _min_obs        | -1.21       |
| _std_act        | 0.527082    |
| _std_adv        | 1           |
| _std_discrew    | 0.349       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.903      |
| ExplainedVarOld | 0.9        |
| KL              | 0.00453608 |
| Phi_loss        | 178.845    |
| PolicyEntropy   | 2.39473    |
| PolicyLoss      | 0.00340462 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0348     |
| _MeanReward     | 2.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45562    |
| _max_adv        | 2.73       |
| _max_discrew    | 2.71       |
| _max_obs        | 1.69       |
| _mean_act       | -0.028683  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.93       |
| _mean_obs       | 0.0381     |
| _min_adv        | -4.68      |
| _min_discrew    | -5.68e-05  |
| _min_obs        | -1.16      |
| _std_act        | 0.52623    |
| _std_adv        | 1          |
| _std_discrew    | 0.376      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.942       |
| ExplainedVarOld | 0.936       |
| KL              | 0.0040544   |
| Phi_loss        | 183.736     |
| PolicyEntropy   | 2.34686     |
| PolicyLoss      | 3.56402e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0238      |
| _MeanReward     | 2.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.53289     |
| _max_adv        | 3.93        |
| _max_discrew    | 2.79        |
| _max_obs        | 1.41        |
| _mean_act       | -0.0260147  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.96        |
| _mean_obs       | 0.0381      |
| _min_adv        | -4.05       |
| _min_discrew    | 0.000808    |
| _min_obs        | -1.22       |
| _std_act        | 0.525444    |
| _std_adv        | 1           |
| _std_discrew    | 0.429       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.919       |
| ExplainedVarOld | 0.912       |
| KL              | 0.00393855  |
| Phi_loss        | 186.605     |
| PolicyEntropy   | 2.31794     |
| PolicyLoss      | -0.00724897 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0348      |
| _MeanReward     | 2.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72871     |
| _max_adv        | 3.62        |
| _max_discrew    | 2.81        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0287489  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.97        |
| _mean_obs       | 0.039       |
| _min_adv        | -4.34       |
| _min_discrew    | 0.00631     |
| _min_obs        | -1.24       |
| _std_act        | 0.53316     |
| _std_adv        | 1           |
| _std_discrew    | 0.398       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00476079 |
| Phi_loss        | 185.721    |
| PolicyEntropy   | 2.30165    |
| PolicyLoss      | -0.0120368 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0231     |
| _MeanReward     | 2.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55948    |
| _max_adv        | 3.71       |
| _max_discrew    | 2.94       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0295082 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 1.96       |
| _mean_obs       | 0.0375     |
| _min_adv        | -3.59      |
| _min_discrew    | 0.00509    |
| _min_obs        | -1.17      |
| _std_act        | 0.523773   |
| _std_adv        | 1          |
| _std_discrew    | 0.377      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.916      |
| ExplainedVarOld | 0.909      |
| KL              | 0.00363252 |
| Phi_loss        | 188.507    |
| PolicyEntropy   | 2.29142    |
| PolicyLoss      | -0.0190801 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0315     |
| _MeanReward     | 2.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65563    |
| _max_adv        | 3.6        |
| _max_discrew    | 2.86       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0279964 |
| _mean_adv       | 5.4e-17    |
| _mean_discrew   | 2.02       |
| _mean_obs       | 0.0395     |
| _min_adv        | -3.89      |
| _min_discrew    | 0.00591    |
| _min_obs        | -1.19      |
| _std_act        | 0.531416   |
| _std_adv        | 1          |
| _std_discrew    | 0.416      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.95        |
| ExplainedVarOld | 0.948       |
| KL              | 0.00425272  |
| Phi_loss        | 194.42      |
| PolicyEntropy   | 2.27226     |
| PolicyLoss      | -0.00368462 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0215      |
| _MeanReward     | 2.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.62717     |
| _max_adv        | 3.26        |
| _max_discrew    | 2.87        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0264682  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.02        |
| _mean_obs       | 0.0379      |
| _min_adv        | -4.07       |
| _min_discrew    | 0.00161     |
| _min_obs        | -1.16       |
| _std_act        | 0.526211    |
| _std_adv        | 1           |
| _std_discrew    | 0.421       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.936      |
| KL              | 0.00415423 |
| Phi_loss        | 204.5      |
| PolicyEntropy   | 2.23156    |
| PolicyLoss      | 0.00106759 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0251     |
| _MeanReward     | 2.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.87518    |
| _max_adv        | 3.81       |
| _max_discrew    | 2.91       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0286312 |
| _mean_adv       | 5.12e-17   |
| _mean_discrew   | 2.06       |
| _mean_obs       | 0.0379     |
| _min_adv        | -4.4       |
| _min_discrew    | 0.00354    |
| _min_obs        | -1.15      |
| _std_act        | 0.53374    |
| _std_adv        | 1          |
| _std_discrew    | 0.443      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.937      |
| ExplainedVarOld | 0.936      |
| KL              | 0.00318074 |
| Phi_loss        | 214.661    |
| PolicyEntropy   | 2.21424    |
| PolicyLoss      | 0.00347443 |
| Steps           | 10000      |
| VarFuncLoss     | 0.028      |
| _MeanReward     | 2.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53498    |
| _max_adv        | 3.26       |
| _max_discrew    | 2.75       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0332394 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.01       |
| _mean_obs       | 0.038      |
| _min_adv        | -4.42      |
| _min_discrew    | -0.00346   |
| _min_obs        | -1.23      |
| _std_act        | 0.538585   |
| _std_adv        | 1          |
| _std_discrew    | 0.388      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.935      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00311575 |
| Phi_loss        | 200.758    |
| PolicyEntropy   | 2.19652    |
| PolicyLoss      | -0.0015538 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0257     |
| _MeanReward     | 2.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.61059    |
| _max_adv        | 3.13       |
| _max_discrew    | 2.81       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0325335 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 2.05       |
| _mean_obs       | 0.0378     |
| _min_adv        | -4.51      |
| _min_discrew    | 0.00828    |
| _min_obs        | -1.14      |
| _std_act        | 0.534828   |
| _std_adv        | 1          |
| _std_discrew    | 0.425      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.962       |
| ExplainedVarOld | 0.96        |
| KL              | 0.00424538  |
| Phi_loss        | 223.52      |
| PolicyEntropy   | 2.1592      |
| PolicyLoss      | -0.00097183 |
| Steps           | 10000       |
| VarFuncLoss     | 0.017       |
| _MeanReward     | 2.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58011     |
| _max_adv        | 4.69        |
| _max_discrew    | 3.07        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0311619  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 2.1         |
| _mean_obs       | 0.0384      |
| _min_adv        | -4.74       |
| _min_discrew    | -0.00565    |
| _min_obs        | -1.2        |
| _std_act        | 0.538263    |
| _std_adv        | 1           |
| _std_discrew    | 0.466       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.925      |
| KL              | 0.00397435 |
| Phi_loss        | 217.806    |
| PolicyEntropy   | 2.15648    |
| PolicyLoss      | -0.0175336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0342     |
| _MeanReward     | 2.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.78925    |
| _max_adv        | 3.47       |
| _max_discrew    | 2.9        |
| _max_obs        | 1.32       |
| _mean_act       | -0.0290805 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 2.06       |
| _mean_obs       | 0.0371     |
| _min_adv        | -4.57      |
| _min_discrew    | 0.0038     |
| _min_obs        | -1.27      |
| _std_act        | 0.534587   |
| _std_adv        | 1          |
| _std_discrew    | 0.446      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.952      |
| ExplainedVarOld | 0.952      |
| KL              | 0.00477893 |
| Phi_loss        | 226.243    |
| PolicyEntropy   | 2.10489    |
| PolicyLoss      | 0.0163801  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0213     |
| _MeanReward     | 2.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67921    |
| _max_adv        | 4.15       |
| _max_discrew    | 3.03       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0256124 |
| _mean_adv       | 5.68e-17   |
| _mean_discrew   | 2.12       |
| _mean_obs       | 0.0381     |
| _min_adv        | -3.63      |
| _min_discrew    | -0.00455   |
| _min_obs        | -1.16      |
| _std_act        | 0.528774   |
| _std_adv        | 1          |
| _std_discrew    | 0.481      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.957        |
| ExplainedVarOld | 0.956        |
| KL              | 0.00349406   |
| Phi_loss        | 234.281      |
| PolicyEntropy   | 2.08644      |
| PolicyLoss      | -0.000111684 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0213       |
| _MeanReward     | 2.57e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.53784      |
| _max_adv        | 3.64         |
| _max_discrew    | 2.93         |
| _max_obs        | 1.3          |
| _mean_act       | -0.0279759   |
| _mean_adv       | 0            |
| _mean_discrew   | 2.11         |
| _mean_obs       | 0.0383       |
| _min_adv        | -4.92        |
| _min_discrew    | 0.00377      |
| _min_obs        | -1.4         |
| _std_act        | 0.535475     |
| _std_adv        | 1            |
| _std_discrew    | 0.455        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.94       |
| KL              | 0.00432376 |
| Phi_loss        | 237.915    |
| PolicyEntropy   | 2.05819    |
| PolicyLoss      | 0.0126733  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0265     |
| _MeanReward     | 2.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65141    |
| _max_adv        | 2.95       |
| _max_discrew    | 3.02       |
| _max_obs        | 1.32       |
| _mean_act       | -0.023429  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.21       |
| _mean_obs       | 0.0392     |
| _min_adv        | -5.7       |
| _min_discrew    | -0.00237   |
| _min_obs        | -1.16      |
| _std_act        | 0.534338   |
| _std_adv        | 1          |
| _std_discrew    | 0.478      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00433994 |
| Phi_loss        | 228.842    |
| PolicyEntropy   | 2.06306    |
| PolicyLoss      | -0.0179939 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0196     |
| _MeanReward     | 2.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47623    |
| _max_adv        | 4          |
| _max_discrew    | 3.03       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0269661 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.18       |
| _mean_obs       | 0.0384     |
| _min_adv        | -5.42      |
| _min_discrew    | 0.00162    |
| _min_obs        | -1.21      |
| _std_act        | 0.535419   |
| _std_adv        | 1          |
| _std_discrew    | 0.481      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.96        |
| ExplainedVarOld | 0.957       |
| KL              | 0.00328601  |
| Phi_loss        | 237.597     |
| PolicyEntropy   | 2.03492     |
| PolicyLoss      | -0.00475644 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0196      |
| _MeanReward     | 2.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6887      |
| _max_adv        | 2.91        |
| _max_discrew    | 3.06        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0248959  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.22        |
| _mean_obs       | 0.0388      |
| _min_adv        | -4.86       |
| _min_discrew    | 0.00483     |
| _min_obs        | -1.16       |
| _std_act        | 0.534206    |
| _std_adv        | 1           |
| _std_discrew    | 0.499       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00290377 |
| Phi_loss        | 240.885    |
| PolicyEntropy   | 2.01703    |
| PolicyLoss      | 0.00532168 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0174     |
| _MeanReward     | 2.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.49395    |
| _max_adv        | 3.46       |
| _max_discrew    | 3.05       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0254253 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 2.23       |
| _mean_obs       | 0.0382     |
| _min_adv        | -6.44      |
| _min_discrew    | 0.00715    |
| _min_obs        | -1.16      |
| _std_act        | 0.534859   |
| _std_adv        | 1          |
| _std_discrew    | 0.482      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.944      |
| KL              | 0.00378381 |
| Phi_loss        | 251.849    |
| PolicyEntropy   | 1.97434    |
| PolicyLoss      | 0.00790392 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0258     |
| _MeanReward     | 2.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59365    |
| _max_adv        | 4.14       |
| _max_discrew    | 3.1        |
| _max_obs        | 1.21       |
| _mean_act       | -0.0260385 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 2.22       |
| _mean_obs       | 0.0386     |
| _min_adv        | -4.71      |
| _min_discrew    | 0.00221    |
| _min_obs        | -1.18      |
| _std_act        | 0.536777   |
| _std_adv        | 1          |
| _std_discrew    | 0.496      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.941       |
| ExplainedVarOld | 0.941       |
| KL              | 0.00456815  |
| Phi_loss        | 257.22      |
| PolicyEntropy   | 1.95715     |
| PolicyLoss      | 0.000730039 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0291      |
| _MeanReward     | 2.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5407      |
| _max_adv        | 4.35        |
| _max_discrew    | 3.16        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0260828  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.26        |
| _mean_obs       | 0.0385      |
| _min_adv        | -3.84       |
| _min_discrew    | 0.00403     |
| _min_obs        | -1.23       |
| _std_act        | 0.532374    |
| _std_adv        | 1           |
| _std_discrew    | 0.507       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00415279 |
| Phi_loss        | 229.713    |
| PolicyEntropy   | 1.95614    |
| PolicyLoss      | -0.0365943 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67249    |
| _max_adv        | 4.04       |
| _max_discrew    | 3.15       |
| _max_obs        | 1.26       |
| _mean_act       | -0.027008  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.038      |
| _min_adv        | -5.77      |
| _min_discrew    | 0.00877    |
| _min_obs        | -1.19      |
| _std_act        | 0.540186   |
| _std_adv        | 1          |
| _std_discrew    | 0.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.959      |
| KL              | 0.00409311 |
| Phi_loss        | 263.811    |
| PolicyEntropy   | 1.9351     |
| PolicyLoss      | 0.00868791 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 2.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61988    |
| _max_adv        | 6.28       |
| _max_discrew    | 3.1        |
| _max_obs        | 1.22       |
| _mean_act       | -0.0246981 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.24       |
| _mean_obs       | 0.0385     |
| _min_adv        | -5.32      |
| _min_discrew    | 0.00548    |
| _min_obs        | -1.17      |
| _std_act        | 0.545414   |
| _std_adv        | 1          |
| _std_discrew    | 0.496      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.942      |
| KL              | 0.00484629 |
| Phi_loss        | 250.752    |
| PolicyEntropy   | 1.9277     |
| PolicyLoss      | -0.0129234 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0262     |
| _MeanReward     | 2.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.61826    |
| _max_adv        | 5.41       |
| _max_discrew    | 3.14       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0263079 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 2.31       |
| _mean_obs       | 0.039      |
| _min_adv        | -5.53      |
| _min_discrew    | 0.00181    |
| _min_obs        | -1.14      |
| _std_act        | 0.549525   |
| _std_adv        | 1          |
| _std_discrew    | 0.497      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00489984 |
| Phi_loss        | 280.093    |
| PolicyEntropy   | 1.89438    |
| PolicyLoss      | 0.00345067 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 2.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3975     |
| _max_adv        | 3.32       |
| _max_discrew    | 3.05       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0242526 |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 2.25       |
| _mean_obs       | 0.0382     |
| _min_adv        | -4.94      |
| _min_discrew    | 0.00467    |
| _min_obs        | -1.14      |
| _std_act        | 0.540144   |
| _std_adv        | 1          |
| _std_discrew    | 0.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00344761 |
| Phi_loss        | 274.673    |
| PolicyEntropy   | 1.87723    |
| PolicyLoss      | 0.00971823 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 2.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54946    |
| _max_adv        | 4.06       |
| _max_discrew    | 3.23       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0268217 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 2.36       |
| _mean_obs       | 0.0388     |
| _min_adv        | -5.43      |
| _min_discrew    | 0.00744    |
| _min_obs        | -1.16      |
| _std_act        | 0.544095   |
| _std_adv        | 1          |
| _std_discrew    | 0.527      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.959        |
| ExplainedVarOld | 0.957        |
| KL              | 0.00409185   |
| Phi_loss        | 278.192      |
| PolicyEntropy   | 1.85964      |
| PolicyLoss      | -0.000895196 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0244       |
| _MeanReward     | 2.85e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.44912      |
| _max_adv        | 4.48         |
| _max_discrew    | 3.2          |
| _max_obs        | 1.37         |
| _mean_act       | -0.0265193   |
| _mean_adv       | -2.84e-17    |
| _mean_discrew   | 2.36         |
| _mean_obs       | 0.0388       |
| _min_adv        | -4.77        |
| _min_discrew    | 0.008        |
| _min_obs        | -1.24        |
| _std_act        | 0.544736     |
| _std_adv        | 1            |
| _std_discrew    | 0.511        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.964      |
| KL              | 0.004142   |
| Phi_loss        | 266.016    |
| PolicyEntropy   | 1.85825    |
| PolicyLoss      | -0.0143157 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0165     |
| _MeanReward     | 2.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64833    |
| _max_adv        | 3.59       |
| _max_discrew    | 3.25       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0300788 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.31       |
| _mean_obs       | 0.0375     |
| _min_adv        | -6.32      |
| _min_discrew    | 0.00269    |
| _min_obs        | -1.22      |
| _std_act        | 0.544078   |
| _std_adv        | 1          |
| _std_discrew    | 0.544      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.948       |
| ExplainedVarOld | 0.945       |
| KL              | 0.00554798  |
| Phi_loss        | 278.606     |
| PolicyEntropy   | 1.81995     |
| PolicyLoss      | -0.00139014 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0286      |
| _MeanReward     | 2.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.61565     |
| _max_adv        | 3.54        |
| _max_discrew    | 3.34        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0298775  |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | 2.37        |
| _mean_obs       | 0.0387      |
| _min_adv        | -6.45       |
| _min_discrew    | 0.000187    |
| _min_obs        | -1.33       |
| _std_act        | 0.552405    |
| _std_adv        | 1           |
| _std_discrew    | 0.529       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.956       |
| KL              | 0.00413049  |
| Phi_loss        | 286.012     |
| PolicyEntropy   | 1.80259     |
| PolicyLoss      | -0.00970333 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0238      |
| _MeanReward     | 2.85e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55746     |
| _max_adv        | 3.84        |
| _max_discrew    | 3.29        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0297578  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 2.36        |
| _mean_obs       | 0.038       |
| _min_adv        | -5.73       |
| _min_discrew    | 0.0076      |
| _min_obs        | -1.36       |
| _std_act        | 0.552616    |
| _std_adv        | 1           |
| _std_discrew    | 0.576       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.947      |
| ExplainedVarOld | 0.945      |
| KL              | 0.0043355  |
| Phi_loss        | 289.094    |
| PolicyEntropy   | 1.77717    |
| PolicyLoss      | 0.0102554  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0306     |
| _MeanReward     | 2.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7504     |
| _max_adv        | 3.91       |
| _max_discrew    | 3.31       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0287102 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 2.43       |
| _mean_obs       | 0.039      |
| _min_adv        | -4.27      |
| _min_discrew    | 0.00804    |
| _min_obs        | -1.16      |
| _std_act        | 0.543225   |
| _std_adv        | 1          |
| _std_discrew    | 0.533      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.958      |
| ExplainedVarOld | 0.957      |
| KL              | 0.00423932 |
| Phi_loss        | 298.446    |
| PolicyEntropy   | 1.75217    |
| PolicyLoss      | -0.0111293 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0235     |
| _MeanReward     | 2.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70693    |
| _max_adv        | 3.54       |
| _max_discrew    | 3.29       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0250976 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.42       |
| _mean_obs       | 0.0386     |
| _min_adv        | -4.38      |
| _min_discrew    | 0.00907    |
| _min_obs        | -1.16      |
| _std_act        | 0.547801   |
| _std_adv        | 1          |
| _std_discrew    | 0.542      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.956      |
| KL              | 0.00330053 |
| Phi_loss        | 296.433    |
| PolicyEntropy   | 1.74076    |
| PolicyLoss      | -0.0210391 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0221     |
| _MeanReward     | 2.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54203    |
| _max_adv        | 2.83       |
| _max_discrew    | 3.34       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0293338 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 2.45       |
| _mean_obs       | 0.0391     |
| _min_adv        | -4.52      |
| _min_discrew    | 0.00344    |
| _min_obs        | -1.27      |
| _std_act        | 0.554148   |
| _std_adv        | 1          |
| _std_discrew    | 0.593      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00431925 |
| Phi_loss        | 304.341    |
| PolicyEntropy   | 1.7149     |
| PolicyLoss      | -0.0175272 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5312     |
| _max_adv        | 3.22       |
| _max_discrew    | 3.35       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0219239 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.52       |
| _mean_obs       | 0.0396     |
| _min_adv        | -4.84      |
| _min_discrew    | 0.00347    |
| _min_obs        | -1.21      |
| _std_act        | 0.551862   |
| _std_adv        | 1          |
| _std_discrew    | 0.603      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00468583 |
| Phi_loss        | 319.448    |
| PolicyEntropy   | 1.67575    |
| PolicyLoss      | -0.0121249 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 3.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46826    |
| _max_adv        | 3.52       |
| _max_discrew    | 3.34       |
| _max_obs        | 1.32       |
| _mean_act       | -0.027503  |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 2.52       |
| _mean_obs       | 0.0393     |
| _min_adv        | -4.56      |
| _min_discrew    | 0.00356    |
| _min_obs        | -1.16      |
| _std_act        | 0.554836   |
| _std_adv        | 1          |
| _std_discrew    | 0.595      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.967       |
| ExplainedVarOld | 0.965       |
| KL              | 0.00408669  |
| Phi_loss        | 324.757     |
| PolicyEntropy   | 1.65508     |
| PolicyLoss      | -0.00276258 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0194      |
| _MeanReward     | 3.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58852     |
| _max_adv        | 2.93        |
| _max_discrew    | 3.27        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0258929  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 2.5         |
| _mean_obs       | 0.0392      |
| _min_adv        | -5.57       |
| _min_discrew    | 0.00532     |
| _min_obs        | -1.16       |
| _std_act        | 0.560639    |
| _std_adv        | 1           |
| _std_discrew    | 0.588       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.969      |
| KL              | 0.00381849 |
| Phi_loss        | 317.922    |
| PolicyEntropy   | 1.63292    |
| PolicyLoss      | 0.0072459  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0176     |
| _MeanReward     | 3.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.33999    |
| _max_adv        | 3.71       |
| _max_discrew    | 3.36       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0278366 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.51       |
| _mean_obs       | 0.0391     |
| _min_adv        | -4.66      |
| _min_discrew    | 0.00273    |
| _min_obs        | -1.16      |
| _std_act        | 0.555312   |
| _std_adv        | 1          |
| _std_discrew    | 0.607      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00385347 |
| Phi_loss        | 350.108    |
| PolicyEntropy   | 1.6146     |
| PolicyLoss      | -0.023499  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0169     |
| _MeanReward     | 3.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.83205    |
| _max_adv        | 2.67       |
| _max_discrew    | 3.33       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0280438 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.0387     |
| _min_adv        | -5.07      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.19      |
| _std_act        | 0.558072   |
| _std_adv        | 1          |
| _std_discrew    | 0.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00456678 |
| Phi_loss        | 339.815    |
| PolicyEntropy   | 1.59115    |
| PolicyLoss      | 0.00373871 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0209     |
| _MeanReward     | 3.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.68077    |
| _max_adv        | 3.14       |
| _max_discrew    | 3.44       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0256558 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.57       |
| _mean_obs       | 0.0389     |
| _min_adv        | -5.24      |
| _min_discrew    | 0.00252    |
| _min_obs        | -1.2       |
| _std_act        | 0.556018   |
| _std_adv        | 1          |
| _std_discrew    | 0.627      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.975       |
| KL              | 0.0038589   |
| Phi_loss        | 331.521     |
| PolicyEntropy   | 1.5578      |
| PolicyLoss      | -0.00808344 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0156      |
| _MeanReward     | 3.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86486     |
| _max_adv        | 2.54        |
| _max_discrew    | 3.5         |
| _max_obs        | 1.23        |
| _mean_act       | -0.0307708  |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 2.62        |
| _mean_obs       | 0.0397      |
| _min_adv        | -7.13       |
| _min_discrew    | 0.00317     |
| _min_obs        | -1.16       |
| _std_act        | 0.566065    |
| _std_adv        | 1           |
| _std_discrew    | 0.653       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00412609 |
| Phi_loss        | 327.611    |
| PolicyEntropy   | 1.55739    |
| PolicyLoss      | -0.0238335 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 3.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72358    |
| _max_adv        | 3.12       |
| _max_discrew    | 3.45       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0263966 |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 2.61       |
| _mean_obs       | 0.0391     |
| _min_adv        | -4.23      |
| _min_discrew    | 0.00814    |
| _min_obs        | -1.17      |
| _std_act        | 0.562865   |
| _std_adv        | 1          |
| _std_discrew    | 0.634      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.969       |
| ExplainedVarOld | 0.967       |
| KL              | 0.00536296  |
| Phi_loss        | 361.709     |
| PolicyEntropy   | 1.5494      |
| PolicyLoss      | -0.00842805 |
| Steps           | 10000       |
| VarFuncLoss     | 0.02        |
| _MeanReward     | 3.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.50929     |
| _max_adv        | 4.33        |
| _max_discrew    | 3.49        |
| _max_obs        | 1.35        |
| _mean_act       | -0.0284769  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.62        |
| _mean_obs       | 0.0393      |
| _min_adv        | -6.52       |
| _min_discrew    | 0.00955     |
| _min_obs        | -1.2        |
| _std_act        | 0.567204    |
| _std_adv        | 1           |
| _std_discrew    | 0.659       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00406402 |
| Phi_loss        | 342.16     |
| PolicyEntropy   | 1.54122    |
| PolicyLoss      | -0.0037983 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0227     |
| _MeanReward     | 3.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56363    |
| _max_adv        | 4.03       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0283903 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.6        |
| _mean_obs       | 0.0387     |
| _min_adv        | -4.97      |
| _min_discrew    | 0.00924    |
| _min_obs        | -1.22      |
| _std_act        | 0.560204   |
| _std_adv        | 1          |
| _std_discrew    | 0.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00441263  |
| Phi_loss        | 369.447     |
| PolicyEntropy   | 1.49884     |
| PolicyLoss      | -0.00687414 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0157      |
| _MeanReward     | 3.19e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57282     |
| _max_adv        | 3.81        |
| _max_discrew    | 3.58        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0303924  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.63        |
| _mean_obs       | 0.0387      |
| _min_adv        | -5.26       |
| _min_discrew    | 0.00977     |
| _min_obs        | -1.21       |
| _std_act        | 0.567011    |
| _std_adv        | 1           |
| _std_discrew    | 0.665       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.971      |
| KL              | 0.00467122 |
| Phi_loss        | 387.745    |
| PolicyEntropy   | 1.48231    |
| PolicyLoss      | -0.0293544 |
| Steps           | 10000      |
| VarFuncLoss     | 0.019      |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47176    |
| _max_adv        | 3.88       |
| _max_discrew    | 3.54       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0275104 |
| _mean_adv       | 6.25e-17   |
| _mean_discrew   | 2.69       |
| _mean_obs       | 0.0393     |
| _min_adv        | -6.9       |
| _min_discrew    | 0.00753    |
| _min_obs        | -1.17      |
| _std_act        | 0.570722   |
| _std_adv        | 1          |
| _std_discrew    | 0.672      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.968      |
| KL              | 0.00380426 |
| Phi_loss        | 389.272    |
| PolicyEntropy   | 1.45062    |
| PolicyLoss      | 0.00104803 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0221     |
| _MeanReward     | 3.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62235    |
| _max_adv        | 3.22       |
| _max_discrew    | 3.7        |
| _max_obs        | 1.22       |
| _mean_act       | -0.0308261 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.65       |
| _mean_obs       | 0.0394     |
| _min_adv        | -6.79      |
| _min_discrew    | 0.00738    |
| _min_obs        | -1.31      |
| _std_act        | 0.570488   |
| _std_adv        | 1          |
| _std_discrew    | 0.659      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.963       |
| ExplainedVarOld | 0.961       |
| KL              | 0.00500312  |
| Phi_loss        | 389.623     |
| PolicyEntropy   | 1.42215     |
| PolicyLoss      | -0.00553079 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0246      |
| _MeanReward     | 3.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.61173     |
| _max_adv        | 4.1         |
| _max_discrew    | 3.62        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0307829  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.72        |
| _mean_obs       | 0.0394      |
| _min_adv        | -6.83       |
| _min_discrew    | 0.00921     |
| _min_obs        | -1.23       |
| _std_act        | 0.565694    |
| _std_adv        | 1           |
| _std_discrew    | 0.673       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.969       |
| KL              | 0.00486254  |
| Phi_loss        | 399.182     |
| PolicyEntropy   | 1.41149     |
| PolicyLoss      | -0.00640196 |
| Steps           | 10000       |
| VarFuncLoss     | 0.021       |
| _MeanReward     | 3.26e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.539       |
| _max_adv        | 3.7         |
| _max_discrew    | 3.73        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0280902  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.69        |
| _mean_obs       | 0.0395      |
| _min_adv        | -5.96       |
| _min_discrew    | 0.00871     |
| _min_obs        | -1.19       |
| _std_act        | 0.578049    |
| _std_adv        | 1           |
| _std_discrew    | 0.681       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.969      |
| KL              | 0.00481897 |
| Phi_loss        | 417.314    |
| PolicyEntropy   | 1.38179    |
| PolicyLoss      | 0.00584417 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0205     |
| _MeanReward     | 2.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72706    |
| _max_adv        | 1.95       |
| _max_discrew    | 3.53       |
| _max_obs        | 1.46       |
| _mean_act       | -0.0807984 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.42       |
| _mean_obs       | 0.036      |
| _min_adv        | -10.4      |
| _min_discrew    | -1.21      |
| _min_obs        | -1.21      |
| _std_act        | 0.662055   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.768      |
| KL              | 0.00674229 |
| Phi_loss        | 209.551    |
| PolicyEntropy   | 1.40843    |
| PolicyLoss      | -0.0281887 |
| Steps           | 10000      |
| VarFuncLoss     | 0.174      |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52956    |
| _max_adv        | 17.5       |
| _max_discrew    | 3.6        |
| _max_obs        | 1.2        |
| _mean_act       | -0.0268304 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.71       |
| _mean_obs       | 0.0395     |
| _min_adv        | -6.16      |
| _min_discrew    | 0.00754    |
| _min_obs        | -1.2       |
| _std_act        | 0.578506   |
| _std_adv        | 1          |
| _std_discrew    | 0.679      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00504347 |
| Phi_loss        | 383.539    |
| PolicyEntropy   | 1.37667    |
| PolicyLoss      | 0.0137381  |
| Steps           | 10000      |
| VarFuncLoss     | 0.027      |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77636    |
| _max_adv        | 14.1       |
| _max_discrew    | 3.6        |
| _max_obs        | 1.27       |
| _mean_act       | -0.0289202 |
| _mean_adv       | -2.77e-17  |
| _mean_discrew   | 2.67       |
| _mean_obs       | 0.0388     |
| _min_adv        | -6.09      |
| _min_discrew    | 0.0105     |
| _min_obs        | -1.33      |
| _std_act        | 0.570723   |
| _std_adv        | 1          |
| _std_discrew    | 0.694      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.961      |
| KL              | 0.00245527 |
| Phi_loss        | 373.812    |
| PolicyEntropy   | 1.35976    |
| PolicyLoss      | -0.0162768 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39727    |
| _max_adv        | 5.72       |
| _max_discrew    | 3.61       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0258332 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.71       |
| _mean_obs       | 0.0388     |
| _min_adv        | -7.03      |
| _min_discrew    | 0.00675    |
| _min_obs        | -1.32      |
| _std_act        | 0.571505   |
| _std_adv        | 1          |
| _std_discrew    | 0.745      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00228491  |
| Phi_loss        | 446.0       |
| PolicyEntropy   | 1.3309      |
| PolicyLoss      | -0.00742753 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0192      |
| _MeanReward     | 3.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76231     |
| _max_adv        | 5.73        |
| _max_discrew    | 3.74        |
| _max_obs        | 1.26        |
| _mean_act       | -0.0242632  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.75        |
| _mean_obs       | 0.0397      |
| _min_adv        | -5.17       |
| _min_discrew    | 0.017       |
| _min_obs        | -1.26       |
| _std_act        | 0.572539    |
| _std_adv        | 1           |
| _std_discrew    | 0.691       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.0021316   |
| Phi_loss        | 422.958     |
| PolicyEntropy   | 1.30233     |
| PolicyLoss      | -0.00750156 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 3.4e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.69178     |
| _max_adv        | 4.99        |
| _max_discrew    | 3.75        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0223185  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 2.8         |
| _mean_obs       | 0.0397      |
| _min_adv        | -5.06       |
| _min_discrew    | 0.00803     |
| _min_obs        | -1.13       |
| _std_act        | 0.569399    |
| _std_adv        | 1           |
| _std_discrew    | 0.729       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00206421  |
| Phi_loss        | 447.133     |
| PolicyEntropy   | 1.27908     |
| PolicyLoss      | -0.00925143 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 3.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.68285     |
| _max_adv        | 8.32        |
| _max_discrew    | 3.78        |
| _max_obs        | 1.23        |
| _mean_act       | -0.019151   |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 2.78        |
| _mean_obs       | 0.0403      |
| _min_adv        | -5.98       |
| _min_discrew    | 0.00134     |
| _min_obs        | -1.15       |
| _std_act        | 0.56917     |
| _std_adv        | 1           |
| _std_discrew    | 0.78        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00174888 |
| Phi_loss        | 398.673    |
| PolicyEntropy   | 1.26155    |
| PolicyLoss      | -0.0227766 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0274     |
| _MeanReward     | 3.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58653    |
| _max_adv        | 4.21       |
| _max_discrew    | 3.68       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0266197 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.76       |
| _mean_obs       | 0.0392     |
| _min_adv        | -8.67      |
| _min_discrew    | 0.00829    |
| _min_obs        | -1.18      |
| _std_act        | 0.575571   |
| _std_adv        | 1          |
| _std_discrew    | 0.727      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.968       |
| ExplainedVarOld | 0.967       |
| KL              | 0.00286442  |
| Phi_loss        | 405.48      |
| PolicyEntropy   | 1.24762     |
| PolicyLoss      | -0.00591649 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 3.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59584     |
| _max_adv        | 4.3         |
| _max_discrew    | 3.95        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0269251  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.83        |
| _mean_obs       | 0.0403      |
| _min_adv        | -6.42       |
| _min_discrew    | 0.00652     |
| _min_obs        | -1.26       |
| _std_act        | 0.577275    |
| _std_adv        | 1           |
| _std_discrew    | 0.834       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00204474 |
| Phi_loss        | 431.218    |
| PolicyEntropy   | 1.24766    |
| PolicyLoss      | -0.0176553 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0288     |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48901    |
| _max_adv        | 2.75       |
| _max_discrew    | 3.67       |
| _max_obs        | 1.47       |
| _mean_act       | -0.0417872 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.69       |
| _mean_obs       | 0.0387     |
| _min_adv        | -14.4      |
| _min_discrew    | -0.771     |
| _min_obs        | -1.3       |
| _std_act        | 0.609985   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.906      |
| KL              | 0.00364822 |
| Phi_loss        | 317.238    |
| PolicyEntropy   | 1.24692    |
| PolicyLoss      | -0.0271354 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0857     |
| _MeanReward     | 3.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73808    |
| _max_adv        | 13.3       |
| _max_discrew    | 3.73       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0261314 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 2.85       |
| _mean_obs       | 0.04       |
| _min_adv        | -7.15      |
| _min_discrew    | 0.0051     |
| _min_obs        | -1.2       |
| _std_act        | 0.576976   |
| _std_adv        | 1          |
| _std_discrew    | 0.792      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00265136 |
| Phi_loss        | 425.715    |
| PolicyEntropy   | 1.22397    |
| PolicyLoss      | -0.0300425 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0251     |
| _MeanReward     | 3.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46049    |
| _max_adv        | 6.3        |
| _max_discrew    | 3.82       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0251011 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 2.82       |
| _mean_obs       | 0.0396     |
| _min_adv        | -10        |
| _min_discrew    | 0.00824    |
| _min_obs        | -1.12      |
| _std_act        | 0.579552   |
| _std_adv        | 1          |
| _std_discrew    | 0.751      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.954      |
| KL              | 0.00178861 |
| Phi_loss        | 392.927    |
| PolicyEntropy   | 1.21926    |
| PolicyLoss      | 0.00334135 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0304     |
| _MeanReward     | 3.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62608    |
| _max_adv        | 10.1       |
| _max_discrew    | 3.92       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0241362 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.89       |
| _mean_obs       | 0.0402     |
| _min_adv        | -8.78      |
| _min_discrew    | 0.00617    |
| _min_obs        | -1.31      |
| _std_act        | 0.578739   |
| _std_adv        | 1          |
| _std_discrew    | 0.851      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00207492 |
| Phi_loss        | 436.591    |
| PolicyEntropy   | 1.19795    |
| PolicyLoss      | 0.00340193 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0223     |
| _MeanReward     | 3.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65214    |
| _max_adv        | 7.13       |
| _max_discrew    | 3.72       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0295921 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.8        |
| _mean_obs       | 0.0395     |
| _min_adv        | -13.1      |
| _min_discrew    | 0.00776    |
| _min_obs        | -1.13      |
| _std_act        | 0.580391   |
| _std_adv        | 1          |
| _std_discrew    | 0.761      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.932      |
| KL              | 0.00272156 |
| Phi_loss        | 514.759    |
| PolicyEntropy   | 1.18611    |
| PolicyLoss      | 0.00343896 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0469     |
| _MeanReward     | 3.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54795    |
| _max_adv        | 4.52       |
| _max_discrew    | 3.86       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0222052 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.9        |
| _mean_obs       | 0.0402     |
| _min_adv        | -4.03      |
| _min_discrew    | 0.0041     |
| _min_obs        | -1.14      |
| _std_act        | 0.57776    |
| _std_adv        | 1          |
| _std_discrew    | 0.791      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00207958 |
| Phi_loss        | 499.323    |
| PolicyEntropy   | 1.16685    |
| PolicyLoss      | -0.0154293 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0133     |
| _MeanReward     | 3.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67096    |
| _max_adv        | 8.56       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0255136 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.87       |
| _mean_obs       | 0.0396     |
| _min_adv        | -9.9       |
| _min_discrew    | 0.00544    |
| _min_obs        | -1.21      |
| _std_act        | 0.578477   |
| _std_adv        | 1          |
| _std_discrew    | 0.758      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.969       |
| KL              | 0.00162814  |
| Phi_loss        | 457.538     |
| PolicyEntropy   | 1.15322     |
| PolicyLoss      | -0.00373865 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0224      |
| _MeanReward     | 3.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.37239     |
| _max_adv        | 12.8        |
| _max_discrew    | 3.81        |
| _max_obs        | 1.17        |
| _mean_act       | -0.0216875  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.89        |
| _mean_obs       | 0.0401      |
| _min_adv        | -6.45       |
| _min_discrew    | 0.00727     |
| _min_obs        | -1.17       |
| _std_act        | 0.573432    |
| _std_adv        | 1           |
| _std_discrew    | 0.776       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00226301 |
| Phi_loss        | 521.407    |
| PolicyEntropy   | 1.12509    |
| PolicyLoss      | 0.00615689 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0107     |
| _MeanReward     | 3.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54667    |
| _max_adv        | 7.88       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0236653 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 2.91       |
| _mean_obs       | 0.0396     |
| _min_adv        | -4.93      |
| _min_discrew    | 0.00655    |
| _min_obs        | -1.24      |
| _std_act        | 0.581443   |
| _std_adv        | 1          |
| _std_discrew    | 0.783      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00212346 |
| Phi_loss        | 504.016    |
| PolicyEntropy   | 1.10205    |
| PolicyLoss      | 0.00284268 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 3.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45164    |
| _max_adv        | 2.61       |
| _max_discrew    | 3.87       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0238705 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.91       |
| _mean_obs       | 0.0398     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.00784    |
| _min_obs        | -1.16      |
| _std_act        | 0.580937   |
| _std_adv        | 1          |
| _std_discrew    | 0.854      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.969      |
| KL              | 0.00246555 |
| Phi_loss        | 557.878    |
| PolicyEntropy   | 1.09422    |
| PolicyLoss      | -0.0269186 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0244     |
| _MeanReward     | 3.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84924    |
| _max_adv        | 11.7       |
| _max_discrew    | 3.87       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0222498 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.96       |
| _mean_obs       | 0.04       |
| _min_adv        | -10.3      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.12      |
| _std_act        | 0.588356   |
| _std_adv        | 1          |
| _std_discrew    | 0.807      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.978       |
| KL              | 0.00207112  |
| Phi_loss        | 461.962     |
| PolicyEntropy   | 1.07101     |
| PolicyLoss      | -0.00803982 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0167      |
| _MeanReward     | 3.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.53341     |
| _max_adv        | 7.16        |
| _max_discrew    | 3.99        |
| _max_obs        | 1.25        |
| _mean_act       | -0.0215732  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.97        |
| _mean_obs       | 0.0397      |
| _min_adv        | -4.73       |
| _min_discrew    | 0.00595     |
| _min_obs        | -1.18       |
| _std_act        | 0.582792    |
| _std_adv        | 1           |
| _std_discrew    | 0.835       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00254975 |
| Phi_loss        | 489.165    |
| PolicyEntropy   | 1.03135    |
| PolicyLoss      | 0.0176216  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82767    |
| _max_adv        | 5.13       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0247044 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.97       |
| _mean_obs       | 0.0402     |
| _min_adv        | -7.59      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.16      |
| _std_act        | 0.57958    |
| _std_adv        | 1          |
| _std_discrew    | 0.847      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00190566 |
| Phi_loss        | 578.924    |
| PolicyEntropy   | 1.01284    |
| PolicyLoss      | 0.0111889  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0142     |
| _MeanReward     | 3.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51541    |
| _max_adv        | 2.96       |
| _max_discrew    | 3.93       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0288175 |
| _mean_adv       | -8.17e-18  |
| _mean_discrew   | 2.97       |
| _mean_obs       | 0.0398     |
| _min_adv        | -8.86      |
| _min_discrew    | 0.00871    |
| _min_obs        | -1.23      |
| _std_act        | 0.58903    |
| _std_adv        | 1          |
| _std_discrew    | 0.856      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.942      |
| ExplainedVarOld | 0.92       |
| KL              | 0.00551202 |
| Phi_loss        | 305.664    |
| PolicyEntropy   | 1.02344    |
| PolicyLoss      | -0.027613  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0499     |
| _MeanReward     | 3.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46529    |
| _max_adv        | 8.68       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0221016 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0408     |
| _min_adv        | -6.34      |
| _min_discrew    | 0.0095     |
| _min_obs        | -1.17      |
| _std_act        | 0.586761   |
| _std_adv        | 1          |
| _std_discrew    | 0.871      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00367719 |
| Phi_loss        | 571.062    |
| PolicyEntropy   | 1.01268    |
| PolicyLoss      | 0.0432541  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6671     |
| _max_adv        | 7.37       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0201991 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 2.98       |
| _mean_obs       | 0.0394     |
| _min_adv        | -7.69      |
| _min_discrew    | 0.00804    |
| _min_obs        | -1.41      |
| _std_act        | 0.577712   |
| _std_adv        | 1          |
| _std_discrew    | 0.846      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00249008  |
| Phi_loss        | 583.216     |
| PolicyEntropy   | 1.01036     |
| PolicyLoss      | -0.00968791 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0169      |
| _MeanReward     | 3.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.42221     |
| _max_adv        | 11.3        |
| _max_discrew    | 4.09        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0189183  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.99        |
| _mean_obs       | 0.0401      |
| _min_adv        | -4.98       |
| _min_discrew    | 0.00608     |
| _min_obs        | -1.12       |
| _std_act        | 0.578345    |
| _std_adv        | 1           |
| _std_discrew    | 0.847       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00197405 |
| Phi_loss        | 617.382    |
| PolicyEntropy   | 1.00232    |
| PolicyLoss      | -0.0230511 |
| Steps           | 10000      |
| VarFuncLoss     | 0.02       |
| _MeanReward     | 3.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59332    |
| _max_adv        | 6.92       |
| _max_discrew    | 3.96       |
| _max_obs        | 1.19       |
| _mean_act       | -0.020176  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.01       |
| _mean_obs       | 0.04       |
| _min_adv        | -6.34      |
| _min_discrew    | 0.00885    |
| _min_obs        | -1.2       |
| _std_act        | 0.584761   |
| _std_adv        | 1          |
| _std_discrew    | 0.846      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00209713  |
| Phi_loss        | 585.97      |
| PolicyEntropy   | 0.98877     |
| PolicyLoss      | -0.00272525 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 3.65e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71647     |
| _max_adv        | 10.6        |
| _max_discrew    | 3.9         |
| _max_obs        | 1.17        |
| _mean_act       | -0.0228305  |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | 3.02        |
| _mean_obs       | 0.0399      |
| _min_adv        | -10.2       |
| _min_discrew    | 0.0107      |
| _min_obs        | -1.2        |
| _std_act        | 0.585711    |
| _std_adv        | 1           |
| _std_discrew    | 0.846       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00310887 |
| Phi_loss        | 455.995    |
| PolicyEntropy   | 0.968918   |
| PolicyLoss      | -0.0123976 |
| Steps           | 10000      |
| VarFuncLoss     | 0.016      |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45694    |
| _max_adv        | 3.08       |
| _max_discrew    | 3.93       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0224751 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0398     |
| _min_adv        | -7.4       |
| _min_discrew    | 0.00601    |
| _min_obs        | -1.22      |
| _std_act        | 0.590021   |
| _std_adv        | 1          |
| _std_discrew    | 0.845      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00241688 |
| Phi_loss        | 566.598    |
| PolicyEntropy   | 0.952732   |
| PolicyLoss      | 0.0146843  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 3.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59979    |
| _max_adv        | 2.73       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0334169 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 2.94       |
| _mean_obs       | 0.0385     |
| _min_adv        | -8.62      |
| _min_discrew    | 0.0102     |
| _min_obs        | -1.15      |
| _std_act        | 0.595525   |
| _std_adv        | 1          |
| _std_discrew    | 0.859      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.923      |
| KL              | 0.00419691 |
| Phi_loss        | 289.194    |
| PolicyEntropy   | 0.954471   |
| PolicyLoss      | 0.00673004 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0367     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54406    |
| _max_adv        | 6.12       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0232881 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0397     |
| _min_adv        | -7.52      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.19      |
| _std_act        | 0.594215   |
| _std_adv        | 1          |
| _std_discrew    | 0.887      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00277291 |
| Phi_loss        | 561.34     |
| PolicyEntropy   | 0.933553   |
| PolicyLoss      | -0.0328302 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0149     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68958    |
| _max_adv        | 5.9        |
| _max_discrew    | 4.09       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0243897 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0396     |
| _min_adv        | -11.9      |
| _min_discrew    | 0.00668    |
| _min_obs        | -1.28      |
| _std_act        | 0.591051   |
| _std_adv        | 1          |
| _std_discrew    | 0.94       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00218067 |
| Phi_loss        | 480.602    |
| PolicyEntropy   | 0.926632   |
| PolicyLoss      | -0.0107575 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0305     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59337    |
| _max_adv        | 12.3       |
| _max_discrew    | 4.06       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0401965 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 2.95       |
| _mean_obs       | 0.0389     |
| _min_adv        | -15.7      |
| _min_discrew    | 0.0069     |
| _min_obs        | -1.18      |
| _std_act        | 0.605629   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.91       |
| KL              | 0.00391472 |
| Phi_loss        | 386.962    |
| PolicyEntropy   | 0.920933   |
| PolicyLoss      | 0.0215311  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0465     |
| _MeanReward     | 3.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6625     |
| _max_adv        | 14.6       |
| _max_discrew    | 4.04       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0207288 |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0399     |
| _min_adv        | -5.58      |
| _min_discrew    | 0.00883    |
| _min_obs        | -1.15      |
| _std_act        | 0.591652   |
| _std_adv        | 1          |
| _std_discrew    | 0.912      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0022866  |
| Phi_loss        | 536.551    |
| PolicyEntropy   | 0.901785   |
| PolicyLoss      | -0.0134177 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 3.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.53746    |
| _max_adv        | 7.53       |
| _max_discrew    | 4          |
| _max_obs        | 1.15       |
| _mean_act       | -0.0334778 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.96       |
| _mean_obs       | 0.0391     |
| _min_adv        | -12.6      |
| _min_discrew    | 0.00348    |
| _min_obs        | -1.24      |
| _std_act        | 0.595363   |
| _std_adv        | 1          |
| _std_discrew    | 0.84       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.91       |
| KL              | 0.00226224 |
| Phi_loss        | 482.211    |
| PolicyEntropy   | 0.891706   |
| PolicyLoss      | 0.00780333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0698     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44652    |
| _max_adv        | 15.2       |
| _max_discrew    | 4.12       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0218085 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.03       |
| _mean_obs       | 0.0393     |
| _min_adv        | -9.08      |
| _min_discrew    | 0.00696    |
| _min_obs        | -1.15      |
| _std_act        | 0.59119    |
| _std_adv        | 1          |
| _std_discrew    | 0.866      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00252486  |
| Phi_loss        | 508.109     |
| PolicyEntropy   | 0.868365    |
| PolicyLoss      | -0.00478536 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0188      |
| _MeanReward     | 3.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63851     |
| _max_adv        | 4.06        |
| _max_discrew    | 4.1         |
| _max_obs        | 1.19        |
| _mean_act       | -0.0188056  |
| _mean_adv       | -1.07e-17   |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0399      |
| _min_adv        | -6.68       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.17       |
| _std_act        | 0.590613    |
| _std_adv        | 1           |
| _std_discrew    | 0.923       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.977      |
| KL              | 0.00205033 |
| Phi_loss        | 590.974    |
| PolicyEntropy   | 0.849048   |
| PolicyLoss      | -0.0171945 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51977    |
| _max_adv        | 5.16       |
| _max_discrew    | 4.07       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0243487 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.09       |
| _mean_obs       | 0.0401     |
| _min_adv        | -5.87      |
| _min_discrew    | 0.00137    |
| _min_obs        | -1.08      |
| _std_act        | 0.597994   |
| _std_adv        | 1          |
| _std_discrew    | 0.886      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00245517 |
| Phi_loss        | 645.943    |
| PolicyEntropy   | 0.815607   |
| PolicyLoss      | 0.00751793 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0197     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39578    |
| _max_adv        | 16.2       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0217917 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.02       |
| _mean_obs       | 0.0392     |
| _min_adv        | -8.29      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.24      |
| _std_act        | 0.588452   |
| _std_adv        | 1          |
| _std_discrew    | 0.885      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.962       |
| ExplainedVarOld | 0.96        |
| KL              | 0.00301993  |
| Phi_loss        | 533.047     |
| PolicyEntropy   | 0.799271    |
| PolicyLoss      | -0.00820985 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0347      |
| _MeanReward     | 3.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.44641     |
| _max_adv        | 3.95        |
| _max_discrew    | 4.04        |
| _max_obs        | 1.19        |
| _mean_act       | -0.0237041  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.04        |
| _mean_obs       | 0.0394      |
| _min_adv        | -8.5        |
| _min_discrew    | 0.00359     |
| _min_obs        | -1.31       |
| _std_act        | 0.597564    |
| _std_adv        | 1           |
| _std_discrew    | 0.907       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00205411 |
| Phi_loss        | 656.646    |
| PolicyEntropy   | 0.798015   |
| PolicyLoss      | -0.0223724 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0242     |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6444     |
| _max_adv        | 7.16       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0219914 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.1        |
| _mean_obs       | 0.0394     |
| _min_adv        | -7.1       |
| _min_discrew    | 0.00548    |
| _min_obs        | -1.23      |
| _std_act        | 0.594424   |
| _std_adv        | 1          |
| _std_discrew    | 0.954      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00245494 |
| Phi_loss        | 669.603    |
| PolicyEntropy   | 0.802715   |
| PolicyLoss      | -0.0249194 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0195     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47398    |
| _max_adv        | 6.57       |
| _max_discrew    | 4.14       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0189537 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.0403     |
| _min_adv        | -8.17      |
| _min_discrew    | 0.00549    |
| _min_obs        | -1.32      |
| _std_act        | 0.601152   |
| _std_adv        | 1          |
| _std_discrew    | 0.935      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00276303  |
| Phi_loss        | 632.828     |
| PolicyEntropy   | 0.788151    |
| PolicyLoss      | -0.00200401 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0179      |
| _MeanReward     | 3.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51501     |
| _max_adv        | 3.35        |
| _max_discrew    | 4.13        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0251652  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.1         |
| _mean_obs       | 0.0398      |
| _min_adv        | -9.57       |
| _min_discrew    | 0.00951     |
| _min_obs        | -1.22       |
| _std_act        | 0.606004    |
| _std_adv        | 1           |
| _std_discrew    | 0.905       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00231161 |
| Phi_loss        | 614.712    |
| PolicyEntropy   | 0.782853   |
| PolicyLoss      | 0.0104626  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0229     |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.40182    |
| _max_adv        | 3.19       |
| _max_discrew    | 4.07       |
| _max_obs        | 1.21       |
| _mean_act       | -0.0177213 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0397     |
| _min_adv        | -8.43      |
| _min_discrew    | 0.0126     |
| _min_obs        | -1.19      |
| _std_act        | 0.590604   |
| _std_adv        | 1          |
| _std_discrew    | 0.951      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00219635  |
| Phi_loss        | 667.915     |
| PolicyEntropy   | 0.762022    |
| PolicyLoss      | 0.000494285 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0144      |
| _MeanReward     | 3.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.49544     |
| _max_adv        | 5.68        |
| _max_discrew    | 4.13        |
| _max_obs        | 1.16        |
| _mean_act       | -0.0268239  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.1         |
| _mean_obs       | 0.0398      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.00963     |
| _min_obs        | -1.28       |
| _std_act        | 0.607524    |
| _std_adv        | 1           |
| _std_discrew    | 0.906       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.937      |
| KL              | 0.00253996 |
| Phi_loss        | 718.19     |
| PolicyEntropy   | 0.739955   |
| PolicyLoss      | 0.0223692  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0536     |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.57636    |
| _max_adv        | 8.45       |
| _max_discrew    | 4.16       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0214968 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0394     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0113     |
| _min_obs        | -1.21      |
| _std_act        | 0.597814   |
| _std_adv        | 1          |
| _std_discrew    | 0.961      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.975      |
| KL              | 0.002382   |
| Phi_loss        | 640.24     |
| PolicyEntropy   | 0.72274    |
| PolicyLoss      | -0.0123206 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0241     |
| _MeanReward     | 3.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4379     |
| _max_adv        | 12.1       |
| _max_discrew    | 4.17       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0190402 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0403     |
| _min_adv        | -8.62      |
| _min_discrew    | 0.006      |
| _min_obs        | -1.28      |
| _std_act        | 0.599898   |
| _std_adv        | 1          |
| _std_discrew    | 0.98       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00248455 |
| Phi_loss        | 614.857    |
| PolicyEntropy   | 0.711937   |
| PolicyLoss      | -0.0219777 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0227     |
| _MeanReward     | 3.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60654    |
| _max_adv        | 4.58       |
| _max_discrew    | 4.13       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0280475 |
| _mean_adv       | 4.83e-17   |
| _mean_discrew   | 3.08       |
| _mean_obs       | 0.0397     |
| _min_adv        | -12.3      |
| _min_discrew    | 0.0103     |
| _min_obs        | -1.12      |
| _std_act        | 0.607197   |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.934      |
| KL              | 0.00741848 |
| Phi_loss        | 622.595    |
| PolicyEntropy   | 0.725856   |
| PolicyLoss      | -0.0470566 |
| Steps           | 10000      |
| VarFuncLoss     | 0.058      |
| _MeanReward     | 3.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51179    |
| _max_adv        | 6.46       |
| _max_discrew    | 4.11       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0214974 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.0401     |
| _min_adv        | -9         |
| _min_discrew    | 0.00761    |
| _min_obs        | -1.2       |
| _std_act        | 0.601814   |
| _std_adv        | 1          |
| _std_discrew    | 0.928      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
---------------------------------
| Beta            | 1           |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.975       |
| KL              | 0.0191167   |
| Phi_loss        | 688.22      |
| PolicyEntropy   | 0.718201    |
| PolicyLoss      | -0.00162909 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0221      |
| _MeanReward     | 3.82e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5938      |
| _max_adv        | 11.3        |
| _max_discrew    | 4.16        |
| _max_obs        | 1.12        |
| _mean_act       | -0.0168884  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.16        |
| _mean_obs       | 0.0395      |
| _min_adv        | -9.73       |
| _min_discrew    | 0.013       |
| _min_obs        | -1.09       |
| _std_act        | 0.600858    |
| _std_adv        | 1           |
| _std_discrew    | 0.953       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
-------------------------------
| Beta            | 1.5       |
| ExplainedVarNew | 0.978     |
| ExplainedVarOld | 0.974     |
| KL              | 0.042089  |
| Phi_loss        | 572.745   |
| PolicyEntropy   | 0.716955  |
| PolicyLoss      | 0.114956  |
| Steps           | 10000     |
| VarFuncLoss     | 0.021     |
| _MeanReward     | 3.8e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.52365   |
| _max_adv        | 5.03      |
| _max_discrew    | 4.17      |
| _max_obs        | 1.16      |
| _mean_act       | -0.014103 |
| _mean_adv       | 2.84e-17  |
| _mean_discrew   | 3.14      |
| _mean_obs       | 0.0387    |
| _min_adv        | -4.85     |
| _min_discrew    | 0.0125    |
| _min_obs        | -1.22     |
| _std_act        | 0.57759   |
| _std_adv        | 1         |
| _std_discrew    | 0.928     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
--------------------------------
| Beta            | 2.25       |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0294185  |
| Phi_loss        | 751.916    |
| PolicyEntropy   | 0.71501    |
| PolicyLoss      | 0.0760649  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0129     |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4962     |
| _max_adv        | 5.18       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0144559 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.0375     |
| _min_adv        | -3.9       |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.13      |
| _std_act        | 0.568904   |
| _std_adv        | 1          |
| _std_discrew    | 0.945      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
--------------------------------
| Beta            | 3.38       |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.019762   |
| Phi_loss        | 736.325    |
| PolicyEntropy   | 0.712902   |
| PolicyLoss      | 0.0497201  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58332    |
| _max_adv        | 5.64       |
| _max_discrew    | 3.9        |
| _max_obs        | 1.11       |
| _mean_act       | -0.0127297 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0359     |
| _min_adv        | -4.51      |
| _min_discrew    | 0.0131     |
| _min_obs        | -1.14      |
| _std_act        | 0.556007   |
| _std_adv        | 1          |
| _std_discrew    | 0.845      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
--------------------------------
| Beta            | 5.06       |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.132693   |
| Phi_loss        | 894.306    |
| PolicyEntropy   | 0.710018   |
| PolicyLoss      | 1.20799    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0132     |
| _MeanReward     | 3.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55436    |
| _max_adv        | 3.99       |
| _max_discrew    | 4.16       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0238064 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.0388     |
| _min_adv        | -7.2       |
| _min_discrew    | 0.00619    |
| _min_obs        | -1.19      |
| _std_act        | 0.588841   |
| _std_adv        | 1          |
| _std_discrew    | 0.952      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 7.59       |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.177016   |
| Phi_loss        | 1007.34    |
| PolicyEntropy   | 0.709374   |
| PolicyLoss      | 2.32902    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0208     |
| _MeanReward     | 3.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49262    |
| _max_adv        | 3.11       |
| _max_discrew    | 4.19       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0302946 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.15       |
| _mean_obs       | 0.0386     |
| _min_adv        | -7.22      |
| _min_discrew    | 0.00425    |
| _min_obs        | -1.33      |
| _std_act        | 0.606819   |
| _std_adv        | 1          |
| _std_discrew    | 0.976      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
--------------------------------
| Beta            | 11.4       |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.979      |
| KL              | 0.136309   |
| Phi_loss        | 782.036    |
| PolicyEntropy   | 0.708324   |
| PolicyLoss      | 1.89064    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0192     |
| _MeanReward     | 3.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69078    |
| _max_adv        | 3.85       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0362964 |
| _mean_adv       | 2.7e-17    |
| _mean_discrew   | 2.9        |
| _mean_obs       | 0.0377     |
| _min_adv        | -7.35      |
| _min_discrew    | 0.00246    |
| _min_obs        | -1.22      |
| _std_act        | 0.624377   |
| _std_adv        | 1          |
| _std_discrew    | 0.92       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
--------------------------------
| Beta            | 17.1       |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.953      |
| KL              | 0.10084    |
| Phi_loss        | 885.683    |
| PolicyEntropy   | 0.70686    |
| PolicyLoss      | 1.64286    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0497     |
| _MeanReward     | 3.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80664    |
| _max_adv        | 3.4        |
| _max_discrew    | 3.72       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0645173 |
| _mean_adv       | -8.67e-17  |
| _mean_discrew   | 2.6        |
| _mean_obs       | 0.0354     |
| _min_adv        | -9.71      |
| _min_discrew    | 0.00143    |
| _min_obs        | -1.23      |
| _std_act        | 0.643675   |
| _std_adv        | 1          |
| _std_discrew    | 0.918      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 25.6       |
| ExplainedVarNew | 0.854      |
| ExplainedVarOld | 0.779      |
| KL              | 0.0724836  |
| Phi_loss        | 773.421    |
| PolicyEntropy   | 0.704907   |
| PolicyLoss      | 1.49673    |
| Steps           | 10000      |
| VarFuncLoss     | 0.143      |
| _MeanReward     | 2.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88382    |
| _max_adv        | 6.32       |
| _max_discrew    | 3.58       |
| _max_obs        | 1.68       |
| _mean_act       | -0.0838922 |
| _mean_adv       | 3.84e-17   |
| _mean_discrew   | 2.2        |
| _mean_obs       | 0.0332     |
| _min_adv        | -7.75      |
| _min_discrew    | -0.58      |
| _min_obs        | -1.1       |
| _std_act        | 0.675859   |
| _std_adv        | 1          |
| _std_discrew    | 0.761      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.803     |
| ExplainedVarOld | 0.763     |
| KL              | 0.0524287 |
| Phi_loss        | 729.518   |
| PolicyEntropy   | 0.703356  |
| PolicyLoss      | 1.40282   |
| Steps           | 10000     |
| VarFuncLoss     | 0.179     |
| _MeanReward     | 2.22e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.029     |
| _max_adv        | 5.12      |
| _max_discrew    | 3.58      |
| _max_obs        | 1.61      |
| _mean_act       | -0.138486 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 1.79      |
| _mean_obs       | 0.0307    |
| _min_adv        | -11.3     |
| _min_discrew    | -1.34     |
| _min_obs        | -1.16     |
| _std_act        | 0.750235  |
| _std_adv        | 1         |
| _std_discrew    | 1.45      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.85      |
| ExplainedVarOld | 0.827     |
| KL              | 0.0367214 |
| Phi_loss        | 715.989   |
| PolicyEntropy   | 0.701967  |
| PolicyLoss      | 1.32857   |
| Steps           | 10000     |
| VarFuncLoss     | 0.224     |
| _MeanReward     | 2.11e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.96436   |
| _max_adv        | 6.52      |
| _max_discrew    | 3.23      |
| _max_obs        | 1.61      |
| _mean_act       | -0.127488 |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 1.65      |
| _mean_obs       | 0.0305    |
| _min_adv        | -9.77     |
| _min_discrew    | -1.06     |
| _min_obs        | -1.35     |
| _std_act        | 0.711808  |
| _std_adv        | 1         |
| _std_discrew    | 0.752     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.718     |
| ExplainedVarOld | 0.664     |
| KL              | 0.0261555 |
| Phi_loss        | 705.047   |
| PolicyEntropy   | 0.700777  |
| PolicyLoss      | 0.986084  |
| Steps           | 10000     |
| VarFuncLoss     | 0.227     |
| _MeanReward     | 1.92e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.96507   |
| _max_adv        | 6.28      |
| _max_discrew    | 3.1       |
| _max_obs        | 1.67      |
| _mean_act       | -0.122438 |
| _mean_adv       | 0         |
| _mean_discrew   | 1.58      |
| _mean_obs       | 0.0291    |
| _min_adv        | -6.66     |
| _min_discrew    | -0.0226   |
| _min_obs        | -1.19     |
| _std_act        | 0.671271  |
| _std_adv        | 1         |
| _std_discrew    | 0.61      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.694     |
| ExplainedVarOld | 0.659     |
| KL              | 0.0202285 |
| Phi_loss        | 669.52    |
| PolicyEntropy   | 0.699565  |
| PolicyLoss      | 0.738834  |
| Steps           | 10000     |
| VarFuncLoss     | 0.187     |
| _MeanReward     | 1.76e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.11833   |
| _max_adv        | 4.35      |
| _max_discrew    | 2.77      |
| _max_obs        | 1.82      |
| _mean_act       | -0.149536 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 1.42      |
| _mean_obs       | 0.0283    |
| _min_adv        | -7.98     |
| _min_discrew    | -1.11     |
| _min_obs        | -1.28     |
| _std_act        | 0.70763   |
| _std_adv        | 1         |
| _std_discrew    | 0.626     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.651     |
| ExplainedVarOld | 0.59      |
| KL              | 0.0152532 |
| Phi_loss        | 671.793   |
| PolicyEntropy   | 0.698134  |
| PolicyLoss      | 0.504429  |
| Steps           | 10000     |
| VarFuncLoss     | 0.221     |
| _MeanReward     | 1.46e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.20299   |
| _max_adv        | 3.7       |
| _max_discrew    | 2.96      |
| _max_obs        | 1.66      |
| _mean_act       | -0.206648 |
| _mean_adv       | -8.53e-18 |
| _mean_discrew   | 1.14      |
| _mean_obs       | 0.0273    |
| _min_adv        | -8.92     |
| _min_discrew    | -1.32     |
| _min_obs        | -1.3      |
| _std_act        | 0.768864  |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.769     |
| ExplainedVarOld | 0.763     |
| KL              | 0.0861291 |
| Phi_loss        | 734.219   |
| PolicyEntropy   | 0.703937  |
| PolicyLoss      | 3.35011   |
| Steps           | 10000     |
| VarFuncLoss     | 0.305     |
| _MeanReward     | 2.05e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.88741   |
| _max_adv        | 3.2       |
| _max_discrew    | 2.92      |
| _max_obs        | 1.6       |
| _mean_act       | -0.108159 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 1.63      |
| _mean_obs       | 0.0304    |
| _min_adv        | -4.73     |
| _min_discrew    | -0.0455   |
| _min_obs        | -1.06     |
| _std_act        | 0.683364  |
| _std_adv        | 1         |
| _std_discrew    | 0.473     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.683     |
| ExplainedVarOld | 0.636     |
| KL              | 0.149808  |
| Phi_loss        | 806.346   |
| PolicyEntropy   | 0.710007  |
| PolicyLoss      | 6.28835   |
| Steps           | 10000     |
| VarFuncLoss     | 0.156     |
| _MeanReward     | 2.19e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.8052    |
| _max_adv        | 3.38      |
| _max_discrew    | 3.27      |
| _max_obs        | 1.58      |
| _mean_act       | -0.140461 |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 1.79      |
| _mean_obs       | 0.0301    |
| _min_adv        | -11.4     |
| _min_discrew    | -1.22     |
| _min_obs        | -1.22     |
| _std_act        | 0.71551   |
| _std_adv        | 1         |
| _std_discrew    | 1.11      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.809     |
| ExplainedVarOld | 0.794     |
| KL              | 0.119015  |
| Phi_loss        | 777.837   |
| PolicyEntropy   | 0.715209  |
| PolicyLoss      | 4.8105    |
| Steps           | 10000     |
| VarFuncLoss     | 0.229     |
| _MeanReward     | 2.68e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.84314   |
| _max_adv        | 3.75      |
| _max_discrew    | 3.72      |
| _max_obs        | 1.59      |
| _mean_act       | -0.12616  |
| _mean_adv       | -7.96e-17 |
| _mean_discrew   | 2.18      |
| _mean_obs       | 0.0322    |
| _min_adv        | -13       |
| _min_discrew    | -1.29     |
| _min_obs        | -1.2      |
| _std_act        | 0.723512  |
| _std_adv        | 1         |
| _std_discrew    | 1.81      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.893      |
| ExplainedVarOld | 0.842      |
| KL              | 0.100837   |
| Phi_loss        | 553.769    |
| PolicyEntropy   | 0.719905   |
| PolicyLoss      | 3.99259    |
| Steps           | 10000      |
| VarFuncLoss     | 0.228      |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71855    |
| _max_adv        | 8.11       |
| _max_discrew    | 3.83       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0556316 |
| _mean_adv       | 4.26e-17   |
| _mean_discrew   | 2.68       |
| _mean_obs       | 0.0355     |
| _min_adv        | -7.36      |
| _min_discrew    | 0.00256    |
| _min_obs        | -1.2       |
| _std_act        | 0.624975   |
| _std_adv        | 1          |
| _std_discrew    | 0.775      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.903     |
| ExplainedVarOld | 0.884     |
| KL              | 0.0912919 |
| Phi_loss        | 633.101   |
| PolicyEntropy   | 0.724026  |
| PolicyLoss      | 3.58143   |
| Steps           | 10000     |
| VarFuncLoss     | 0.082     |
| _MeanReward     | 3.05e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.6871    |
| _max_adv        | 2.51      |
| _max_discrew    | 3.93      |
| _max_obs        | 1.6       |
| _mean_act       | -0.107717 |
| _mean_adv       | 2.56e-17  |
| _mean_discrew   | 2.48      |
| _mean_obs       | 0.0337    |
| _min_adv        | -15.9     |
| _min_discrew    | -1.24     |
| _min_obs        | -1.21     |
| _std_act        | 0.700819  |
| _std_adv        | 1         |
| _std_discrew    | 1.87      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.88       |
| KL              | 0.068594   |
| Phi_loss        | 1058.24    |
| PolicyEntropy   | 0.727745   |
| PolicyLoss      | 2.59675    |
| Steps           | 10000      |
| VarFuncLoss     | 0.218      |
| _MeanReward     | 3.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45374    |
| _max_adv        | 7.34       |
| _max_discrew    | 3.99       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0378036 |
| _mean_adv       | -7.96e-17  |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0369     |
| _min_adv        | -7.92      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.2       |
| _std_act        | 0.585571   |
| _std_adv        | 1          |
| _std_discrew    | 0.872      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.972      |
| KL              | 0.0613306  |
| Phi_loss        | 726.296    |
| PolicyEntropy   | 0.730913   |
| PolicyLoss      | 2.28676    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0273     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69472    |
| _max_adv        | 21.3       |
| _max_discrew    | 4          |
| _max_obs        | 1.15       |
| _mean_act       | -0.0310631 |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.04       |
| _mean_obs       | 0.0371     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.00727    |
| _min_obs        | -1.17      |
| _std_act        | 0.5818     |
| _std_adv        | 1          |
| _std_discrew    | 0.883      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.965      |
| KL              | 0.0487602  |
| Phi_loss        | 550.9      |
| PolicyEntropy   | 0.733869   |
| PolicyLoss      | 1.8085     |
| Steps           | 10000      |
| VarFuncLoss     | 0.0259     |
| _MeanReward     | 3.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48522    |
| _max_adv        | 3.76       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.15       |
| _mean_act       | -0.0244424 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3          |
| _mean_obs       | 0.0362     |
| _min_adv        | -6.6       |
| _min_discrew    | 0.000772   |
| _min_obs        | -1.19      |
| _std_act        | 0.562653   |
| _std_adv        | 1          |
| _std_discrew    | 0.88       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.982      |
| KL              | 0.0381281  |
| Phi_loss        | 691.274    |
| PolicyEntropy   | 0.736454   |
| PolicyLoss      | 1.36677    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0159     |
| _MeanReward     | 3.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51062    |
| _max_adv        | 5.75       |
| _max_discrew    | 3.84       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0234201 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.92       |
| _mean_obs       | 0.0348     |
| _min_adv        | -3.79      |
| _min_discrew    | 0.0128     |
| _min_obs        | -1.19      |
| _std_act        | 0.55394    |
| _std_adv        | 1          |
| _std_discrew    | 0.82       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0298391  |
| Phi_loss        | 761.169    |
| PolicyEntropy   | 0.738433   |
| PolicyLoss      | 1.08033    |
| Steps           | 10000      |
| VarFuncLoss     | 0.012      |
| _MeanReward     | 2.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69848    |
| _max_adv        | 3.87       |
| _max_discrew    | 3.69       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0958156 |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 2.39       |
| _mean_obs       | 0.03       |
| _min_adv        | -17.5      |
| _min_discrew    | -1.26      |
| _min_obs        | -1.17      |
| _std_act        | 0.674786   |
| _std_adv        | 1          |
| _std_discrew    | 1.93       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.942      |
| KL              | 0.0207512  |
| Phi_loss        | 613.314    |
| PolicyEntropy   | 0.740518   |
| PolicyLoss      | 0.813633   |
| Steps           | 10000      |
| VarFuncLoss     | 0.101      |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.28489    |
| _max_adv        | 7.34       |
| _max_discrew    | 3.61       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0145399 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 2.69       |
| _mean_obs       | 0.0325     |
| _min_adv        | -4.63      |
| _min_discrew    | 0.00811    |
| _min_obs        | -1.15      |
| _std_act        | 0.528235   |
| _std_adv        | 1          |
| _std_discrew    | 0.742      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.969      |
| KL              | 0.0177418  |
| Phi_loss        | 685.06     |
| PolicyEntropy   | 0.742287   |
| PolicyLoss      | 0.596047   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0224     |
| _MeanReward     | 3.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52882    |
| _max_adv        | 8.6        |
| _max_discrew    | 3.44       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0124966 |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 2.59       |
| _mean_obs       | 0.0307     |
| _min_adv        | -3.29      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.19      |
| _std_act        | 0.523114   |
| _std_adv        | 1          |
| _std_discrew    | 0.645      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.975      |
| ExplainedVarOld | 0.967      |
| KL              | 0.0139363  |
| Phi_loss        | 636.984    |
| PolicyEntropy   | 0.743795   |
| PolicyLoss      | 0.470712   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32186    |
| _max_adv        | 14         |
| _max_discrew    | 3.42       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0116034 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.0297     |
| _min_adv        | -5.02      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.18      |
| _std_act        | 0.516496   |
| _std_adv        | 1          |
| _std_discrew    | 0.568      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.965      |
| KL              | 0.0519543  |
| Phi_loss        | 725.684    |
| PolicyEntropy   | 0.749      |
| PolicyLoss      | 1.9175     |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 3.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62636    |
| _max_adv        | 4.23       |
| _max_discrew    | 3.54       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0210426 |
| _mean_adv       | 6.54e-17   |
| _mean_discrew   | 2.64       |
| _mean_obs       | 0.0316     |
| _min_adv        | -8.63      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.16      |
| _std_act        | 0.528451   |
| _std_adv        | 1          |
| _std_discrew    | 0.705      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.97      |
| ExplainedVarOld | 0.966     |
| KL              | 0.0855956 |
| Phi_loss        | 698.938   |
| PolicyEntropy   | 0.752491  |
| PolicyLoss      | 3.27089   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0259    |
| _MeanReward     | 3.43e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.60626   |
| _max_adv        | 4.71      |
| _max_discrew    | 3.81      |
| _max_obs        | 1.14      |
| _mean_act       | -0.03043  |
| _mean_adv       | 5.12e-17  |
| _mean_discrew   | 2.83      |
| _mean_obs       | 0.0335    |
| _min_adv        | -3.84     |
| _min_discrew    | 0.00828   |
| _min_obs        | -1.19     |
| _std_act        | 0.545511  |
| _std_adv        | 1         |
| _std_discrew    | 0.781     |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.973      |
| KL              | 0.0692605  |
| Phi_loss        | 759.295    |
| PolicyEntropy   | 0.7555     |
| PolicyLoss      | 2.5798     |
| Steps           | 10000      |
| VarFuncLoss     | 0.0217     |
| _MeanReward     | 3.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.38784    |
| _max_adv        | 4.62       |
| _max_discrew    | 3.77       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0381973 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 2.85       |
| _mean_obs       | 0.0333     |
| _min_adv        | -6.77      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.23      |
| _std_act        | 0.55325    |
| _std_adv        | 1          |
| _std_discrew    | 0.748      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0541153  |
| Phi_loss        | 693.363    |
| PolicyEntropy   | 0.757999   |
| PolicyLoss      | 1.99402    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0126     |
| _MeanReward     | 3.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52765    |
| _max_adv        | 11.1       |
| _max_discrew    | 3.89       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0509764 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.87       |
| _mean_obs       | 0.0333     |
| _min_adv        | -9.45      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.17      |
| _std_act        | 0.575926   |
| _std_adv        | 1          |
| _std_discrew    | 0.768      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.968      |
| KL              | 0.0423021  |
| Phi_loss        | 840.629    |
| PolicyEntropy   | 0.75984    |
| PolicyLoss      | 1.57679    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0235     |
| _MeanReward     | 3.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46478    |
| _max_adv        | 3.96       |
| _max_discrew    | 3.72       |
| _max_obs        | 1.24       |
| _mean_act       | -0.0633026 |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 2.78       |
| _mean_obs       | 0.033      |
| _min_adv        | -8.11      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.26      |
| _std_act        | 0.584207   |
| _std_adv        | 1          |
| _std_discrew    | 0.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.955     |
| ExplainedVarOld | 0.952     |
| KL              | 0.0324378 |
| Phi_loss        | 795.184   |
| PolicyEntropy   | 0.761364  |
| PolicyLoss      | 1.20405   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0342    |
| _MeanReward     | 3.16e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.75562   |
| _max_adv        | 2.35      |
| _max_discrew    | 3.83      |
| _max_obs        | 1.6       |
| _mean_act       | -0.098139 |
| _mean_adv       | 2.84e-17  |
| _mean_discrew   | 2.61      |
| _mean_obs       | 0.0313    |
| _min_adv        | -12.2     |
| _min_discrew    | -0.828    |
| _min_obs        | -1.17     |
| _std_act        | 0.623148  |
| _std_adv        | 1         |
| _std_discrew    | 1.09      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.844     |
| ExplainedVarOld | 0.823     |
| KL              | 0.0241975 |
| Phi_loss        | 611.557   |
| PolicyEntropy   | 0.76249   |
| PolicyLoss      | 0.856282  |
| Steps           | 10000     |
| VarFuncLoss     | 0.171     |
| _MeanReward     | 2.59e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.67809   |
| _max_adv        | 4.17      |
| _max_discrew    | 3.59      |
| _max_obs        | 1.59      |
| _mean_act       | -0.178506 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 2.07      |
| _mean_obs       | 0.0273    |
| _min_adv        | -12.5     |
| _min_discrew    | -1.17     |
| _min_obs        | -1.22     |
| _std_act        | 0.704769  |
| _std_adv        | 1         |
| _std_discrew    | 2.05      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.854     |
| ExplainedVarOld | 0.841     |
| KL              | 0.016736  |
| Phi_loss        | 846.165   |
| PolicyEntropy   | 0.763353  |
| PolicyLoss      | 0.592878  |
| Steps           | 10000     |
| VarFuncLoss     | 0.306     |
| _MeanReward     | 2.85e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.97183   |
| _max_adv        | 9.5       |
| _max_discrew    | 3.53      |
| _max_obs        | 1.59      |
| _mean_act       | -0.126274 |
| _mean_adv       | 1.42e-17  |
| _mean_discrew   | 2.31      |
| _mean_obs       | 0.0295    |
| _min_adv        | -14       |
| _min_discrew    | -1.07     |
| _min_obs        | -1.33     |
| _std_act        | 0.646645  |
| _std_adv        | 1         |
| _std_discrew    | 1.29      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.858     |
| ExplainedVarOld | 0.849     |
| KL              | 0.0141458 |
| Phi_loss        | 870.557   |
| PolicyEntropy   | 0.764104  |
| PolicyLoss      | 0.49888   |
| Steps           | 10000     |
| VarFuncLoss     | 0.184     |
| _MeanReward     | 2.68e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.8641    |
| _max_adv        | 8.34      |
| _max_discrew    | 3.44      |
| _max_obs        | 1.58      |
| _mean_act       | -0.137249 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 2.18      |
| _mean_obs       | 0.0288    |
| _min_adv        | -8.49     |
| _min_discrew    | -0.791    |
| _min_obs        | -1.17     |
| _std_act        | 0.642152  |
| _std_adv        | 1         |
| _std_discrew    | 1.06      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
---------------------------------
| Beta            | 23.3        |
| ExplainedVarNew | 0.794       |
| ExplainedVarOld | 0.77        |
| KL              | 0.000968353 |
| Phi_loss        | 652.442     |
| PolicyEntropy   | 0.762932    |
| PolicyLoss      | 0.0640934   |
| Steps           | 10000       |
| VarFuncLoss     | 0.227       |
| _MeanReward     | 2.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63579     |
| _max_adv        | 7.76        |
| _max_discrew    | 3.58        |
| _max_obs        | 1.6         |
| _mean_act       | -0.2218     |
| _mean_adv       | 0           |
| _mean_discrew   | 1.67        |
| _mean_obs       | 0.0247      |
| _min_adv        | -9.69       |
| _min_discrew    | -1.11       |
| _min_obs        | -1.1        |
| _std_act        | 0.729199    |
| _std_adv        | 1           |
| _std_discrew    | 2.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
---------------------------------
| Beta            | 15.6        |
| ExplainedVarNew | 0.818       |
| ExplainedVarOld | 0.803       |
| KL              | 8.38056e-05 |
| Phi_loss        | 623.638     |
| PolicyEntropy   | 0.76228     |
| PolicyLoss      | -0.0104482  |
| Steps           | 10000       |
| VarFuncLoss     | 0.388       |
| _MeanReward     | 2.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5775      |
| _max_adv        | 6.1         |
| _max_discrew    | 3.54        |
| _max_obs        | 1.58        |
| _mean_act       | -0.142566   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 2.09        |
| _mean_obs       | 0.0288      |
| _min_adv        | -13.5       |
| _min_discrew    | -1.11       |
| _min_obs        | -1.14       |
| _std_act        | 0.661176    |
| _std_adv        | 1           |
| _std_discrew    | 1.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.852       |
| ExplainedVarOld | 0.849       |
| KL              | 7.68595e-06 |
| Phi_loss        | 681.302     |
| PolicyEntropy   | 0.76228     |
| PolicyLoss      | 0.0264001   |
| Steps           | 10000       |
| VarFuncLoss     | 0.204       |
| _MeanReward     | 2.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90536     |
| _max_adv        | 9.47        |
| _max_discrew    | 3.42        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0963293  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 2.34        |
| _mean_obs       | 0.0306      |
| _min_adv        | -7.16       |
| _min_discrew    | -0.00357    |
| _min_obs        | -1.14       |
| _std_act        | 0.609667    |
| _std_adv        | 1           |
| _std_discrew    | 0.644       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
---------------------------------
| Beta            | 6.91        |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.862       |
| KL              | 4.26309e-06 |
| Phi_loss        | 626.634     |
| PolicyEntropy   | 0.761922    |
| PolicyLoss      | 0.00371448  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0757      |
| _MeanReward     | 2.59e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.47175     |
| _max_adv        | 5.64        |
| _max_discrew    | 3.71        |
| _max_obs        | 1.56        |
| _mean_act       | -0.163772   |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | 2.08        |
| _mean_obs       | 0.0274      |
| _min_adv        | -11         |
| _min_discrew    | -1.08       |
| _min_obs        | -1.23       |
| _std_act        | 0.686394    |
| _std_adv        | 1           |
| _std_discrew    | 1.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.815       |
| ExplainedVarOld | 0.809       |
| KL              | 7.22809e-06 |
| Phi_loss        | 690.293     |
| PolicyEntropy   | 0.761297    |
| PolicyLoss      | 0.00901958  |
| Steps           | 10000       |
| VarFuncLoss     | 0.343       |
| _MeanReward     | 2.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58743     |
| _max_adv        | 5.95        |
| _max_discrew    | 3.37        |
| _max_obs        | 1.58        |
| _mean_act       | -0.115199   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.21        |
| _mean_obs       | 0.0304      |
| _min_adv        | -11.2       |
| _min_discrew    | -0.862      |
| _min_obs        | -1.21       |
| _std_act        | 0.633987    |
| _std_adv        | 1           |
| _std_discrew    | 0.995       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.845       |
| ExplainedVarOld | 0.838       |
| KL              | 9.72128e-06 |
| Phi_loss        | 637.448     |
| PolicyEntropy   | 0.76032     |
| PolicyLoss      | 0.0180546   |
| Steps           | 10000       |
| VarFuncLoss     | 0.155       |
| _MeanReward     | 2.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.61169     |
| _max_adv        | 4.8         |
| _max_discrew    | 3.63        |
| _max_obs        | 1.6         |
| _mean_act       | -0.234863   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.64        |
| _mean_obs       | 0.0248      |
| _min_adv        | -9.68       |
| _min_discrew    | -1.14       |
| _min_obs        | -1.23       |
| _std_act        | 0.736404    |
| _std_adv        | 1           |
| _std_discrew    | 2.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
---------------------------------
| Beta            | 2.05        |
| ExplainedVarNew | 0.825       |
| ExplainedVarOld | 0.818       |
| KL              | 1.74462e-05 |
| Phi_loss        | 761.198     |
| PolicyEntropy   | 0.760189    |
| PolicyLoss      | 0.0234168   |
| Steps           | 10000       |
| VarFuncLoss     | 0.417       |
| _MeanReward     | 2.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60357     |
| _max_adv        | 9.22        |
| _max_discrew    | 3.63        |
| _max_obs        | 1.62        |
| _mean_act       | -0.117161   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.33        |
| _mean_obs       | 0.0295      |
| _min_adv        | -12.3       |
| _min_discrew    | -0.968      |
| _min_obs        | -1.2        |
| _std_act        | 0.637155    |
| _std_adv        | 1           |
| _std_discrew    | 1.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.831       |
| ExplainedVarOld | 0.822       |
| KL              | 3.7725e-05  |
| Phi_loss        | 785.574     |
| PolicyEntropy   | 0.760128    |
| PolicyLoss      | -0.00236816 |
| Steps           | 10000       |
| VarFuncLoss     | 0.198       |
| _MeanReward     | 3.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55892     |
| _max_adv        | 10.7        |
| _max_discrew    | 3.54        |
| _max_obs        | 1.67        |
| _mean_act       | -0.0910986  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.45        |
| _mean_obs       | 0.0318      |
| _min_adv        | -7.82       |
| _min_discrew    | -0.373      |
| _min_obs        | -1.14       |
| _std_act        | 0.609171    |
| _std_adv        | 1           |
| _std_discrew    | 0.772       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.917       |
| ExplainedVarOld | 0.885       |
| KL              | 6.31666e-05 |
| Phi_loss        | 623.949     |
| PolicyEntropy   | 0.760674    |
| PolicyLoss      | 0.00328831  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0642      |
| _MeanReward     | 2.66e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6602      |
| _max_adv        | 4.24        |
| _max_discrew    | 3.36        |
| _max_obs        | 1.55        |
| _mean_act       | -0.131369   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.15        |
| _mean_obs       | 0.0291      |
| _min_adv        | -14.9       |
| _min_discrew    | -1.05       |
| _min_obs        | -1.17       |
| _std_act        | 0.655475    |
| _std_adv        | 1           |
| _std_discrew    | 1.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.86        |
| ExplainedVarOld | 0.849       |
| KL              | 0.000110653 |
| Phi_loss        | 711.09      |
| PolicyEntropy   | 0.763831    |
| PolicyLoss      | 0.00387546  |
| Steps           | 10000       |
| VarFuncLoss     | 0.168       |
| _MeanReward     | 2.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85932     |
| _max_adv        | 2.91        |
| _max_discrew    | 3.47        |
| _max_obs        | 1.65        |
| _mean_act       | -0.209655   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 1.79        |
| _mean_obs       | 0.025       |
| _min_adv        | -11.9       |
| _min_discrew    | -1.14       |
| _min_obs        | -1.13       |
| _std_act        | 0.720865    |
| _std_adv        | 1           |
| _std_discrew    | 2.18        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
---------------------------------
| Beta            | 0.405       |
| ExplainedVarNew | 0.892       |
| ExplainedVarOld | 0.882       |
| KL              | 0.000260926 |
| Phi_loss        | 460.782     |
| PolicyEntropy   | 0.763343    |
| PolicyLoss      | 0.0193809   |
| Steps           | 10000       |
| VarFuncLoss     | 0.236       |
| _MeanReward     | 2.92e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71906     |
| _max_adv        | 6.99        |
| _max_discrew    | 3.58        |
| _max_obs        | 1.64        |
| _mean_act       | -0.106772   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.35        |
| _mean_obs       | 0.0308      |
| _min_adv        | -10.7       |
| _min_discrew    | -0.747      |
| _min_obs        | -1.45       |
| _std_act        | 0.636111    |
| _std_adv        | 1           |
| _std_discrew    | 1.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
--------------------------------
| Beta            | 0.27       |
| ExplainedVarNew | 0.871      |
| ExplainedVarOld | 0.844      |
| KL              | 0.00080303 |
| Phi_loss        | 697.512    |
| PolicyEntropy   | 0.763988   |
| PolicyLoss      | 0.014692   |
| Steps           | 10000      |
| VarFuncLoss     | 0.144      |
| _MeanReward     | 2.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82522    |
| _max_adv        | 6.15       |
| _max_discrew    | 3.67       |
| _max_obs        | 1.8        |
| _mean_act       | -0.172379  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.01       |
| _mean_obs       | 0.0272     |
| _min_adv        | -12.8      |
| _min_discrew    | -1.14      |
| _min_obs        | -1.28      |
| _std_act        | 0.689237   |
| _std_adv        | 1          |
| _std_discrew    | 1.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.855       |
| ExplainedVarOld | 0.851       |
| KL              | 0.000816973 |
| Phi_loss        | 661.174     |
| PolicyEntropy   | 0.769981    |
| PolicyLoss      | 0.00503967  |
| Steps           | 10000       |
| VarFuncLoss     | 0.257       |
| _MeanReward     | 2.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66204     |
| _max_adv        | 8.84        |
| _max_discrew    | 3.64        |
| _max_obs        | 1.68        |
| _mean_act       | -0.174114   |
| _mean_adv       | 0           |
| _mean_discrew   | 2.03        |
| _mean_obs       | 0.0274      |
| _min_adv        | -10.9       |
| _min_discrew    | -1.14       |
| _min_obs        | -1.3        |
| _std_act        | 0.692334    |
| _std_adv        | 1           |
| _std_discrew    | 1.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.875      |
| ExplainedVarOld | 0.865      |
| KL              | 0.00100214 |
| Phi_loss        | 508.204    |
| PolicyEntropy   | 0.776175   |
| PolicyLoss      | -0.0194638 |
| Steps           | 10000      |
| VarFuncLoss     | 0.233      |
| _MeanReward     | 3.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7775     |
| _max_adv        | 9.02       |
| _max_discrew    | 3.71       |
| _max_obs        | 1.81       |
| _mean_act       | -0.0734874 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.56       |
| _mean_obs       | 0.0325     |
| _min_adv        | -5.05      |
| _min_discrew    | 0.00623    |
| _min_obs        | -1.11      |
| _std_act        | 0.594064   |
| _std_adv        | 1          |
| _std_discrew    | 0.683      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
--------------------------------
| Beta            | 0.12       |
| ExplainedVarNew | 0.889      |
| ExplainedVarOld | 0.877      |
| KL              | 0.00191408 |
| Phi_loss        | 691.92     |
| PolicyEntropy   | 0.770668   |
| PolicyLoss      | 0.0122053  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0791     |
| _MeanReward     | 3.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7544     |
| _max_adv        | 3.46       |
| _max_discrew    | 3.71       |
| _max_obs        | 1.65       |
| _mean_act       | -0.0911724 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.55       |
| _mean_obs       | 0.0318     |
| _min_adv        | -15.8      |
| _min_discrew    | -0.919     |
| _min_obs        | -1.2       |
| _std_act        | 0.625542   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.872      |
| ExplainedVarOld | 0.864      |
| KL              | 0.00138904 |
| Phi_loss        | 874.901    |
| PolicyEntropy   | 0.771393   |
| PolicyLoss      | -0.0145042 |
| Steps           | 10000      |
| VarFuncLoss     | 0.159      |
| _MeanReward     | 3.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6398     |
| _max_adv        | 7.86       |
| _max_discrew    | 3.63       |
| _max_obs        | 1.69       |
| _mean_act       | -0.0760278 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.59       |
| _mean_obs       | 0.0328     |
| _min_adv        | -6.92      |
| _min_discrew    | 0.00993    |
| _min_obs        | -1.11      |
| _std_act        | 0.597603   |
| _std_adv        | 1          |
| _std_discrew    | 0.679      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.928      |
| ExplainedVarOld | 0.916      |
| KL              | 0.00184204 |
| Phi_loss        | 580.715    |
| PolicyEntropy   | 0.766892   |
| PolicyLoss      | 0.0225752  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0495     |
| _MeanReward     | 2.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47823    |
| _max_adv        | 5.42       |
| _max_discrew    | 3.74       |
| _max_obs        | 1.52       |
| _mean_act       | -0.128887  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.33       |
| _mean_obs       | 0.0294     |
| _min_adv        | -15.5      |
| _min_discrew    | -1.11      |
| _min_obs        | -1.25      |
| _std_act        | 0.662336   |
| _std_adv        | 1          |
| _std_discrew    | 1.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.89       |
| KL              | 0.0034745  |
| Phi_loss        | 716.364    |
| PolicyEntropy   | 0.741987   |
| PolicyLoss      | 0.0162003  |
| Steps           | 10000      |
| VarFuncLoss     | 0.179      |
| _MeanReward     | 3.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59829    |
| _max_adv        | 7.8        |
| _max_discrew    | 3.68       |
| _max_obs        | 1.26       |
| _mean_act       | -0.0625216 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.65       |
| _mean_obs       | 0.0331     |
| _min_adv        | -5.35      |
| _min_discrew    | 0.00591    |
| _min_obs        | -1.22      |
| _std_act        | 0.585585   |
| _std_adv        | 1          |
| _std_discrew    | 0.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.955      |
| ExplainedVarOld | 0.95       |
| KL              | 0.0036138  |
| Phi_loss        | 737.277    |
| PolicyEntropy   | 0.731955   |
| PolicyLoss      | 0.0146342  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0343     |
| _MeanReward     | 3.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52262    |
| _max_adv        | 12.6       |
| _max_discrew    | 3.71       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0612934 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.73       |
| _mean_obs       | 0.0331     |
| _min_adv        | -8.85      |
| _min_discrew    | 0.00642    |
| _min_obs        | -1.26      |
| _std_act        | 0.57862    |
| _std_adv        | 1          |
| _std_discrew    | 0.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
--------------------------------
| Beta            | 0.0799     |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.938      |
| KL              | 0.00185215 |
| Phi_loss        | 778.212    |
| PolicyEntropy   | 0.720873   |
| PolicyLoss      | -0.0165821 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0467     |
| _MeanReward     | 3.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6851     |
| _max_adv        | 4.63       |
| _max_discrew    | 3.81       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0546208 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.81       |
| _mean_obs       | 0.0343     |
| _min_adv        | -6.4       |
| _min_discrew    | 0.012      |
| _min_obs        | -1.19      |
| _std_act        | 0.58792    |
| _std_adv        | 1          |
| _std_discrew    | 0.83       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.967      |
| KL              | 0.00130213 |
| Phi_loss        | 728.056    |
| PolicyEntropy   | 0.703191   |
| PolicyLoss      | 0.00433161 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0255     |
| _MeanReward     | 3.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66109    |
| _max_adv        | 4.42       |
| _max_discrew    | 3.78       |
| _max_obs        | 1.52       |
| _mean_act       | -0.0602    |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.72       |
| _mean_obs       | 0.034      |
| _min_adv        | -11        |
| _min_discrew    | -0.402     |
| _min_obs        | -1.16      |
| _std_act        | 0.594752   |
| _std_adv        | 1          |
| _std_discrew    | 0.858      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.914       |
| KL              | 0.0012524   |
| Phi_loss        | 776.484     |
| PolicyEntropy   | 0.697452    |
| PolicyLoss      | -0.00678171 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0728      |
| _MeanReward     | 3.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.53676     |
| _max_adv        | 4.35        |
| _max_discrew    | 3.86        |
| _max_obs        | 1.57        |
| _mean_act       | -0.0507725  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 2.85        |
| _mean_obs       | 0.0347      |
| _min_adv        | -9.63       |
| _min_discrew    | 0.0133      |
| _min_obs        | -1.17       |
| _std_act        | 0.585737    |
| _std_adv        | 1           |
| _std_discrew    | 0.808       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.952       |
| ExplainedVarOld | 0.95        |
| KL              | 0.00273148  |
| Phi_loss        | 856.174     |
| PolicyEntropy   | 0.691957    |
| PolicyLoss      | -0.00842785 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0421      |
| _MeanReward     | 3.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52319     |
| _max_adv        | 5.65        |
| _max_discrew    | 3.77        |
| _max_obs        | 1.11        |
| _mean_act       | -0.0516005  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.81        |
| _mean_obs       | 0.034       |
| _min_adv        | -5.92       |
| _min_discrew    | 0.00568     |
| _min_obs        | -1.14       |
| _std_act        | 0.578997    |
| _std_adv        | 1           |
| _std_discrew    | 0.801       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00358581 |
| Phi_loss        | 790.933    |
| PolicyEntropy   | 0.673369   |
| PolicyLoss      | 0.0088111  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0265     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61586    |
| _max_adv        | 18.3       |
| _max_discrew    | 3.95       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0475332 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 2.93       |
| _mean_obs       | 0.0349     |
| _min_adv        | -8.38      |
| _min_discrew    | 0.00917    |
| _min_obs        | -1.2       |
| _std_act        | 0.584727   |
| _std_adv        | 1          |
| _std_discrew    | 0.841      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.968       |
| ExplainedVarOld | 0.962       |
| KL              | 0.00295662  |
| Phi_loss        | 657.967     |
| PolicyEntropy   | 0.662128    |
| PolicyLoss      | -0.00337738 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0292      |
| _MeanReward     | 3.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58321     |
| _max_adv        | 2.37        |
| _max_discrew    | 3.88        |
| _max_obs        | 1.54        |
| _mean_act       | -0.0608997  |
| _mean_adv       | 0           |
| _mean_discrew   | 2.86        |
| _mean_obs       | 0.0342      |
| _min_adv        | -10         |
| _min_discrew    | -0.419      |
| _min_obs        | -1.16       |
| _std_act        | 0.600468    |
| _std_adv        | 1           |
| _std_discrew    | 0.969       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.936      |
| ExplainedVarOld | 0.932      |
| KL              | 0.00220475 |
| Phi_loss        | 737.041    |
| PolicyEntropy   | 0.672675   |
| PolicyLoss      | 0.0102681  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0625     |
| _MeanReward     | 3.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7239     |
| _max_adv        | 2.55       |
| _max_discrew    | 3.99       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0543887 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.91       |
| _mean_obs       | 0.0349     |
| _min_adv        | -7.48      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.22      |
| _std_act        | 0.57858    |
| _std_adv        | 1          |
| _std_discrew    | 0.811      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.947       |
| ExplainedVarOld | 0.943       |
| KL              | 0.00132487  |
| Phi_loss        | 793.106     |
| PolicyEntropy   | 0.669361    |
| PolicyLoss      | 0.000375637 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0439      |
| _MeanReward     | 3.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.50694     |
| _max_adv        | 6.87        |
| _max_discrew    | 3.99        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0472522  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.98        |
| _mean_obs       | 0.0351      |
| _min_adv        | -7.71       |
| _min_discrew    | -0.0182     |
| _min_obs        | -1.08       |
| _std_act        | 0.573042    |
| _std_adv        | 1           |
| _std_discrew    | 0.89        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00416743 |
| Phi_loss        | 779.996    |
| PolicyEntropy   | 0.643167   |
| PolicyLoss      | 0.0287032  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0212     |
| _MeanReward     | 3.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61033    |
| _max_adv        | 7.55       |
| _max_discrew    | 3.94       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0395745 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.99       |
| _mean_obs       | 0.0361     |
| _min_adv        | -9.8       |
| _min_discrew    | 0.00568    |
| _min_obs        | -1.18      |
| _std_act        | 0.57936    |
| _std_adv        | 1          |
| _std_discrew    | 0.853      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00272513 |
| Phi_loss        | 721.871    |
| PolicyEntropy   | 0.620639   |
| PolicyLoss      | -0.0245455 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0196     |
| _MeanReward     | 3.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55803    |
| _max_adv        | 4.37       |
| _max_discrew    | 4.02       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0419554 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.03       |
| _mean_obs       | 0.0362     |
| _min_adv        | -7.77      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.23      |
| _std_act        | 0.586983   |
| _std_adv        | 1          |
| _std_discrew    | 0.862      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.979      |
| KL              | 0.00350884 |
| Phi_loss        | 735.806    |
| PolicyEntropy   | 0.597837   |
| PolicyLoss      | 0.0111134  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0182     |
| _MeanReward     | 3.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.56006    |
| _max_adv        | 3.7        |
| _max_discrew    | 4.03       |
| _max_obs        | 1.12       |
| _mean_act       | -0.040686  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.06       |
| _mean_obs       | 0.0366     |
| _min_adv        | -9.07      |
| _min_discrew    | 0.0107     |
| _min_obs        | -1.25      |
| _std_act        | 0.585193   |
| _std_adv        | 1          |
| _std_discrew    | 0.854      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.963      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00386297 |
| Phi_loss        | 674.674    |
| PolicyEntropy   | 0.555553   |
| PolicyLoss      | 0.00124022 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0315     |
| _MeanReward     | 3.73e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47706    |
| _max_adv        | 7.45       |
| _max_discrew    | 4.03       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0382443 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.08       |
| _mean_obs       | 0.0365     |
| _min_adv        | -8.6       |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.16      |
| _std_act        | 0.58727    |
| _std_adv        | 1          |
| _std_discrew    | 0.912      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00215536 |
| Phi_loss        | 730.337    |
| PolicyEntropy   | 0.509602   |
| PolicyLoss      | -0.0092462 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0186     |
| _MeanReward     | 3.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37628    |
| _max_adv        | 2.33       |
| _max_discrew    | 4          |
| _max_obs        | 1.54       |
| _mean_act       | -0.0587925 |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 2.89       |
| _mean_obs       | 0.0352     |
| _min_adv        | -13.6      |
| _min_discrew    | -0.716     |
| _min_obs        | -1.14      |
| _std_act        | 0.610549   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.894      |
| KL              | 0.00171636 |
| Phi_loss        | 710.151    |
| PolicyEntropy   | 0.504004   |
| PolicyLoss      | 0.00304819 |
| Steps           | 10000      |
| VarFuncLoss     | 0.117      |
| _MeanReward     | 3.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43296    |
| _max_adv        | 7.6        |
| _max_discrew    | 4.04       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0386261 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0364     |
| _min_adv        | -9.37      |
| _min_discrew    | 0.00908    |
| _min_obs        | -1.26      |
| _std_act        | 0.58566    |
| _std_adv        | 1          |
| _std_discrew    | 0.877      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.969      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00282051 |
| Phi_loss        | 734.631    |
| PolicyEntropy   | 0.500943   |
| PolicyLoss      | 0.00158136 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0328     |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46863    |
| _max_adv        | 14.2       |
| _max_discrew    | 4.21       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0406217 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.11       |
| _mean_obs       | 0.0366     |
| _min_adv        | -5.32      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.22      |
| _std_act        | 0.587193   |
| _std_adv        | 1          |
| _std_discrew    | 0.9        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.977      |
| KL              | 0.00265786 |
| Phi_loss        | 721.056    |
| PolicyEntropy   | 0.491906   |
| PolicyLoss      | 0.00996705 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0196     |
| _MeanReward     | 3.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35993    |
| _max_adv        | 2.65       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.57       |
| _mean_act       | -0.0562753 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.96       |
| _mean_obs       | 0.0354     |
| _min_adv        | -17.9      |
| _min_discrew    | -0.777     |
| _min_obs        | -1.12      |
| _std_act        | 0.610486   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.882       |
| ExplainedVarOld | 0.878       |
| KL              | 0.00165567  |
| Phi_loss        | 792.297     |
| PolicyEntropy   | 0.502571    |
| PolicyLoss      | 2.46398e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.15        |
| _MeanReward     | 3.72e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63972     |
| _max_adv        | 3.5         |
| _max_discrew    | 4.04        |
| _max_obs        | 1.09        |
| _mean_act       | -0.0369625  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 3.07        |
| _mean_obs       | 0.0365      |
| _min_adv        | -7.6        |
| _min_discrew    | 0.0184      |
| _min_obs        | -1.19       |
| _std_act        | 0.583995    |
| _std_adv        | 1           |
| _std_discrew    | 0.893       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.966      |
| KL              | 0.00290154 |
| Phi_loss        | 781.338    |
| PolicyEntropy   | 0.488158   |
| PolicyLoss      | 0.00634023 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0309     |
| _MeanReward     | 3.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.57829    |
| _max_adv        | 11.3       |
| _max_discrew    | 4.16       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0340024 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 3.14       |
| _mean_obs       | 0.0371     |
| _min_adv        | -5.9       |
| _min_discrew    | 0.00895    |
| _min_obs        | -1.12      |
| _std_act        | 0.588462   |
| _std_adv        | 1          |
| _std_discrew    | 0.948      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00263317  |
| Phi_loss        | 710.332     |
| PolicyEntropy   | 0.470267    |
| PolicyLoss      | -0.00123017 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0181      |
| _MeanReward     | 3.81e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60615     |
| _max_adv        | 21.6        |
| _max_discrew    | 4.15        |
| _max_obs        | 1.18        |
| _mean_act       | -0.0363616  |
| _mean_adv       | -7.11e-18   |
| _mean_discrew   | 3.16        |
| _mean_obs       | 0.0374      |
| _min_adv        | -9.92       |
| _min_discrew    | 0.00845     |
| _min_obs        | -1.13       |
| _std_act        | 0.585817    |
| _std_adv        | 1           |
| _std_discrew    | 0.939       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0020674  |
| Phi_loss        | 579.251    |
| PolicyEntropy   | 0.450707   |
| PolicyLoss      | 0.00863649 |
| Steps           | 10000      |
| VarFuncLoss     | 0.016      |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.668      |
| _max_adv        | 3.42       |
| _max_discrew    | 4.31       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0344956 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.11       |
| _mean_obs       | 0.037      |
| _min_adv        | -9.33      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.16      |
| _std_act        | 0.585375   |
| _std_adv        | 1          |
| _std_discrew    | 0.971      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.956      |
| ExplainedVarOld | 0.946      |
| KL              | 0.00276867 |
| Phi_loss        | 630.294    |
| PolicyEntropy   | 0.429253   |
| PolicyLoss      | -0.0170437 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0435     |
| _MeanReward     | 3.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51011    |
| _max_adv        | 11.3       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0311799 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0372     |
| _min_adv        | -9.36      |
| _min_discrew    | 0.00507    |
| _min_obs        | -1.2       |
| _std_act        | 0.597877   |
| _std_adv        | 1          |
| _std_discrew    | 0.984      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00360347  |
| Phi_loss        | 751.312     |
| PolicyEntropy   | 0.420003    |
| PolicyLoss      | 4.82987e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0223      |
| _MeanReward     | 3.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60232     |
| _max_adv        | 6           |
| _max_discrew    | 4.2         |
| _max_obs        | 1.16        |
| _mean_act       | -0.0280198  |
| _mean_adv       | -1.56e-17   |
| _mean_discrew   | 3.12        |
| _mean_obs       | 0.0376      |
| _min_adv        | -8.68       |
| _min_discrew    | 0.0117      |
| _min_obs        | -1.1        |
| _std_act        | 0.587668    |
| _std_adv        | 1           |
| _std_discrew    | 0.927       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00283034 |
| Phi_loss        | 745.372    |
| PolicyEntropy   | 0.416365   |
| PolicyLoss      | 0.028967   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0246     |
| _MeanReward     | 3.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5632     |
| _max_adv        | 5.75       |
| _max_discrew    | 4.2        |
| _max_obs        | 1.13       |
| _mean_act       | -0.0299356 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0377     |
| _min_adv        | -6.95      |
| _min_discrew    | 0.0114     |
| _min_obs        | -1.2       |
| _std_act        | 0.588086   |
| _std_adv        | 1          |
| _std_discrew    | 0.93       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00442781  |
| Phi_loss        | 960.139     |
| PolicyEntropy   | 0.389599    |
| PolicyLoss      | -0.00814211 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0151      |
| _MeanReward     | 3.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.41967     |
| _max_adv        | 4.21        |
| _max_discrew    | 4.14        |
| _max_obs        | 1.16        |
| _mean_act       | -0.0244535  |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 3.13        |
| _mean_obs       | 0.0376      |
| _min_adv        | -8.55       |
| _min_discrew    | 0.00797     |
| _min_obs        | -1.15       |
| _std_act        | 0.584635    |
| _std_adv        | 1           |
| _std_discrew    | 0.927       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00298337 |
| Phi_loss        | 907.678    |
| PolicyEntropy   | 0.356751   |
| PolicyLoss      | -0.0106998 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0309     |
| _MeanReward     | 3.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.613      |
| _max_adv        | 3.18       |
| _max_discrew    | 4.28       |
| _max_obs        | 1.25       |
| _mean_act       | -0.0176088 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0379     |
| _min_adv        | -12.4      |
| _min_discrew    | 0.0109     |
| _min_obs        | -1.36      |
| _std_act        | 0.58839    |
| _std_adv        | 1          |
| _std_discrew    | 0.912      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.971      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00366084 |
| Phi_loss        | 1007.6     |
| PolicyEntropy   | 0.313727   |
| PolicyLoss      | 0.00291953 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0266     |
| _MeanReward     | 3.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.67025    |
| _max_adv        | 9.74       |
| _max_discrew    | 4.24       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0177502 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.039      |
| _min_adv        | -5.33      |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.13      |
| _std_act        | 0.59092    |
| _std_adv        | 1          |
| _std_discrew    | 0.982      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00253929 |
| Phi_loss        | 893.692    |
| PolicyEntropy   | 0.292185   |
| PolicyLoss      | -0.0125898 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 3.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66585    |
| _max_adv        | 7.22       |
| _max_discrew    | 4.23       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0146981 |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 3.21       |
| _mean_obs       | 0.0387     |
| _min_adv        | -5.99      |
| _min_discrew    | 0.0101     |
| _min_obs        | -1.13      |
| _std_act        | 0.588245   |
| _std_adv        | 1          |
| _std_discrew    | 0.968      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00454734 |
| Phi_loss        | 905.897    |
| PolicyEntropy   | 0.268756   |
| PolicyLoss      | -0.0431163 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0135     |
| _MeanReward     | 3.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48415    |
| _max_adv        | 3.87       |
| _max_discrew    | 4.22       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0210116 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.12       |
| _mean_obs       | 0.0378     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.00991    |
| _min_obs        | -1.17      |
| _std_act        | 0.586618   |
| _std_adv        | 1          |
| _std_discrew    | 0.933      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.956      |
| KL              | 0.00427882 |
| Phi_loss        | 797.732    |
| PolicyEntropy   | 0.261434   |
| PolicyLoss      | 0.0274123  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0387     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52575    |
| _max_adv        | 5.16       |
| _max_discrew    | 4.25       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0161087 |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 3.19       |
| _mean_obs       | 0.0387     |
| _min_adv        | -6.72      |
| _min_discrew    | 0.00603    |
| _min_obs        | -1.14      |
| _std_act        | 0.591365   |
| _std_adv        | 1          |
| _std_discrew    | 0.94       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.973      |
| KL              | 0.00345941 |
| Phi_loss        | 939.053    |
| PolicyEntropy   | 0.249202   |
| PolicyLoss      | -0.0131262 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0244     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55066    |
| _max_adv        | 4.65       |
| _max_discrew    | 4.15       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0125919 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.2        |
| _mean_obs       | 0.0391     |
| _min_adv        | -8.88      |
| _min_discrew    | 0.0075     |
| _min_obs        | -1.07      |
| _std_act        | 0.594268   |
| _std_adv        | 1          |
| _std_discrew    | 0.977      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00261415  |
| Phi_loss        | 947.167     |
| PolicyEntropy   | 0.236738    |
| PolicyLoss      | 0.000636268 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0208      |
| _MeanReward     | 3.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51634     |
| _max_adv        | 3.34        |
| _max_discrew    | 4.26        |
| _max_obs        | 1.1         |
| _mean_act       | -0.0167028  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.25        |
| _mean_obs       | 0.0395      |
| _min_adv        | -9.15       |
| _min_discrew    | 0.00356     |
| _min_obs        | -1.25       |
| _std_act        | 0.595771    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00437534 |
| Phi_loss        | 1046.07    |
| PolicyEntropy   | 0.22731    |
| PolicyLoss      | -0.0481667 |
| Steps           | 10000      |
| VarFuncLoss     | 0.022      |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51056    |
| _max_adv        | 18.5       |
| _max_discrew    | 4.37       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0145434 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.25       |
| _mean_obs       | 0.0398     |
| _min_adv        | -7.77      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.09      |
| _std_act        | 0.599468   |
| _std_adv        | 1          |
| _std_discrew    | 1.01       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00326633 |
| Phi_loss        | 1092.82    |
| PolicyEntropy   | 0.208709   |
| PolicyLoss      | 0.0158675  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0141     |
| _MeanReward     | 3.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37044    |
| _max_adv        | 4.83       |
| _max_discrew    | 4.14       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0203336 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.17       |
| _mean_obs       | 0.0394     |
| _min_adv        | -7.21      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.23      |
| _std_act        | 0.610084   |
| _std_adv        | 1          |
| _std_discrew    | 0.927      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.962      |
| KL              | 0.00367422 |
| Phi_loss        | 967.112    |
| PolicyEntropy   | 0.217183   |
| PolicyLoss      | 0.0051099  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0345     |
| _MeanReward     | 3.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.34239    |
| _max_adv        | 3.99       |
| _max_discrew    | 4.27       |
| _max_obs        | 1.14       |
| _mean_act       | -0.013405  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0399     |
| _min_adv        | -11.8      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.21      |
| _std_act        | 0.608657   |
| _std_adv        | 1          |
| _std_discrew    | 1.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.975       |
| KL              | 0.00314952  |
| Phi_loss        | 900.638     |
| PolicyEntropy   | 0.216161    |
| PolicyLoss      | -0.0182347  |
| Steps           | 10000       |
| VarFuncLoss     | 0.025       |
| _MeanReward     | 3.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.40335     |
| _max_adv        | 3.77        |
| _max_discrew    | 4.38        |
| _max_obs        | 1.1         |
| _mean_act       | -0.00900443 |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.21        |
| _mean_obs       | 0.0396      |
| _min_adv        | -6.03       |
| _min_discrew    | 0.0118      |
| _min_obs        | -1.19       |
| _std_act        | 0.607031    |
| _std_adv        | 1           |
| _std_discrew    | 1           |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.972       |
| KL              | 0.00588573  |
| Phi_loss        | 1074.64     |
| PolicyEntropy   | 0.202523    |
| PolicyLoss      | -0.0277812  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0278      |
| _MeanReward     | 3.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5284      |
| _max_adv        | 3.58        |
| _max_discrew    | 4.33        |
| _max_obs        | 1.21        |
| _mean_act       | -0.00857011 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.21        |
| _mean_obs       | 0.0397      |
| _min_adv        | -7.57       |
| _min_discrew    | 0.0114      |
| _min_obs        | -1.23       |
| _std_act        | 0.605234    |
| _std_adv        | 1           |
| _std_discrew    | 0.974       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00448954 |
| Phi_loss        | 1060.81    |
| PolicyEntropy   | 0.177359   |
| PolicyLoss      | 0.0114011  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0312     |
| _MeanReward     | 3.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.34846    |
| _max_adv        | 4.32       |
| _max_discrew    | 4.25       |
| _max_obs        | 1.61       |
| _mean_act       | -0.0107936 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.24       |
| _mean_obs       | 0.0399     |
| _min_adv        | -7.5       |
| _min_discrew    | -0.0595    |
| _min_obs        | -1.24      |
| _std_act        | 0.612471   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.973       |
| KL              | 0.0043089   |
| Phi_loss        | 1092.93     |
| PolicyEntropy   | 0.13594     |
| PolicyLoss      | 0.0125654   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0272      |
| _MeanReward     | 3.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.49235     |
| _max_adv        | 4.2         |
| _max_discrew    | 4.39        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00908435 |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 3.26        |
| _mean_obs       | 0.0403      |
| _min_adv        | -8.44       |
| _min_discrew    | 0.0108      |
| _min_obs        | -1.25       |
| _std_act        | 0.606419    |
| _std_adv        | 1           |
| _std_discrew    | 0.97        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.973       |
| ExplainedVarOld | 0.972       |
| KL              | 0.0044627   |
| Phi_loss        | 1048.84     |
| PolicyEntropy   | 0.109187    |
| PolicyLoss      | -0.0012038  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0259      |
| _MeanReward     | 4.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.50074     |
| _max_adv        | 5.5         |
| _max_discrew    | 4.33        |
| _max_obs        | 1.17        |
| _mean_act       | -0.00485898 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0407      |
| _min_adv        | -6.01       |
| _min_discrew    | 0.00728     |
| _min_obs        | -1.34       |
| _std_act        | 0.608317    |
| _std_adv        | 1           |
| _std_discrew    | 1.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00419179  |
| Phi_loss        | 1085.48     |
| PolicyEntropy   | 0.0658903   |
| PolicyLoss      | -0.0159181  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0157      |
| _MeanReward     | 3.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.54223     |
| _max_adv        | 3.27        |
| _max_discrew    | 4.26        |
| _max_obs        | 1.16        |
| _mean_act       | -0.00738112 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.23        |
| _mean_obs       | 0.0396      |
| _min_adv        | -12.2       |
| _min_discrew    | 0.00727     |
| _min_obs        | -1.26       |
| _std_act        | 0.606026    |
| _std_adv        | 1           |
| _std_discrew    | 0.981       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.966       |
| ExplainedVarOld | 0.963       |
| KL              | 0.0049301   |
| Phi_loss        | 1079.39     |
| PolicyEntropy   | 0.0243254   |
| PolicyLoss      | -0.00703473 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0348      |
| _MeanReward     | 3.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.36975     |
| _max_adv        | 3.01        |
| _max_discrew    | 4.4         |
| _max_obs        | 1.63        |
| _mean_act       | -0.0142235  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.21        |
| _mean_obs       | 0.0396      |
| _min_adv        | -15.2       |
| _min_discrew    | -0.396      |
| _min_obs        | -1.28       |
| _std_act        | 0.622174    |
| _std_adv        | 1           |
| _std_discrew    | 1.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.953       |
| ExplainedVarOld | 0.95        |
| KL              | 0.00298272  |
| Phi_loss        | 914.983     |
| PolicyEntropy   | -0.0120678  |
| PolicyLoss      | 0.0286856   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0558      |
| _MeanReward     | 4e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 2.45743     |
| _max_adv        | 3.79        |
| _max_discrew    | 4.27        |
| _max_obs        | 1.13        |
| _mean_act       | -0.00719398 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0395      |
| _min_adv        | -4.66       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.32       |
| _std_act        | 0.613042    |
| _std_adv        | 1           |
| _std_discrew    | 0.973       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
----------------------------------
| Beta            | 0.0286       |
| ExplainedVarNew | 0.981        |
| ExplainedVarOld | 0.981        |
| KL              | 0.00575271   |
| Phi_loss        | 1088.59      |
| PolicyEntropy   | -0.0291605   |
| PolicyLoss      | -0.000259714 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0207       |
| _MeanReward     | 3.93e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.63464      |
| _max_adv        | 8.27         |
| _max_discrew    | 4.3          |
| _max_obs        | 1.11         |
| _mean_act       | -0.0127271   |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 3.26         |
| _mean_obs       | 0.0395       |
| _min_adv        | -13.3        |
| _min_discrew    | 0.0136       |
| _min_obs        | -1.2         |
| _std_act        | 0.61124      |
| _std_adv        | 1            |
| _std_discrew    | 1.04         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.972       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00569153  |
| Phi_loss        | 1300.69     |
| PolicyEntropy   | -0.0460329  |
| PolicyLoss      | 0.0174749   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0299      |
| _MeanReward     | 3.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5975      |
| _max_adv        | 10          |
| _max_discrew    | 4.34        |
| _max_obs        | 1.36        |
| _mean_act       | -0.00939678 |
| _mean_adv       | -4.83e-17   |
| _mean_discrew   | 3.27        |
| _mean_obs       | 0.0396      |
| _min_adv        | -9.77       |
| _min_discrew    | 0.0132      |
| _min_obs        | -1.18       |
| _std_act        | 0.607064    |
| _std_adv        | 1           |
| _std_discrew    | 1.01        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.971       |
| ExplainedVarOld | 0.97        |
| KL              | 0.00391044  |
| Phi_loss        | 1106.71     |
| PolicyEntropy   | -0.0740881  |
| PolicyLoss      | -0.0221847  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0291      |
| _MeanReward     | 3.97e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59161     |
| _max_adv        | 10.7        |
| _max_discrew    | 4.27        |
| _max_obs        | 1.2         |
| _mean_act       | -0.00773016 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.29        |
| _mean_obs       | 0.04        |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.43       |
| _std_act        | 0.605141    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.977       |
| KL              | 0.00416239  |
| Phi_loss        | 1097.31     |
| PolicyEntropy   | -0.100986   |
| PolicyLoss      | 0.0111135   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0225      |
| _MeanReward     | 4.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54407     |
| _max_adv        | 5.39        |
| _max_discrew    | 4.34        |
| _max_obs        | 1.15        |
| _mean_act       | -0.00637292 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0401      |
| _min_adv        | -10.7       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.32       |
| _std_act        | 0.599016    |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.973       |
| KL              | 0.0034645   |
| Phi_loss        | 1059.69     |
| PolicyEntropy   | -0.12308    |
| PolicyLoss      | 0.00878977  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0254      |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.49913     |
| _max_adv        | 7.31        |
| _max_discrew    | 4.35        |
| _max_obs        | 1.13        |
| _mean_act       | 0.000317868 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.35        |
| _mean_obs       | 0.0408      |
| _min_adv        | -11.2       |
| _min_discrew    | 0.00396     |
| _min_obs        | -1.21       |
| _std_act        | 0.595156    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00657392  |
| Phi_loss        | 1227.9      |
| PolicyEntropy   | -0.162793   |
| PolicyLoss      | 0.0164865   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0242      |
| _MeanReward     | 4.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.56717     |
| _max_adv        | 10.1        |
| _max_discrew    | 4.43        |
| _max_obs        | 1.1         |
| _mean_act       | -0.00299314 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.36        |
| _mean_obs       | 0.0409      |
| _min_adv        | -9.17       |
| _min_discrew    | 0.0107      |
| _min_obs        | -1.22       |
| _std_act        | 0.600334    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.975       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00657006  |
| Phi_loss        | 1084.4      |
| PolicyEntropy   | -0.196376   |
| PolicyLoss      | -0.00372524 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0271      |
| _MeanReward     | 4.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.38234     |
| _max_adv        | 4.91        |
| _max_discrew    | 4.32        |
| _max_obs        | 1.11        |
| _mean_act       | -0.00464674 |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0402      |
| _min_adv        | -4.39       |
| _min_discrew    | 0.00661     |
| _min_obs        | -1.16       |
| _std_act        | 0.593631    |
| _std_adv        | 1           |
| _std_discrew    | 1.07        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.989       |
| KL              | 0.0041312   |
| Phi_loss        | 1270.79     |
| PolicyEntropy   | -0.210377   |
| PolicyLoss      | -0.0141235  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0116      |
| _MeanReward     | 3.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93665     |
| _max_adv        | 5.52        |
| _max_discrew    | 4.34        |
| _max_obs        | 1.18        |
| _mean_act       | -0.00244443 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.29        |
| _mean_obs       | 0.0402      |
| _min_adv        | -9.77       |
| _min_discrew    | 0.0169      |
| _min_obs        | -1.36       |
| _std_act        | 0.591808    |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.969       |
| ExplainedVarOld | 0.967       |
| KL              | 0.0044844   |
| Phi_loss        | 1207.14     |
| PolicyEntropy   | -0.242746   |
| PolicyLoss      | 0.0258589   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0324      |
| _MeanReward     | 4.05e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74614     |
| _max_adv        | 5.91        |
| _max_discrew    | 4.29        |
| _max_obs        | 1.12        |
| _mean_act       | -0.00190209 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.34        |
| _mean_obs       | 0.0405      |
| _min_adv        | -5.71       |
| _min_discrew    | 0.0181      |
| _min_obs        | -1.13       |
| _std_act        | 0.593943    |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
---------------------------------
| Beta            | 0.0643      |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00588574  |
| Phi_loss        | 1331.31     |
| PolicyEntropy   | -0.262923   |
| PolicyLoss      | 0.00532243  |
| Steps           | 10000       |
| VarFuncLoss     | 0.017       |
| _MeanReward     | 4.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.323       |
| _max_adv        | 6.81        |
| _max_discrew    | 4.39        |
| _max_obs        | 1.18        |
| _mean_act       | -0.00230413 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0402      |
| _min_adv        | -6.31       |
| _min_discrew    | 0.0146      |
| _min_obs        | -1.26       |
| _std_act        | 0.59014     |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
----------------------------------
| Beta            | 0.0643       |
| ExplainedVarNew | 0.984        |
| ExplainedVarOld | 0.982        |
| KL              | 0.00599104   |
| Phi_loss        | 1273.46      |
| PolicyEntropy   | -0.276633    |
| PolicyLoss      | 0.00520901   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0163       |
| _MeanReward     | 4.07e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.37119      |
| _max_adv        | 3.5          |
| _max_discrew    | 4.45         |
| _max_obs        | 1.13         |
| _mean_act       | -0.000942621 |
| _mean_adv       | -5.68e-18    |
| _mean_discrew   | 3.38         |
| _mean_obs       | 0.0409       |
| _min_adv        | -6.88        |
| _min_discrew    | 0.00854      |
| _min_obs        | -1.25        |
| _std_act        | 0.594378     |
| _std_adv        | 1            |
| _std_discrew    | 1.04         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00219439 |
| Phi_loss        | 1312.6     |
| PolicyEntropy   | -0.292633  |
| PolicyLoss      | 0.00949161 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0229     |
| _MeanReward     | 4.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58013    |
| _max_adv        | 3.95       |
| _max_discrew    | 4.38       |
| _max_obs        | 1.06       |
| _mean_act       | 0.00134519 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.38       |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.65      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.21      |
| _std_act        | 0.589841   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
--------------------------------
| Beta            | 0.0643     |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00501497 |
| Phi_loss        | 1289.05    |
| PolicyEntropy   | -0.316746  |
| PolicyLoss      | -0.0256739 |
| Steps           | 10000      |
| VarFuncLoss     | 0.013      |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54549    |
| _max_adv        | 4.94       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00127769 |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0406     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.00954    |
| _min_obs        | -1.25      |
| _std_act        | 0.592405   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00663275 |
| Phi_loss        | 1336.88    |
| PolicyEntropy   | -0.326953  |
| PolicyLoss      | 0.0159328  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0164     |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.6062     |
| _max_adv        | 4.5        |
| _max_discrew    | 4.43       |
| _max_obs        | 1.16       |
| _mean_act       | 0.00810417 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0412     |
| _min_adv        | -8.8       |
| _min_discrew    | 0.00884    |
| _min_obs        | -1.28      |
| _std_act        | 0.597053   |
| _std_adv        | 1          |
| _std_discrew    | 1.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00514634 |
| Phi_loss        | 1300.36    |
| PolicyEntropy   | -0.361884  |
| PolicyLoss      | 0.00861535 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 4.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45824    |
| _max_adv        | 6.17       |
| _max_discrew    | 4.37       |
| _max_obs        | 1.09       |
| _mean_act       | 0.00461176 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 3.35       |
| _mean_obs       | 0.0411     |
| _min_adv        | -9.06      |
| _min_discrew    | 0.00768    |
| _min_obs        | -1.18      |
| _std_act        | 0.593534   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00541692 |
| Phi_loss        | 1502.01    |
| PolicyEntropy   | -0.384588  |
| PolicyLoss      | 0.00886592 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0183     |
| _MeanReward     | 4.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42333    |
| _max_adv        | 5.45       |
| _max_discrew    | 4.46       |
| _max_obs        | 1.09       |
| _mean_act       | 0.009334   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0409     |
| _min_adv        | -5.39      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.25      |
| _std_act        | 0.582746   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00306683 |
| Phi_loss        | 1434.73    |
| PolicyEntropy   | -0.392838  |
| PolicyLoss      | -0.0128969 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.41873    |
| _max_adv        | 7.12       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00551824 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0413     |
| _min_adv        | -7.76      |
| _min_discrew    | 0.0126     |
| _min_obs        | -1.21      |
| _std_act        | 0.599191   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.984       |
| KL              | 0.0038224   |
| Phi_loss        | 1451.68     |
| PolicyEntropy   | -0.384786   |
| PolicyLoss      | -0.011767   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0178      |
| _MeanReward     | 4.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.46062     |
| _max_adv        | 1.79        |
| _max_discrew    | 4.43        |
| _max_obs        | 1.65        |
| _mean_act       | -0.00175706 |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 3.36        |
| _mean_obs       | 0.0408      |
| _min_adv        | -15.1       |
| _min_discrew    | -0.598      |
| _min_obs        | -1.3        |
| _std_act        | 0.608709    |
| _std_adv        | 1           |
| _std_discrew    | 1.37        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
-------------------------------
| Beta            | 0.145     |
| ExplainedVarNew | 0.938     |
| ExplainedVarOld | 0.929     |
| KL              | 0.0101988 |
| Phi_loss        | 1166.37   |
| PolicyEntropy   | -0.387793 |
| PolicyLoss      | 0.0529221 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0851    |
| _MeanReward     | 4.08e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.411     |
| _max_adv        | 7.89      |
| _max_discrew    | 4.43      |
| _max_obs        | 1.15      |
| _mean_act       | 0.0118251 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.38      |
| _mean_obs       | 0.0409    |
| _min_adv        | -6.55     |
| _min_discrew    | 0.0105    |
| _min_obs        | -1.14     |
| _std_act        | 0.590294  |
| _std_adv        | 1         |
| _std_discrew    | 1.1       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00258594 |
| Phi_loss        | 1469.5     |
| PolicyEntropy   | -0.412299  |
| PolicyLoss      | -0.0162765 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0168     |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.58553    |
| _max_adv        | 3.52       |
| _max_discrew    | 4.42       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0103129  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0412     |
| _min_adv        | -11.6      |
| _min_discrew    | 0.0105     |
| _min_obs        | -1.24      |
| _std_act        | 0.598495   |
| _std_adv        | 1          |
| _std_discrew    | 1.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00258858 |
| Phi_loss        | 1400.38    |
| PolicyEntropy   | -0.421829  |
| PolicyLoss      | -0.0130895 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0164     |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.38139    |
| _max_adv        | 13         |
| _max_discrew    | 4.37       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00836229 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.35       |
| _mean_obs       | 0.0404     |
| _min_adv        | -5.34      |
| _min_discrew    | 0.0123     |
| _min_obs        | -1.21      |
| _std_act        | 0.58811    |
| _std_adv        | 1          |
| _std_discrew    | 1.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.0024012   |
| Phi_loss        | 1323.1      |
| PolicyEntropy   | -0.428041   |
| PolicyLoss      | -0.00641268 |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 4.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52722     |
| _max_adv        | 5.54        |
| _max_discrew    | 4.31        |
| _max_obs        | 1.09        |
| _mean_act       | 0.0104255   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 3.4         |
| _mean_obs       | 0.0414      |
| _min_adv        | -10.1       |
| _min_discrew    | 0.00925     |
| _min_obs        | -1.21       |
| _std_act        | 0.595222    |
| _std_adv        | 1           |
| _std_discrew    | 1.05        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00342818 |
| Phi_loss        | 1459.15    |
| PolicyEntropy   | -0.455663  |
| PolicyLoss      | 0.0149154  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0169     |
| _MeanReward     | 3.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5726     |
| _max_adv        | 4.64       |
| _max_discrew    | 4.4        |
| _max_obs        | 1.16       |
| _mean_act       | -0.0058329 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0401     |
| _min_adv        | -6.77      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.1       |
| _std_act        | 0.60433    |
| _std_adv        | 1          |
| _std_discrew    | 1.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.861      |
| KL              | 0.00233563 |
| Phi_loss        | 580.453    |
| PolicyEntropy   | -0.47095   |
| PolicyLoss      | -0.0290136 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0495     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47031    |
| _max_adv        | 9.19       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.08       |
| _mean_act       | 0.0121256  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0417     |
| _min_adv        | -4.8       |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.19      |
| _std_act        | 0.598268   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00307902  |
| Phi_loss        | 1419.05     |
| PolicyEntropy   | -0.492536   |
| PolicyLoss      | 0.0149671   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0181      |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71239     |
| _max_adv        | 13.1        |
| _max_discrew    | 4.44        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00457498 |
| _mean_adv       | -3.55e-18   |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0395      |
| _min_adv        | -20.3       |
| _min_discrew    | 0.0147      |
| _min_obs        | -1.26       |
| _std_act        | 0.60339     |
| _std_adv        | 1           |
| _std_discrew    | 1.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
----------------------------------
| Beta            | 0.145        |
| ExplainedVarNew | 0.973        |
| ExplainedVarOld | 0.966        |
| KL              | 0.00343167   |
| Phi_loss        | 1329.66      |
| PolicyEntropy   | -0.503907    |
| PolicyLoss      | -0.000511748 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0315       |
| _MeanReward     | 4.06e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.54531      |
| _max_adv        | 16.8         |
| _max_discrew    | 4.47         |
| _max_obs        | 1.13         |
| _mean_act       | 0.011177     |
| _mean_adv       | 1.99e-17     |
| _mean_discrew   | 3.37         |
| _mean_obs       | 0.0406       |
| _min_adv        | -7.51        |
| _min_discrew    | 0.0134       |
| _min_obs        | -1.26        |
| _std_act        | 0.588951     |
| _std_adv        | 1            |
| _std_discrew    | 1.06         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00217623 |
| Phi_loss        | 1454.03    |
| PolicyEntropy   | -0.518689  |
| PolicyLoss      | -0.0227215 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0234     |
| _MeanReward     | 3.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56687    |
| _max_adv        | 8.94       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.65       |
| _mean_act       | -0.0435973 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.07       |
| _mean_obs       | 0.0387     |
| _min_adv        | -17.2      |
| _min_discrew    | -1.1       |
| _min_obs        | -1.29      |
| _std_act        | 0.67275    |
| _std_adv        | 1          |
| _std_discrew    | 2.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.902      |
| ExplainedVarOld | 0.885      |
| KL              | 0.00640104 |
| Phi_loss        | 946.987    |
| PolicyEntropy   | -0.54367   |
| PolicyLoss      | -0.0270035 |
| Steps           | 10000      |
| VarFuncLoss     | 0.229      |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39039    |
| _max_adv        | 9.75       |
| _max_discrew    | 4.51       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0103518  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0416     |
| _min_adv        | -8.45      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.22      |
| _std_act        | 0.594219   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00213939  |
| Phi_loss        | 1576.75     |
| PolicyEntropy   | -0.571427   |
| PolicyLoss      | -0.00764057 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 4.07e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.31978     |
| _max_adv        | 30.7        |
| _max_discrew    | 4.47        |
| _max_obs        | 1.17        |
| _mean_act       | 0.0109903   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.39        |
| _mean_obs       | 0.0411      |
| _min_adv        | -9.59       |
| _min_discrew    | 0.0118      |
| _min_obs        | -1.2        |
| _std_act        | 0.591341    |
| _std_adv        | 1           |
| _std_discrew    | 1.1         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00197077 |
| Phi_loss        | 1541.68    |
| PolicyEntropy   | -0.598542  |
| PolicyLoss      | 0.0311198  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0268     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77868    |
| _max_adv        | 8.15       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.18       |
| _mean_act       | 0.00874405 |
| _mean_adv       | 6.25e-17   |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0416     |
| _min_adv        | -9.79      |
| _min_discrew    | 0.0189     |
| _min_obs        | -1.17      |
| _std_act        | 0.593733   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00254445 |
| Phi_loss        | 1526.88    |
| PolicyEntropy   | -0.617478  |
| PolicyLoss      | -0.0084403 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0138     |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.36901    |
| _max_adv        | 5.93       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0105824  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0411     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0115     |
| _min_obs        | -1.31      |
| _std_act        | 0.593468   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.965      |
| ExplainedVarOld | 0.963      |
| KL              | 0.00188614 |
| Phi_loss        | 1731.32    |
| PolicyEntropy   | -0.614116  |
| PolicyLoss      | -0.0150056 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0394     |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.25816    |
| _max_adv        | 5.84       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0105692  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0417     |
| _min_adv        | -7.83      |
| _min_discrew    | 0.0102     |
| _min_obs        | -1.24      |
| _std_act        | 0.594169   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00158138 |
| Phi_loss        | 1615.0     |
| PolicyEntropy   | -0.608098  |
| PolicyLoss      | 0.00158483 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0278     |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52486    |
| _max_adv        | 11.1       |
| _max_discrew    | 4.47       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0102038  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0414     |
| _min_adv        | -8.15      |
| _min_discrew    | 0.0059     |
| _min_obs        | -1.25      |
| _std_act        | 0.590312   |
| _std_adv        | 1          |
| _std_discrew    | 1.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00131021 |
| Phi_loss        | 1589.82    |
| PolicyEntropy   | -0.615793  |
| PolicyLoss      | -0.0193251 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0188     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58773    |
| _max_adv        | 4.72       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.26       |
| _mean_act       | 0.00913122 |
| _mean_adv       | -1.6e-17   |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0414     |
| _min_adv        | -6.15      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.28      |
| _std_act        | 0.592697   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00336442 |
| Phi_loss        | 1695.35    |
| PolicyEntropy   | -0.651535  |
| PolicyLoss      | -0.0122247 |
| Steps           | 10000      |
| VarFuncLoss     | 0.013      |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50296    |
| _max_adv        | 6.2        |
| _max_discrew    | 4.51       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0074362  |
| _mean_adv       | -4.83e-17  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0413     |
| _min_adv        | -9.58      |
| _min_discrew    | 0.0152     |
| _min_obs        | -1.19      |
| _std_act        | 0.600942   |
| _std_adv        | 1          |
| _std_discrew    | 1.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00300671 |
| Phi_loss        | 1723.12    |
| PolicyEntropy   | -0.68282   |
| PolicyLoss      | 0.0138979  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0397     |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.40345    |
| _max_adv        | 5.92       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0114649  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0412     |
| _min_adv        | -10.4      |
| _min_discrew    | 0.0119     |
| _min_obs        | -1.15      |
| _std_act        | 0.589768   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00330697 |
| Phi_loss        | 1808.88    |
| PolicyEntropy   | -0.716791  |
| PolicyLoss      | -0.0145725 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0152     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39411    |
| _max_adv        | 15.2       |
| _max_discrew    | 4.43       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0125549  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0417     |
| _min_adv        | -10.3      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.29      |
| _std_act        | 0.592139   |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00486643 |
| Phi_loss        | 1829.25    |
| PolicyEntropy   | -0.744658  |
| PolicyLoss      | -0.0106101 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.23235    |
| _max_adv        | 13.7       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.19       |
| _mean_act       | 0.0166578  |
| _mean_adv       | 1.28e-17   |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0416     |
| _min_adv        | -8.9       |
| _min_discrew    | 0.0092     |
| _min_obs        | -1.42      |
| _std_act        | 0.586697   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00351996 |
| Phi_loss        | 1471.86    |
| PolicyEntropy   | -0.732325  |
| PolicyLoss      | -0.0123623 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.36134    |
| _max_adv        | 4.88       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0103941  |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 3.5        |
| _mean_obs       | 0.0419     |
| _min_adv        | -7.49      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.19      |
| _std_act        | 0.598723   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00329852 |
| Phi_loss        | 1866.69    |
| PolicyEntropy   | -0.726176  |
| PolicyLoss      | 0.0264773  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0165     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56433    |
| _max_adv        | 3.55       |
| _max_discrew    | 4.52       |
| _max_obs        | 1.09       |
| _mean_act       | 0.00981225 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0421     |
| _min_adv        | -8.81      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.18      |
| _std_act        | 0.60066    |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00446246  |
| Phi_loss        | 1740.81     |
| PolicyEntropy   | -0.747454   |
| PolicyLoss      | -0.00485359 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0184      |
| _MeanReward     | 4.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64518     |
| _max_adv        | 5.19        |
| _max_discrew    | 4.57        |
| _max_obs        | 1.18        |
| _mean_act       | 0.0143791   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.5         |
| _mean_obs       | 0.0419      |
| _min_adv        | -4.99       |
| _min_discrew    | 0.012       |
| _min_obs        | -1.17       |
| _std_act        | 0.596467    |
| _std_adv        | 1           |
| _std_discrew    | 1.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00296264  |
| Phi_loss        | 1686.14     |
| PolicyEntropy   | -0.763003   |
| PolicyLoss      | -0.00814817 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0157      |
| _MeanReward     | 4.27e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.33088     |
| _max_adv        | 2.4         |
| _max_discrew    | 4.56        |
| _max_obs        | 1.23        |
| _mean_act       | 0.00599419  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.53        |
| _mean_obs       | 0.0416      |
| _min_adv        | -10.4       |
| _min_discrew    | 0.00491     |
| _min_obs        | -1.3        |
| _std_act        | 0.601677    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00281745 |
| Phi_loss        | 1554.5     |
| PolicyEntropy   | -0.790979  |
| PolicyLoss      | 0.0239111  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0227     |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57634    |
| _max_adv        | 5.35       |
| _max_discrew    | 4.61       |
| _max_obs        | 1.14       |
| _mean_act       | 0.00683212 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0411     |
| _min_adv        | -10.2      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.19      |
| _std_act        | 0.604518   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.977      |
| KL              | 0.00519592 |
| Phi_loss        | 1775.29    |
| PolicyEntropy   | -0.811657  |
| PolicyLoss      | -0.0188019 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0239     |
| _MeanReward     | 4.22e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46094    |
| _max_adv        | 9.71       |
| _max_discrew    | 4.59       |
| _max_obs        | 1.16       |
| _mean_act       | 0.00707698 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.5        |
| _mean_obs       | 0.0411     |
| _min_adv        | -8.99      |
| _min_discrew    | 0.00797    |
| _min_obs        | -1.14      |
| _std_act        | 0.602794   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.978      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00385945 |
| Phi_loss        | 1987.84    |
| PolicyEntropy   | -0.8297    |
| PolicyLoss      | 0.0182862  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0247     |
| _MeanReward     | 4.27e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.50585    |
| _max_adv        | 5.94       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00956539 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0415     |
| _min_adv        | -5.94      |
| _min_discrew    | 0.00704    |
| _min_obs        | -1.17      |
| _std_act        | 0.593011   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00245874 |
| Phi_loss        | 1840.69    |
| PolicyEntropy   | -0.859425  |
| PolicyLoss      | -0.0144483 |
| Steps           | 10000      |
| VarFuncLoss     | 0.018      |
| _MeanReward     | 4.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.19797    |
| _max_adv        | 3.43       |
| _max_discrew    | 4.6        |
| _max_obs        | 1.15       |
| _mean_act       | 0.00785431 |
| _mean_adv       | -2.98e-17  |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0416     |
| _min_adv        | -4.85      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.24      |
| _std_act        | 0.603454   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00346158 |
| Phi_loss        | 1970.67    |
| PolicyEntropy   | -0.877077  |
| PolicyLoss      | -0.0142314 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0166     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46371    |
| _max_adv        | 6.35       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00677803 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0416     |
| _min_adv        | -5.42      |
| _min_discrew    | 0.0181     |
| _min_obs        | -1.15      |
| _std_act        | 0.601568   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
----------------------------------
| Beta            | 0.145        |
| ExplainedVarNew | 0.99         |
| ExplainedVarOld | 0.99         |
| KL              | 0.00240784   |
| Phi_loss        | 2001.26      |
| PolicyEntropy   | -0.911258    |
| PolicyLoss      | -0.0140551   |
| Steps           | 10000        |
| VarFuncLoss     | 0.0121       |
| _MeanReward     | 4.2e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 2.54917      |
| _max_adv        | 5.05         |
| _max_discrew    | 4.68         |
| _max_obs        | 1.13         |
| _mean_act       | -0.000496265 |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 3.47         |
| _mean_obs       | 0.0408       |
| _min_adv        | -10.5        |
| _min_discrew    | 0.0146       |
| _min_obs        | -1.22        |
| _std_act        | 0.607348     |
| _std_adv        | 1            |
| _std_discrew    | 1.17         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.97        |
| ExplainedVarOld | 0.969       |
| KL              | 0.00271956  |
| Phi_loss        | 1787.58     |
| PolicyEntropy   | -0.925678   |
| PolicyLoss      | -0.00485328 |
| Steps           | 10000       |
| VarFuncLoss     | 0.036       |
| _MeanReward     | 4.28e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5403      |
| _max_adv        | 5.22        |
| _max_discrew    | 4.64        |
| _max_obs        | 1.1         |
| _mean_act       | 0.0044921   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.54        |
| _mean_obs       | 0.0413      |
| _min_adv        | -10         |
| _min_discrew    | 0.0115      |
| _min_obs        | -1.23       |
| _std_act        | 0.604177    |
| _std_adv        | 1           |
| _std_discrew    | 1.24        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.98       |
| KL              | 0.00338189 |
| Phi_loss        | 1789.22    |
| PolicyEntropy   | -0.926676  |
| PolicyLoss      | -0.0137411 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0254     |
| _MeanReward     | 4.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.41687    |
| _max_adv        | 5.08       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.08       |
| _mean_act       | -0.0102787 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.04       |
| _min_adv        | -10.5      |
| _min_discrew    | 0.019      |
| _min_obs        | -1.28      |
| _std_act        | 0.609331   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.968      |
| ExplainedVarOld | 0.93       |
| KL              | 0.00411807 |
| Phi_loss        | 1324.84    |
| PolicyEntropy   | -0.959275  |
| PolicyLoss      | 0.0386799  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0377     |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.21582    |
| _max_adv        | 12.2       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00438962 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.041      |
| _min_adv        | -7.46      |
| _min_discrew    | 0.0136     |
| _min_obs        | -1.3       |
| _std_act        | 0.605169   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00331268 |
| Phi_loss        | 1729.57    |
| PolicyEntropy   | -0.960796  |
| PolicyLoss      | 0.0224543  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0218     |
| _MeanReward     | 4.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44256    |
| _max_adv        | 2.44       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.1        |
| _mean_act       | -0.020186  |
| _mean_adv       | -1.85e-17  |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0392     |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.34      |
| _std_act        | 0.616964   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.926      |
| ExplainedVarOld | 0.832      |
| KL              | 0.00576824 |
| Phi_loss        | 1265.15    |
| PolicyEntropy   | -0.964993  |
| PolicyLoss      | 0.0119311  |
| Steps           | 10000      |
| VarFuncLoss     | 0.106      |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.29895    |
| _max_adv        | 8.41       |
| _max_discrew    | 4.55       |
| _max_obs        | 1.06       |
| _mean_act       | 0.00346137 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0405     |
| _min_adv        | -4.47      |
| _min_discrew    | 0.0082     |
| _min_obs        | -1.19      |
| _std_act        | 0.596351   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00312443 |
| Phi_loss        | 1905.47    |
| PolicyEntropy   | -0.999295  |
| PolicyLoss      | -0.0168501 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0151     |
| _MeanReward     | 4.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24942    |
| _max_adv        | 10.6       |
| _max_discrew    | 4.52       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0131877 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0398     |
| _min_adv        | -15.2      |
| _min_discrew    | 0.00802    |
| _min_obs        | -1.11      |
| _std_act        | 0.61158    |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.912      |
| KL              | 0.00316237 |
| Phi_loss        | 1285.43    |
| PolicyEntropy   | -1.02139   |
| PolicyLoss      | 0.00644265 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0494     |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.19599    |
| _max_adv        | 15.4       |
| _max_discrew    | 4.56       |
| _max_obs        | 1.15       |
| _mean_act       | 0.00288922 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0409     |
| _min_adv        | -11.3      |
| _min_discrew    | 0.0198     |
| _min_obs        | -1.39      |
| _std_act        | 0.596528   |
| _std_adv        | 1          |
| _std_discrew    | 1.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.00350326 |
| Phi_loss        | 1814.01    |
| PolicyEntropy   | -1.03402   |
| PolicyLoss      | 0.025821   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0204     |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24945    |
| _max_adv        | 16.3       |
| _max_discrew    | 4.61       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00479882 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.041      |
| _min_adv        | -6.59      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.3       |
| _std_act        | 0.598233   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00228581  |
| Phi_loss        | 1866.9      |
| PolicyEntropy   | -1.03892    |
| PolicyLoss      | -0.00752886 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0194      |
| _MeanReward     | 4.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.33776     |
| _max_adv        | 29.3        |
| _max_discrew    | 4.69        |
| _max_obs        | 1.23        |
| _mean_act       | 0.00463482  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.6         |
| _mean_obs       | 0.0417      |
| _min_adv        | -7.71       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.19       |
| _std_act        | 0.599789    |
| _std_adv        | 1           |
| _std_discrew    | 1.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00340639 |
| Phi_loss        | 1323.06    |
| PolicyEntropy   | -1.03649   |
| PolicyLoss      | 0.0298774  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0158     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45519    |
| _max_adv        | 4.25       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00272374 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.61       |
| _mean_obs       | 0.0412     |
| _min_adv        | -5.3       |
| _min_discrew    | 0.011      |
| _min_obs        | -1.16      |
| _std_act        | 0.603191   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00272237  |
| Phi_loss        | 1893.8      |
| PolicyEntropy   | -1.03825    |
| PolicyLoss      | -0.00776139 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0224      |
| _MeanReward     | 4.34e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.35363     |
| _max_adv        | 5.76        |
| _max_discrew    | 4.66        |
| _max_obs        | 1.18        |
| _mean_act       | 0.00239997  |
| _mean_adv       | 7.11e-18    |
| _mean_discrew   | 3.59        |
| _mean_obs       | 0.0411      |
| _min_adv        | -4.98       |
| _min_discrew    | 0.0134      |
| _min_obs        | -1.15       |
| _std_act        | 0.593522    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00358111  |
| Phi_loss        | 2170.24     |
| PolicyEntropy   | -1.05254    |
| PolicyLoss      | -0.0283289  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0178      |
| _MeanReward     | 4.21e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.39101     |
| _max_adv        | 2.58        |
| _max_discrew    | 4.66        |
| _max_obs        | 1.32        |
| _mean_act       | -0.00702518 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.48        |
| _mean_obs       | 0.0398      |
| _min_adv        | -7.69       |
| _min_discrew    | 0.0106      |
| _min_obs        | -1.4        |
| _std_act        | 0.600432    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.884       |
| KL              | 0.0068404   |
| Phi_loss        | 962.458     |
| PolicyEntropy   | -1.06466    |
| PolicyLoss      | -0.0299866  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0952      |
| _MeanReward     | 4.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.16819     |
| _max_adv        | 15.5        |
| _max_discrew    | 4.57        |
| _max_obs        | 1.74        |
| _mean_act       | -0.00372623 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.51        |
| _mean_obs       | 0.0403      |
| _min_adv        | -10.5       |
| _min_discrew    | -0.375      |
| _min_obs        | -1.25       |
| _std_act        | 0.615566    |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.953      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00372695 |
| Phi_loss        | 1703.57    |
| PolicyEntropy   | -1.08517   |
| PolicyLoss      | 0.034607   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0622     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.25492    |
| _max_adv        | 5.66       |
| _max_discrew    | 4.66       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00144344 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.041      |
| _min_adv        | -5.69      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.29      |
| _std_act        | 0.603176   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00209057 |
| Phi_loss        | 2061.71    |
| PolicyEntropy   | -1.10954   |
| PolicyLoss      | -0.0133685 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0155     |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31308    |
| _max_adv        | 4.04       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00350265 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0414     |
| _min_adv        | -4.82      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.12      |
| _std_act        | 0.600931   |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00174136 |
| Phi_loss        | 2180.8     |
| PolicyEntropy   | -1.11354   |
| PolicyLoss      | 0.00570126 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0155     |
| _MeanReward     | 4.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42889    |
| _max_adv        | 11.8       |
| _max_discrew    | 4.64       |
| _max_obs        | 1.12       |
| _mean_act       | 0.00220538 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.57       |
| _mean_obs       | 0.0404     |
| _min_adv        | -9.82      |
| _min_discrew    | 0.00905    |
| _min_obs        | -1.48      |
| _std_act        | 0.600029   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00180455 |
| Phi_loss        | 2580.87    |
| PolicyEntropy   | -1.13382   |
| PolicyLoss      | 0.0273582  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0248     |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64536    |
| _max_adv        | 17.6       |
| _max_discrew    | 4.71       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00312339 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0401     |
| _min_adv        | -5.79      |
| _min_discrew    | 0.0095     |
| _min_obs        | -1.19      |
| _std_act        | 0.592745   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00189171  |
| Phi_loss        | 2327.5      |
| PolicyEntropy   | -1.15119    |
| PolicyLoss      | -0.00922587 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0145      |
| _MeanReward     | 4.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.31964     |
| _max_adv        | 9           |
| _max_discrew    | 4.66        |
| _max_obs        | 1.25        |
| _mean_act       | 0.00218644  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0405      |
| _min_adv        | -10.2       |
| _min_discrew    | 0.0151      |
| _min_obs        | -1.29       |
| _std_act        | 0.603654    |
| _std_adv        | 1           |
| _std_discrew    | 1.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.0019744  |
| Phi_loss        | 2257.4     |
| PolicyEntropy   | -1.1639    |
| PolicyLoss      | -0.0366106 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0146     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43896    |
| _max_adv        | 4.27       |
| _max_discrew    | 4.65       |
| _max_obs        | 1.07       |
| _mean_act       | 0.00189398 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.6        |
| _mean_obs       | 0.0407     |
| _min_adv        | -10        |
| _min_discrew    | 0.0154     |
| _min_obs        | -1.24      |
| _std_act        | 0.6046     |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.982       |
| KL              | 0.00153665  |
| Phi_loss        | 2198.51     |
| PolicyEntropy   | -1.17447    |
| PolicyLoss      | 0.000498952 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0195      |
| _MeanReward     | 4.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.18852     |
| _max_adv        | 2.37        |
| _max_discrew    | 4.74        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0245181  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.43        |
| _mean_obs       | 0.0388      |
| _min_adv        | -7          |
| _min_discrew    | -0.0186     |
| _min_obs        | -1.25       |
| _std_act        | 0.617119    |
| _std_adv        | 1           |
| _std_discrew    | 1.65        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.889      |
| ExplainedVarOld | 0.714      |
| KL              | 0.00102394 |
| Phi_loss        | 752.405    |
| PolicyEntropy   | -1.16965   |
| PolicyLoss      | -0.0131815 |
| Steps           | 10000      |
| VarFuncLoss     | 0.184      |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62513    |
| _max_adv        | 14         |
| _max_discrew    | 4.61       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00016791 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0405     |
| _min_adv        | -11.4      |
| _min_discrew    | 0.0169     |
| _min_obs        | -1.13      |
| _std_act        | 0.598543   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.961       |
| ExplainedVarOld | 0.944       |
| KL              | 0.00323763  |
| Phi_loss        | 1323.36     |
| PolicyEntropy   | -1.16945    |
| PolicyLoss      | 0.0138917   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0483      |
| _MeanReward     | 4.38e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.31995     |
| _max_adv        | 18.2        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.13        |
| _mean_act       | 0.000429947 |
| _mean_adv       | -5.12e-17   |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0407      |
| _min_adv        | -7.32       |
| _min_discrew    | 0.0108      |
| _min_obs        | -1.14       |
| _std_act        | 0.604895    |
| _std_adv        | 1           |
| _std_discrew    | 1.21        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00260827  |
| Phi_loss        | 2100.8      |
| PolicyEntropy   | -1.17085    |
| PolicyLoss      | -0.0210619  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0167      |
| _MeanReward     | 4.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.46722     |
| _max_adv        | 6.23        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.19        |
| _mean_act       | -0.00204379 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.58        |
| _mean_obs       | 0.0404      |
| _min_adv        | -10.6       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.21       |
| _std_act        | 0.609141    |
| _std_adv        | 1           |
| _std_discrew    | 1.17        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.966       |
| ExplainedVarOld | 0.963       |
| KL              | 0.0069129   |
| Phi_loss        | 2087.73     |
| PolicyEntropy   | -1.1984     |
| PolicyLoss      | -0.0137506  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0408      |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57832     |
| _max_adv        | 7.29        |
| _max_discrew    | 4.64        |
| _max_obs        | 1.11        |
| _mean_act       | 0.000277109 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0406      |
| _min_adv        | -5.18       |
| _min_discrew    | 0.013       |
| _min_obs        | -1.15       |
| _std_act        | 0.604932    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00257711  |
| Phi_loss        | 2293.67     |
| PolicyEntropy   | -1.22163    |
| PolicyLoss      | -0.00825253 |
| Steps           | 10000       |
| VarFuncLoss     | 0.013       |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.39598     |
| _max_adv        | 10.2        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.1         |
| _mean_act       | 0.000713948 |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0411      |
| _min_adv        | -9.07       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.3        |
| _std_act        | 0.605222    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.00251294  |
| Phi_loss        | 2706.4      |
| PolicyEntropy   | -1.24259    |
| PolicyLoss      | 0.0111612   |
| Steps           | 10000       |
| VarFuncLoss     | 0.012       |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.41485     |
| _max_adv        | 7.93        |
| _max_discrew    | 4.77        |
| _max_obs        | 1.14        |
| _mean_act       | 0.000741514 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.68        |
| _mean_obs       | 0.0412      |
| _min_adv        | -9.23       |
| _min_discrew    | 0.0122      |
| _min_obs        | -1.23       |
| _std_act        | 0.606849    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00178177  |
| Phi_loss        | 2775.86     |
| PolicyEntropy   | -1.25598    |
| PolicyLoss      | -0.0298481  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.22631     |
| _max_adv        | 4.87        |
| _max_discrew    | 4.74        |
| _max_obs        | 1.08        |
| _mean_act       | -0.00048958 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.57        |
| _mean_obs       | 0.0403      |
| _min_adv        | -11         |
| _min_discrew    | 0.0108      |
| _min_obs        | -1.26       |
| _std_act        | 0.608003    |
| _std_adv        | 1           |
| _std_discrew    | 1.23        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.951       |
| ExplainedVarOld | 0.947       |
| KL              | 0.00320514  |
| Phi_loss        | 2159.26     |
| PolicyEntropy   | -1.26046    |
| PolicyLoss      | 0.0314123   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0615      |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.29343     |
| _max_adv        | 9.11        |
| _max_discrew    | 4.75        |
| _max_obs        | 1.1         |
| _mean_act       | -0.00047281 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.041       |
| _min_adv        | -8.75       |
| _min_discrew    | 0.015       |
| _min_obs        | -1.25       |
| _std_act        | 0.612986    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.988      |
| KL              | 0.00252288 |
| Phi_loss        | 2387.79    |
| PolicyEntropy   | -1.28398   |
| PolicyLoss      | -0.0503806 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0168     |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.22007    |
| _max_adv        | 5.15       |
| _max_discrew    | 4.73       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00197238 |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0409     |
| _min_adv        | -6.26      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.24      |
| _std_act        | 0.606927   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00176404 |
| Phi_loss        | 2510.63    |
| PolicyEntropy   | -1.30095   |
| PolicyLoss      | 0.0140837  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0186     |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.4542     |
| _max_adv        | 3.64       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.04       |
| _mean_act       | 0.00589059 |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0414     |
| _min_adv        | -4.39      |
| _min_discrew    | 0.0182     |
| _min_obs        | -1.28      |
| _std_act        | 0.606801   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.987       |
| KL              | 0.0028169   |
| Phi_loss        | 2874.16     |
| PolicyEntropy   | -1.32219    |
| PolicyLoss      | 0.0465198   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.18854     |
| _max_adv        | 4.46        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.2         |
| _mean_act       | 0.000539197 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0408      |
| _min_adv        | -5.98       |
| _min_discrew    | 0.0105      |
| _min_obs        | -1.21       |
| _std_act        | 0.609578    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00226247 |
| Phi_loss        | 2824.63    |
| PolicyEntropy   | -1.35244   |
| PolicyLoss      | 0.00405983 |
| Steps           | 10000      |
| VarFuncLoss     | 0.021      |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.28725    |
| _max_adv        | 3.27       |
| _max_discrew    | 4.87       |
| _max_obs        | 1.2        |
| _mean_act       | 0.00210446 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0415     |
| _min_adv        | -4.35      |
| _min_discrew    | 0.0117     |
| _min_obs        | -1.29      |
| _std_act        | 0.608357   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.0014453  |
| Phi_loss        | 2613.4     |
| PolicyEntropy   | -1.36681   |
| PolicyLoss      | 0.00113657 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0144     |
| _MeanReward     | 4.46e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.21773    |
| _max_adv        | 4.05       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.13       |
| _mean_act       | 0.00110679 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0412     |
| _min_adv        | -12.4      |
| _min_discrew    | -0.00579   |
| _min_obs        | -1.33      |
| _std_act        | 0.610672   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.976      |
| ExplainedVarOld | 0.975      |
| KL              | 0.00470609 |
| Phi_loss        | 2601.8     |
| PolicyEntropy   | -1.36635   |
| PolicyLoss      | 0.00300334 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0338     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.34754    |
| _max_adv        | 4.94       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.23       |
| _mean_act       | 0.00523841 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.65       |
| _mean_obs       | 0.0411     |
| _min_adv        | -8.04      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.25      |
| _std_act        | 0.60468    |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00329161  |
| Phi_loss        | 2888.98     |
| PolicyEntropy   | -1.36137    |
| PolicyLoss      | -0.00920413 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0243      |
| _MeanReward     | 4.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.33996     |
| _max_adv        | 5.19        |
| _max_discrew    | 4.82        |
| _max_obs        | 1.1         |
| _mean_act       | 0.00630077  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0415      |
| _min_adv        | -8.21       |
| _min_discrew    | 0.0089      |
| _min_obs        | -1.37       |
| _std_act        | 0.6021      |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0023631  |
| Phi_loss        | 2863.27    |
| PolicyEntropy   | -1.39026   |
| PolicyLoss      | 0.0052322  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0173     |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.4011     |
| _max_adv        | 1.88       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0237722 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0389     |
| _min_adv        | -7.31      |
| _min_discrew    | -0.037     |
| _min_obs        | -1.18      |
| _std_act        | 0.618491   |
| _std_adv        | 1          |
| _std_discrew    | 1.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.923       |
| ExplainedVarOld | 0.75        |
| KL              | 0.00600656  |
| Phi_loss        | 941.965     |
| PolicyEntropy   | -1.41181    |
| PolicyLoss      | -0.0327396  |
| Steps           | 10000       |
| VarFuncLoss     | 0.136       |
| _MeanReward     | 4.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.30584     |
| _max_adv        | 22          |
| _max_discrew    | 4.8         |
| _max_obs        | 1.21        |
| _mean_act       | -0.00472189 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0411      |
| _min_adv        | -11         |
| _min_discrew    | 0.00823     |
| _min_obs        | -1.3        |
| _std_act        | 0.613781    |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.959      |
| KL              | 0.00735823 |
| Phi_loss        | 2284.9     |
| PolicyEntropy   | -1.38805   |
| PolicyLoss      | 0.0718824  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0477     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24618    |
| _max_adv        | 11.3       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.1        |
| _mean_act       | -0.0188664 |
| _mean_adv       | 2.2e-17    |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0393     |
| _min_adv        | -16.5      |
| _min_discrew    | 0.00898    |
| _min_obs        | -1.22      |
| _std_act        | 0.614448   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.964      |
| ExplainedVarOld | 0.933      |
| KL              | 0.00724868 |
| Phi_loss        | 2294.94    |
| PolicyEntropy   | -1.38963   |
| PolicyLoss      | -0.0294221 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0563     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.17318    |
| _max_adv        | 5.3        |
| _max_discrew    | 4.81       |
| _max_obs        | 1.12       |
| _mean_act       | -0.0268255 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0392     |
| _min_adv        | -20.4      |
| _min_discrew    | -0.134     |
| _min_obs        | -1.15      |
| _std_act        | 0.623577   |
| _std_adv        | 1          |
| _std_discrew    | 1.76       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.973      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00130722 |
| Phi_loss        | 2058.01    |
| PolicyEntropy   | -1.38794   |
| PolicyLoss      | -0.0252606 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0483     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.29434    |
| _max_adv        | 37         |
| _max_discrew    | 4.78       |
| _max_obs        | 1.07       |
| _mean_act       | 0.00520648 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0415     |
| _min_adv        | -4.55      |
| _min_discrew    | 0.0123     |
| _min_obs        | -1.22      |
| _std_act        | 0.607192   |
| _std_adv        | 1          |
| _std_discrew    | 1.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.985      |
| KL              | 0.0010743  |
| Phi_loss        | 1941.81    |
| PolicyEntropy   | -1.41563   |
| PolicyLoss      | -0.0177094 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0157     |
| _MeanReward     | 4.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31104    |
| _max_adv        | 15.5       |
| _max_discrew    | 4.75       |
| _max_obs        | 1.15       |
| _mean_act       | 0.00428952 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0412     |
| _min_adv        | -10        |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.2       |
| _std_act        | 0.607229   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00141319 |
| Phi_loss        | 2719.0     |
| PolicyEntropy   | -1.42624   |
| PolicyLoss      | 0.00289456 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0212     |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61957    |
| _max_adv        | 8.31       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00519023 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0415     |
| _min_adv        | -11.5      |
| _min_discrew    | 0.0108     |
| _min_obs        | -1.3       |
| _std_act        | 0.607254   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.984      |
| KL              | 0.00375072 |
| Phi_loss        | 2624.14    |
| PolicyEntropy   | -1.42412   |
| PolicyLoss      | -0.0293271 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0192     |
| _MeanReward     | 4.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.21131    |
| _max_adv        | 5.8        |
| _max_discrew    | 4.74       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00266613 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.041      |
| _min_adv        | -8.39      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.2       |
| _std_act        | 0.608282   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00399098 |
| Phi_loss        | 2746.67    |
| PolicyEntropy   | -1.445     |
| PolicyLoss      | 0.0194124  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 4.43e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24675    |
| _max_adv        | 6.47       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.1        |
| _mean_act       | 0.00618182 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.041      |
| _min_adv        | -5.83      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.23      |
| _std_act        | 0.600241   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00360826 |
| Phi_loss        | 2909.42    |
| PolicyEntropy   | -1.46554   |
| PolicyLoss      | -0.0268423 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 4.44e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.2308     |
| _max_adv        | 6.55       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.15       |
| _mean_act       | 0.0033367  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.68       |
| _mean_obs       | 0.0412     |
| _min_adv        | -7.65      |
| _min_discrew    | 0.0156     |
| _min_obs        | -1.4       |
| _std_act        | 0.612859   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 0.0047214   |
| Phi_loss        | 3120.38     |
| PolicyEntropy   | -1.45594    |
| PolicyLoss      | -0.00103215 |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 4.47e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.33825     |
| _max_adv        | 5.54        |
| _max_discrew    | 4.7         |
| _max_obs        | 1.13        |
| _mean_act       | 0.0035646   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.71        |
| _mean_obs       | 0.0405      |
| _min_adv        | -4.09       |
| _min_discrew    | 0.0137      |
| _min_obs        | -1.13       |
| _std_act        | 0.612921    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00423276 |
| Phi_loss        | 3259.03    |
| PolicyEntropy   | -1.45811   |
| PolicyLoss      | 0.0314931  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.34501    |
| _max_adv        | 6.95       |
| _max_discrew    | 4.83       |
| _max_obs        | 1.27       |
| _mean_act       | 0.00246841 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0407     |
| _min_adv        | -9.39      |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.17      |
| _std_act        | 0.610923   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.99        |
| KL              | 0.0044768   |
| Phi_loss        | 3174.86     |
| PolicyEntropy   | -1.4881     |
| PolicyLoss      | -0.00263357 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0124      |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.36846     |
| _max_adv        | 8.06        |
| _max_discrew    | 4.77        |
| _max_obs        | 1.1         |
| _mean_act       | 0.000626789 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.68        |
| _mean_obs       | 0.0399      |
| _min_adv        | -6.61       |
| _min_discrew    | 0.00952     |
| _min_obs        | -1.16       |
| _std_act        | 0.614283    |
| _std_adv        | 1           |
| _std_discrew    | 1.26        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
----------------------------------
| Beta            | 0.145        |
| ExplainedVarNew | 0.988        |
| ExplainedVarOld | 0.987        |
| KL              | 0.0046881    |
| Phi_loss        | 3190.42      |
| PolicyEntropy   | -1.49963     |
| PolicyLoss      | -0.000676252 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0154       |
| _MeanReward     | 4.48e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.24772      |
| _max_adv        | 5.07         |
| _max_discrew    | 4.88         |
| _max_obs        | 1.1          |
| _mean_act       | -0.000921871 |
| _mean_adv       | 2.84e-18     |
| _mean_discrew   | 3.7          |
| _mean_obs       | 0.0404       |
| _min_adv        | -7.88        |
| _min_discrew    | 0.0199       |
| _min_obs        | -1.15        |
| _std_act        | 0.611797     |
| _std_adv        | 1            |
| _std_discrew    | 1.32         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.979      |
| KL              | 0.00411765 |
| Phi_loss        | 2864.67    |
| PolicyEntropy   | -1.5294    |
| PolicyLoss      | 0.0113959  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0258     |
| _MeanReward     | 4.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.35073    |
| _max_adv        | 2.95       |
| _max_discrew    | 4.78       |
| _max_obs        | 1.13       |
| _mean_act       | 0.00313831 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0396     |
| _min_adv        | -7         |
| _min_discrew    | 0.00657    |
| _min_obs        | -1.16      |
| _std_act        | 0.603755   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00463925  |
| Phi_loss        | 3417.09     |
| PolicyEntropy   | -1.57264    |
| PolicyLoss      | 0.00117582  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0185      |
| _MeanReward     | 4.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.27921     |
| _max_adv        | 4.81        |
| _max_discrew    | 4.79        |
| _max_obs        | 1.75        |
| _mean_act       | -0.00551413 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0399      |
| _min_adv        | -13.9       |
| _min_discrew    | -0.364      |
| _min_obs        | -1.21       |
| _std_act        | 0.616053    |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.96       |
| KL              | 0.0120946  |
| Phi_loss        | 2782.07    |
| PolicyEntropy   | -1.5766    |
| PolicyLoss      | -0.497463  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0543     |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6847     |
| _max_adv        | 4.78       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00133294 |
| _mean_adv       | -5.68e-17  |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0402     |
| _min_adv        | -5.64      |
| _min_discrew    | 0.0195     |
| _min_obs        | -1.14      |
| _std_act        | 0.612485   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00369278 |
| Phi_loss        | 3842.54    |
| PolicyEntropy   | -1.58123   |
| PolicyLoss      | -0.0492132 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0167     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.23483    |
| _max_adv        | 7.18       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.06       |
| _mean_act       | -0.0340182 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.48       |
| _mean_obs       | 0.0378     |
| _min_adv        | -19.1      |
| _min_discrew    | -0.211     |
| _min_obs        | -1.14      |
| _std_act        | 0.637159   |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
----------------------------------
| Beta            | 0.325        |
| ExplainedVarNew | 0.976        |
| ExplainedVarOld | 0.933        |
| KL              | 0.00729426   |
| Phi_loss        | 2323.01      |
| PolicyEntropy   | -1.55886     |
| PolicyLoss      | -0.00239885  |
| Steps           | 10000        |
| VarFuncLoss     | 0.0428       |
| _MeanReward     | 4.51e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.29736      |
| _max_adv        | 5.94         |
| _max_discrew    | 4.86         |
| _max_obs        | 1.13         |
| _mean_act       | -0.000295508 |
| _mean_adv       | 0            |
| _mean_discrew   | 3.73         |
| _mean_obs       | 0.0404       |
| _min_adv        | -5.17        |
| _min_discrew    | 0.0153       |
| _min_obs        | -1.17        |
| _std_act        | 0.617999     |
| _std_adv        | 1            |
| _std_discrew    | 1.3          |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00159865 |
| Phi_loss        | 3433.24    |
| PolicyEntropy   | -1.56594   |
| PolicyLoss      | 0.0182322  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0134     |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.30159    |
| _max_adv        | 21.6       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00135621 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0404     |
| _min_adv        | -7.27      |
| _min_discrew    | 0.0104     |
| _min_obs        | -1.15      |
| _std_act        | 0.611556   |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00148096 |
| Phi_loss        | 3329.31    |
| PolicyEntropy   | -1.58473   |
| PolicyLoss      | -0.0127938 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0199     |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39845    |
| _max_adv        | 5.41       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.77       |
| _mean_act       | -0.0496451 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.39       |
| _mean_obs       | 0.0382     |
| _min_adv        | -13.7      |
| _min_discrew    | -0.81      |
| _min_obs        | -1.11      |
| _std_act        | 0.668855   |
| _std_adv        | 1          |
| _std_discrew    | 2.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
----------------------------------
| Beta            | 0.217        |
| ExplainedVarNew | 0.874        |
| ExplainedVarOld | 0.752        |
| KL              | 0.00477666   |
| Phi_loss        | 2371.18      |
| PolicyEntropy   | -1.5873      |
| PolicyLoss      | 0.069289     |
| Steps           | 10000        |
| VarFuncLoss     | 0.297        |
| _MeanReward     | 4.5e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 2.41378      |
| _max_adv        | 14           |
| _max_discrew    | 4.91         |
| _max_obs        | 1.14         |
| _mean_act       | -0.000650856 |
| _mean_adv       | -2.06e-17    |
| _mean_discrew   | 3.72         |
| _mean_obs       | 0.04         |
| _min_adv        | -13.6        |
| _min_discrew    | 0.0155       |
| _min_obs        | -1.18        |
| _std_act        | 0.620126     |
| _std_adv        | 1            |
| _std_discrew    | 1.34         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.974       |
| KL              | 0.00271207  |
| Phi_loss        | 2573.19     |
| PolicyEntropy   | -1.59355    |
| PolicyLoss      | -0.0132005  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0355      |
| _MeanReward     | 4.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.24826     |
| _max_adv        | 9.42        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.12        |
| _mean_act       | 0.000823911 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0402      |
| _min_adv        | -4.68       |
| _min_discrew    | 0.0104      |
| _min_obs        | -1.17       |
| _std_act        | 0.621921    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.985      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00159657 |
| Phi_loss        | 2912.57    |
| PolicyEntropy   | -1.58858   |
| PolicyLoss      | -0.0240891 |
| Steps           | 10000      |
| VarFuncLoss     | 0.02       |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35971    |
| _max_adv        | 6.26       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0244344 |
| _mean_adv       | 2.13e-17   |
| _mean_discrew   | 3.55       |
| _mean_obs       | 0.0388     |
| _min_adv        | -15.5      |
| _min_discrew    | 0.00826    |
| _min_obs        | -1.2       |
| _std_act        | 0.633482   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00674516 |
| Phi_loss        | 2866.0     |
| PolicyEntropy   | -1.57953   |
| PolicyLoss      | -0.0385725 |
| Steps           | 10000      |
| VarFuncLoss     | 0.175      |
| _MeanReward     | 4.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.21949    |
| _max_adv        | 4.14       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.11       |
| _mean_act       | -0.0502883 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.037      |
| _min_adv        | -19.7      |
| _min_discrew    | -0.423     |
| _min_obs        | -1.21      |
| _std_act        | 0.646356   |
| _std_adv        | 1          |
| _std_discrew    | 2.25       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.966      |
| ExplainedVarOld | 0.958      |
| KL              | 0.00199314 |
| Phi_loss        | 2415.83    |
| PolicyEntropy   | -1.57291   |
| PolicyLoss      | 0.0401109  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0763     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.2534     |
| _max_adv        | 11         |
| _max_discrew    | 4.77       |
| _max_obs        | 1.13       |
| _mean_act       | -0.0167741 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 3.59       |
| _mean_obs       | 0.0387     |
| _min_adv        | -13.3      |
| _min_discrew    | 0.00986    |
| _min_obs        | -1.21      |
| _std_act        | 0.625762   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.84       |
| KL              | 0.00167214 |
| Phi_loss        | 2663.05    |
| PolicyEntropy   | -1.56528   |
| PolicyLoss      | -0.0444228 |
| Steps           | 10000      |
| VarFuncLoss     | 0.166      |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.24369    |
| _max_adv        | 7.34       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.08       |
| _mean_act       | -0.0404348 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0376     |
| _min_adv        | -13.9      |
| _min_discrew    | 0.0166     |
| _min_obs        | -1.38      |
| _std_act        | 0.647989   |
| _std_adv        | 1          |
| _std_discrew    | 1.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.832      |
| ExplainedVarOld | 0.812      |
| KL              | 0.00338047 |
| Phi_loss        | 3155.77    |
| PolicyEntropy   | -1.56047   |
| PolicyLoss      | 0.0296575  |
| Steps           | 10000      |
| VarFuncLoss     | 0.287      |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.29504    |
| _max_adv        | 7.75       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.76       |
| _mean_act       | -0.0239829 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0392     |
| _min_adv        | -14.5      |
| _min_discrew    | -1         |
| _min_obs        | -1.29      |
| _std_act        | 0.657631   |
| _std_adv        | 1          |
| _std_discrew    | 1.85       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.9         |
| ExplainedVarOld | 0.88        |
| KL              | 0.001534    |
| Phi_loss        | 1858.35     |
| PolicyEntropy   | -1.56614    |
| PolicyLoss      | -0.00595947 |
| Steps           | 10000       |
| VarFuncLoss     | 0.186       |
| _MeanReward     | 4.18e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.13381     |
| _max_adv        | 7.99        |
| _max_discrew    | 4.91        |
| _max_obs        | 1.07        |
| _mean_act       | -0.0459796  |
| _mean_adv       | 1.78e-17    |
| _mean_discrew   | 3.47        |
| _mean_obs       | 0.0374      |
| _min_adv        | -21.1       |
| _min_discrew    | -0.444      |
| _min_obs        | -1.2        |
| _std_act        | 0.640531    |
| _std_adv        | 1           |
| _std_discrew    | 2.15        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.976       |
| ExplainedVarOld | 0.957       |
| KL              | 0.00318929  |
| Phi_loss        | 1668.73     |
| PolicyEntropy   | -1.58708    |
| PolicyLoss      | -0.0448626  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0545      |
| _MeanReward     | 4.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.35549     |
| _max_adv        | 9.04        |
| _max_discrew    | 4.94        |
| _max_obs        | 1.06        |
| _mean_act       | 0.000304144 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0403      |
| _min_adv        | -4.86       |
| _min_discrew    | 0.0159      |
| _min_obs        | -1.17       |
| _std_act        | 0.621185    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00175746 |
| Phi_loss        | 2985.92    |
| PolicyEntropy   | -1.60428   |
| PolicyLoss      | 0.0243634  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0148     |
| _MeanReward     | 4.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.28183    |
| _max_adv        | 32.4       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.16       |
| _mean_act       | 0.00148014 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0405     |
| _min_adv        | -6.97      |
| _min_discrew    | 0.0151     |
| _min_obs        | -1.31      |
| _std_act        | 0.613306   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.986      |
| KL              | 0.00185661 |
| Phi_loss        | 2317.45    |
| PolicyEntropy   | -1.62146   |
| PolicyLoss      | -0.0299425 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0157     |
| _MeanReward     | 4.54e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45025    |
| _max_adv        | 22.5       |
| _max_discrew    | 4.82       |
| _max_obs        | 1.18       |
| _mean_act       | 0.00127941 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0399     |
| _min_adv        | -7.51      |
| _min_discrew    | 0.013      |
| _min_obs        | -1.16      |
| _std_act        | 0.615139   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00124206 |
| Phi_loss        | 3176.84    |
| PolicyEntropy   | -1.63278   |
| PolicyLoss      | 0.0280632  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0133     |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.31584    |
| _max_adv        | 2.18       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0396465 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0375     |
| _min_adv        | -15.1      |
| _min_discrew    | -0.332     |
| _min_obs        | -1.34      |
| _std_act        | 0.639623   |
| _std_adv        | 1          |
| _std_discrew    | 2.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.925      |
| ExplainedVarOld | 0.89       |
| KL              | 0.00895815 |
| Phi_loss        | 2737.71    |
| PolicyEntropy   | -1.60576   |
| PolicyLoss      | -0.0753333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.155      |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45564    |
| _max_adv        | 14.5       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0360589 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.49       |
| _mean_obs       | 0.0377     |
| _min_adv        | -14.2      |
| _min_discrew    | -0.215     |
| _min_obs        | -1.22      |
| _std_act        | 0.64066    |
| _std_adv        | 1          |
| _std_discrew    | 2          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.89       |
| KL              | 0.00256745 |
| Phi_loss        | 3087.54    |
| PolicyEntropy   | -1.59059   |
| PolicyLoss      | -0.0162624 |
| Steps           | 10000      |
| VarFuncLoss     | 0.192      |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.28011    |
| _max_adv        | 21.4       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.43       |
| _mean_act       | 0.00136823 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0395     |
| _min_adv        | -6.75      |
| _min_discrew    | 0.015      |
| _min_obs        | -1.31      |
| _std_act        | 0.614747   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.981      |
| KL              | 0.00142903 |
| Phi_loss        | 1788.89    |
| PolicyEntropy   | -1.61007   |
| PolicyLoss      | 0.0154937  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 4.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.19798    |
| _max_adv        | 5.09       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.23       |
| _mean_act       | 0.00383875 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0404     |
| _min_adv        | -6.15      |
| _min_discrew    | 0.0131     |
| _min_obs        | -1.19      |
| _std_act        | 0.614585   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.991       |
| ExplainedVarOld | 0.989       |
| KL              | 0.00332893  |
| Phi_loss        | 3280.08     |
| PolicyEntropy   | -1.61717    |
| PolicyLoss      | -0.0290422  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0129      |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.25855     |
| _max_adv        | 5.64        |
| _max_discrew    | 4.89        |
| _max_obs        | 1.77        |
| _mean_act       | -0.00656378 |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 3.67        |
| _mean_obs       | 0.0397      |
| _min_adv        | -16.1       |
| _min_discrew    | -0.54       |
| _min_obs        | -1.27       |
| _std_act        | 0.62899     |
| _std_adv        | 1           |
| _std_discrew    | 1.56        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.952      |
| ExplainedVarOld | 0.949      |
| KL              | 0.0102827  |
| Phi_loss        | 2920.14    |
| PolicyEntropy   | -1.62282   |
| PolicyLoss      | -0.0603465 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0759     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.24358    |
| _max_adv        | 26.7       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.07       |
| _mean_act       | 0.00684562 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0408     |
| _min_adv        | -8.17      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.1       |
| _std_act        | 0.611455   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
--------------------------------
| Beta            | 0.325      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.985      |
| KL              | 0.00157509 |
| Phi_loss        | 2418.65    |
| PolicyEntropy   | -1.63702   |
| PolicyLoss      | 0.0226593  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0165     |
| _MeanReward     | 3.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37638    |
| _max_adv        | 8.29       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.16       |
| _mean_act       | -0.0764979 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.23       |
| _mean_obs       | 0.035      |
| _min_adv        | -11.6      |
| _min_discrew    | -0.525     |
| _min_obs        | -1.13      |
| _std_act        | 0.66153    |
| _std_adv        | 1          |
| _std_discrew    | 2.63       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.881      |
| ExplainedVarOld | 0.839      |
| KL              | 0.00764352 |
| Phi_loss        | 3273.34    |
| PolicyEntropy   | -1.67516   |
| PolicyLoss      | -0.157358  |
| Steps           | 10000      |
| VarFuncLoss     | 0.314      |
| _MeanReward     | 4.56e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.15373    |
| _max_adv        | 24.8       |
| _max_discrew    | 5          |
| _max_obs        | 1.21       |
| _mean_act       | 0.00251853 |
| _mean_adv       | -3.69e-17  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0402     |
| _min_adv        | -8.68      |
| _min_discrew    | 0.0127     |
| _min_obs        | -1.22      |
| _std_act        | 0.607817   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.981      |
| ExplainedVarOld | 0.978      |
| KL              | 0.00177948 |
| Phi_loss        | 2170.07    |
| PolicyEntropy   | -1.68297   |
| PolicyLoss      | 0.00585538 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0274     |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32467    |
| _max_adv        | 14.8       |
| _max_discrew    | 4.91       |
| _max_obs        | 1.14       |
| _mean_act       | -0.0352204 |
| _mean_adv       | -4.97e-18  |
| _mean_discrew   | 3.53       |
| _mean_obs       | 0.0376     |
| _min_adv        | -16        |
| _min_discrew    | -0.346     |
| _min_obs        | -1.21      |
| _std_act        | 0.643554   |
| _std_adv        | 1          |
| _std_discrew    | 1.94       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.488      |
| ExplainedVarNew | 0.962      |
| ExplainedVarOld | 0.941      |
| KL              | 0.00313791 |
| Phi_loss        | 2404.3     |
| PolicyEntropy   | -1.68662   |
| PolicyLoss      | 0.0611698  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0744     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.23822    |
| _max_adv        | 10.9       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.19       |
| _mean_act       | 0.00549692 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0399     |
| _min_adv        | -5.2       |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.14      |
| _std_act        | 0.615214   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
---------------------------------
| Beta            | 0.325       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.988       |
| KL              | 0.000983816 |
| Phi_loss        | 2879.99     |
| PolicyEntropy   | -1.69604    |
| PolicyLoss      | -0.0146435  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0145      |
| _MeanReward     | 4.54e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.29367     |
| _max_adv        | 12.3        |
| _max_discrew    | 4.85        |
| _max_obs        | 1.09        |
| _mean_act       | 0.00256732  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0396      |
| _min_adv        | -4.74       |
| _min_discrew    | 0.0085      |
| _min_obs        | -1.37       |
| _std_act        | 0.613344    |
| _std_adv        | 1           |
| _std_discrew    | 1.31        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.989      |
| KL              | 0.00130514 |
| Phi_loss        | 3304.72    |
| PolicyEntropy   | -1.70593   |
| PolicyLoss      | 0.00615095 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0136     |
| _MeanReward     | 4.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43204    |
| _max_adv        | 10.2       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.12       |
| _mean_act       | 0.00389369 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.04       |
| _min_adv        | -5.56      |
| _min_discrew    | 0.0207     |
| _min_obs        | -1.31      |
| _std_act        | 0.617843   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00271154 |
| Phi_loss        | 3415.95    |
| PolicyEntropy   | -1.73814   |
| PolicyLoss      | -0.0375828 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0111     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42635    |
| _max_adv        | 6.87       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.09       |
| _mean_act       | 0.00115356 |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.04       |
| _min_adv        | -5.69      |
| _min_discrew    | 0.0179     |
| _min_obs        | -1.07      |
| _std_act        | 0.619452   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00229306 |
| Phi_loss        | 3576.05    |
| PolicyEntropy   | -1.76743   |
| PolicyLoss      | -0.0190302 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.23219    |
| _max_adv        | 4.35       |
| _max_discrew    | 4.98       |
| _max_obs        | 1.07       |
| _mean_act       | 0.00120148 |
| _mean_adv       | 3.84e-17   |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0401     |
| _min_adv        | -5.03      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.15      |
| _std_act        | 0.61747    |
| _std_adv        | 1          |
| _std_discrew    | 1.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
