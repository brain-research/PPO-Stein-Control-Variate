Logging to halfcheetah_unbiased--state-only_169
Using large structure 
Policy Params -- h1: 180, h2: 103,                     h3: 60, lr: 8.87e-05, logvar_speed: 12
phi with MinVar as objecive function

#Training Iter 0
Draw Samples..
------------------------------
| Steps         | 10000      |
| _MeanReward   | -360       |
| _max_act      | 3.10501    |
| _max_adv      | 3.68       |
| _max_discrew  | 0.209      |
| _max_obs      | 1.31       |
| _mean_act     | 0.00541864 |
| _mean_adv     | -5.68e-17  |
| _mean_discrew | -0.283     |
| _mean_obs     | -0.00078   |
| _min_adv      | -3.33      |
| _min_discrew  | -0.623     |
| _min_obs      | -1.25      |
| _std_act      | 0.406065   |
| _std_adv      | 1          |
| _std_discrew  | 0.0194     |
------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 1
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.365       |
| ExplainedVarOld | -2.35       |
| KL              | 0.000204348 |
| Phi_loss        | 1.29261     |
| PolicyEntropy   | 5.51401     |
| PolicyLoss      | 0.00175526  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0123      |
| _MeanReward     | -340        |
| _lr_multiplier  | 1           |
| _max_act        | 3.41297     |
| _max_adv        | 4.89        |
| _max_discrew    | 0.0322      |
| _max_obs        | 1.37        |
| _mean_act       | 0.012358    |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | -0.273      |
| _mean_obs       | 0.0326      |
| _min_adv        | -5.02       |
| _min_discrew    | -0.632      |
| _min_obs        | -1.48       |
| _std_act        | 0.410084    |
| _std_adv        | 1           |
| _std_discrew    | 0.019       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 2
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.382      |
| ExplainedVarOld | -0.0846    |
| KL              | 0.0014562  |
| Phi_loss        | 22.1669    |
| PolicyEntropy   | 5.50912    |
| PolicyLoss      | 0.00107715 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0118     |
| _MeanReward     | -367       |
| _lr_multiplier  | 1          |
| _max_act        | 2.62424    |
| _max_adv        | 3.42       |
| _max_discrew    | 0.00388    |
| _max_obs        | 1.26       |
| _mean_act       | 0.00305995 |
| _mean_adv       | 0          |
| _mean_discrew   | -0.297     |
| _mean_obs       | 0.0246     |
| _min_adv        | -3         |
| _min_discrew    | -0.654     |
| _min_obs        | -1.5       |
| _std_act        | 0.409396   |
| _std_adv        | 1          |
| _std_discrew    | 0.0224     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 3
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.289       |
| ExplainedVarOld | 0.259       |
| KL              | 0.00140363  |
| Phi_loss        | 27.4581     |
| PolicyEntropy   | 5.5116      |
| PolicyLoss      | -0.00174604 |
| Steps           | 10000       |
| VarFuncLoss     | 0.016       |
| _MeanReward     | -364        |
| _lr_multiplier  | 1           |
| _max_act        | 3.16876     |
| _max_adv        | 3.74        |
| _max_discrew    | 0.0469      |
| _max_obs        | 1.7         |
| _mean_act       | 0.00659941  |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | -0.289      |
| _mean_obs       | 0.0263      |
| _min_adv        | -3.69       |
| _min_discrew    | -0.64       |
| _min_obs        | -1.33       |
| _std_act        | 0.410374    |
| _std_adv        | 1           |
| _std_discrew    | 0.0193      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 4
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.403       |
| ExplainedVarOld | 0.392       |
| KL              | 0.00305501  |
| Phi_loss        | 25.1977     |
| PolicyEntropy   | 5.51238     |
| PolicyLoss      | 0.000419282 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0115      |
| _MeanReward     | -312        |
| _lr_multiplier  | 1           |
| _max_act        | 3.43976     |
| _max_adv        | 3.65        |
| _max_discrew    | 0.0769      |
| _max_obs        | 1.85        |
| _mean_act       | -0.00845181 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | -0.255      |
| _mean_obs       | 0.0428      |
| _min_adv        | -4.63       |
| _min_discrew    | -0.602      |
| _min_obs        | -1.33       |
| _std_act        | 0.42113     |
| _std_adv        | 1           |
| _std_discrew    | 0.0127      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 5
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.267       |
| ExplainedVarOld | -0.472      |
| KL              | 0.00316068  |
| Phi_loss        | 17.2431     |
| PolicyEntropy   | 5.50862     |
| PolicyLoss      | 0.00297871  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00959     |
| _MeanReward     | -304        |
| _lr_multiplier  | 1           |
| _max_act        | 3.15026     |
| _max_adv        | 4.43        |
| _max_discrew    | 0.0834      |
| _max_obs        | 1.34        |
| _mean_act       | -0.00491348 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | -0.249      |
| _mean_obs       | 0.0379      |
| _min_adv        | -3.91       |
| _min_discrew    | -0.555      |
| _min_obs        | -1.26       |
| _std_act        | 0.414127    |
| _std_adv        | 1           |
| _std_discrew    | 0.0135      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 6
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.35        |
| ExplainedVarOld | 0.328       |
| KL              | 0.00318675  |
| Phi_loss        | 19.9051     |
| PolicyEntropy   | 5.49541     |
| PolicyLoss      | 0.00303391  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00878     |
| _MeanReward     | -248        |
| _lr_multiplier  | 1           |
| _max_act        | 2.77958     |
| _max_adv        | 3.72        |
| _max_discrew    | 0.0926      |
| _max_obs        | 1.37        |
| _mean_act       | -0.00277635 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.203      |
| _mean_obs       | 0.0351      |
| _min_adv        | -3.61       |
| _min_discrew    | -0.509      |
| _min_obs        | -1.24       |
| _std_act        | 0.415445    |
| _std_adv        | 1           |
| _std_discrew    | 0.0135      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 7
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.214       |
| ExplainedVarOld | 0.155       |
| KL              | 0.00345934  |
| Phi_loss        | 18.8397     |
| PolicyEntropy   | 5.47774     |
| PolicyLoss      | 0.00603946  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0109      |
| _MeanReward     | -226        |
| _lr_multiplier  | 1           |
| _max_act        | 2.73564     |
| _max_adv        | 3.33        |
| _max_discrew    | 0.0806      |
| _max_obs        | 1.45        |
| _mean_act       | -0.00692919 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.184      |
| _mean_obs       | 0.032       |
| _min_adv        | -3.53       |
| _min_discrew    | -0.479      |
| _min_obs        | -1.29       |
| _std_act        | 0.40684     |
| _std_adv        | 1           |
| _std_discrew    | 0.0114      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 8
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.268       |
| ExplainedVarOld | 0.261       |
| KL              | 0.00289683  |
| Phi_loss        | 21.5925     |
| PolicyEntropy   | 5.45667     |
| PolicyLoss      | 0.00625201  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00848     |
| _MeanReward     | -242        |
| _lr_multiplier  | 1           |
| _max_act        | 2.69666     |
| _max_adv        | 3.64        |
| _max_discrew    | 0.0635      |
| _max_obs        | 1.47        |
| _mean_act       | -0.00264772 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.194      |
| _mean_obs       | 0.03        |
| _min_adv        | -3.83       |
| _min_discrew    | -0.499      |
| _min_obs        | -1.39       |
| _std_act        | 0.408563    |
| _std_adv        | 1           |
| _std_discrew    | 0.00999     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 9
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.259       |
| ExplainedVarOld | 0.222       |
| KL              | 0.00345239  |
| Phi_loss        | 19.512      |
| PolicyEntropy   | 5.42199     |
| PolicyLoss      | 0.00924665  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00743     |
| _MeanReward     | -205        |
| _lr_multiplier  | 1           |
| _max_act        | 2.9929      |
| _max_adv        | 3.6         |
| _max_discrew    | 0.123       |
| _max_obs        | 1.53        |
| _mean_act       | -0.00575783 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.17       |
| _mean_obs       | 0.0314      |
| _min_adv        | -4.21       |
| _min_discrew    | -0.522      |
| _min_obs        | -1.23       |
| _std_act        | 0.405089    |
| _std_adv        | 1           |
| _std_discrew    | 0.0118      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 10
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.284       |
| ExplainedVarOld | 0.247       |
| KL              | 0.00317286  |
| Phi_loss        | 22.7128     |
| PolicyEntropy   | 5.3991      |
| PolicyLoss      | 0.00244064  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00868     |
| _MeanReward     | -153        |
| _lr_multiplier  | 1           |
| _max_act        | 2.55833     |
| _max_adv        | 3.77        |
| _max_discrew    | 0.128       |
| _max_obs        | 1.31        |
| _mean_act       | -0.00330102 |
| _mean_adv       | 6.82e-17    |
| _mean_discrew   | -0.128      |
| _mean_obs       | 0.0361      |
| _min_adv        | -3.53       |
| _min_discrew    | -0.432      |
| _min_obs        | -1.4        |
| _std_act        | 0.403103    |
| _std_adv        | 1           |
| _std_discrew    | 0.0123      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 11
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.277       |
| ExplainedVarOld | 0.183       |
| KL              | 0.00261513  |
| Phi_loss        | 19.9137     |
| PolicyEntropy   | 5.37397     |
| PolicyLoss      | 0.00566669  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00958     |
| _MeanReward     | -185        |
| _lr_multiplier  | 1           |
| _max_act        | 2.84731     |
| _max_adv        | 3.4         |
| _max_discrew    | 0.0966      |
| _max_obs        | 1.51        |
| _mean_act       | -0.00485934 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | -0.155      |
| _mean_obs       | 0.0323      |
| _min_adv        | -4.54       |
| _min_discrew    | -0.47       |
| _min_obs        | -1.22       |
| _std_act        | 0.396957    |
| _std_adv        | 1           |
| _std_discrew    | 0.0121      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 12
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.183       |
| ExplainedVarOld | 0.157       |
| KL              | 0.00398527  |
| Phi_loss        | 20.568      |
| PolicyEntropy   | 5.35798     |
| PolicyLoss      | 0.00249413  |
| Steps           | 10000       |
| VarFuncLoss     | 0.01        |
| _MeanReward     | -152        |
| _lr_multiplier  | 1           |
| _max_act        | 2.92223     |
| _max_adv        | 3.84        |
| _max_discrew    | 0.124       |
| _max_obs        | 1.27        |
| _mean_act       | -0.00220735 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | -0.126      |
| _mean_obs       | 0.0363      |
| _min_adv        | -5.01       |
| _min_discrew    | -0.449      |
| _min_obs        | -1.45       |
| _std_act        | 0.399022    |
| _std_adv        | 1           |
| _std_discrew    | 0.0098      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 13
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.287       |
| ExplainedVarOld | 0.173       |
| KL              | 0.00294052  |
| Phi_loss        | 19.1255     |
| PolicyEntropy   | 5.33955     |
| PolicyLoss      | 0.000126677 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00728     |
| _MeanReward     | -138        |
| _lr_multiplier  | 1           |
| _max_act        | 2.73636     |
| _max_adv        | 3.63        |
| _max_discrew    | 0.151       |
| _max_obs        | 1.3         |
| _mean_act       | -0.00186243 |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | -0.123      |
| _mean_obs       | 0.0365      |
| _min_adv        | -4.73       |
| _min_discrew    | -0.471      |
| _min_obs        | -1.33       |
| _std_act        | 0.400819    |
| _std_adv        | 1           |
| _std_discrew    | 0.0127      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 14
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.393       |
| ExplainedVarOld | 0.344       |
| KL              | 0.00230197  |
| Phi_loss        | 19.41       |
| PolicyEntropy   | 5.3204      |
| PolicyLoss      | 0.00191726  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0077      |
| _MeanReward     | -149        |
| _lr_multiplier  | 1           |
| _max_act        | 2.87345     |
| _max_adv        | 3.48        |
| _max_discrew    | 0.122       |
| _max_obs        | 1.3         |
| _mean_act       | -0.00288184 |
| _mean_adv       | -1.99e-17   |
| _mean_discrew   | -0.136      |
| _mean_obs       | 0.0366      |
| _min_adv        | -4.36       |
| _min_discrew    | -0.396      |
| _min_obs        | -1.37       |
| _std_act        | 0.396442    |
| _std_adv        | 1           |
| _std_discrew    | 0.00829     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 15
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.27        |
| ExplainedVarOld | 0.146       |
| KL              | 0.00310945  |
| Phi_loss        | 18.6517     |
| PolicyEntropy   | 5.30918     |
| PolicyLoss      | 0.000625308 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00609     |
| _MeanReward     | -93.4       |
| _lr_multiplier  | 1           |
| _max_act        | 2.71653     |
| _max_adv        | 4.06        |
| _max_discrew    | 0.289       |
| _max_obs        | 1.64        |
| _mean_act       | 0.00223993  |
| _mean_adv       | -5.68e-17   |
| _mean_discrew   | -0.0816     |
| _mean_obs       | 0.0402      |
| _min_adv        | -3.83       |
| _min_discrew    | -0.29       |
| _min_obs        | -1.39       |
| _std_act        | 0.398242    |
| _std_adv        | 1           |
| _std_discrew    | 0.00979     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 16
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.293      |
| ExplainedVarOld | 0.243      |
| KL              | 0.00310601 |
| Phi_loss        | 20.3976    |
| PolicyEntropy   | 5.29114    |
| PolicyLoss      | 0.00359409 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00737    |
| _MeanReward     | -71.7      |
| _lr_multiplier  | 1          |
| _max_act        | 2.91601    |
| _max_adv        | 4.73       |
| _max_discrew    | 0.233      |
| _max_obs        | 1.48       |
| _mean_act       | 0.00217691 |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | -0.0645    |
| _mean_obs       | 0.0396     |
| _min_adv        | -4.7       |
| _min_discrew    | -0.281     |
| _min_obs        | -1.3       |
| _std_act        | 0.395274   |
| _std_adv        | 1          |
| _std_discrew    | 0.00721    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 17
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.343      |
| ExplainedVarOld | 0.296      |
| KL              | 0.00330072 |
| Phi_loss        | 21.9875    |
| PolicyEntropy   | 5.25477    |
| PolicyLoss      | 0.00482513 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00475    |
| _MeanReward     | -67        |
| _lr_multiplier  | 1          |
| _max_act        | 2.70145    |
| _max_adv        | 3.94       |
| _max_discrew    | 0.32       |
| _max_obs        | 1.44       |
| _mean_act       | 0.00123717 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | -0.065     |
| _mean_obs       | 0.0402     |
| _min_adv        | -4.1       |
| _min_discrew    | -0.314     |
| _min_obs        | -1.21      |
| _std_act        | 0.392921   |
| _std_adv        | 1          |
| _std_discrew    | 0.0115     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 18
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.566      |
| ExplainedVarOld | 0.526      |
| KL              | 0.00383027 |
| Phi_loss        | 19.6577    |
| PolicyEntropy   | 5.21668    |
| PolicyLoss      | 0.00594418 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00508    |
| _MeanReward     | -84        |
| _lr_multiplier  | 1          |
| _max_act        | 2.82493    |
| _max_adv        | 4.04       |
| _max_discrew    | 0.285      |
| _max_obs        | 1.23       |
| _mean_act       | 0.00740312 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | -0.0849    |
| _mean_obs       | 0.0419     |
| _min_adv        | -4.37      |
| _min_discrew    | -0.301     |
| _min_obs        | -1.23      |
| _std_act        | 0.390289   |
| _std_adv        | 1          |
| _std_discrew    | 0.0119     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 19
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.602      |
| ExplainedVarOld | 0.56       |
| KL              | 0.00370228 |
| Phi_loss        | 18.066     |
| PolicyEntropy   | 5.20099    |
| PolicyLoss      | 0.00201589 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00475    |
| _MeanReward     | -37.7      |
| _lr_multiplier  | 1          |
| _max_act        | 2.81633    |
| _max_adv        | 4.04       |
| _max_discrew    | 0.297      |
| _max_obs        | 1.3        |
| _mean_act       | 0.00227084 |
| _mean_adv       | -4.26e-17  |
| _mean_discrew   | -0.0385    |
| _mean_obs       | 0.0414     |
| _min_adv        | -3.28      |
| _min_discrew    | -0.247     |
| _min_obs        | -1.28      |
| _std_act        | 0.388781   |
| _std_adv        | 1          |
| _std_discrew    | 0.00776    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 20
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.188        |
| ExplainedVarOld | 0.161        |
| KL              | 0.00353665   |
| Phi_loss        | 22.1923      |
| PolicyEntropy   | 5.18785      |
| PolicyLoss      | -0.000939357 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0063       |
| _MeanReward     | -58.5        |
| _lr_multiplier  | 1            |
| _max_act        | 3.08161      |
| _max_adv        | 3.71         |
| _max_discrew    | 0.234        |
| _max_obs        | 1.34         |
| _mean_act       | 0.00535334   |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | -0.0463      |
| _mean_obs       | 0.0372       |
| _min_adv        | -3.91        |
| _min_discrew    | -0.266       |
| _min_obs        | -1.32        |
| _std_act        | 0.395241     |
| _std_adv        | 1            |
| _std_discrew    | 0.00856      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 21
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.311        |
| ExplainedVarOld | 0.192        |
| KL              | 0.00341067   |
| Phi_loss        | 23.2918      |
| PolicyEntropy   | 5.17864      |
| PolicyLoss      | -0.000344222 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00589      |
| _MeanReward     | 19.5         |
| _lr_multiplier  | 1            |
| _max_act        | 2.72067      |
| _max_adv        | 3.75         |
| _max_discrew    | 0.448        |
| _max_obs        | 1.32         |
| _mean_act       | 0.00707721   |
| _mean_adv       | 3.41e-17     |
| _mean_discrew   | 0.014        |
| _mean_obs       | 0.0418       |
| _min_adv        | -3.11        |
| _min_discrew    | -0.194       |
| _min_obs        | -1.45        |
| _std_act        | 0.389586     |
| _std_adv        | 1            |
| _std_discrew    | 0.0134       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 22
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.276        |
| ExplainedVarOld | 0.195        |
| KL              | 0.00376312   |
| Phi_loss        | 24.4646      |
| PolicyEntropy   | 5.15721      |
| PolicyLoss      | -7.22773e-05 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0105       |
| _MeanReward     | -16.1        |
| _lr_multiplier  | 1            |
| _max_act        | 2.83747      |
| _max_adv        | 3.68         |
| _max_discrew    | 0.27         |
| _max_obs        | 1.38         |
| _mean_act       | 0.00617215   |
| _mean_adv       | 0            |
| _mean_discrew   | -0.0239      |
| _mean_obs       | 0.0402       |
| _min_adv        | -4.24        |
| _min_discrew    | -0.256       |
| _min_obs        | -1.29        |
| _std_act        | 0.387583     |
| _std_adv        | 1            |
| _std_discrew    | 0.00812      |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 23
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.266       |
| ExplainedVarOld | 0.244       |
| KL              | 0.00293281  |
| Phi_loss        | 25.6587     |
| PolicyEntropy   | 5.14291     |
| PolicyLoss      | -0.00310751 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00646     |
| _MeanReward     | -16.1       |
| _lr_multiplier  | 1           |
| _max_act        | 2.76689     |
| _max_adv        | 4.12        |
| _max_discrew    | 0.302       |
| _max_obs        | 1.24        |
| _mean_act       | 0.00310084  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | -0.0217     |
| _mean_obs       | 0.0417      |
| _min_adv        | -4.67       |
| _min_discrew    | -0.222      |
| _min_obs        | -1.19       |
| _std_act        | 0.389044    |
| _std_adv        | 1           |
| _std_discrew    | 0.00787     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 24
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.313      |
| ExplainedVarOld | 0.24       |
| KL              | 0.00286811 |
| Phi_loss        | 23.3465    |
| PolicyEntropy   | 5.13939    |
| PolicyLoss      | 0.00118259 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00542    |
| _MeanReward     | -28.2      |
| _lr_multiplier  | 1          |
| _max_act        | 2.83217    |
| _max_adv        | 4.06       |
| _max_discrew    | 0.323      |
| _max_obs        | 1.25       |
| _mean_act       | 0.00380688 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | -0.0329    |
| _mean_obs       | 0.0472     |
| _min_adv        | -3.94      |
| _min_discrew    | -0.277     |
| _min_obs        | -1.23      |
| _std_act        | 0.388109   |
| _std_adv        | 1          |
| _std_discrew    | 0.0089     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 25
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.399      |
| ExplainedVarOld | 0.384      |
| KL              | 0.00377818 |
| Phi_loss        | 24.1214    |
| PolicyEntropy   | 5.10046    |
| PolicyLoss      | 0.0127757  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00535    |
| _MeanReward     | 81.6       |
| _lr_multiplier  | 1          |
| _max_act        | 2.57441    |
| _max_adv        | 3.49       |
| _max_discrew    | 0.439      |
| _max_obs        | 1.32       |
| _mean_act       | 0.00109007 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.0666     |
| _mean_obs       | 0.0404     |
| _min_adv        | -4.79      |
| _min_discrew    | -0.208     |
| _min_obs        | -1.2       |
| _std_act        | 0.392254   |
| _std_adv        | 1          |
| _std_discrew    | 0.0133     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 26
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.385      |
| ExplainedVarOld | 0.282      |
| KL              | 0.00241973 |
| Phi_loss        | 23.5214    |
| PolicyEntropy   | 5.05562    |
| PolicyLoss      | 0.00930038 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00908    |
| _MeanReward     | 1.02       |
| _lr_multiplier  | 1          |
| _max_act        | 2.57612    |
| _max_adv        | 3.63       |
| _max_discrew    | 0.333      |
| _max_obs        | 1.31       |
| _mean_act       | 0.00406365 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | -0.0103    |
| _mean_obs       | 0.0411     |
| _min_adv        | -4.22      |
| _min_discrew    | -0.328     |
| _min_obs        | -1.23      |
| _std_act        | 0.390705   |
| _std_adv        | 1          |
| _std_discrew    | 0.00993    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 27
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.446       |
| ExplainedVarOld | 0.445       |
| KL              | 0.00340071  |
| Phi_loss        | 26.1532     |
| PolicyEntropy   | 5.06158     |
| PolicyLoss      | -0.00502337 |
| Steps           | 10000       |
| VarFuncLoss     | 0.006       |
| _MeanReward     | 22.8        |
| _lr_multiplier  | 1           |
| _max_act        | 2.86113     |
| _max_adv        | 3.65        |
| _max_discrew    | 0.336       |
| _max_obs        | 1.4         |
| _mean_act       | 0.00244744  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.00707     |
| _mean_obs       | 0.0403      |
| _min_adv        | -4.21       |
| _min_discrew    | -0.235      |
| _min_obs        | -1.28       |
| _std_act        | 0.384504    |
| _std_adv        | 1           |
| _std_discrew    | 0.00956     |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 28
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.437      |
| ExplainedVarOld | 0.363      |
| KL              | 0.00280425 |
| Phi_loss        | 26.4609    |
| PolicyEntropy   | 5.03075    |
| PolicyLoss      | 0.00522751 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00538    |
| _MeanReward     | 68.8       |
| _lr_multiplier  | 1          |
| _max_act        | 2.66452    |
| _max_adv        | 4.51       |
| _max_discrew    | 0.373      |
| _max_obs        | 1.49       |
| _mean_act       | 0.00909196 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.0412     |
| _mean_obs       | 0.0425     |
| _min_adv        | -4.32      |
| _min_discrew    | -0.17      |
| _min_obs        | -1.2       |
| _std_act        | 0.378011   |
| _std_adv        | 1          |
| _std_discrew    | 0.00992    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 29
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.433        |
| ExplainedVarOld | 0.388        |
| KL              | 0.00395976   |
| Phi_loss        | 26.3025      |
| PolicyEntropy   | 4.99862      |
| PolicyLoss      | 0.00293336   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00587      |
| _MeanReward     | 58.4         |
| _lr_multiplier  | 1            |
| _max_act        | 2.5661       |
| _max_adv        | 4.23         |
| _max_discrew    | 0.383        |
| _max_obs        | 1.27         |
| _mean_act       | -0.000633054 |
| _mean_adv       | 2.84e-17     |
| _mean_discrew   | 0.0419       |
| _mean_obs       | 0.0418       |
| _min_adv        | -4.65        |
| _min_discrew    | -0.163       |
| _min_obs        | -1.2         |
| _std_act        | 0.378298     |
| _std_adv        | 1            |
| _std_discrew    | 0.012        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 30
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.494      |
| ExplainedVarOld | 0.446      |
| KL              | 0.0033893  |
| Phi_loss        | 27.5264    |
| PolicyEntropy   | 4.96841    |
| PolicyLoss      | 0.00646329 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0061     |
| _MeanReward     | 84.2       |
| _lr_multiplier  | 1          |
| _max_act        | 2.45985    |
| _max_adv        | 4.4        |
| _max_discrew    | 0.496      |
| _max_obs        | 1.42       |
| _mean_act       | 0.00368276 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 0.054      |
| _mean_obs       | 0.0431     |
| _min_adv        | -4         |
| _min_discrew    | -0.143     |
| _min_obs        | -1.29      |
| _std_act        | 0.377055   |
| _std_adv        | 1          |
| _std_discrew    | 0.00897    |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 31
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.427      |
| ExplainedVarOld | 0.375      |
| KL              | 0.00411161 |
| Phi_loss        | 27.7405    |
| PolicyEntropy   | 4.95201    |
| PolicyLoss      | 0.00554413 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00522    |
| _MeanReward     | 144        |
| _lr_multiplier  | 1          |
| _max_act        | 2.92891    |
| _max_adv        | 4.12       |
| _max_discrew    | 0.52       |
| _max_obs        | 1.32       |
| _mean_act       | 0.00375917 |
| _mean_adv       | -3.98e-17  |
| _mean_discrew   | 0.109      |
| _mean_obs       | 0.0362     |
| _min_adv        | -3.65      |
| _min_discrew    | -0.107     |
| _min_obs        | -1.16      |
| _std_act        | 0.380829   |
| _std_adv        | 1          |
| _std_discrew    | 0.0126     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 32
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.367       |
| ExplainedVarOld | 0.334       |
| KL              | 0.00268545  |
| Phi_loss        | 28.4344     |
| PolicyEntropy   | 4.9275      |
| PolicyLoss      | 0.0020444   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00829     |
| _MeanReward     | 132         |
| _lr_multiplier  | 1           |
| _max_act        | 2.62139     |
| _max_adv        | 3.91        |
| _max_discrew    | 0.488       |
| _max_obs        | 1.37        |
| _mean_act       | -0.00119996 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.0973      |
| _mean_obs       | 0.0385      |
| _min_adv        | -3.54       |
| _min_discrew    | -0.147      |
| _min_obs        | -1.24       |
| _std_act        | 0.379696    |
| _std_adv        | 1           |
| _std_discrew    | 0.0189      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 33
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.55        |
| ExplainedVarOld | 0.517       |
| KL              | 0.00307503  |
| Phi_loss        | 29.9074     |
| PolicyEntropy   | 4.90187     |
| PolicyLoss      | 0.00300204  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00849     |
| _MeanReward     | 150         |
| _lr_multiplier  | 1           |
| _max_act        | 2.65462     |
| _max_adv        | 3.26        |
| _max_discrew    | 0.528       |
| _max_obs        | 1.57        |
| _mean_act       | -0.00198167 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.105       |
| _mean_obs       | 0.034       |
| _min_adv        | -3.71       |
| _min_discrew    | -0.252      |
| _min_obs        | -1.26       |
| _std_act        | 0.380439    |
| _std_adv        | 1           |
| _std_discrew    | 0.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 34
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.437       |
| ExplainedVarOld | 0.387       |
| KL              | 0.00390763  |
| Phi_loss        | 30.481      |
| PolicyEntropy   | 4.86374     |
| PolicyLoss      | 0.00491227  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0112      |
| _MeanReward     | 140         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83596     |
| _max_adv        | 3.99        |
| _max_discrew    | 0.443       |
| _max_obs        | 1.44        |
| _mean_act       | -0.00381504 |
| _mean_adv       | -3.69e-17   |
| _mean_discrew   | 0.106       |
| _mean_obs       | 0.037       |
| _min_adv        | -3.99       |
| _min_discrew    | -0.118      |
| _min_obs        | -1.26       |
| _std_act        | 0.374731    |
| _std_adv        | 1           |
| _std_discrew    | 0.0113      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 35
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.458        |
| ExplainedVarOld | 0.41         |
| KL              | 0.00350318   |
| Phi_loss        | 30.9238      |
| PolicyEntropy   | 4.8506       |
| PolicyLoss      | -0.000931611 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00613      |
| _MeanReward     | 164          |
| _lr_multiplier  | 1            |
| _max_act        | 3.23817      |
| _max_adv        | 4.27         |
| _max_discrew    | 0.446        |
| _max_obs        | 1.47         |
| _mean_act       | -0.00403673  |
| _mean_adv       | -3.69e-17    |
| _mean_discrew   | 0.117        |
| _mean_obs       | 0.0344       |
| _min_adv        | -4.72        |
| _min_discrew    | -0.102       |
| _min_obs        | -1.21        |
| _std_act        | 0.377139     |
| _std_adv        | 1            |
| _std_discrew    | 0.011        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 36
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.383       |
| ExplainedVarOld | 0.347       |
| KL              | 0.00243896  |
| Phi_loss        | 32.8165     |
| PolicyEntropy   | 4.83548     |
| PolicyLoss      | 0.00253956  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00684     |
| _MeanReward     | 160         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90582     |
| _max_adv        | 4.57        |
| _max_discrew    | 0.525       |
| _max_obs        | 1.47        |
| _mean_act       | -0.00452892 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.118       |
| _mean_obs       | 0.0398      |
| _min_adv        | -3.74       |
| _min_discrew    | -0.0691     |
| _min_obs        | -1.24       |
| _std_act        | 0.370209    |
| _std_adv        | 1           |
| _std_discrew    | 0.0145      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 37
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.453       |
| ExplainedVarOld | 0.433       |
| KL              | 0.00379642  |
| Phi_loss        | 32.651      |
| PolicyEntropy   | 4.81642     |
| PolicyLoss      | -0.00316628 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00799     |
| _MeanReward     | 148         |
| _lr_multiplier  | 1           |
| _max_act        | 2.97705     |
| _max_adv        | 4.87        |
| _max_discrew    | 0.523       |
| _max_obs        | 1.38        |
| _mean_act       | -0.00715809 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.102       |
| _mean_obs       | 0.0394      |
| _min_adv        | -3.34       |
| _min_discrew    | -0.197      |
| _min_obs        | -1.23       |
| _std_act        | 0.378549    |
| _std_adv        | 1           |
| _std_discrew    | 0.0161      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 38
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.506       |
| ExplainedVarOld | 0.477       |
| KL              | 0.00312379  |
| Phi_loss        | 30.6859     |
| PolicyEntropy   | 4.80495     |
| PolicyLoss      | -0.00153147 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00796     |
| _MeanReward     | 217         |
| _lr_multiplier  | 1           |
| _max_act        | 2.6755      |
| _max_adv        | 3.75        |
| _max_discrew    | 0.541       |
| _max_obs        | 1.42        |
| _mean_act       | -0.00407433 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.167       |
| _mean_obs       | 0.0363      |
| _min_adv        | -3.79       |
| _min_discrew    | -0.119      |
| _min_obs        | -1.38       |
| _std_act        | 0.382915    |
| _std_adv        | 1           |
| _std_discrew    | 0.0216      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 39
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.481       |
| ExplainedVarOld | 0.425       |
| KL              | 0.00281358  |
| Phi_loss        | 32.3303     |
| PolicyEntropy   | 4.79453     |
| PolicyLoss      | 0.00123838  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0118      |
| _MeanReward     | 189         |
| _lr_multiplier  | 1           |
| _max_act        | 2.59282     |
| _max_adv        | 4.02        |
| _max_discrew    | 0.496       |
| _max_obs        | 1.39        |
| _mean_act       | -0.00420716 |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.141       |
| _mean_obs       | 0.0391      |
| _min_adv        | -4.51       |
| _min_discrew    | -0.115      |
| _min_obs        | -1.27       |
| _std_act        | 0.376193    |
| _std_adv        | 1           |
| _std_discrew    | 0.0168      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 40
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.506       |
| ExplainedVarOld | 0.49        |
| KL              | 0.00391249  |
| Phi_loss        | 33.6231     |
| PolicyEntropy   | 4.79315     |
| PolicyLoss      | -0.00222893 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00838     |
| _MeanReward     | 196         |
| _lr_multiplier  | 1           |
| _max_act        | 2.7689      |
| _max_adv        | 3.71        |
| _max_discrew    | 0.619       |
| _max_obs        | 1.38        |
| _mean_act       | -0.00822326 |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 0.132       |
| _mean_obs       | 0.036       |
| _min_adv        | -4.35       |
| _min_discrew    | -0.415      |
| _min_obs        | -1.3        |
| _std_act        | 0.399747    |
| _std_adv        | 1           |
| _std_discrew    | 0.0321      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 41
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.637       |
| ExplainedVarOld | 0.603       |
| KL              | 0.00294943  |
| Phi_loss        | 33.2444     |
| PolicyEntropy   | 4.76277     |
| PolicyLoss      | 0.00177718  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0117      |
| _MeanReward     | 218         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83669     |
| _max_adv        | 4.35        |
| _max_discrew    | 0.574       |
| _max_obs        | 1.37        |
| _mean_act       | -0.00487038 |
| _mean_adv       | 2.98e-17    |
| _mean_discrew   | 0.161       |
| _mean_obs       | 0.0397      |
| _min_adv        | -3.76       |
| _min_discrew    | -0.093      |
| _min_obs        | -1.41       |
| _std_act        | 0.380713    |
| _std_adv        | 1           |
| _std_discrew    | 0.0187      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 42
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.42        |
| ExplainedVarOld | 0.387       |
| KL              | 0.00242202  |
| Phi_loss        | 32.5958     |
| PolicyEntropy   | 4.76322     |
| PolicyLoss      | -0.0019052  |
| Steps           | 10000       |
| VarFuncLoss     | 0.011       |
| _MeanReward     | 216         |
| _lr_multiplier  | 1           |
| _max_act        | 2.90646     |
| _max_adv        | 4.39        |
| _max_discrew    | 0.766       |
| _max_obs        | 1.38        |
| _mean_act       | -0.00463993 |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 0.169       |
| _mean_obs       | 0.0378      |
| _min_adv        | -3.88       |
| _min_discrew    | -0.0422     |
| _min_obs        | -1.27       |
| _std_act        | 0.384192    |
| _std_adv        | 1           |
| _std_discrew    | 0.0251      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 43
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.444       |
| ExplainedVarOld | 0.434       |
| KL              | 0.00319088  |
| Phi_loss        | 37.2906     |
| PolicyEntropy   | 4.75223     |
| PolicyLoss      | 0.00181989  |
| Steps           | 10000       |
| VarFuncLoss     | 0.014       |
| _MeanReward     | 233         |
| _lr_multiplier  | 1           |
| _max_act        | 2.79062     |
| _max_adv        | 3.69        |
| _max_discrew    | 0.632       |
| _max_obs        | 1.5         |
| _mean_act       | -0.00652281 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.174       |
| _mean_obs       | 0.037       |
| _min_adv        | -4.23       |
| _min_discrew    | -0.0887     |
| _min_obs        | -1.53       |
| _std_act        | 0.383478    |
| _std_adv        | 1           |
| _std_discrew    | 0.0215      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 44
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.536       |
| ExplainedVarOld | 0.508       |
| KL              | 0.0030886   |
| Phi_loss        | 34.1777     |
| PolicyEntropy   | 4.74548     |
| PolicyLoss      | -0.00569073 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00998     |
| _MeanReward     | 208         |
| _lr_multiplier  | 1           |
| _max_act        | 2.99381     |
| _max_adv        | 4.82        |
| _max_discrew    | 0.504       |
| _max_obs        | 1.35        |
| _mean_act       | -0.0123864  |
| _mean_adv       | -2.42e-17   |
| _mean_discrew   | 0.153       |
| _mean_obs       | 0.0348      |
| _min_adv        | -4.43       |
| _min_discrew    | -0.1        |
| _min_obs        | -1.32       |
| _std_act        | 0.389805    |
| _std_adv        | 1           |
| _std_discrew    | 0.0151      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 45
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.55        |
| ExplainedVarOld | 0.529       |
| KL              | 0.00246846  |
| Phi_loss        | 35.0655     |
| PolicyEntropy   | 4.72663     |
| PolicyLoss      | 0.000908827 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00691     |
| _MeanReward     | 250         |
| _lr_multiplier  | 1           |
| _max_act        | 2.99996     |
| _max_adv        | 3.91        |
| _max_discrew    | 0.748       |
| _max_obs        | 1.49        |
| _mean_act       | -0.00887587 |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.185       |
| _mean_obs       | 0.0358      |
| _min_adv        | -3.95       |
| _min_discrew    | -0.199      |
| _min_obs        | -1.26       |
| _std_act        | 0.393351    |
| _std_adv        | 1           |
| _std_discrew    | 0.0237      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 46
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.604       |
| ExplainedVarOld | 0.573       |
| KL              | 0.00247502  |
| Phi_loss        | 39.6542     |
| PolicyEntropy   | 4.70323     |
| PolicyLoss      | 0.00481669  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00964     |
| _MeanReward     | 256         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60446     |
| _max_adv        | 4.1         |
| _max_discrew    | 0.538       |
| _max_obs        | 1.35        |
| _mean_act       | -0.00881959 |
| _mean_adv       | 0           |
| _mean_discrew   | 0.195       |
| _mean_obs       | 0.0329      |
| _min_adv        | -3.81       |
| _min_discrew    | -0.0768     |
| _min_obs        | -1.22       |
| _std_act        | 0.386454    |
| _std_adv        | 1           |
| _std_discrew    | 0.0222      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 47
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.542       |
| ExplainedVarOld | 0.521       |
| KL              | 0.00281076  |
| Phi_loss        | 37.0361     |
| PolicyEntropy   | 4.70289     |
| PolicyLoss      | -0.00291558 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0102      |
| _MeanReward     | 270         |
| _lr_multiplier  | 1           |
| _max_act        | 2.66939     |
| _max_adv        | 3.49        |
| _max_discrew    | 0.635       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0112859  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 0.217       |
| _mean_obs       | 0.0306      |
| _min_adv        | -3.67       |
| _min_discrew    | -0.146      |
| _min_obs        | -1.43       |
| _std_act        | 0.39072     |
| _std_adv        | 1           |
| _std_discrew    | 0.0243      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 48
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.51        |
| ExplainedVarOld | 0.469       |
| KL              | 0.00371863  |
| Phi_loss        | 37.8857     |
| PolicyEntropy   | 4.69507     |
| PolicyLoss      | -0.00137257 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0119      |
| _MeanReward     | 249         |
| _lr_multiplier  | 1           |
| _max_act        | 2.48669     |
| _max_adv        | 4.32        |
| _max_discrew    | 0.731       |
| _max_obs        | 1.49        |
| _mean_act       | -0.010604   |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 0.188       |
| _mean_obs       | 0.037       |
| _min_adv        | -4.08       |
| _min_discrew    | -0.122      |
| _min_obs        | -1.4        |
| _std_act        | 0.381146    |
| _std_adv        | 1           |
| _std_discrew    | 0.0257      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 49
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.474      |
| ExplainedVarOld | 0.467      |
| KL              | 0.00263738 |
| Phi_loss        | 40.0124    |
| PolicyEntropy   | 4.68031    |
| PolicyLoss      | 0.00660174 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0135     |
| _MeanReward     | 241        |
| _lr_multiplier  | 1          |
| _max_act        | 2.62371    |
| _max_adv        | 4.54       |
| _max_discrew    | 0.588      |
| _max_obs        | 1.34       |
| _mean_act       | -0.0133751 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.186      |
| _mean_obs       | 0.0349     |
| _min_adv        | -3.81      |
| _min_discrew    | -0.0576    |
| _min_obs        | -1.29      |
| _std_act        | 0.381747   |
| _std_adv        | 1          |
| _std_discrew    | 0.0217     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 50
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.485       |
| ExplainedVarOld | 0.469       |
| KL              | 0.00318416  |
| Phi_loss        | 39.0806     |
| PolicyEntropy   | 4.68619     |
| PolicyLoss      | -0.00736248 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0112      |
| _MeanReward     | 320         |
| _lr_multiplier  | 1           |
| _max_act        | 2.49575     |
| _max_adv        | 4.03        |
| _max_discrew    | 0.576       |
| _max_obs        | 1.55        |
| _mean_act       | -0.0145425  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.257       |
| _mean_obs       | 0.0302      |
| _min_adv        | -3.83       |
| _min_discrew    | -0.0136     |
| _min_obs        | -1.27       |
| _std_act        | 0.390895    |
| _std_adv        | 1           |
| _std_discrew    | 0.0151      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 51
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.505       |
| ExplainedVarOld | 0.434       |
| KL              | 0.00254079  |
| Phi_loss        | 36.1784     |
| PolicyEntropy   | 4.68033     |
| PolicyLoss      | -0.00544372 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00792     |
| _MeanReward     | 253         |
| _lr_multiplier  | 1           |
| _max_act        | 2.80787     |
| _max_adv        | 3.6         |
| _max_discrew    | 0.616       |
| _max_obs        | 1.64        |
| _mean_act       | -0.0158357  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 0.193       |
| _mean_obs       | 0.0333      |
| _min_adv        | -3.14       |
| _min_discrew    | -0.344      |
| _min_obs        | -1.38       |
| _std_act        | 0.397577    |
| _std_adv        | 1           |
| _std_discrew    | 0.0315      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 52
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.543      |
| ExplainedVarOld | 0.511      |
| KL              | 0.00306859 |
| Phi_loss        | 37.665     |
| PolicyEntropy   | 4.67607    |
| PolicyLoss      | 0.00158479 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0148     |
| _MeanReward     | 298        |
| _lr_multiplier  | 1          |
| _max_act        | 3.16912    |
| _max_adv        | 3.33       |
| _max_discrew    | 0.654      |
| _max_obs        | 1.68       |
| _mean_act       | -0.0114379 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 0.235      |
| _mean_obs       | 0.0327     |
| _min_adv        | -7.91      |
| _min_discrew    | -0.384     |
| _min_obs        | -1.36      |
| _std_act        | 0.401463   |
| _std_adv        | 1          |
| _std_discrew    | 0.0376     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 53
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.618      |
| ExplainedVarOld | 0.599      |
| KL              | 0.00261322 |
| Phi_loss        | 33.0181    |
| PolicyEntropy   | 4.68423    |
| PolicyLoss      | 0.00107882 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 291        |
| _lr_multiplier  | 1          |
| _max_act        | 2.57264    |
| _max_adv        | 3.36       |
| _max_discrew    | 0.692      |
| _max_obs        | 1.51       |
| _mean_act       | -0.0145835 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.222      |
| _mean_obs       | 0.0336     |
| _min_adv        | -3.86      |
| _min_discrew    | -0.0766    |
| _min_obs        | -1.28      |
| _std_act        | 0.388001   |
| _std_adv        | 1          |
| _std_discrew    | 0.0287     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 54
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.517       |
| ExplainedVarOld | 0.494       |
| KL              | 0.00306274  |
| Phi_loss        | 37.1655     |
| PolicyEntropy   | 4.67284     |
| PolicyLoss      | 0.000464582 |
| Steps           | 10000       |
| VarFuncLoss     | 0.014       |
| _MeanReward     | 403         |
| _lr_multiplier  | 1           |
| _max_act        | 3.03105     |
| _max_adv        | 3.57        |
| _max_discrew    | 0.843       |
| _max_obs        | 1.43        |
| _mean_act       | -0.0122232  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.319       |
| _mean_obs       | 0.0304      |
| _min_adv        | -3.87       |
| _min_discrew    | -0.068      |
| _min_obs        | -1.31       |
| _std_act        | 0.392241    |
| _std_adv        | 1           |
| _std_discrew    | 0.0504      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 55
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.591      |
| ExplainedVarOld | 0.528      |
| KL              | 0.00325008 |
| Phi_loss        | 40.6209    |
| PolicyEntropy   | 4.65982    |
| PolicyLoss      | -0.0022776 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0213     |
| _MeanReward     | 328        |
| _lr_multiplier  | 1          |
| _max_act        | 2.51559    |
| _max_adv        | 3.93       |
| _max_discrew    | 0.787      |
| _max_obs        | 1.45       |
| _mean_act       | -0.0163224 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.264      |
| _mean_obs       | 0.0339     |
| _min_adv        | -4.49      |
| _min_discrew    | -0.0772    |
| _min_obs        | -1.46      |
| _std_act        | 0.393916   |
| _std_adv        | 1          |
| _std_discrew    | 0.036      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 56
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.605      |
| ExplainedVarOld | 0.585      |
| KL              | 0.0026073  |
| Phi_loss        | 38.0369    |
| PolicyEntropy   | 4.63463    |
| PolicyLoss      | 0.00396959 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0143     |
| _MeanReward     | 331        |
| _lr_multiplier  | 1          |
| _max_act        | 2.76838    |
| _max_adv        | 3.4        |
| _max_discrew    | 0.712      |
| _max_obs        | 1.41       |
| _mean_act       | -0.0175866 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.267      |
| _mean_obs       | 0.0307     |
| _min_adv        | -4.61      |
| _min_discrew    | -0.0324    |
| _min_obs        | -1.27      |
| _std_act        | 0.393772   |
| _std_adv        | 1          |
| _std_discrew    | 0.0301     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 57
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.587      |
| ExplainedVarOld | 0.516      |
| KL              | 0.0022489  |
| Phi_loss        | 37.4718    |
| PolicyEntropy   | 4.62799    |
| PolicyLoss      | 0.00429499 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0125     |
| _MeanReward     | 383        |
| _lr_multiplier  | 1          |
| _max_act        | 2.74236    |
| _max_adv        | 3.57       |
| _max_discrew    | 0.802      |
| _max_obs        | 1.5        |
| _mean_act       | -0.0111815 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.301      |
| _mean_obs       | 0.0335     |
| _min_adv        | -4.48      |
| _min_discrew    | -0.0741    |
| _min_obs        | -1.22      |
| _std_act        | 0.393168   |
| _std_adv        | 1          |
| _std_discrew    | 0.041      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 58
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.649      |
| ExplainedVarOld | 0.644      |
| KL              | 0.00265728 |
| Phi_loss        | 40.8312    |
| PolicyEntropy   | 4.6255     |
| PolicyLoss      | 0.00272508 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0147     |
| _MeanReward     | 366        |
| _lr_multiplier  | 1          |
| _max_act        | 2.78649    |
| _max_adv        | 3.92       |
| _max_discrew    | 0.792      |
| _max_obs        | 1.51       |
| _mean_act       | -0.0141972 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.282      |
| _mean_obs       | 0.0356     |
| _min_adv        | -4.51      |
| _min_discrew    | -0.0405    |
| _min_obs        | -1.28      |
| _std_act        | 0.388377   |
| _std_adv        | 1          |
| _std_discrew    | 0.0302     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 59
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.549       |
| ExplainedVarOld | 0.541       |
| KL              | 0.00232679  |
| Phi_loss        | 38.3056     |
| PolicyEntropy   | 4.62489     |
| PolicyLoss      | -0.00269457 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0136      |
| _MeanReward     | 356         |
| _lr_multiplier  | 1           |
| _max_act        | 2.68487     |
| _max_adv        | 3.52        |
| _max_discrew    | 0.772       |
| _max_obs        | 1.54        |
| _mean_act       | -0.023475   |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.283       |
| _mean_obs       | 0.0266      |
| _min_adv        | -4.04       |
| _min_discrew    | -0.099      |
| _min_obs        | -1.35       |
| _std_act        | 0.399483    |
| _std_adv        | 1           |
| _std_discrew    | 0.0419      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 60
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.591        |
| ExplainedVarOld | 0.581        |
| KL              | 0.00367732   |
| Phi_loss        | 41.9667      |
| PolicyEntropy   | 4.61391      |
| PolicyLoss      | -0.000965065 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0173       |
| _MeanReward     | 385          |
| _lr_multiplier  | 1            |
| _max_act        | 2.69946      |
| _max_adv        | 3.52         |
| _max_discrew    | 0.756        |
| _max_obs        | 1.44         |
| _mean_act       | -0.0179319   |
| _mean_adv       | 7.11e-18     |
| _mean_discrew   | 0.319        |
| _mean_obs       | 0.028        |
| _min_adv        | -4.01        |
| _min_discrew    | -0.0495      |
| _min_obs        | -1.25        |
| _std_act        | 0.397655     |
| _std_adv        | 1            |
| _std_discrew    | 0.0288       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 61
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.63         |
| ExplainedVarOld | 0.591        |
| KL              | 0.00395775   |
| Phi_loss        | 41.2534      |
| PolicyEntropy   | 4.60976      |
| PolicyLoss      | -0.000948129 |
| Steps           | 10000        |
| VarFuncLoss     | 0.011        |
| _MeanReward     | 379          |
| _lr_multiplier  | 1            |
| _max_act        | 2.57223      |
| _max_adv        | 2.88         |
| _max_discrew    | 0.739        |
| _max_obs        | 1.44         |
| _mean_act       | -0.0206071   |
| _mean_adv       | -8.53e-18    |
| _mean_discrew   | 0.289        |
| _mean_obs       | 0.0298       |
| _min_adv        | -4.38        |
| _min_discrew    | -0.123       |
| _min_obs        | -1.36        |
| _std_act        | 0.39878      |
| _std_adv        | 1            |
| _std_discrew    | 0.0289       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 62
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.48        |
| ExplainedVarOld | 0.407       |
| KL              | 0.00342872  |
| Phi_loss        | 38.4702     |
| PolicyEntropy   | 4.60217     |
| PolicyLoss      | -0.00158351 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0151      |
| _MeanReward     | 345         |
| _lr_multiplier  | 1           |
| _max_act        | 2.7946      |
| _max_adv        | 3.55        |
| _max_discrew    | 0.839       |
| _max_obs        | 1.52        |
| _mean_act       | -0.0187059  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.265       |
| _mean_obs       | 0.031       |
| _min_adv        | -3.91       |
| _min_discrew    | -0.0339     |
| _min_obs        | -1.33       |
| _std_act        | 0.399129    |
| _std_adv        | 1           |
| _std_discrew    | 0.0476      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 63
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.653       |
| ExplainedVarOld | 0.58        |
| KL              | 0.0031458   |
| Phi_loss        | 40.6966     |
| PolicyEntropy   | 4.56057     |
| PolicyLoss      | 1.82614e-05 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 417         |
| _lr_multiplier  | 1           |
| _max_act        | 2.42953     |
| _max_adv        | 3.72        |
| _max_discrew    | 0.772       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0211628  |
| _mean_adv       | -3.98e-17   |
| _mean_discrew   | 0.335       |
| _mean_obs       | 0.0265      |
| _min_adv        | -4.63       |
| _min_discrew    | -0.0924     |
| _min_obs        | -1.4        |
| _std_act        | 0.397967    |
| _std_adv        | 1           |
| _std_discrew    | 0.0382      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 64
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.595       |
| ExplainedVarOld | 0.562       |
| KL              | 0.0035343   |
| Phi_loss        | 43.5809     |
| PolicyEntropy   | 4.54706     |
| PolicyLoss      | 0.000180242 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 403         |
| _lr_multiplier  | 1           |
| _max_act        | 2.66402     |
| _max_adv        | 4.12        |
| _max_discrew    | 0.727       |
| _max_obs        | 1.37        |
| _mean_act       | -0.0168708  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.324       |
| _mean_obs       | 0.0281      |
| _min_adv        | -5.44       |
| _min_discrew    | -0.0632     |
| _min_obs        | -1.38       |
| _std_act        | 0.396755    |
| _std_adv        | 1           |
| _std_discrew    | 0.0249      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 65
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.597      |
| ExplainedVarOld | 0.457      |
| KL              | 0.00236093 |
| Phi_loss        | 42.0243    |
| PolicyEntropy   | 4.51366    |
| PolicyLoss      | 0.00933058 |
| Steps           | 10000      |
| VarFuncLoss     | 0.01       |
| _MeanReward     | 429        |
| _lr_multiplier  | 1          |
| _max_act        | 2.39089    |
| _max_adv        | 3.64       |
| _max_discrew    | 0.848      |
| _max_obs        | 1.37       |
| _mean_act       | -0.02007   |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.344      |
| _mean_obs       | 0.0272     |
| _min_adv        | -4.09      |
| _min_discrew    | -0.0449    |
| _min_obs        | -1.31      |
| _std_act        | 0.39748    |
| _std_adv        | 1          |
| _std_discrew    | 0.0364     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 66
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.549      |
| ExplainedVarOld | 0.531      |
| KL              | 0.00296911 |
| Phi_loss        | 47.8316    |
| PolicyEntropy   | 4.48374    |
| PolicyLoss      | 0.00722625 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0164     |
| _MeanReward     | 375        |
| _lr_multiplier  | 1          |
| _max_act        | 2.60232    |
| _max_adv        | 4.01       |
| _max_discrew    | 0.793      |
| _max_obs        | 1.44       |
| _mean_act       | -0.0211994 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.293      |
| _mean_obs       | 0.0335     |
| _min_adv        | -4.68      |
| _min_discrew    | -0.0695    |
| _min_obs        | -1.36      |
| _std_act        | 0.383641   |
| _std_adv        | 1          |
| _std_discrew    | 0.0334     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 67
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.667       |
| ExplainedVarOld | 0.642       |
| KL              | 0.00300716  |
| Phi_loss        | 43.5982     |
| PolicyEntropy   | 4.48408     |
| PolicyLoss      | -0.00574605 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0111      |
| _MeanReward     | 461         |
| _lr_multiplier  | 1           |
| _max_act        | 2.61452     |
| _max_adv        | 3.63        |
| _max_discrew    | 0.916       |
| _max_obs        | 1.42        |
| _mean_act       | -0.0271     |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.366       |
| _mean_obs       | 0.0251      |
| _min_adv        | -4.03       |
| _min_discrew    | -0.0187     |
| _min_obs        | -1.3        |
| _std_act        | 0.396977    |
| _std_adv        | 1           |
| _std_discrew    | 0.0321      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 68
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.495       |
| ExplainedVarOld | 0.45        |
| KL              | 0.00308724  |
| Phi_loss        | 44.622      |
| PolicyEntropy   | 4.48027     |
| PolicyLoss      | -0.00291335 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 427         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60656     |
| _max_adv        | 3.65        |
| _max_discrew    | 0.881       |
| _max_obs        | 1.34        |
| _mean_act       | -0.0259779  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.348       |
| _mean_obs       | 0.0272      |
| _min_adv        | -4.58       |
| _min_discrew    | -0.0881     |
| _min_obs        | -1.31       |
| _std_act        | 0.393763    |
| _std_adv        | 1           |
| _std_discrew    | 0.0359      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 69
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.633       |
| ExplainedVarOld | 0.627       |
| KL              | 0.00260205  |
| Phi_loss        | 45.3094     |
| PolicyEntropy   | 4.4638      |
| PolicyLoss      | -0.00253798 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0132      |
| _MeanReward     | 469         |
| _lr_multiplier  | 1           |
| _max_act        | 2.89697     |
| _max_adv        | 3.17        |
| _max_discrew    | 0.772       |
| _max_obs        | 1.52        |
| _mean_act       | -0.024219   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.378       |
| _mean_obs       | 0.0244      |
| _min_adv        | -4.21       |
| _min_discrew    | -0.144      |
| _min_obs        | -1.54       |
| _std_act        | 0.402124    |
| _std_adv        | 1           |
| _std_discrew    | 0.0442      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 70
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.69       |
| ExplainedVarOld | 0.656      |
| KL              | 0.00277911 |
| Phi_loss        | 47.4993    |
| PolicyEntropy   | 4.44556    |
| PolicyLoss      | 0.00289912 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0137     |
| _MeanReward     | 541        |
| _lr_multiplier  | 1          |
| _max_act        | 2.91966    |
| _max_adv        | 3.32       |
| _max_discrew    | 0.876      |
| _max_obs        | 1.37       |
| _mean_act       | -0.0204875 |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 0.434      |
| _mean_obs       | 0.0249     |
| _min_adv        | -4.42      |
| _min_discrew    | -0.0101    |
| _min_obs        | -1.27      |
| _std_act        | 0.407418   |
| _std_adv        | 1          |
| _std_discrew    | 0.0437     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 71
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.658       |
| ExplainedVarOld | 0.634       |
| KL              | 0.00273152  |
| Phi_loss        | 50.8917     |
| PolicyEntropy   | 4.4407      |
| PolicyLoss      | -0.00840757 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0155      |
| _MeanReward     | 502         |
| _lr_multiplier  | 1           |
| _max_act        | 2.59542     |
| _max_adv        | 3.5         |
| _max_discrew    | 0.99        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0183252  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.405       |
| _mean_obs       | 0.0305      |
| _min_adv        | -4.43       |
| _min_discrew    | -0.0328     |
| _min_obs        | -1.3        |
| _std_act        | 0.390543    |
| _std_adv        | 1           |
| _std_discrew    | 0.0493      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 72
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.602       |
| ExplainedVarOld | 0.517       |
| KL              | 0.00260107  |
| Phi_loss        | 41.2612     |
| PolicyEntropy   | 4.42863     |
| PolicyLoss      | -0.00291221 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0197      |
| _MeanReward     | 469         |
| _lr_multiplier  | 1           |
| _max_act        | 2.44068     |
| _max_adv        | 3.95        |
| _max_discrew    | 0.898       |
| _max_obs        | 1.38        |
| _mean_act       | -0.0255441  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.371       |
| _mean_obs       | 0.0269      |
| _min_adv        | -4.59       |
| _min_discrew    | -0.107      |
| _min_obs        | -1.33       |
| _std_act        | 0.402077    |
| _std_adv        | 1           |
| _std_discrew    | 0.0554      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 73
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.612      |
| ExplainedVarOld | 0.605      |
| KL              | 0.0027719  |
| Phi_loss        | 48.4715    |
| PolicyEntropy   | 4.41664    |
| PolicyLoss      | 0.00374084 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0226     |
| _MeanReward     | 587        |
| _lr_multiplier  | 1          |
| _max_act        | 2.59994    |
| _max_adv        | 3.54       |
| _max_discrew    | 0.911      |
| _max_obs        | 1.38       |
| _mean_act       | -0.0222362 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 0.475      |
| _mean_obs       | 0.0266     |
| _min_adv        | -4.8       |
| _min_discrew    | -0.0611    |
| _min_obs        | -1.36      |
| _std_act        | 0.398215   |
| _std_adv        | 1          |
| _std_discrew    | 0.0503     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 74
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.644       |
| ExplainedVarOld | 0.626       |
| KL              | 0.00384359  |
| Phi_loss        | 52.5176     |
| PolicyEntropy   | 4.40134     |
| PolicyLoss      | 0.000813199 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0196      |
| _MeanReward     | 487         |
| _lr_multiplier  | 1           |
| _max_act        | 2.41454     |
| _max_adv        | 3.65        |
| _max_discrew    | 0.881       |
| _max_obs        | 1.43        |
| _mean_act       | -0.0320741  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.392       |
| _mean_obs       | 0.0254      |
| _min_adv        | -4.52       |
| _min_discrew    | -0.00844    |
| _min_obs        | -1.42       |
| _std_act        | 0.396161    |
| _std_adv        | 1           |
| _std_discrew    | 0.0379      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 75
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.589       |
| ExplainedVarOld | 0.554       |
| KL              | 0.00310944  |
| Phi_loss        | 51.1731     |
| PolicyEntropy   | 4.39048     |
| PolicyLoss      | -0.00260941 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 611         |
| _lr_multiplier  | 1           |
| _max_act        | 2.48575     |
| _max_adv        | 3.42        |
| _max_discrew    | 0.989       |
| _max_obs        | 1.39        |
| _mean_act       | -0.0215256  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.478       |
| _mean_obs       | 0.0251      |
| _min_adv        | -4.65       |
| _min_discrew    | -0.00471    |
| _min_obs        | -1.34       |
| _std_act        | 0.396866    |
| _std_adv        | 1           |
| _std_discrew    | 0.0548      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 76
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.673      |
| ExplainedVarOld | 0.645      |
| KL              | 0.00274196 |
| Phi_loss        | 49.0604    |
| PolicyEntropy   | 4.37023    |
| PolicyLoss      | -0.0100853 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0188     |
| _MeanReward     | 581        |
| _lr_multiplier  | 1          |
| _max_act        | 2.57974    |
| _max_adv        | 3.36       |
| _max_discrew    | 1.16       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0254798 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 0.472      |
| _mean_obs       | 0.0275     |
| _min_adv        | -4.38      |
| _min_discrew    | -0.00579   |
| _min_obs        | -1.4       |
| _std_act        | 0.409648   |
| _std_adv        | 1          |
| _std_discrew    | 0.0589     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 77
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.628       |
| ExplainedVarOld | 0.619       |
| KL              | 0.00287971  |
| Phi_loss        | 50.5676     |
| PolicyEntropy   | 4.36225     |
| PolicyLoss      | -0.00408415 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0219      |
| _MeanReward     | 560         |
| _lr_multiplier  | 1           |
| _max_act        | 2.83701     |
| _max_adv        | 3.63        |
| _max_discrew    | 0.953       |
| _max_obs        | 1.57        |
| _mean_act       | -0.0255501  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 0.445       |
| _mean_obs       | 0.0259      |
| _min_adv        | -4.9        |
| _min_discrew    | -0.00944    |
| _min_obs        | -1.33       |
| _std_act        | 0.40726     |
| _std_adv        | 1           |
| _std_discrew    | 0.0474      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 78
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.659       |
| ExplainedVarOld | 0.644       |
| KL              | 0.00278088  |
| Phi_loss        | 51.4014     |
| PolicyEntropy   | 4.37186     |
| PolicyLoss      | -0.00666236 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0164      |
| _MeanReward     | 611         |
| _lr_multiplier  | 1           |
| _max_act        | 3.629       |
| _max_adv        | 2.72        |
| _max_discrew    | 1.04        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0245138  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 0.494       |
| _mean_obs       | 0.0238      |
| _min_adv        | -5.71       |
| _min_discrew    | -0.618      |
| _min_obs        | -1.34       |
| _std_act        | 0.442168    |
| _std_adv        | 1           |
| _std_discrew    | 0.0959      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 79
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.627       |
| ExplainedVarOld | 0.565       |
| KL              | 0.00276657  |
| Phi_loss        | 45.6774     |
| PolicyEntropy   | 4.36511     |
| PolicyLoss      | -0.00403825 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0359      |
| _MeanReward     | 632         |
| _lr_multiplier  | 1           |
| _max_act        | 2.88663     |
| _max_adv        | 3.47        |
| _max_discrew    | 1.13        |
| _max_obs        | 1.42        |
| _mean_act       | -0.024317   |
| _mean_adv       | -2.84e-17   |
| _mean_discrew   | 0.51        |
| _mean_obs       | 0.0264      |
| _min_adv        | -4.68       |
| _min_discrew    | -0.0145     |
| _min_obs        | -1.52       |
| _std_act        | 0.408655    |
| _std_adv        | 1           |
| _std_discrew    | 0.0696      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 80
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.628      |
| ExplainedVarOld | 0.615      |
| KL              | 0.00270902 |
| Phi_loss        | 52.1841    |
| PolicyEntropy   | 4.3234     |
| PolicyLoss      | 0.00381665 |
| Steps           | 10000      |
| VarFuncLoss     | 0.026      |
| _MeanReward     | 590        |
| _lr_multiplier  | 1          |
| _max_act        | 2.68659    |
| _max_adv        | 4.07       |
| _max_discrew    | 1.08       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0303399 |
| _mean_adv       | 0          |
| _mean_discrew   | 0.471      |
| _mean_obs       | 0.0268     |
| _min_adv        | -5.58      |
| _min_discrew    | -0.00306   |
| _min_obs        | -1.38      |
| _std_act        | 0.400533   |
| _std_adv        | 1          |
| _std_discrew    | 0.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 81
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.627       |
| ExplainedVarOld | 0.566       |
| KL              | 0.00303794  |
| Phi_loss        | 46.7696     |
| PolicyEntropy   | 4.30699     |
| PolicyLoss      | 0.000687974 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0189      |
| _MeanReward     | 602         |
| _lr_multiplier  | 1           |
| _max_act        | 2.58011     |
| _max_adv        | 4.15        |
| _max_discrew    | 0.931       |
| _max_obs        | 1.44        |
| _mean_act       | -0.0309035  |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 0.487       |
| _mean_obs       | 0.0227      |
| _min_adv        | -4.88       |
| _min_discrew    | -0.0043     |
| _min_obs        | -1.37       |
| _std_act        | 0.402745    |
| _std_adv        | 1           |
| _std_discrew    | 0.0411      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 82
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.607       |
| ExplainedVarOld | 0.551       |
| KL              | 0.00267634  |
| Phi_loss        | 50.218      |
| PolicyEntropy   | 4.27493     |
| PolicyLoss      | -0.00218927 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0162      |
| _MeanReward     | 527         |
| _lr_multiplier  | 1           |
| _max_act        | 3.8699      |
| _max_adv        | 3           |
| _max_discrew    | 1.05        |
| _max_obs        | 1.48        |
| _mean_act       | -0.0254328  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.405       |
| _mean_obs       | 0.0249      |
| _min_adv        | -4.29       |
| _min_discrew    | -0.964      |
| _min_obs        | -1.32       |
| _std_act        | 0.509076    |
| _std_adv        | 1           |
| _std_discrew    | 0.198       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 83
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.852       |
| ExplainedVarOld | 0.653       |
| KL              | 0.00274042  |
| Phi_loss        | 35.37       |
| PolicyEntropy   | 4.27441     |
| PolicyLoss      | -0.00259711 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0295      |
| _MeanReward     | 592         |
| _lr_multiplier  | 1           |
| _max_act        | 2.705       |
| _max_adv        | 4.42        |
| _max_discrew    | 1.12        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0307536  |
| _mean_adv       | 2.13e-17    |
| _mean_discrew   | 0.474       |
| _mean_obs       | 0.0274      |
| _min_adv        | -3.88       |
| _min_discrew    | -0.0333     |
| _min_obs        | -1.25       |
| _std_act        | 0.397482    |
| _std_adv        | 1           |
| _std_discrew    | 0.0572      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 84
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.616       |
| ExplainedVarOld | 0.587       |
| KL              | 0.00302607  |
| Phi_loss        | 44.9248     |
| PolicyEntropy   | 4.25611     |
| PolicyLoss      | -0.00366291 |
| Steps           | 10000       |
| VarFuncLoss     | 0.022       |
| _MeanReward     | 693         |
| _lr_multiplier  | 1           |
| _max_act        | 3.2182      |
| _max_adv        | 4.32        |
| _max_discrew    | 1.11        |
| _max_obs        | 1.4         |
| _mean_act       | -0.0294971  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.554       |
| _mean_obs       | 0.0252      |
| _min_adv        | -4.52       |
| _min_discrew    | -0.0616     |
| _min_obs        | -1.28       |
| _std_act        | 0.400272    |
| _std_adv        | 1           |
| _std_discrew    | 0.0772      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 85
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.67        |
| ExplainedVarOld | 0.645       |
| KL              | 0.00245003  |
| Phi_loss        | 48.554      |
| PolicyEntropy   | 4.23677     |
| PolicyLoss      | -0.00339998 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0263      |
| _MeanReward     | 724         |
| _lr_multiplier  | 1           |
| _max_act        | 2.42097     |
| _max_adv        | 3.99        |
| _max_discrew    | 1.18        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0253571  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 0.578       |
| _mean_obs       | 0.0286      |
| _min_adv        | -4.74       |
| _min_discrew    | -0.0246     |
| _min_obs        | -1.4        |
| _std_act        | 0.414333    |
| _std_adv        | 1           |
| _std_discrew    | 0.0795      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 86
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.673      |
| ExplainedVarOld | 0.648      |
| KL              | 0.00367677 |
| Phi_loss        | 50.7379    |
| PolicyEntropy   | 4.21678    |
| PolicyLoss      | -0.0101974 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0265     |
| _MeanReward     | 640        |
| _lr_multiplier  | 1          |
| _max_act        | 2.60108    |
| _max_adv        | 3.22       |
| _max_discrew    | 1.31       |
| _max_obs        | 1.37       |
| _mean_act       | -0.030579  |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | 0.51       |
| _mean_obs       | 0.0285     |
| _min_adv        | -5.83      |
| _min_discrew    | -0.0296    |
| _min_obs        | -1.27      |
| _std_act        | 0.407536   |
| _std_adv        | 1          |
| _std_discrew    | 0.0774     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 87
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.623        |
| ExplainedVarOld | 0.579        |
| KL              | 0.00244855   |
| Phi_loss        | 47.0478      |
| PolicyEntropy   | 4.20984      |
| PolicyLoss      | -0.000646028 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0296       |
| _MeanReward     | 761          |
| _lr_multiplier  | 1            |
| _max_act        | 3.10144      |
| _max_adv        | 4.14         |
| _max_discrew    | 1.15         |
| _max_obs        | 1.3          |
| _mean_act       | -0.027828    |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 0.62         |
| _mean_obs       | 0.0269       |
| _min_adv        | -6.81        |
| _min_discrew    | -0.000826    |
| _min_obs        | -1.26        |
| _std_act        | 0.408166     |
| _std_adv        | 1            |
| _std_discrew    | 0.0748       |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 88
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.678       |
| ExplainedVarOld | 0.669       |
| KL              | 0.00214637  |
| Phi_loss        | 54.2486     |
| PolicyEntropy   | 4.18354     |
| PolicyLoss      | 0.000473983 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0255      |
| _MeanReward     | 804         |
| _lr_multiplier  | 1           |
| _max_act        | 2.88481     |
| _max_adv        | 4.65        |
| _max_discrew    | 1.22        |
| _max_obs        | 1.45        |
| _mean_act       | -0.0276595  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 0.657       |
| _mean_obs       | 0.0252      |
| _min_adv        | -6.33       |
| _min_discrew    | -0.0555     |
| _min_obs        | -1.34       |
| _std_act        | 0.412974    |
| _std_adv        | 1           |
| _std_discrew    | 0.0708      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 89
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.704       |
| ExplainedVarOld | 0.661       |
| KL              | 0.00288825  |
| Phi_loss        | 51.6124     |
| PolicyEntropy   | 4.17898     |
| PolicyLoss      | -0.00838472 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0211      |
| _MeanReward     | 761         |
| _lr_multiplier  | 1           |
| _max_act        | 2.54832     |
| _max_adv        | 3.14        |
| _max_discrew    | 1.16        |
| _max_obs        | 1.58        |
| _mean_act       | -0.0309427  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 0.603       |
| _mean_obs       | 0.0293      |
| _min_adv        | -4.93       |
| _min_discrew    | -0.0309     |
| _min_obs        | -1.22       |
| _std_act        | 0.412283    |
| _std_adv        | 1           |
| _std_discrew    | 0.0908      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 90
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.714      |
| ExplainedVarOld | 0.685      |
| KL              | 0.00263293 |
| Phi_loss        | 54.8899    |
| PolicyEntropy   | 4.14518    |
| PolicyLoss      | 0.00224595 |
| Steps           | 10000      |
| VarFuncLoss     | 0.026      |
| _MeanReward     | 824        |
| _lr_multiplier  | 1          |
| _max_act        | 2.47989    |
| _max_adv        | 3.79       |
| _max_discrew    | 1.38       |
| _max_obs        | 1.58       |
| _mean_act       | -0.0295807 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 0.658      |
| _mean_obs       | 0.0283     |
| _min_adv        | -5.47      |
| _min_discrew    | -0.00874   |
| _min_obs        | -1.32      |
| _std_act        | 0.412043   |
| _std_adv        | 1          |
| _std_discrew    | 0.109      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 91
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.71        |
| ExplainedVarOld | 0.683       |
| KL              | 0.00333941  |
| Phi_loss        | 51.7056     |
| PolicyEntropy   | 4.1375      |
| PolicyLoss      | -0.00777318 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0321      |
| _MeanReward     | 757         |
| _lr_multiplier  | 1           |
| _max_act        | 2.60266     |
| _max_adv        | 4.28        |
| _max_discrew    | 1.24        |
| _max_obs        | 1.38        |
| _mean_act       | -0.0276125  |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 0.593       |
| _mean_obs       | 0.03        |
| _min_adv        | -4.5        |
| _min_discrew    | -0.103      |
| _min_obs        | -1.4        |
| _std_act        | 0.411098    |
| _std_adv        | 1           |
| _std_discrew    | 0.103       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 92
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.725       |
| ExplainedVarOld | 0.712       |
| KL              | 0.00230701  |
| Phi_loss        | 53.504      |
| PolicyEntropy   | 4.13258     |
| PolicyLoss      | -0.00462882 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0287      |
| _MeanReward     | 921         |
| _lr_multiplier  | 1           |
| _max_act        | 2.57028     |
| _max_adv        | 4.48        |
| _max_discrew    | 1.3         |
| _max_obs        | 1.47        |
| _mean_act       | -0.0261155  |
| _mean_adv       | 7.39e-17    |
| _mean_discrew   | 0.749       |
| _mean_obs       | 0.0258      |
| _min_adv        | -5.27       |
| _min_discrew    | -0.0133     |
| _min_obs        | -1.25       |
| _std_act        | 0.414845    |
| _std_adv        | 1           |
| _std_discrew    | 0.0819      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 93
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.703       |
| ExplainedVarOld | 0.685       |
| KL              | 0.00290921  |
| Phi_loss        | 56.2944     |
| PolicyEntropy   | 4.12103     |
| PolicyLoss      | -0.00749545 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0268      |
| _MeanReward     | 865         |
| _lr_multiplier  | 1           |
| _max_act        | 3.01654     |
| _max_adv        | 4.09        |
| _max_discrew    | 1.24        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0257852  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.684       |
| _mean_obs       | 0.0303      |
| _min_adv        | -5.14       |
| _min_discrew    | -0.0203     |
| _min_obs        | -1.35       |
| _std_act        | 0.414655    |
| _std_adv        | 1           |
| _std_discrew    | 0.126       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 94
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.702      |
| ExplainedVarOld | 0.668      |
| KL              | 0.00309606 |
| Phi_loss        | 51.6378    |
| PolicyEntropy   | 4.12143    |
| PolicyLoss      | -0.0151295 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0376     |
| _MeanReward     | 762        |
| _lr_multiplier  | 1          |
| _max_act        | 2.84418    |
| _max_adv        | 4.36       |
| _max_discrew    | 1.15       |
| _max_obs        | 1.46       |
| _mean_act       | -0.0359663 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 0.614      |
| _mean_obs       | 0.0291     |
| _min_adv        | -4.93      |
| _min_discrew    | -0.0409    |
| _min_obs        | -1.31      |
| _std_act        | 0.421688   |
| _std_adv        | 1          |
| _std_discrew    | 0.0883     |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 95
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.642       |
| ExplainedVarOld | 0.599       |
| KL              | 0.00302413  |
| Phi_loss        | 57.6033     |
| PolicyEntropy   | 4.12262     |
| PolicyLoss      | -0.00778028 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0323      |
| _MeanReward     | 862         |
| _lr_multiplier  | 1           |
| _max_act        | 2.77048     |
| _max_adv        | 4.68        |
| _max_discrew    | 1.27        |
| _max_obs        | 1.46        |
| _mean_act       | -0.0290758  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.716       |
| _mean_obs       | 0.0281      |
| _min_adv        | -5.77       |
| _min_discrew    | -0.00361    |
| _min_obs        | -1.23       |
| _std_act        | 0.424117    |
| _std_adv        | 1           |
| _std_discrew    | 0.0824      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 96
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.686       |
| ExplainedVarOld | 0.654       |
| KL              | 0.00307746  |
| Phi_loss        | 52.7178     |
| PolicyEntropy   | 4.10291     |
| PolicyLoss      | -0.00860044 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0271      |
| _MeanReward     | 891         |
| _lr_multiplier  | 1           |
| _max_act        | 2.51163     |
| _max_adv        | 4.03        |
| _max_discrew    | 1.3         |
| _max_obs        | 1.44        |
| _mean_act       | -0.030088   |
| _mean_adv       | -2.7e-17    |
| _mean_discrew   | 0.714       |
| _mean_obs       | 0.0271      |
| _min_adv        | -6.35       |
| _min_discrew    | -0.0369     |
| _min_obs        | -1.45       |
| _std_act        | 0.424675    |
| _std_adv        | 1           |
| _std_discrew    | 0.111       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 97
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.748      |
| ExplainedVarOld | 0.703      |
| KL              | 0.00359095 |
| Phi_loss        | 54.436     |
| PolicyEntropy   | 4.07079    |
| PolicyLoss      | 0.00454696 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0279     |
| _MeanReward     | 847        |
| _lr_multiplier  | 1          |
| _max_act        | 4.23914    |
| _max_adv        | 3.28       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.5        |
| _mean_act       | -0.0233541 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 0.657      |
| _mean_obs       | 0.0289     |
| _min_adv        | -9.81      |
| _min_discrew    | -0.979     |
| _min_obs        | -1.29      |
| _std_act        | 0.481556   |
| _std_adv        | 1          |
| _std_discrew    | 0.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 98
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.733      |
| ExplainedVarOld | 0.689      |
| KL              | 0.00550254 |
| Phi_loss        | 57.0375    |
| PolicyEntropy   | 4.04691    |
| PolicyLoss      | -0.0253233 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0586     |
| _MeanReward     | 1.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.01582    |
| _max_adv        | 4.76       |
| _max_discrew    | 1.41       |
| _max_obs        | 1.45       |
| _mean_act       | -0.025481  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.849      |
| _mean_obs       | 0.0284     |
| _min_adv        | -5.69      |
| _min_discrew    | -0.00121   |
| _min_obs        | -1.29      |
| _std_act        | 0.433523   |
| _std_adv        | 1          |
| _std_discrew    | 0.107      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 99
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.763       |
| ExplainedVarOld | 0.706       |
| KL              | 0.00333432  |
| Phi_loss        | 60.9878     |
| PolicyEntropy   | 4.03134     |
| PolicyLoss      | -0.00576339 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0281      |
| _MeanReward     | 869         |
| _lr_multiplier  | 1           |
| _max_act        | 2.65199     |
| _max_adv        | 5.08        |
| _max_discrew    | 1.31        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0331412  |
| _mean_adv       | 3.84e-17    |
| _mean_discrew   | 0.695       |
| _mean_obs       | 0.0288      |
| _min_adv        | -5.61       |
| _min_discrew    | -0.0361     |
| _min_obs        | -1.23       |
| _std_act        | 0.423265    |
| _std_adv        | 1           |
| _std_discrew    | 0.0955      |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 100
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.703      |
| ExplainedVarOld | 0.666      |
| KL              | 0.00305434 |
| Phi_loss        | 56.274     |
| PolicyEntropy   | 4.023      |
| PolicyLoss      | -0.0166714 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0313     |
| _MeanReward     | 964        |
| _lr_multiplier  | 1          |
| _max_act        | 3.78082    |
| _max_adv        | 2.91       |
| _max_discrew    | 1.41       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0292905 |
| _mean_adv       | -9.95e-18  |
| _mean_discrew   | 0.767      |
| _mean_obs       | 0.0294     |
| _min_adv        | -5.95      |
| _min_discrew    | -0.00982   |
| _min_obs        | -1.46      |
| _std_act        | 0.42781    |
| _std_adv        | 1          |
| _std_discrew    | 0.111      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 101
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.744       |
| ExplainedVarOld | 0.68        |
| KL              | 0.00384726  |
| Phi_loss        | 58.1651     |
| PolicyEntropy   | 4.02646     |
| PolicyLoss      | -0.00538922 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0287      |
| _MeanReward     | 1.02e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86066     |
| _max_adv        | 2.81        |
| _max_discrew    | 1.52        |
| _max_obs        | 1.54        |
| _mean_act       | -0.0221026  |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 0.842       |
| _mean_obs       | 0.0291      |
| _min_adv        | -5.73       |
| _min_discrew    | 0.00131     |
| _min_obs        | -1.35       |
| _std_act        | 0.435271    |
| _std_adv        | 1           |
| _std_discrew    | 0.107       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 102
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.729       |
| ExplainedVarOld | 0.71        |
| KL              | 0.00309485  |
| Phi_loss        | 62.6103     |
| PolicyEntropy   | 4.01848     |
| PolicyLoss      | -0.00790591 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0303      |
| _MeanReward     | 980         |
| _lr_multiplier  | 1           |
| _max_act        | 4.61699     |
| _max_adv        | 2.87        |
| _max_discrew    | 1.45        |
| _max_obs        | 1.62        |
| _mean_act       | -0.0171779  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 0.773       |
| _mean_obs       | 0.0285      |
| _min_adv        | -10         |
| _min_discrew    | -1.36       |
| _min_obs        | -1.59       |
| _std_act        | 0.552295    |
| _std_adv        | 1           |
| _std_discrew    | 0.334       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 103
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.818      |
| ExplainedVarOld | 0.751      |
| KL              | 0.00303309 |
| Phi_loss        | 41.9583    |
| PolicyEntropy   | 4.01525    |
| PolicyLoss      | 0.0058922  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0608     |
| _MeanReward     | 1e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.71361    |
| _max_adv        | 5.8        |
| _max_discrew    | 1.54       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0331039 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 0.837      |
| _mean_obs       | 0.0281     |
| _min_adv        | -5.82      |
| _min_discrew    | -0.0437    |
| _min_obs        | -1.25      |
| _std_act        | 0.428447   |
| _std_adv        | 1          |
| _std_discrew    | 0.108      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 104
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.744      |
| ExplainedVarOld | 0.725      |
| KL              | 0.00414065 |
| Phi_loss        | 53.464     |
| PolicyEntropy   | 4.00954    |
| PolicyLoss      | -0.0075903 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0278     |
| _MeanReward     | 1.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.04567    |
| _max_adv        | 5.16       |
| _max_discrew    | 1.44       |
| _max_obs        | 1.44       |
| _mean_act       | -0.0297204 |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 0.813      |
| _mean_obs       | 0.0288     |
| _min_adv        | -6.75      |
| _min_discrew    | -0.00953   |
| _min_obs        | -1.41      |
| _std_act        | 0.432488   |
| _std_adv        | 1          |
| _std_discrew    | 0.103      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 105
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.724       |
| ExplainedVarOld | 0.713       |
| KL              | 0.00356531  |
| Phi_loss        | 59.956      |
| PolicyEntropy   | 4.01581     |
| PolicyLoss      | -0.00464108 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0285      |
| _MeanReward     | 1.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55905     |
| _max_adv        | 4.79        |
| _max_discrew    | 1.52        |
| _max_obs        | 1.5         |
| _mean_act       | -0.0252793  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.901       |
| _mean_obs       | 0.03        |
| _min_adv        | -5.87       |
| _min_discrew    | -0.00326    |
| _min_obs        | -1.36       |
| _std_act        | 0.442696    |
| _std_adv        | 1           |
| _std_discrew    | 0.123       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 106
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.772       |
| ExplainedVarOld | 0.749       |
| KL              | 0.00318913  |
| Phi_loss        | 57.9131     |
| PolicyEntropy   | 3.98868     |
| PolicyLoss      | -0.00677796 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0298      |
| _MeanReward     | 1.1e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.669       |
| _max_adv        | 4.44        |
| _max_discrew    | 1.68        |
| _max_obs        | 1.42        |
| _mean_act       | -0.030726   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 0.896       |
| _mean_obs       | 0.0286      |
| _min_adv        | -6.67       |
| _min_discrew    | -0.0169     |
| _min_obs        | -1.34       |
| _std_act        | 0.43702     |
| _std_adv        | 1           |
| _std_discrew    | 0.117       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 107
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.79       |
| ExplainedVarOld | 0.775      |
| KL              | 0.00325995 |
| Phi_loss        | 63.5125    |
| PolicyEntropy   | 3.981      |
| PolicyLoss      | -0.0056106 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0246     |
| _MeanReward     | 1.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.66948    |
| _max_adv        | 3.5        |
| _max_discrew    | 1.44       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0313015 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 0.889      |
| _mean_obs       | 0.0316     |
| _min_adv        | -5.71      |
| _min_discrew    | 0.00205    |
| _min_obs        | -1.35      |
| _std_act        | 0.4425     |
| _std_adv        | 1          |
| _std_discrew    | 0.142      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 108
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.717       |
| ExplainedVarOld | 0.658       |
| KL              | 0.00352257  |
| Phi_loss        | 60.0346     |
| PolicyEntropy   | 3.96707     |
| PolicyLoss      | -0.00388081 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0404      |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.84264     |
| _max_adv        | 5.02        |
| _max_discrew    | 1.51        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0248787  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 0.942       |
| _mean_obs       | 0.0303      |
| _min_adv        | -7.66       |
| _min_discrew    | -0.0179     |
| _min_obs        | -1.31       |
| _std_act        | 0.440825    |
| _std_adv        | 1           |
| _std_discrew    | 0.126       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 109
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.81       |
| ExplainedVarOld | 0.801      |
| KL              | 0.00315696 |
| Phi_loss        | 62.8809    |
| PolicyEntropy   | 3.9282     |
| PolicyLoss      | 0.00285634 |
| Steps           | 10000      |
| VarFuncLoss     | 0.024      |
| _MeanReward     | 1.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5755     |
| _max_adv        | 5.34       |
| _max_discrew    | 1.51       |
| _max_obs        | 1.4        |
| _mean_act       | -0.0295805 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.904      |
| _mean_obs       | 0.0311     |
| _min_adv        | -6.76      |
| _min_discrew    | -0.0314    |
| _min_obs        | -1.26      |
| _std_act        | 0.438242   |
| _std_adv        | 1          |
| _std_discrew    | 0.13       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 110
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.774      |
| ExplainedVarOld | 0.744      |
| KL              | 0.00332143 |
| Phi_loss        | 59.1098    |
| PolicyEntropy   | 3.92726    |
| PolicyLoss      | -0.0102308 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0299     |
| _MeanReward     | 947        |
| _lr_multiplier  | 1          |
| _max_act        | 4.58569    |
| _max_adv        | 3.3        |
| _max_discrew    | 1.57       |
| _max_obs        | 1.35       |
| _mean_act       | -0.019677  |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 0.734      |
| _mean_obs       | 0.0301     |
| _min_adv        | -11.9      |
| _min_discrew    | -1.37      |
| _min_obs        | -1.3       |
| _std_act        | 0.581991   |
| _std_adv        | 1          |
| _std_discrew    | 0.393      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 111
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.842       |
| ExplainedVarOld | 0.816       |
| KL              | 0.00396104  |
| Phi_loss        | 49.3389     |
| PolicyEntropy   | 3.91189     |
| PolicyLoss      | -0.00351382 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0622      |
| _MeanReward     | 1.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.81127     |
| _max_adv        | 5.32        |
| _max_discrew    | 1.54        |
| _max_obs        | 1.44        |
| _mean_act       | -0.0236155  |
| _mean_adv       | 0           |
| _mean_discrew   | 0.975       |
| _mean_obs       | 0.0306      |
| _min_adv        | -6.45       |
| _min_discrew    | -0.00604    |
| _min_obs        | -1.29       |
| _std_act        | 0.438147    |
| _std_adv        | 1           |
| _std_discrew    | 0.144       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 112
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.82        |
| ExplainedVarOld | 0.804       |
| KL              | 0.00278799  |
| Phi_loss        | 58.4279     |
| PolicyEntropy   | 3.89276     |
| PolicyLoss      | 0.000684682 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0286      |
| _MeanReward     | 1.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.44193     |
| _max_adv        | 3.66        |
| _max_discrew    | 1.78        |
| _max_obs        | 1.44        |
| _mean_act       | -0.0162502  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 0.828       |
| _mean_obs       | 0.032       |
| _min_adv        | -12.6       |
| _min_discrew    | -1.26       |
| _min_obs        | -1.39       |
| _std_act        | 0.542242    |
| _std_adv        | 1           |
| _std_discrew    | 0.392       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 113
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.78       |
| ExplainedVarOld | 0.727      |
| KL              | 0.00408263 |
| Phi_loss        | 57.3801    |
| PolicyEntropy   | 3.87959    |
| PolicyLoss      | -0.0080577 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0869     |
| _MeanReward     | 1.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74529    |
| _max_adv        | 6.22       |
| _max_discrew    | 1.65       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0225329 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.02       |
| _mean_obs       | 0.0318     |
| _min_adv        | -9.13      |
| _min_discrew    | -0.0661    |
| _min_obs        | -1.25      |
| _std_act        | 0.446951   |
| _std_adv        | 1          |
| _std_discrew    | 0.155      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 114
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.814       |
| ExplainedVarOld | 0.808       |
| KL              | 0.00408823  |
| Phi_loss        | 65.1984     |
| PolicyEntropy   | 3.85031     |
| PolicyLoss      | 0.000272244 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0298      |
| _MeanReward     | 1.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02436     |
| _max_adv        | 6.28        |
| _max_discrew    | 1.88        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0198084  |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 1.11        |
| _mean_obs       | 0.0318      |
| _min_adv        | -8.8        |
| _min_discrew    | 0.000477    |
| _min_obs        | -1.42       |
| _std_act        | 0.446851    |
| _std_adv        | 1           |
| _std_discrew    | 0.175       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 115
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.797       |
| KL              | 0.00353869  |
| Phi_loss        | 61.4668     |
| PolicyEntropy   | 3.82662     |
| PolicyLoss      | -0.00584281 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0275      |
| _MeanReward     | 1.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.7287      |
| _max_adv        | 3.4         |
| _max_discrew    | 1.79        |
| _max_obs        | 1.3         |
| _mean_act       | -0.013408   |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 0.913       |
| _mean_obs       | 0.0313      |
| _min_adv        | -11.4       |
| _min_discrew    | -1.39       |
| _min_obs        | -1.4        |
| _std_act        | 0.578102    |
| _std_adv        | 1           |
| _std_discrew    | 0.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 116
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.82       |
| ExplainedVarOld | 0.783      |
| KL              | 0.00662327 |
| Phi_loss        | 50.0864    |
| PolicyEntropy   | 3.79352    |
| PolicyLoss      | 0.0117739  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0888     |
| _MeanReward     | 1.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.9208     |
| _max_adv        | 5.48       |
| _max_discrew    | 1.78       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0190478 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 0.94       |
| _mean_obs       | 0.0312     |
| _min_adv        | -13.2      |
| _min_discrew    | -1.35      |
| _min_obs        | -1.2       |
| _std_act        | 0.582846   |
| _std_adv        | 1          |
| _std_discrew    | 0.478      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 117
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.833       |
| ExplainedVarOld | 0.827       |
| KL              | 0.00228241  |
| Phi_loss        | 60.9287     |
| PolicyEntropy   | 3.79572     |
| PolicyLoss      | -0.00322921 |
| Steps           | 10000       |
| VarFuncLoss     | 0.08        |
| _MeanReward     | 1.41e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.57822     |
| _max_adv        | 11.3        |
| _max_discrew    | 1.75        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0170274  |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 1.16        |
| _mean_obs       | 0.0316      |
| _min_adv        | -4.15       |
| _min_discrew    | 0.003       |
| _min_obs        | -1.24       |
| _std_act        | 0.444725    |
| _std_adv        | 1           |
| _std_discrew    | 0.131       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 118
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00142792 |
| Phi_loss        | 69.4645    |
| PolicyEntropy   | 3.77687    |
| PolicyLoss      | -0.0132799 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0131     |
| _MeanReward     | 1.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57363    |
| _max_adv        | 8.81       |
| _max_discrew    | 1.78       |
| _max_obs        | 1.48       |
| _mean_act       | -0.0200432 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 1.16       |
| _mean_obs       | 0.0321     |
| _min_adv        | -7.48      |
| _min_discrew    | -0.00122   |
| _min_obs        | -1.49      |
| _std_act        | 0.442703   |
| _std_adv        | 1          |
| _std_discrew    | 0.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 119
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.858      |
| ExplainedVarOld | 0.838      |
| KL              | 0.00354631 |
| Phi_loss        | 63.7211    |
| PolicyEntropy   | 3.74753    |
| PolicyLoss      | -0.0182278 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0214     |
| _MeanReward     | 1.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.27763    |
| _max_adv        | 7.84       |
| _max_discrew    | 1.77       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0270171 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.09       |
| _mean_obs       | 0.0315     |
| _min_adv        | -6.13      |
| _min_discrew    | 0.00137    |
| _min_obs        | -1.26      |
| _std_act        | 0.457202   |
| _std_adv        | 1          |
| _std_discrew    | 0.133      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 120
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.758      |
| ExplainedVarOld | 0.739      |
| KL              | 0.00344738 |
| Phi_loss        | 78.1302    |
| PolicyEntropy   | 3.73517    |
| PolicyLoss      | 0.00150921 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0329     |
| _MeanReward     | 1.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.58669    |
| _max_adv        | 2.91       |
| _max_discrew    | 1.87       |
| _max_obs        | 1.45       |
| _mean_act       | -0.012548  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.968      |
| _mean_obs       | 0.032      |
| _min_adv        | -13.8      |
| _min_discrew    | -1.4       |
| _min_obs        | -1.22      |
| _std_act        | 0.619021   |
| _std_adv        | 1          |
| _std_discrew    | 0.552      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 121
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.833      |
| ExplainedVarOld | 0.81       |
| KL              | 0.00464782 |
| Phi_loss        | 57.5345    |
| PolicyEntropy   | 3.73606    |
| PolicyLoss      | -0.0231686 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0924     |
| _MeanReward     | 1.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.53684    |
| _max_adv        | 5.1        |
| _max_discrew    | 1.88       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0148749 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.04       |
| _mean_obs       | 0.0329     |
| _min_adv        | -14.1      |
| _min_discrew    | -1.46      |
| _min_obs        | -1.46      |
| _std_act        | 0.597881   |
| _std_adv        | 1          |
| _std_discrew    | 0.548      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 122
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.861      |
| ExplainedVarOld | 0.85       |
| KL              | 0.00336738 |
| Phi_loss        | 64.9739    |
| PolicyEntropy   | 3.72081    |
| PolicyLoss      | 0.00273209 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0778     |
| _MeanReward     | 1.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68289    |
| _max_adv        | 6.86       |
| _max_discrew    | 1.91       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0311548 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0349     |
| _min_adv        | -7.07      |
| _min_discrew    | -0.00699   |
| _min_obs        | -1.55      |
| _std_act        | 0.459713   |
| _std_adv        | 1          |
| _std_discrew    | 0.226      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 123
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.756        |
| ExplainedVarOld | 0.731        |
| KL              | 0.00357844   |
| Phi_loss        | 69.5573      |
| PolicyEntropy   | 3.69755      |
| PolicyLoss      | -0.000153346 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0553       |
| _MeanReward     | 1.5e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 2.71909      |
| _max_adv        | 9.99         |
| _max_discrew    | 1.94         |
| _max_obs        | 1.37         |
| _mean_act       | -0.0225272   |
| _mean_adv       | 8.53e-18     |
| _mean_discrew   | 1.22         |
| _mean_obs       | 0.035        |
| _min_adv        | -7.94        |
| _min_discrew    | -0.00031     |
| _min_obs        | -1.32        |
| _std_act        | 0.459459     |
| _std_adv        | 1            |
| _std_discrew    | 0.193        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 124
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.812      |
| ExplainedVarOld | 0.791      |
| KL              | 0.00427389 |
| Phi_loss        | 63.9885    |
| PolicyEntropy   | 3.67989    |
| PolicyLoss      | 0.00415041 |
| Steps           | 10000      |
| VarFuncLoss     | 0.037      |
| _MeanReward     | 1.39e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10491    |
| _max_adv        | 5.05       |
| _max_discrew    | 1.86       |
| _max_obs        | 1.38       |
| _mean_act       | -0.0300266 |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 1.12       |
| _mean_obs       | 0.0332     |
| _min_adv        | -7.42      |
| _min_discrew    | -0.0773    |
| _min_obs        | -1.3       |
| _std_act        | 0.455649   |
| _std_adv        | 1          |
| _std_discrew    | 0.213      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 125
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.806      |
| ExplainedVarOld | 0.769      |
| KL              | 0.00360593 |
| Phi_loss        | 72.9712    |
| PolicyEntropy   | 3.67096    |
| PolicyLoss      | -0.0120091 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0428     |
| _MeanReward     | 1.58e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.42768    |
| _max_adv        | 2.51       |
| _max_discrew    | 2.03       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0154829 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.3        |
| _mean_obs       | 0.0361     |
| _min_adv        | -11.5      |
| _min_discrew    | -0.935     |
| _min_obs        | -1.22      |
| _std_act        | 0.505768   |
| _std_adv        | 1          |
| _std_discrew    | 0.306      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 126
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.815      |
| ExplainedVarOld | 0.803      |
| KL              | 0.00785952 |
| Phi_loss        | 79.3021    |
| PolicyEntropy   | 3.66769    |
| PolicyLoss      | -0.0181521 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0617     |
| _MeanReward     | 1.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88945    |
| _max_adv        | 6.68       |
| _max_discrew    | 1.86       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0279962 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.25       |
| _mean_obs       | 0.0349     |
| _min_adv        | -7.05      |
| _min_discrew    | -0.005     |
| _min_obs        | -1.59      |
| _std_act        | 0.466732   |
| _std_adv        | 1          |
| _std_discrew    | 0.176      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 127
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.787       |
| ExplainedVarOld | 0.766       |
| KL              | 0.00183906  |
| Phi_loss        | 75.8541     |
| PolicyEntropy   | 3.66315     |
| PolicyLoss      | -0.00236657 |
| Steps           | 10000       |
| VarFuncLoss     | 0.038       |
| _MeanReward     | 1.29e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.72236     |
| _max_adv        | 3.83        |
| _max_discrew    | 1.94        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0211773  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 1.04        |
| _mean_obs       | 0.033       |
| _min_adv        | -13.4       |
| _min_discrew    | -1.51       |
| _min_obs        | -1.32       |
| _std_act        | 0.621992    |
| _std_adv        | 1           |
| _std_discrew    | 0.672       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 128
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.865       |
| ExplainedVarOld | 0.853       |
| KL              | 0.00239757  |
| Phi_loss        | 60.0728     |
| PolicyEntropy   | 3.65417     |
| PolicyLoss      | -0.00503712 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0908      |
| _MeanReward     | 1.56e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64944     |
| _max_adv        | 3.78        |
| _max_discrew    | 1.97        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0265286  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 1.27        |
| _mean_obs       | 0.0355      |
| _min_adv        | -7.26       |
| _min_discrew    | 0.00292     |
| _min_obs        | -1.47       |
| _std_act        | 0.464431    |
| _std_adv        | 1           |
| _std_discrew    | 0.218       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 129
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.847       |
| ExplainedVarOld | 0.816       |
| KL              | 0.00202859  |
| Phi_loss        | 70.9346     |
| PolicyEntropy   | 3.64759     |
| PolicyLoss      | -0.00816719 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0346      |
| _MeanReward     | 1.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.02713     |
| _max_adv        | 5.77        |
| _max_discrew    | 1.9         |
| _max_obs        | 1.44        |
| _mean_act       | -0.035963   |
| _mean_adv       | -6.39e-18   |
| _mean_discrew   | 1.24        |
| _mean_obs       | 0.0343      |
| _min_adv        | -7.19       |
| _min_discrew    | 0.00147     |
| _min_obs        | -1.35       |
| _std_act        | 0.474027    |
| _std_adv        | 1           |
| _std_discrew    | 0.176       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 130
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.771      |
| ExplainedVarOld | 0.722      |
| KL              | 0.00163002 |
| Phi_loss        | 71.3952    |
| PolicyEntropy   | 3.62892    |
| PolicyLoss      | 0.00998607 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0403     |
| _MeanReward     | 1.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61491    |
| _max_adv        | 5.2        |
| _max_discrew    | 2.08       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0344136 |
| _mean_adv       | -2.42e-17  |
| _mean_discrew   | 1.26       |
| _mean_obs       | 0.0344     |
| _min_adv        | -7.11      |
| _min_discrew    | -0.0167    |
| _min_obs        | -1.37      |
| _std_act        | 0.466997   |
| _std_adv        | 1          |
| _std_discrew    | 0.179      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 131
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.819       |
| ExplainedVarOld | 0.792       |
| KL              | 0.00126677  |
| Phi_loss        | 75.3398     |
| PolicyEntropy   | 3.61581     |
| PolicyLoss      | 0.000620243 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0323      |
| _MeanReward     | 1.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7903      |
| _max_adv        | 5.33        |
| _max_discrew    | 1.93        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0266093  |
| _mean_adv       | -6.82e-17   |
| _mean_discrew   | 1.34        |
| _mean_obs       | 0.0356      |
| _min_adv        | -7.84       |
| _min_discrew    | -0.00689    |
| _min_obs        | -1.25       |
| _std_act        | 0.473487    |
| _std_adv        | 1           |
| _std_discrew    | 0.193       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 132
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.869      |
| ExplainedVarOld | 0.86       |
| KL              | 0.00308143 |
| Phi_loss        | 82.4146    |
| PolicyEntropy   | 3.59285    |
| PolicyLoss      | -0.0104252 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0267     |
| _MeanReward     | 1.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.38739    |
| _max_adv        | 2.96       |
| _max_discrew    | 2.26       |
| _max_obs        | 1.45       |
| _mean_act       | -0.02265   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 1.32       |
| _mean_obs       | 0.0356     |
| _min_adv        | -9.13      |
| _min_discrew    | -0.946     |
| _min_obs        | -1.35      |
| _std_act        | 0.509536   |
| _std_adv        | 1          |
| _std_discrew    | 0.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 133
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.794      |
| ExplainedVarOld | 0.719      |
| KL              | 0.00421391 |
| Phi_loss        | 60.5032    |
| PolicyEntropy   | 3.59185    |
| PolicyLoss      | -0.0126451 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0761     |
| _MeanReward     | 1.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56356    |
| _max_adv        | 4.08       |
| _max_discrew    | 2.12       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0293073 |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 1.34       |
| _mean_obs       | 0.0352     |
| _min_adv        | -7.25      |
| _min_discrew    | 0.00172    |
| _min_obs        | -1.26      |
| _std_act        | 0.461533   |
| _std_adv        | 1          |
| _std_discrew    | 0.243      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 134
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.797      |
| ExplainedVarOld | 0.8        |
| KL              | 0.00315928 |
| Phi_loss        | 90.89      |
| PolicyEntropy   | 3.57035    |
| PolicyLoss      | -0.0127657 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0494     |
| _MeanReward     | 1.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74185    |
| _max_adv        | 4.25       |
| _max_discrew    | 2.21       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0337351 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.34       |
| _mean_obs       | 0.0371     |
| _min_adv        | -6.81      |
| _min_discrew    | -0.0023    |
| _min_obs        | -1.23      |
| _std_act        | 0.473144   |
| _std_adv        | 1          |
| _std_discrew    | 0.295      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 135
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.816      |
| ExplainedVarOld | 0.803      |
| KL              | 0.0035625  |
| Phi_loss        | 78.5933    |
| PolicyEntropy   | 3.5535     |
| PolicyLoss      | -0.0120899 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0542     |
| _MeanReward     | 1.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.40445    |
| _max_adv        | 3.68       |
| _max_discrew    | 2.09       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0323762 |
| _mean_adv       | 0          |
| _mean_discrew   | 1.28       |
| _mean_obs       | 0.0342     |
| _min_adv        | -11.4      |
| _min_discrew    | -1.21      |
| _min_obs        | -1.36      |
| _std_act        | 0.547693   |
| _std_adv        | 1          |
| _std_discrew    | 0.424      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 136
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.772       |
| ExplainedVarOld | 0.761       |
| KL              | 0.00401132  |
| Phi_loss        | 75.8224     |
| PolicyEntropy   | 3.55084     |
| PolicyLoss      | -0.00771241 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0966      |
| _MeanReward     | 1.74e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83699     |
| _max_adv        | 5.24        |
| _max_discrew    | 2.2         |
| _max_obs        | 1.42        |
| _mean_act       | -0.0339365  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 1.43        |
| _mean_obs       | 0.0353      |
| _min_adv        | -8.69       |
| _min_discrew    | -0.0396     |
| _min_obs        | -1.31       |
| _std_act        | 0.479696    |
| _std_adv        | 1           |
| _std_discrew    | 0.271       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 137
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.861      |
| ExplainedVarOld | 0.849      |
| KL              | 0.00450131 |
| Phi_loss        | 82.242     |
| PolicyEntropy   | 3.53621    |
| PolicyLoss      | -0.0115564 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0386     |
| _MeanReward     | 976        |
| _lr_multiplier  | 1          |
| _max_act        | 4.70916    |
| _max_adv        | 2.5        |
| _max_discrew    | 2.31       |
| _max_obs        | 1.46       |
| _mean_act       | -0.0275473 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 0.764      |
| _mean_obs       | 0.0298     |
| _min_adv        | -9.83      |
| _min_discrew    | -1.39      |
| _min_obs        | -1.27      |
| _std_act        | 0.832941   |
| _std_adv        | 1          |
| _std_discrew    | 1.37       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 138
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.888      |
| ExplainedVarOld | 0.875      |
| KL              | 0.00676656 |
| Phi_loss        | 65.0807    |
| PolicyEntropy   | 3.5212     |
| PolicyLoss      | 0.00596807 |
| Steps           | 10000      |
| VarFuncLoss     | 0.156      |
| _MeanReward     | 1.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.12207    |
| _max_adv        | 8.04       |
| _max_discrew    | 2.31       |
| _max_obs        | 1.42       |
| _mean_act       | -0.0259236 |
| _mean_adv       | 5.12e-17   |
| _mean_discrew   | 1.47       |
| _mean_obs       | 0.0377     |
| _min_adv        | -7.97      |
| _min_discrew    | -0.528     |
| _min_obs        | -1.36      |
| _std_act        | 0.504398   |
| _std_adv        | 1          |
| _std_discrew    | 0.359      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 139
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.841      |
| ExplainedVarOld | 0.816      |
| KL              | 0.00207027 |
| Phi_loss        | 78.5291    |
| PolicyEntropy   | 3.50928    |
| PolicyLoss      | -0.0213916 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0596     |
| _MeanReward     | 1.67e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.48036    |
| _max_adv        | 6.02       |
| _max_discrew    | 2.29       |
| _max_obs        | 1.45       |
| _mean_act       | -0.0205204 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.33       |
| _mean_obs       | 0.0361     |
| _min_adv        | -16.1      |
| _min_discrew    | -1.38      |
| _min_obs        | -1.29      |
| _std_act        | 0.617697   |
| _std_adv        | 1          |
| _std_discrew    | 0.745      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 140
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.852      |
| ExplainedVarOld | 0.849      |
| KL              | 0.00188981 |
| Phi_loss        | 82.5295    |
| PolicyEntropy   | 3.49164    |
| PolicyLoss      | 0.00219115 |
| Steps           | 10000      |
| VarFuncLoss     | 0.11       |
| _MeanReward     | 1.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6782     |
| _max_adv        | 6.59       |
| _max_discrew    | 2.39       |
| _max_obs        | 1.29       |
| _mean_act       | -0.0294746 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 1.52       |
| _mean_obs       | 0.0376     |
| _min_adv        | -6.88      |
| _min_discrew    | 0.00659    |
| _min_obs        | -1.27      |
| _std_act        | 0.486263   |
| _std_adv        | 1          |
| _std_discrew    | 0.294      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 141
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.817      |
| ExplainedVarOld | 0.8        |
| KL              | 0.00262357 |
| Phi_loss        | 85.3666    |
| PolicyEntropy   | 3.50696    |
| PolicyLoss      | -0.0310652 |
| Steps           | 10000      |
| VarFuncLoss     | 0.054      |
| _MeanReward     | 1.63e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.37793    |
| _max_adv        | 3.48       |
| _max_discrew    | 2.45       |
| _max_obs        | 1.39       |
| _mean_act       | -0.0302013 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 1.31       |
| _mean_obs       | 0.0354     |
| _min_adv        | -15.2      |
| _min_discrew    | -1.39      |
| _min_obs        | -1.33      |
| _std_act        | 0.622244   |
| _std_adv        | 1          |
| _std_discrew    | 0.754      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 142
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.846        |
| ExplainedVarOld | 0.839        |
| KL              | 0.00231732   |
| Phi_loss        | 97.4361      |
| PolicyEntropy   | 3.48625      |
| PolicyLoss      | -0.000109543 |
| Steps           | 10000        |
| VarFuncLoss     | 0.117        |
| _MeanReward     | 1.81e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 4.36285      |
| _max_adv        | 5.74         |
| _max_discrew    | 2.34         |
| _max_obs        | 1.43         |
| _mean_act       | -0.0311171   |
| _mean_adv       | 5.68e-18     |
| _mean_discrew   | 1.47         |
| _mean_obs       | 0.038        |
| _min_adv        | -9.6         |
| _min_discrew    | -0.889       |
| _min_obs        | -1.28        |
| _std_act        | 0.530781     |
| _std_adv        | 1            |
| _std_discrew    | 0.432        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 143
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.817      |
| ExplainedVarOld | 0.8        |
| KL              | 0.00150773 |
| Phi_loss        | 83.8158    |
| PolicyEntropy   | 3.46777    |
| PolicyLoss      | -0.0033848 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0791     |
| _MeanReward     | 1.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.5891     |
| _max_adv        | 9.49       |
| _max_discrew    | 2.29       |
| _max_obs        | 1.66       |
| _mean_act       | -0.0327339 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.37       |
| _mean_obs       | 0.0352     |
| _min_adv        | -11.2      |
| _min_discrew    | -1.2       |
| _min_obs        | -1.28      |
| _std_act        | 0.585033   |
| _std_adv        | 1          |
| _std_discrew    | 0.608      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 144
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.798       |
| ExplainedVarOld | 0.781       |
| KL              | 0.00148708  |
| Phi_loss        | 81.7581     |
| PolicyEntropy   | 3.45559     |
| PolicyLoss      | -0.00168884 |
| Steps           | 10000       |
| VarFuncLoss     | 0.124       |
| _MeanReward     | 1.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.1897      |
| _max_adv        | 4.6         |
| _max_discrew    | 2.37        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0247412  |
| _mean_adv       | 2.42e-17    |
| _mean_discrew   | 1.4         |
| _mean_obs       | 0.0367      |
| _min_adv        | -16.6       |
| _min_discrew    | -1.35       |
| _min_obs        | -1.52       |
| _std_act        | 0.641654    |
| _std_adv        | 1           |
| _std_discrew    | 0.902       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 145
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.868      |
| KL              | 0.0042041  |
| Phi_loss        | 83.4372    |
| PolicyEntropy   | 3.45434    |
| PolicyLoss      | -0.0122939 |
| Steps           | 10000      |
| VarFuncLoss     | 0.114      |
| _MeanReward     | 1.45e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.38987    |
| _max_adv        | 5.53       |
| _max_discrew    | 2.58       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0284501 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 1.13       |
| _mean_obs       | 0.0332     |
| _min_adv        | -12.6      |
| _min_discrew    | -1.39      |
| _min_obs        | -1.32      |
| _std_act        | 0.743384   |
| _std_adv        | 1          |
| _std_discrew    | 1.3        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 146
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.856       |
| ExplainedVarOld | 0.84        |
| KL              | 0.00453751  |
| Phi_loss        | 98.1061     |
| PolicyEntropy   | 3.42973     |
| PolicyLoss      | -0.00424293 |
| Steps           | 10000       |
| VarFuncLoss     | 0.187       |
| _MeanReward     | 1.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 4.79002     |
| _max_adv        | 6.63        |
| _max_discrew    | 2.44        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0329587  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.26        |
| _mean_obs       | 0.0355      |
| _min_adv        | -11.1       |
| _min_discrew    | -1.39       |
| _min_obs        | -1.27       |
| _std_act        | 0.69093     |
| _std_adv        | 1           |
| _std_discrew    | 1.04        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 147
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.812       |
| ExplainedVarOld | 0.805       |
| KL              | 0.00318703  |
| Phi_loss        | 87.431      |
| PolicyEntropy   | 3.41673     |
| PolicyLoss      | -0.00393606 |
| Steps           | 10000       |
| VarFuncLoss     | 0.195       |
| _MeanReward     | 1.74e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.30452     |
| _max_adv        | 5.01        |
| _max_discrew    | 2.39        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0257415  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 1.4         |
| _mean_obs       | 0.0362      |
| _min_adv        | -16.1       |
| _min_discrew    | -1.38       |
| _min_obs        | -1.26       |
| _std_act        | 0.656303    |
| _std_adv        | 1           |
| _std_discrew    | 0.929       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 148
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.857       |
| ExplainedVarOld | 0.849       |
| KL              | 0.00290022  |
| Phi_loss        | 102.325     |
| PolicyEntropy   | 3.39812     |
| PolicyLoss      | -0.00464218 |
| Steps           | 10000       |
| VarFuncLoss     | 0.133       |
| _MeanReward     | 1.69e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.32908     |
| _max_adv        | 5.72        |
| _max_discrew    | 2.44        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0310881  |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 1.36        |
| _mean_obs       | 0.0346      |
| _min_adv        | -16.3       |
| _min_discrew    | -1.35       |
| _min_obs        | -1.17       |
| _std_act        | 0.6533      |
| _std_adv        | 1           |
| _std_discrew    | 0.956       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 149
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.922       |
| ExplainedVarOld | 0.917       |
| KL              | 0.00306774  |
| Phi_loss        | 93.7932     |
| PolicyEntropy   | 3.36763     |
| PolicyLoss      | -0.00646759 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0748      |
| _MeanReward     | 2e+03       |
| _lr_multiplier  | 1           |
| _max_act        | 4.30396     |
| _max_adv        | 10.5        |
| _max_discrew    | 2.53        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0299219  |
| _mean_adv       | 3.84e-17    |
| _mean_discrew   | 1.62        |
| _mean_obs       | 0.0388      |
| _min_adv        | -11.8       |
| _min_discrew    | -1.01       |
| _min_obs        | -1.24       |
| _std_act        | 0.545261    |
| _std_adv        | 1           |
| _std_discrew    | 0.525       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 150
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.852      |
| ExplainedVarOld | 0.828      |
| KL              | 0.00500738 |
| Phi_loss        | 67.9948    |
| PolicyEntropy   | 3.38011    |
| PolicyLoss      | -0.0211644 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0787     |
| _MeanReward     | 1.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.2045     |
| _max_adv        | 8.41       |
| _max_discrew    | 2.49       |
| _max_obs        | 1.38       |
| _mean_act       | -0.030709  |
| _mean_adv       | 0          |
| _mean_discrew   | 1.45       |
| _mean_obs       | 0.0362     |
| _min_adv        | -15.4      |
| _min_discrew    | -1.35      |
| _min_obs        | -1.21      |
| _std_act        | 0.628965   |
| _std_adv        | 1          |
| _std_discrew    | 0.838      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 151
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.85       |
| ExplainedVarOld | 0.828      |
| KL              | 0.00534448 |
| Phi_loss        | 79.9837    |
| PolicyEntropy   | 3.355      |
| PolicyLoss      | -0.0121273 |
| Steps           | 10000      |
| VarFuncLoss     | 0.126      |
| _MeanReward     | 2.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64942    |
| _max_adv        | 12.9       |
| _max_discrew    | 2.52       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0250629 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 1.73       |
| _mean_obs       | 0.0404     |
| _min_adv        | -8.31      |
| _min_discrew    | -0.0545    |
| _min_obs        | -1.29      |
| _std_act        | 0.506416   |
| _std_adv        | 1          |
| _std_discrew    | 0.338      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 152
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.87        |
| ExplainedVarOld | 0.869       |
| KL              | 0.00369746  |
| Phi_loss        | 93.5617     |
| PolicyEntropy   | 3.33441     |
| PolicyLoss      | -0.00184698 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0451      |
| _MeanReward     | 2.12e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.07303     |
| _max_adv        | 10.9        |
| _max_discrew    | 2.53        |
| _max_obs        | 1.31        |
| _mean_act       | -0.0269553  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.75        |
| _mean_obs       | 0.0402      |
| _min_adv        | -8.74       |
| _min_discrew    | 0.000765    |
| _min_obs        | -1.32       |
| _std_act        | 0.50383     |
| _std_adv        | 1           |
| _std_discrew    | 0.333       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 153
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.875       |
| ExplainedVarOld | 0.862       |
| KL              | 0.00305563  |
| Phi_loss        | 88.4346     |
| PolicyEntropy   | 3.31833     |
| PolicyLoss      | -0.00689427 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0418      |
| _MeanReward     | 1.98e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.23566     |
| _max_adv        | 4.19        |
| _max_discrew    | 2.63        |
| _max_obs        | 1.47        |
| _mean_act       | -0.0196194  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.6         |
| _mean_obs       | 0.0389      |
| _min_adv        | -14.7       |
| _min_discrew    | -1.35       |
| _min_obs        | -1.21       |
| _std_act        | 0.611566    |
| _std_adv        | 1           |
| _std_discrew    | 0.811       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 154
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.845      |
| ExplainedVarOld | 0.831      |
| KL              | 0.00515717 |
| Phi_loss        | 84.925     |
| PolicyEntropy   | 3.30012    |
| PolicyLoss      | -0.0254513 |
| Steps           | 10000      |
| VarFuncLoss     | 0.126      |
| _MeanReward     | 2.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71572    |
| _max_adv        | 8.02       |
| _max_discrew    | 2.66       |
| _max_obs        | 1.36       |
| _mean_act       | -0.0174531 |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 1.86       |
| _mean_obs       | 0.0419     |
| _min_adv        | -7.04      |
| _min_discrew    | -0.000665  |
| _min_obs        | -1.45      |
| _std_act        | 0.507092   |
| _std_adv        | 1          |
| _std_discrew    | 0.427      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 155
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.917      |
| ExplainedVarOld | 0.894      |
| KL              | 0.00338816 |
| Phi_loss        | 95.0866    |
| PolicyEntropy   | 3.28773    |
| PolicyLoss      | -0.0250414 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0374     |
| _MeanReward     | 2.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.91425    |
| _max_adv        | 4.88       |
| _max_discrew    | 2.72       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0158958 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.86       |
| _mean_obs       | 0.0416     |
| _min_adv        | -3.8       |
| _min_discrew    | 0.00506    |
| _min_obs        | -1.25      |
| _std_act        | 0.512972   |
| _std_adv        | 1          |
| _std_discrew    | 0.355      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 156
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.935       |
| ExplainedVarOld | 0.927       |
| KL              | 0.00417969  |
| Phi_loss        | 106.023     |
| PolicyEntropy   | 3.24487     |
| PolicyLoss      | -0.00748934 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0232      |
| _MeanReward     | 2.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.08354     |
| _max_adv        | 5.48        |
| _max_discrew    | 2.79        |
| _max_obs        | 1.37        |
| _mean_act       | -0.0171419  |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 1.81        |
| _mean_obs       | 0.0437      |
| _min_adv        | -11.3       |
| _min_discrew    | -0.657      |
| _min_obs        | -1.26       |
| _std_act        | 0.542796    |
| _std_adv        | 1           |
| _std_discrew    | 0.542       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 157
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.853       |
| ExplainedVarOld | 0.846       |
| KL              | 0.00329309  |
| Phi_loss        | 105.757     |
| PolicyEntropy   | 3.22339     |
| PolicyLoss      | -0.00773282 |
| Steps           | 10000       |
| VarFuncLoss     | 0.08        |
| _MeanReward     | 2.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.95599     |
| _max_adv        | 12.7        |
| _max_discrew    | 2.81        |
| _max_obs        | 1.44        |
| _mean_act       | -0.0129946  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 1.94        |
| _mean_obs       | 0.0434      |
| _min_adv        | -9.26       |
| _min_discrew    | 0.00445     |
| _min_obs        | -1.25       |
| _std_act        | 0.525691    |
| _std_adv        | 1           |
| _std_discrew    | 0.409       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 158
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.887       |
| KL              | 0.0067155   |
| Phi_loss        | 88.6593     |
| PolicyEntropy   | 3.22492     |
| PolicyLoss      | -0.00701268 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0411      |
| _MeanReward     | 2.09e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.03986     |
| _max_adv        | 4.6         |
| _max_discrew    | 2.93        |
| _max_obs        | 1.42        |
| _mean_act       | -0.0186855  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.68        |
| _mean_obs       | 0.0416      |
| _min_adv        | -14.2       |
| _min_discrew    | -1.22       |
| _min_obs        | -1.31       |
| _std_act        | 0.624235    |
| _std_adv        | 1           |
| _std_discrew    | 0.991       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 159
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.824      |
| ExplainedVarOld | 0.78       |
| KL              | 0.00758391 |
| Phi_loss        | 137.659    |
| PolicyEntropy   | 3.2578     |
| PolicyLoss      | -0.08908   |
| Steps           | 10000      |
| VarFuncLoss     | 0.176      |
| _MeanReward     | 2.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.31071    |
| _max_adv        | 5.16       |
| _max_discrew    | 2.96       |
| _max_obs        | 1.38       |
| _mean_act       | -0.014199  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 1.73       |
| _mean_obs       | 0.0413     |
| _min_adv        | -16        |
| _min_discrew    | -1.34      |
| _min_obs        | -1.28      |
| _std_act        | 0.665799   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 160
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.884      |
| ExplainedVarOld | 0.877      |
| KL              | 0.00111031 |
| Phi_loss        | 105.738    |
| PolicyEntropy   | 3.25017    |
| PolicyLoss      | 0.00189956 |
| Steps           | 10000      |
| VarFuncLoss     | 0.137      |
| _MeanReward     | 2.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60034    |
| _max_adv        | 4.83       |
| _max_discrew    | 2.86       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0114072 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 1.98       |
| _mean_obs       | 0.0433     |
| _min_adv        | -6.79      |
| _min_discrew    | 0.00145    |
| _min_obs        | -1.28      |
| _std_act        | 0.532129   |
| _std_adv        | 1          |
| _std_discrew    | 0.463      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 161
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.939      |
| KL              | 0.00189167 |
| Phi_loss        | 100.602    |
| PolicyEntropy   | 3.24224    |
| PolicyLoss      | -0.0121227 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0225     |
| _MeanReward     | 2.4e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.7584     |
| _max_adv        | 9.64       |
| _max_discrew    | 2.76       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0178712 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 1.97       |
| _mean_obs       | 0.0436     |
| _min_adv        | -8.27      |
| _min_discrew    | 0.00557    |
| _min_obs        | -1.27      |
| _std_act        | 0.533547   |
| _std_adv        | 1          |
| _std_discrew    | 0.427      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 162
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.877       |
| ExplainedVarOld | 0.867       |
| KL              | 0.00197596  |
| Phi_loss        | 104.587     |
| PolicyEntropy   | 3.21896     |
| PolicyLoss      | -0.00904496 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0527      |
| _MeanReward     | 2.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66602     |
| _max_adv        | 7.9         |
| _max_discrew    | 2.98        |
| _max_obs        | 1.28        |
| _mean_act       | -0.0148108  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.02        |
| _mean_obs       | 0.0443      |
| _min_adv        | -5.34       |
| _min_discrew    | 0.00878     |
| _min_obs        | -1.28       |
| _std_act        | 0.538682    |
| _std_adv        | 1           |
| _std_discrew    | 0.455       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 163
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.95        |
| ExplainedVarOld | 0.949       |
| KL              | 0.00235655  |
| Phi_loss        | 125.043     |
| PolicyEntropy   | 3.18654     |
| PolicyLoss      | -0.00769267 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0233      |
| _MeanReward     | 2.22e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 4.09433     |
| _max_adv        | 2.98        |
| _max_discrew    | 2.85        |
| _max_obs        | 1.29        |
| _mean_act       | -0.0190868  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 1.78        |
| _mean_obs       | 0.0414      |
| _min_adv        | -14.3       |
| _min_discrew    | -1.25       |
| _min_obs        | -1.26       |
| _std_act        | 0.641752    |
| _std_adv        | 1           |
| _std_discrew    | 1.07        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 164
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.897       |
| ExplainedVarOld | 0.879       |
| KL              | 0.00279998  |
| Phi_loss        | 74.9019     |
| PolicyEntropy   | 3.1732      |
| PolicyLoss      | -0.00622948 |
| Steps           | 10000       |
| VarFuncLoss     | 0.111       |
| _MeanReward     | 2.16e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.97273     |
| _max_adv        | 9.5         |
| _max_discrew    | 2.94        |
| _max_obs        | 1.34        |
| _mean_act       | -0.0256484  |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 1.73        |
| _mean_obs       | 0.0402      |
| _min_adv        | -14.3       |
| _min_discrew    | -1.24       |
| _min_obs        | -1.35       |
| _std_act        | 0.638076    |
| _std_adv        | 1           |
| _std_discrew    | 1.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 165
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.863      |
| ExplainedVarOld | 0.845      |
| KL              | 0.00742423 |
| Phi_loss        | 91.5637    |
| PolicyEntropy   | 3.18787    |
| PolicyLoss      | -0.0372544 |
| Steps           | 10000      |
| VarFuncLoss     | 0.14       |
| _MeanReward     | 1.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.10596    |
| _max_adv        | 8.15       |
| _max_discrew    | 3.01       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0264888 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.5        |
| _mean_obs       | 0.0385     |
| _min_adv        | -13        |
| _min_discrew    | -1.24      |
| _min_obs        | -1.4       |
| _std_act        | 0.739314   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 166
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.855       |
| ExplainedVarOld | 0.848       |
| KL              | 0.000998412 |
| Phi_loss        | 109.884     |
| PolicyEntropy   | 3.18608     |
| PolicyLoss      | 0.003313    |
| Steps           | 10000       |
| VarFuncLoss     | 0.227       |
| _MeanReward     | 2.3e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 4.13285     |
| _max_adv        | 5.5         |
| _max_discrew    | 2.93        |
| _max_obs        | 1.32        |
| _mean_act       | -0.0187241  |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 1.86        |
| _mean_obs       | 0.0425      |
| _min_adv        | -16.2       |
| _min_discrew    | -1.19       |
| _min_obs        | -1.29       |
| _std_act        | 0.623276    |
| _std_adv        | 1           |
| _std_discrew    | 0.907       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 167
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.848       |
| ExplainedVarOld | 0.842       |
| KL              | 0.00173853  |
| Phi_loss        | 130.009     |
| PolicyEntropy   | 3.16636     |
| PolicyLoss      | 0.000572416 |
| Steps           | 10000       |
| VarFuncLoss     | 0.14        |
| _MeanReward     | 2.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83419     |
| _max_adv        | 13.7        |
| _max_discrew    | 2.91        |
| _max_obs        | 1.21        |
| _mean_act       | -0.0199282  |
| _mean_adv       | -3.13e-17   |
| _mean_discrew   | 2.06        |
| _mean_obs       | 0.0426      |
| _min_adv        | -8.96       |
| _min_discrew    | 0.00379     |
| _min_obs        | -1.28       |
| _std_act        | 0.530403    |
| _std_adv        | 1           |
| _std_discrew    | 0.479       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 168
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.946      |
| ExplainedVarOld | 0.926      |
| KL              | 0.00159555 |
| Phi_loss        | 99.5855    |
| PolicyEntropy   | 3.14702    |
| PolicyLoss      | -0.0126179 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0273     |
| _MeanReward     | 2.55e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70315    |
| _max_adv        | 8.46       |
| _max_discrew    | 2.88       |
| _max_obs        | 1.42       |
| _mean_act       | -0.017622  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 2.09       |
| _mean_obs       | 0.0433     |
| _min_adv        | -5.21      |
| _min_discrew    | -0.00451   |
| _min_obs        | -1.29      |
| _std_act        | 0.543381   |
| _std_adv        | 1          |
| _std_discrew    | 0.459      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 169
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.937      |
| ExplainedVarOld | 0.932      |
| KL              | 0.00192027 |
| Phi_loss        | 121.443    |
| PolicyEntropy   | 3.14108    |
| PolicyLoss      | -0.0150508 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0292     |
| _MeanReward     | 2.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.6854     |
| _max_adv        | 2.53       |
| _max_discrew    | 2.98       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0198125 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 1.93       |
| _mean_obs       | 0.0421     |
| _min_adv        | -16.6      |
| _min_discrew    | -1.22      |
| _min_obs        | -1.4       |
| _std_act        | 0.643761   |
| _std_adv        | 1          |
| _std_discrew    | 1.07       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 170
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.88        |
| ExplainedVarOld | 0.864       |
| KL              | 0.00245882  |
| Phi_loss        | 84.0771     |
| PolicyEntropy   | 3.14718     |
| PolicyLoss      | -0.00530122 |
| Steps           | 10000       |
| VarFuncLoss     | 0.129       |
| _MeanReward     | 2.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.53271     |
| _max_adv        | 12          |
| _max_discrew    | 2.98        |
| _max_obs        | 1.2         |
| _mean_act       | -0.0207743  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.12        |
| _mean_obs       | 0.0433      |
| _min_adv        | -14.2       |
| _min_discrew    | 0.0056      |
| _min_obs        | -1.39       |
| _std_act        | 0.541328    |
| _std_adv        | 1           |
| _std_discrew    | 0.489       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 171
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.916      |
| KL              | 0.00144717 |
| Phi_loss        | 97.3134    |
| PolicyEntropy   | 3.14152    |
| PolicyLoss      | -0.0225584 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0356     |
| _MeanReward     | 2.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59389    |
| _max_adv        | 13.5       |
| _max_discrew    | 3.02       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0163695 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.11       |
| _mean_obs       | 0.044      |
| _min_adv        | -9.2       |
| _min_discrew    | 0.00601    |
| _min_obs        | -1.3       |
| _std_act        | 0.549018   |
| _std_adv        | 1          |
| _std_discrew    | 0.503      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 172
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.929       |
| ExplainedVarOld | 0.916       |
| KL              | 0.00387045  |
| Phi_loss        | 116.433     |
| PolicyEntropy   | 3.1265      |
| PolicyLoss      | -0.00955799 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0355      |
| _MeanReward     | 2.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.88742     |
| _max_adv        | 3.58        |
| _max_discrew    | 3.1         |
| _max_obs        | 1.38        |
| _mean_act       | -0.0242929  |
| _mean_adv       | 0           |
| _mean_discrew   | 1.95        |
| _mean_obs       | 0.0412      |
| _min_adv        | -15.7       |
| _min_discrew    | -1.25       |
| _min_obs        | -1.27       |
| _std_act        | 0.65367     |
| _std_adv        | 1           |
| _std_discrew    | 1.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 173
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.879      |
| ExplainedVarOld | 0.866      |
| KL              | 0.00834208 |
| Phi_loss        | 104.38     |
| PolicyEntropy   | 3.12339    |
| PolicyLoss      | -0.0686642 |
| Steps           | 10000      |
| VarFuncLoss     | 0.144      |
| _MeanReward     | 2.61e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76601    |
| _max_adv        | 17.8       |
| _max_discrew    | 3.09       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0221005 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.14       |
| _mean_obs       | 0.0431     |
| _min_adv        | -9.16      |
| _min_discrew    | 0.00445    |
| _min_obs        | -1.25      |
| _std_act        | 0.552022   |
| _std_adv        | 1          |
| _std_discrew    | 0.494      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 174
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.898      |
| ExplainedVarOld | 0.893      |
| KL              | 0.0124913  |
| Phi_loss        | 131.246    |
| PolicyEntropy   | 3.10389    |
| PolicyLoss      | -0.0821403 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0506     |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72334    |
| _max_adv        | 10.1       |
| _max_discrew    | 3.18       |
| _max_obs        | 1.28       |
| _mean_act       | -0.0155989 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.24       |
| _mean_obs       | 0.0448     |
| _min_adv        | -9.24      |
| _min_discrew    | -0.0167    |
| _min_obs        | -1.23      |
| _std_act        | 0.558119   |
| _std_adv        | 1          |
| _std_discrew    | 0.531      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 175
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.954      |
| ExplainedVarOld | 0.947      |
| KL              | 0.00154458 |
| Phi_loss        | 157.594    |
| PolicyEntropy   | 3.08718    |
| PolicyLoss      | -0.0181513 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0262     |
| _MeanReward     | 2.65e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.87843    |
| _max_adv        | 7.8        |
| _max_discrew    | 3.08       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0175492 |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 2.21       |
| _mean_obs       | 0.0436     |
| _min_adv        | -12.7      |
| _min_discrew    | 0.0094     |
| _min_obs        | -1.23      |
| _std_act        | 0.558354   |
| _std_adv        | 1          |
| _std_discrew    | 0.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 176
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00170756 |
| Phi_loss        | 126.148    |
| PolicyEntropy   | 3.0752     |
| PolicyLoss      | -0.0270657 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0315     |
| _MeanReward     | 2.74e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88707    |
| _max_adv        | 8.84       |
| _max_discrew    | 3.07       |
| _max_obs        | 1.19       |
| _mean_act       | -0.0137475 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.26       |
| _mean_obs       | 0.0451     |
| _min_adv        | -9.08      |
| _min_discrew    | 0.0057     |
| _min_obs        | -1.3       |
| _std_act        | 0.561744   |
| _std_adv        | 1          |
| _std_discrew    | 0.52       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 177
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.923       |
| ExplainedVarOld | 0.921       |
| KL              | 0.000968601 |
| Phi_loss        | 142.102     |
| PolicyEntropy   | 3.06084     |
| PolicyLoss      | -0.0186385  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0401      |
| _MeanReward     | 2.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9176      |
| _max_adv        | 11.1        |
| _max_discrew    | 3.25        |
| _max_obs        | 1.29        |
| _mean_act       | -0.016553   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.27        |
| _mean_obs       | 0.0446      |
| _min_adv        | -8.85       |
| _min_discrew    | 0.00369     |
| _min_obs        | -1.27       |
| _std_act        | 0.565395    |
| _std_adv        | 1           |
| _std_discrew    | 0.531       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 178
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.957      |
| ExplainedVarOld | 0.953      |
| KL              | 0.0018043  |
| Phi_loss        | 120.191    |
| PolicyEntropy   | 3.04325    |
| PolicyLoss      | -0.0172983 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0226     |
| _MeanReward     | 2.52e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.20283    |
| _max_adv        | 1.58       |
| _max_discrew    | 3.23       |
| _max_obs        | 1.31       |
| _mean_act       | -0.0163231 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.04       |
| _mean_obs       | 0.0423     |
| _min_adv        | -16.5      |
| _min_discrew    | -1.32      |
| _min_obs        | -1.2       |
| _std_act        | 0.686012   |
| _std_adv        | 1          |
| _std_discrew    | 1.4        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 179
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.895       |
| ExplainedVarOld | 0.862       |
| KL              | 0.00257667  |
| Phi_loss        | 85.41       |
| PolicyEntropy   | 3.04733     |
| PolicyLoss      | -0.00398593 |
| Steps           | 10000       |
| VarFuncLoss     | 0.146       |
| _MeanReward     | 2.79e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59548     |
| _max_adv        | 5.83        |
| _max_discrew    | 3.19        |
| _max_obs        | 1.22        |
| _mean_act       | -0.0161506  |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 2.3         |
| _mean_obs       | 0.0449      |
| _min_adv        | -11.2       |
| _min_discrew    | 0.00414     |
| _min_obs        | -1.24       |
| _std_act        | 0.566698    |
| _std_adv        | 1           |
| _std_discrew    | 0.568       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 180
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.948        |
| ExplainedVarOld | 0.945        |
| KL              | 0.0017132    |
| Phi_loss        | 141.565      |
| PolicyEntropy   | 3.00939      |
| PolicyLoss      | -0.000615418 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0295       |
| _MeanReward     | 2.85e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.04066      |
| _max_adv        | 14.5         |
| _max_discrew    | 3.23         |
| _max_obs        | 1.27         |
| _mean_act       | -0.0144496   |
| _mean_adv       | 1.71e-17     |
| _mean_discrew   | 2.36         |
| _mean_obs       | 0.0451       |
| _min_adv        | -9.66        |
| _min_discrew    | 0.0109       |
| _min_obs        | -1.29        |
| _std_act        | 0.569526     |
| _std_adv        | 1            |
| _std_discrew    | 0.545        |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 181
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.96       |
| ExplainedVarOld | 0.955      |
| KL              | 0.0016093  |
| Phi_loss        | 125.898    |
| PolicyEntropy   | 2.9964     |
| PolicyLoss      | -0.0162987 |
| Steps           | 10000      |
| VarFuncLoss     | 0.023      |
| _MeanReward     | 2.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68069    |
| _max_adv        | 9.06       |
| _max_discrew    | 3.17       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0230066 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.23       |
| _mean_obs       | 0.0435     |
| _min_adv        | -7.23      |
| _min_discrew    | 0.0073     |
| _min_obs        | -1.25      |
| _std_act        | 0.567307   |
| _std_adv        | 1          |
| _std_discrew    | 0.588      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 182
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.869      |
| KL              | 0.00191905 |
| Phi_loss        | 126.919    |
| PolicyEntropy   | 2.9791     |
| PolicyLoss      | 0.00256883 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0742     |
| _MeanReward     | 2.83e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68923    |
| _max_adv        | 6.85       |
| _max_discrew    | 3.3        |
| _max_obs        | 1.38       |
| _mean_act       | -0.0185636 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.32       |
| _mean_obs       | 0.0444     |
| _min_adv        | -8.77      |
| _min_discrew    | -0.0926    |
| _min_obs        | -1.27      |
| _std_act        | 0.567725   |
| _std_adv        | 1          |
| _std_discrew    | 0.573      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 183
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.939      |
| KL              | 0.00181044 |
| Phi_loss        | 124.479    |
| PolicyEntropy   | 2.96805    |
| PolicyLoss      | -0.0224818 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0322     |
| _MeanReward     | 2.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.10244    |
| _max_adv        | 4.6        |
| _max_discrew    | 3.19       |
| _max_obs        | 1.32       |
| _mean_act       | -0.0163285 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.24       |
| _mean_obs       | 0.0439     |
| _min_adv        | -16.3      |
| _min_discrew    | -1.18      |
| _min_obs        | -1.19      |
| _std_act        | 0.64034    |
| _std_adv        | 1          |
| _std_discrew    | 1.08       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 184
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.867      |
| KL              | 0.00236327 |
| Phi_loss        | 110.38     |
| PolicyEntropy   | 2.97438    |
| PolicyLoss      | 0.00621607 |
| Steps           | 10000      |
| VarFuncLoss     | 0.133      |
| _MeanReward     | 2.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.02057    |
| _max_adv        | 7.63       |
| _max_discrew    | 3.24       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0164833 |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 2.4        |
| _mean_obs       | 0.0445     |
| _min_adv        | -9.5       |
| _min_discrew    | 0.00964    |
| _min_obs        | -1.18      |
| _std_act        | 0.572964   |
| _std_adv        | 1          |
| _std_discrew    | 0.569      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 185
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.955      |
| KL              | 0.00169735 |
| Phi_loss        | 135.612    |
| PolicyEntropy   | 2.95062    |
| PolicyLoss      | -0.0121508 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0238     |
| _MeanReward     | 2.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54859    |
| _max_adv        | 15.4       |
| _max_discrew    | 3.35       |
| _max_obs        | 1.28       |
| _mean_act       | -0.016808  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.37       |
| _mean_obs       | 0.0441     |
| _min_adv        | -10.9      |
| _min_discrew    | 0.00862    |
| _min_obs        | -1.29      |
| _std_act        | 0.572704   |
| _std_adv        | 1          |
| _std_discrew    | 0.589      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 186
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.904      |
| ExplainedVarOld | 0.9        |
| KL              | 0.00228233 |
| Phi_loss        | 142.856    |
| PolicyEntropy   | 2.92511    |
| PolicyLoss      | 0.00423024 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0565     |
| _MeanReward     | 2.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81985    |
| _max_adv        | 8.16       |
| _max_discrew    | 3.36       |
| _max_obs        | 1.22       |
| _mean_act       | -0.0160097 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 2.38       |
| _mean_obs       | 0.0438     |
| _min_adv        | -10.7      |
| _min_discrew    | 0.00827    |
| _min_obs        | -1.14      |
| _std_act        | 0.579285   |
| _std_adv        | 1          |
| _std_discrew    | 0.593      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 187
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.932      |
| ExplainedVarOld | 0.931      |
| KL              | 0.00207316 |
| Phi_loss        | 156.507    |
| PolicyEntropy   | 2.90731    |
| PolicyLoss      | -0.0222799 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0403     |
| _MeanReward     | 2.9e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.94922    |
| _max_adv        | 9.85       |
| _max_discrew    | 3.32       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0156824 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.38       |
| _mean_obs       | 0.0451     |
| _min_adv        | -9.4       |
| _min_discrew    | 0.0106     |
| _min_obs        | -1.19      |
| _std_act        | 0.580146   |
| _std_adv        | 1          |
| _std_discrew    | 0.659      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 188
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.911       |
| ExplainedVarOld | 0.905       |
| KL              | 0.00186736  |
| Phi_loss        | 162.738     |
| PolicyEntropy   | 2.87458     |
| PolicyLoss      | -0.00396856 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0586      |
| _MeanReward     | 2.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.88036     |
| _max_adv        | 4.77        |
| _max_discrew    | 3.43        |
| _max_obs        | 1.33        |
| _mean_act       | -0.0247987  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.14        |
| _mean_obs       | 0.0411      |
| _min_adv        | -15.5       |
| _min_discrew    | -1.32       |
| _min_obs        | -1.3        |
| _std_act        | 0.699723    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 189
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.914      |
| ExplainedVarOld | 0.903      |
| KL              | 0.00647392 |
| Phi_loss        | 172.785    |
| PolicyEntropy   | 2.85268    |
| PolicyLoss      | 0.0099713  |
| Steps           | 10000      |
| VarFuncLoss     | 0.138      |
| _MeanReward     | 2.79e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.96085    |
| _max_adv        | 9.97       |
| _max_discrew    | 3.32       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0239528 |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 2.28       |
| _mean_obs       | 0.0429     |
| _min_adv        | -13.5      |
| _min_discrew    | -0.963     |
| _min_obs        | -1.28      |
| _std_act        | 0.616948   |
| _std_adv        | 1          |
| _std_discrew    | 0.858      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 190
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.835       |
| ExplainedVarOld | 0.828       |
| KL              | 0.00117169  |
| Phi_loss        | 150.494     |
| PolicyEntropy   | 2.84144     |
| PolicyLoss      | -0.00196123 |
| Steps           | 10000       |
| VarFuncLoss     | 0.145       |
| _MeanReward     | 3.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73915     |
| _max_adv        | 9.79        |
| _max_discrew    | 3.44        |
| _max_obs        | 1.24        |
| _mean_act       | -0.0145406  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.49        |
| _mean_obs       | 0.0459      |
| _min_adv        | -9.87       |
| _min_discrew    | -0.0512     |
| _min_obs        | -1.15       |
| _std_act        | 0.578999    |
| _std_adv        | 1           |
| _std_discrew    | 0.725       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 191
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.951      |
| ExplainedVarOld | 0.926      |
| KL              | 0.00433093 |
| Phi_loss        | 162.098    |
| PolicyEntropy   | 2.81911    |
| PolicyLoss      | -0.0444336 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0406     |
| _MeanReward     | 2.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.78853    |
| _max_adv        | 8.62       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.33       |
| _mean_act       | -0.0226474 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 2.26       |
| _mean_obs       | 0.0419     |
| _min_adv        | -17.6      |
| _min_discrew    | -1.2       |
| _min_obs        | -1.36      |
| _std_act        | 0.652402   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 192
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.868      |
| ExplainedVarOld | 0.86       |
| KL              | 0.00288256 |
| Phi_loss        | 128.475    |
| PolicyEntropy   | 2.79503    |
| PolicyLoss      | -0.0180673 |
| Steps           | 10000      |
| VarFuncLoss     | 0.156      |
| _MeanReward     | 3.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.95209    |
| _max_adv        | 6.96       |
| _max_discrew    | 3.45       |
| _max_obs        | 1.27       |
| _mean_act       | -0.0155636 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.49       |
| _mean_obs       | 0.045      |
| _min_adv        | -8.44      |
| _min_discrew    | 0.00992    |
| _min_obs        | -1.25      |
| _std_act        | 0.578611   |
| _std_adv        | 1          |
| _std_discrew    | 0.697      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 193
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.954       |
| ExplainedVarOld | 0.956       |
| KL              | 0.0019067   |
| Phi_loss        | 178.094     |
| PolicyEntropy   | 2.76813     |
| PolicyLoss      | -0.00423745 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0329      |
| _MeanReward     | 3.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.65847     |
| _max_adv        | 10.3        |
| _max_discrew    | 3.52        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00999916 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 2.51        |
| _mean_obs       | 0.0447      |
| _min_adv        | -4.32       |
| _min_discrew    | 0.00605     |
| _min_obs        | -1.34       |
| _std_act        | 0.574902    |
| _std_adv        | 1           |
| _std_discrew    | 0.619       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 194
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.97       |
| ExplainedVarOld | 0.97       |
| KL              | 0.00195489 |
| Phi_loss        | 175.976    |
| PolicyEntropy   | 2.73691    |
| PolicyLoss      | -0.0177215 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0189     |
| _MeanReward     | 2.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.84527    |
| _max_adv        | 4.03       |
| _max_discrew    | 3.41       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0195304 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.35       |
| _mean_obs       | 0.043      |
| _min_adv        | -18.4      |
| _min_discrew    | -1.23      |
| _min_obs        | -1.28      |
| _std_act        | 0.66195    |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 195
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.887       |
| ExplainedVarOld | 0.876       |
| KL              | 0.0025014   |
| Phi_loss        | 158.256     |
| PolicyEntropy   | 2.71864     |
| PolicyLoss      | 0.000510716 |
| Steps           | 10000       |
| VarFuncLoss     | 0.135       |
| _MeanReward     | 3.13e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.10068     |
| _max_adv        | 8.86        |
| _max_discrew    | 3.51        |
| _max_obs        | 1.18        |
| _mean_act       | -0.00810996 |
| _mean_adv       | 1.42e-17    |
| _mean_discrew   | 2.57        |
| _mean_obs       | 0.0461      |
| _min_adv        | -4.18       |
| _min_discrew    | 0.00857     |
| _min_obs        | -1.21       |
| _std_act        | 0.588136    |
| _std_adv        | 1           |
| _std_discrew    | 0.684       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 196
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.972      |
| KL              | 0.00240378 |
| Phi_loss        | 174.779    |
| PolicyEntropy   | 2.68781    |
| PolicyLoss      | -0.0121333 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0187     |
| _MeanReward     | 3.01e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.80884    |
| _max_adv        | 4.45       |
| _max_discrew    | 3.44       |
| _max_obs        | 1.34       |
| _mean_act       | -0.0173381 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.46       |
| _mean_obs       | 0.0442     |
| _min_adv        | -18.3      |
| _min_discrew    | -0.993     |
| _min_obs        | -1.25      |
| _std_act        | 0.629729   |
| _std_adv        | 1          |
| _std_discrew    | 1          |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 197
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.895      |
| ExplainedVarOld | 0.887      |
| KL              | 0.00282468 |
| Phi_loss        | 159.967    |
| PolicyEntropy   | 2.67611    |
| PolicyLoss      | -0.0106878 |
| Steps           | 10000      |
| VarFuncLoss     | 0.105      |
| _MeanReward     | 3.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7687     |
| _max_adv        | 16.2       |
| _max_discrew    | 3.45       |
| _max_obs        | 1.23       |
| _mean_act       | -0.0130844 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.59       |
| _mean_obs       | 0.0458     |
| _min_adv        | -9.28      |
| _min_discrew    | 0.0088     |
| _min_obs        | -1.22      |
| _std_act        | 0.587157   |
| _std_adv        | 1          |
| _std_discrew    | 0.674      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 198
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.959      |
| ExplainedVarOld | 0.94       |
| KL              | 0.0124426  |
| Phi_loss        | 111.4      |
| PolicyEntropy   | 2.66398    |
| PolicyLoss      | 0.00381194 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0284     |
| _MeanReward     | 2.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.94075    |
| _max_adv        | 2.12       |
| _max_discrew    | 3.51       |
| _max_obs        | 1.35       |
| _mean_act       | -0.0188091 |
| _mean_adv       | 0          |
| _mean_discrew   | 2.22       |
| _mean_obs       | 0.0417     |
| _min_adv        | -13.9      |
| _min_discrew    | -1.22      |
| _min_obs        | -1.21      |
| _std_act        | 0.715765   |
| _std_adv        | 1          |
| _std_discrew    | 1.75       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 199
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.835      |
| ExplainedVarOld | 0.824      |
| KL              | 0.00581004 |
| Phi_loss        | 170.038    |
| PolicyEntropy   | 2.67402    |
| PolicyLoss      | -0.0125451 |
| Steps           | 10000      |
| VarFuncLoss     | 0.292      |
| _MeanReward     | 3.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.88771    |
| _max_adv        | 10.3       |
| _max_discrew    | 3.55       |
| _max_obs        | 1.17       |
| _mean_act       | -0.0126848 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.58       |
| _mean_obs       | 0.0451     |
| _min_adv        | -11.4      |
| _min_discrew    | 0.00927    |
| _min_obs        | -1.21      |
| _std_act        | 0.585824   |
| _std_adv        | 1          |
| _std_discrew    | 0.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 200
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.938      |
| ExplainedVarOld | 0.938      |
| KL              | 0.00150247 |
| Phi_loss        | 191.664    |
| PolicyEntropy   | 2.66291    |
| PolicyLoss      | -0.011911  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0438     |
| _MeanReward     | 3.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7612     |
| _max_adv        | 17.8       |
| _max_discrew    | 3.62       |
| _max_obs        | 1.3        |
| _mean_act       | -0.0118922 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.64       |
| _mean_obs       | 0.0457     |
| _min_adv        | -8.52      |
| _min_discrew    | 0.00545    |
| _min_obs        | -1.24      |
| _std_act        | 0.584111   |
| _std_adv        | 1          |
| _std_discrew    | 0.692      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 201
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.945       |
| ExplainedVarOld | 0.933       |
| KL              | 0.00148112  |
| Phi_loss        | 198.39      |
| PolicyEntropy   | 2.64273     |
| PolicyLoss      | -0.0154026  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0384      |
| _MeanReward     | 3.23e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79689     |
| _max_adv        | 7.55        |
| _max_discrew    | 3.64        |
| _max_obs        | 1.12        |
| _mean_act       | -0.00982806 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 2.67        |
| _mean_obs       | 0.0461      |
| _min_adv        | -5.66       |
| _min_discrew    | 0.00846     |
| _min_obs        | -1.28       |
| _std_act        | 0.591958    |
| _std_adv        | 1           |
| _std_discrew    | 0.707       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 202
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00224666  |
| Phi_loss        | 196.701     |
| PolicyEntropy   | 2.60526     |
| PolicyLoss      | -0.00920596 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0135      |
| _MeanReward     | 3.2e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.65833     |
| _max_adv        | 5.07        |
| _max_discrew    | 3.57        |
| _max_obs        | 1.36        |
| _mean_act       | -0.0134497  |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 2.65        |
| _mean_obs       | 0.0453      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0121      |
| _min_obs        | -1.38       |
| _std_act        | 0.590036    |
| _std_adv        | 1           |
| _std_discrew    | 0.698       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 203
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.946      |
| ExplainedVarOld | 0.945      |
| KL              | 0.00237089 |
| Phi_loss        | 238.335    |
| PolicyEntropy   | 2.59049    |
| PolicyLoss      | -0.0318842 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0381     |
| _MeanReward     | 3.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69757    |
| _max_adv        | 10.5       |
| _max_discrew    | 3.61       |
| _max_obs        | 1.18       |
| _mean_act       | -0.0115504 |
| _mean_adv       | 2.42e-17   |
| _mean_discrew   | 2.69       |
| _mean_obs       | 0.0459     |
| _min_adv        | -12        |
| _min_discrew    | 0.00905    |
| _min_obs        | -1.14      |
| _std_act        | 0.601311   |
| _std_adv        | 1          |
| _std_discrew    | 0.789      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 204
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.927       |
| ExplainedVarOld | 0.91        |
| KL              | 0.00193403  |
| Phi_loss        | 156.753     |
| PolicyEntropy   | 2.56989     |
| PolicyLoss      | -0.00282867 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0597      |
| _MeanReward     | 3.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80571     |
| _max_adv        | 4.68        |
| _max_discrew    | 3.64        |
| _max_obs        | 1.3         |
| _mean_act       | -0.0117763  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.62        |
| _mean_obs       | 0.0452      |
| _min_adv        | -14.1       |
| _min_discrew    | -0.0226     |
| _min_obs        | -1.2        |
| _std_act        | 0.605746    |
| _std_adv        | 1           |
| _std_discrew    | 0.792       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 205
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.916       |
| ExplainedVarOld | 0.91        |
| KL              | 0.00189415  |
| Phi_loss        | 202.397     |
| PolicyEntropy   | 2.55201     |
| PolicyLoss      | -0.00805417 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0675      |
| _MeanReward     | 3.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.01535     |
| _max_adv        | 7.79        |
| _max_discrew    | 3.72        |
| _max_obs        | 1.19        |
| _mean_act       | -0.00668085 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.76        |
| _mean_obs       | 0.0467      |
| _min_adv        | -4.19       |
| _min_discrew    | 0.0112      |
| _min_obs        | -1.17       |
| _std_act        | 0.599213    |
| _std_adv        | 1           |
| _std_discrew    | 0.744       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 206
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.973       |
| KL              | 0.00189195  |
| Phi_loss        | 160.43      |
| PolicyEntropy   | 2.53062     |
| PolicyLoss      | -0.00660901 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0166      |
| _MeanReward     | 3.36e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77772     |
| _max_adv        | 18.2        |
| _max_discrew    | 3.64        |
| _max_obs        | 1.19        |
| _mean_act       | -0.00619248 |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 2.77        |
| _mean_obs       | 0.0465      |
| _min_adv        | -3.85       |
| _min_discrew    | 0.00639     |
| _min_obs        | -1.16       |
| _std_act        | 0.606916    |
| _std_adv        | 1           |
| _std_discrew    | 0.748       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 207
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.983      |
| KL              | 0.0022818  |
| Phi_loss        | 183.239    |
| PolicyEntropy   | 2.50837    |
| PolicyLoss      | -0.0388351 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 3.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.95889    |
| _max_adv        | 6.32       |
| _max_discrew    | 3.73       |
| _max_obs        | 1.37       |
| _mean_act       | -0.0163607 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 2.56       |
| _mean_obs       | 0.044      |
| _min_adv        | -15.8      |
| _min_discrew    | -1.14      |
| _min_obs        | -1.44      |
| _std_act        | 0.667643   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 208
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.877      |
| ExplainedVarOld | 0.861      |
| KL              | 0.00284841 |
| Phi_loss        | 151.439    |
| PolicyEntropy   | 2.49077    |
| PolicyLoss      | 0.00596345 |
| Steps           | 10000      |
| VarFuncLoss     | 0.157      |
| _MeanReward     | 3.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.86403    |
| _max_adv        | 11.8       |
| _max_discrew    | 3.74       |
| _max_obs        | 1.2        |
| _mean_act       | -0.0130888 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 2.78       |
| _mean_obs       | 0.0459     |
| _min_adv        | -16.3      |
| _min_discrew    | 0.0121     |
| _min_obs        | -1.22      |
| _std_act        | 0.612616   |
| _std_adv        | 1          |
| _std_discrew    | 0.784      |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 209
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00224014  |
| Phi_loss        | 144.963     |
| PolicyEntropy   | 2.46599     |
| PolicyLoss      | -0.014404   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0215      |
| _MeanReward     | 3.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64783     |
| _max_adv        | 22.2        |
| _max_discrew    | 3.75        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00582107 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.83        |
| _mean_obs       | 0.0472      |
| _min_adv        | -4.69       |
| _min_discrew    | 0.011       |
| _min_obs        | -1.26       |
| _std_act        | 0.611705    |
| _std_adv        | 1           |
| _std_discrew    | 0.765       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 210
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.985       |
| KL              | 0.00215947  |
| Phi_loss        | 187.243     |
| PolicyEntropy   | 2.42688     |
| PolicyLoss      | 0.000154056 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0103      |
| _MeanReward     | 3.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85788     |
| _max_adv        | 6.56        |
| _max_discrew    | 3.78        |
| _max_obs        | 1.15        |
| _mean_act       | -0.00978538 |
| _mean_adv       | -1.85e-17   |
| _mean_discrew   | 2.84        |
| _mean_obs       | 0.0457      |
| _min_adv        | -5.49       |
| _min_discrew    | 0.0119      |
| _min_obs        | -1.19       |
| _std_act        | 0.607609    |
| _std_adv        | 1           |
| _std_discrew    | 0.804       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 211
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.987      |
| KL              | 0.00188894 |
| Phi_loss        | 222.474    |
| PolicyEntropy   | 2.41206    |
| PolicyLoss      | -0.0177504 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00986    |
| _MeanReward     | 3.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.86397    |
| _max_adv        | 5.58       |
| _max_discrew    | 3.81       |
| _max_obs        | 1.39       |
| _mean_act       | -0.01229   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 2.65       |
| _mean_obs       | 0.0451     |
| _min_adv        | -15.9      |
| _min_discrew    | -1.24      |
| _min_obs        | -1.13      |
| _std_act        | 0.691593   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 212
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.873       |
| ExplainedVarOld | 0.848       |
| KL              | 0.00365903  |
| Phi_loss        | 106.202     |
| PolicyEntropy   | 2.41485     |
| PolicyLoss      | 0.00790565  |
| Steps           | 10000       |
| VarFuncLoss     | 0.196       |
| _MeanReward     | 3.52e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8781      |
| _max_adv        | 10          |
| _max_discrew    | 3.8         |
| _max_obs        | 1.29        |
| _mean_act       | -0.00642776 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 2.91        |
| _mean_obs       | 0.0474      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0113      |
| _min_obs        | -1.14       |
| _std_act        | 0.616698    |
| _std_adv        | 1           |
| _std_discrew    | 0.806       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 213
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.979       |
| KL              | 0.00224411  |
| Phi_loss        | 148.263     |
| PolicyEntropy   | 2.4004      |
| PolicyLoss      | 0.000545884 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0184      |
| _MeanReward     | 3.53e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.85112     |
| _max_adv        | 20.9        |
| _max_discrew    | 3.84        |
| _max_obs        | 1.13        |
| _mean_act       | -0.00484164 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 2.9         |
| _mean_obs       | 0.0474      |
| _min_adv        | -4.67       |
| _min_discrew    | 0.0101      |
| _min_obs        | -1.17       |
| _std_act        | 0.620318    |
| _std_adv        | 1           |
| _std_discrew    | 0.874       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 214
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.975       |
| KL              | 0.00157701  |
| Phi_loss        | 147.69      |
| PolicyEntropy   | 2.37591     |
| PolicyLoss      | -0.0102161  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0117      |
| _MeanReward     | 3.5e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.61153     |
| _max_adv        | 10.6        |
| _max_discrew    | 3.91        |
| _max_obs        | 1.18        |
| _mean_act       | -0.00641062 |
| _mean_adv       | 1.42e-18    |
| _mean_discrew   | 2.91        |
| _mean_obs       | 0.0469      |
| _min_adv        | -15.8       |
| _min_discrew    | 0.0144      |
| _min_obs        | -1.23       |
| _std_act        | 0.617645    |
| _std_adv        | 1           |
| _std_discrew    | 0.849       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 215
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.979       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00519929  |
| Phi_loss        | 133.411     |
| PolicyEntropy   | 2.36135     |
| PolicyLoss      | -0.00846434 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0175      |
| _MeanReward     | 3.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.70302     |
| _max_adv        | 9.56        |
| _max_discrew    | 3.78        |
| _max_obs        | 1.15        |
| _mean_act       | -0.00721056 |
| _mean_adv       | 0           |
| _mean_discrew   | 2.89        |
| _mean_obs       | 0.0463      |
| _min_adv        | -6.09       |
| _min_discrew    | 0.0136      |
| _min_obs        | -1.16       |
| _std_act        | 0.616719    |
| _std_adv        | 1           |
| _std_discrew    | 0.796       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 216
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.984       |
| ExplainedVarOld | 0.983       |
| KL              | 0.00221154  |
| Phi_loss        | 231.805     |
| PolicyEntropy   | 2.32612     |
| PolicyLoss      | -0.00696857 |
| Steps           | 10000       |
| VarFuncLoss     | 0.013       |
| _MeanReward     | 3.48e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79976     |
| _max_adv        | 11.3        |
| _max_discrew    | 3.91        |
| _max_obs        | 1.2         |
| _mean_act       | -0.00864454 |
| _mean_adv       | 0           |
| _mean_discrew   | 2.85        |
| _mean_obs       | 0.0469      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.00841     |
| _min_obs        | -1.14       |
| _std_act        | 0.622888    |
| _std_adv        | 1           |
| _std_discrew    | 0.982       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 217
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.906       |
| ExplainedVarOld | 0.885       |
| KL              | 0.00233908  |
| Phi_loss        | 161.801     |
| PolicyEntropy   | 2.31683     |
| PolicyLoss      | -0.00710989 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0927      |
| _MeanReward     | 3.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.70019     |
| _max_adv        | 13.7        |
| _max_discrew    | 3.94        |
| _max_obs        | 1.28        |
| _mean_act       | -0.00999302 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 2.94        |
| _mean_obs       | 0.0469      |
| _min_adv        | -15.5       |
| _min_discrew    | 0.0105      |
| _min_obs        | -1.22       |
| _std_act        | 0.627793    |
| _std_adv        | 1           |
| _std_discrew    | 0.871       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 218
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.968       |
| ExplainedVarOld | 0.966       |
| KL              | 0.003704    |
| Phi_loss        | 208.949     |
| PolicyEntropy   | 2.31547     |
| PolicyLoss      | -0.0130508  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0291      |
| _MeanReward     | 3.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73624     |
| _max_adv        | 15.4        |
| _max_discrew    | 3.96        |
| _max_obs        | 1.12        |
| _mean_act       | -0.00880083 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 2.93        |
| _mean_obs       | 0.0464      |
| _min_adv        | -6.93       |
| _min_discrew    | 0.00919     |
| _min_obs        | -1.28       |
| _std_act        | 0.628845    |
| _std_adv        | 1           |
| _std_discrew    | 0.847       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 219
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.986       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00176843  |
| Phi_loss        | 221.988     |
| PolicyEntropy   | 2.29961     |
| PolicyLoss      | -0.0045516  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0122      |
| _MeanReward     | 3.62e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75405     |
| _max_adv        | 10.1        |
| _max_discrew    | 3.94        |
| _max_obs        | 1.16        |
| _mean_act       | -0.00226768 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3           |
| _mean_obs       | 0.0476      |
| _min_adv        | -6.33       |
| _min_discrew    | 0.0124      |
| _min_obs        | -1.19       |
| _std_act        | 0.62927     |
| _std_adv        | 1           |
| _std_discrew    | 0.896       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 220
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.986       |
| KL              | 0.00208934  |
| Phi_loss        | 202.861     |
| PolicyEntropy   | 2.27942     |
| PolicyLoss      | -0.0240957  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0119      |
| _MeanReward     | 3.55e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75254     |
| _max_adv        | 8.65        |
| _max_discrew    | 4           |
| _max_obs        | 1.18        |
| _mean_act       | -0.00613725 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 2.93        |
| _mean_obs       | 0.0468      |
| _min_adv        | -10         |
| _min_discrew    | 0.011       |
| _min_obs        | -1.16       |
| _std_act        | 0.630694    |
| _std_adv        | 1           |
| _std_discrew    | 0.889       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 221
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.938       |
| ExplainedVarOld | 0.929       |
| KL              | 0.00308789  |
| Phi_loss        | 174.318     |
| PolicyEntropy   | 2.2592      |
| PolicyLoss      | -0.00273665 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0554      |
| _MeanReward     | 3.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.97529     |
| _max_adv        | 11.8        |
| _max_discrew    | 4           |
| _max_obs        | 1.23        |
| _mean_act       | -0.00298261 |
| _mean_adv       | 1.56e-17    |
| _mean_discrew   | 2.99        |
| _mean_obs       | 0.0472      |
| _min_adv        | -15.2       |
| _min_discrew    | 0.00563     |
| _min_obs        | -1.23       |
| _std_act        | 0.638767    |
| _std_adv        | 1           |
| _std_discrew    | 0.868       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 222
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.98        |
| ExplainedVarOld | 0.971       |
| KL              | 0.0147547   |
| Phi_loss        | 199.707     |
| PolicyEntropy   | 2.2494      |
| PolicyLoss      | 0.10885     |
| Steps           | 10000       |
| VarFuncLoss     | 0.018       |
| _MeanReward     | 3.67e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9186      |
| _max_adv        | 9.03        |
| _max_discrew    | 3.97        |
| _max_obs        | 1.12        |
| _mean_act       | -0.00278944 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.02        |
| _mean_obs       | 0.0477      |
| _min_adv        | -15.1       |
| _min_discrew    | 0.0109      |
| _min_obs        | -1.3        |
| _std_act        | 0.640147    |
| _std_adv        | 1           |
| _std_discrew    | 0.877       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 223
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.974       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00212028  |
| Phi_loss        | 262.353     |
| PolicyEntropy   | 2.24243     |
| PolicyLoss      | -0.0158236  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0226      |
| _MeanReward     | 3.64e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.89573     |
| _max_adv        | 11.1        |
| _max_discrew    | 4           |
| _max_obs        | 1.13        |
| _mean_act       | -0.00540927 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3           |
| _mean_obs       | 0.0465      |
| _min_adv        | -12.7       |
| _min_discrew    | 0.0128      |
| _min_obs        | -1.11       |
| _std_act        | 0.636217    |
| _std_adv        | 1           |
| _std_discrew    | 0.937       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 224
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.98       |
| ExplainedVarOld | 0.978      |
| KL              | 0.00114191 |
| Phi_loss        | 213.298    |
| PolicyEntropy   | 2.23834    |
| PolicyLoss      | -0.0307955 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0185     |
| _MeanReward     | 3.31e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.36931    |
| _max_adv        | 3.03       |
| _max_discrew    | 4.05       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0147126 |
| _mean_adv       | 4.55e-17   |
| _mean_discrew   | 2.7        |
| _mean_obs       | 0.0443     |
| _min_adv        | -17.1      |
| _min_discrew    | -1.11      |
| _min_obs        | -1.12      |
| _std_act        | 0.714178   |
| _std_adv        | 1          |
| _std_discrew    | 2.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 225
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.912       |
| ExplainedVarOld | 0.895       |
| KL              | 0.00544469  |
| Phi_loss        | 188.142     |
| PolicyEntropy   | 2.22727     |
| PolicyLoss      | -0.0234964  |
| Steps           | 10000       |
| VarFuncLoss     | 0.181       |
| _MeanReward     | 3.69e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74415     |
| _max_adv        | 14.1        |
| _max_discrew    | 4.01        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00629573 |
| _mean_adv       | -4.12e-17   |
| _mean_discrew   | 3.06        |
| _mean_obs       | 0.0473      |
| _min_adv        | -6.73       |
| _min_discrew    | 0.00856     |
| _min_obs        | -1.22       |
| _std_act        | 0.639064    |
| _std_adv        | 1           |
| _std_discrew    | 0.932       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 226
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.984      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00244219 |
| Phi_loss        | 194.718    |
| PolicyEntropy   | 2.19059    |
| PolicyLoss      | 0.0120059  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0159     |
| _MeanReward     | 3.37e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.30521    |
| _max_adv        | 5.51       |
| _max_discrew    | 4.07       |
| _max_obs        | 1.41       |
| _mean_act       | -0.0148651 |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 2.75       |
| _mean_obs       | 0.0443     |
| _min_adv        | -18        |
| _min_discrew    | -1.11      |
| _min_obs        | -1.25      |
| _std_act        | 0.707435   |
| _std_adv        | 1          |
| _std_discrew    | 1.83       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 227
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.886       |
| ExplainedVarOld | 0.881       |
| KL              | 0.00297601  |
| Phi_loss        | 212.922     |
| PolicyEntropy   | 2.17705     |
| PolicyLoss      | 0.0111157   |
| Steps           | 10000       |
| VarFuncLoss     | 0.211       |
| _MeanReward     | 3.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5766      |
| _max_adv        | 13.4        |
| _max_discrew    | 4           |
| _max_obs        | 1.2         |
| _mean_act       | -0.00188186 |
| _mean_adv       | 4.97e-17    |
| _mean_discrew   | 3.1         |
| _mean_obs       | 0.0475      |
| _min_adv        | -4.82       |
| _min_discrew    | 0.00905     |
| _min_obs        | -1.17       |
| _std_act        | 0.639234    |
| _std_adv        | 1           |
| _std_discrew    | 0.902       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 228
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.989       |
| KL              | 0.00231773  |
| Phi_loss        | 271.666     |
| PolicyEntropy   | 2.15917     |
| PolicyLoss      | -0.0269721  |
| Steps           | 10000       |
| VarFuncLoss     | 0.014       |
| _MeanReward     | 3.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.8882      |
| _max_adv        | 17.8        |
| _max_discrew    | 4.12        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00464876 |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.047       |
| _min_adv        | -14.5       |
| _min_discrew    | 0.0139      |
| _min_obs        | -1.26       |
| _std_act        | 0.641869    |
| _std_adv        | 1           |
| _std_discrew    | 0.93        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 229
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.95        |
| ExplainedVarOld | 0.943       |
| KL              | 0.00227601  |
| Phi_loss        | 186.807     |
| PolicyEntropy   | 2.14653     |
| PolicyLoss      | -0.00852385 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0467      |
| _MeanReward     | 3.67e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.97752     |
| _max_adv        | 9.61        |
| _max_discrew    | 4.1         |
| _max_obs        | 1.17        |
| _mean_act       | -0.00669487 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0464      |
| _min_adv        | -14.1       |
| _min_discrew    | 0.0108      |
| _min_obs        | -1.13       |
| _std_act        | 0.642397    |
| _std_adv        | 1           |
| _std_discrew    | 0.904       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 230
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.966        |
| ExplainedVarOld | 0.962        |
| KL              | 0.0017774    |
| Phi_loss        | 237.761      |
| PolicyEntropy   | 2.12829      |
| PolicyLoss      | -0.000875213 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0308       |
| _MeanReward     | 3.59e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.25855      |
| _max_adv        | 2.94         |
| _max_discrew    | 4.1          |
| _max_obs        | 1.41         |
| _mean_act       | -0.0145186   |
| _mean_adv       | 4.55e-17     |
| _mean_discrew   | 2.95         |
| _mean_obs       | 0.0461       |
| _min_adv        | -14.3        |
| _min_discrew    | -0.784       |
| _min_obs        | -1.23        |
| _std_act        | 0.678853     |
| _std_adv        | 1            |
| _std_discrew    | 1.27         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 231
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.872       |
| KL              | 0.00474907  |
| Phi_loss        | 237.524     |
| PolicyEntropy   | 2.0975      |
| PolicyLoss      | -0.0284995  |
| Steps           | 10000       |
| VarFuncLoss     | 0.148       |
| _MeanReward     | 3.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.82686     |
| _max_adv        | 6.11        |
| _max_discrew    | 4.17        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00770797 |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.08        |
| _mean_obs       | 0.0464      |
| _min_adv        | -11.5       |
| _min_discrew    | 0.0129      |
| _min_obs        | -1.12       |
| _std_act        | 0.650836    |
| _std_adv        | 1           |
| _std_discrew    | 0.976       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 232
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.943       |
| ExplainedVarOld | 0.939       |
| KL              | 0.00416494  |
| Phi_loss        | 284.189     |
| PolicyEntropy   | 2.08346     |
| PolicyLoss      | 0.0227204   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0563      |
| _MeanReward     | 3.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.97979     |
| _max_adv        | 20.2        |
| _max_discrew    | 4.07        |
| _max_obs        | 1.13        |
| _mean_act       | -0.00796328 |
| _mean_adv       | 1.28e-17    |
| _mean_discrew   | 3.11        |
| _mean_obs       | 0.0464      |
| _min_adv        | -6.2        |
| _min_discrew    | 0.0107      |
| _min_obs        | -1.17       |
| _std_act        | 0.649098    |
| _std_adv        | 1           |
| _std_discrew    | 0.913       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 233
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.984       |
| KL              | 0.00341787  |
| Phi_loss        | 213.066     |
| PolicyEntropy   | 2.07603     |
| PolicyLoss      | -0.024826   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0116      |
| _MeanReward     | 3.86e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58004     |
| _max_adv        | 7.59        |
| _max_discrew    | 4.22        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00351675 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.19        |
| _mean_obs       | 0.0478      |
| _min_adv        | -4.01       |
| _min_discrew    | 0.0124      |
| _min_obs        | -1.21       |
| _std_act        | 0.649811    |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 234
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.989      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0021362  |
| Phi_loss        | 267.718    |
| PolicyEntropy   | 2.04903    |
| PolicyLoss      | -0.0155307 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0129     |
| _MeanReward     | 3.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.23003    |
| _max_adv        | 8.89       |
| _max_discrew    | 4.09       |
| _max_obs        | 1.43       |
| _mean_act       | -0.0134593 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.1        |
| _mean_obs       | 0.0465     |
| _min_adv        | -17.9      |
| _min_discrew    | -0.641     |
| _min_obs        | -1.07      |
| _std_act        | 0.668962   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 235
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.941       |
| ExplainedVarOld | 0.936       |
| KL              | 0.00907807  |
| Phi_loss        | 285.617     |
| PolicyEntropy   | 2.04595     |
| PolicyLoss      | 0.0715024   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0731      |
| _MeanReward     | 3.82e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74119     |
| _max_adv        | 3.52        |
| _max_discrew    | 4.12        |
| _max_obs        | 1.2         |
| _mean_act       | -0.00358562 |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0468      |
| _min_adv        | -6.4        |
| _min_discrew    | 0.0123      |
| _min_obs        | -1.15       |
| _std_act        | 0.655987    |
| _std_adv        | 1           |
| _std_discrew    | 0.972       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 236
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.99        |
| KL              | 0.0012495   |
| Phi_loss        | 274.223     |
| PolicyEntropy   | 2.04336     |
| PolicyLoss      | -0.0146915  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00972     |
| _MeanReward     | 3.8e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.55142     |
| _max_adv        | 6.55        |
| _max_discrew    | 4.12        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00653216 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.15        |
| _mean_obs       | 0.0463      |
| _min_adv        | -14         |
| _min_discrew    | 0.0122      |
| _min_obs        | -1.25       |
| _std_act        | 0.652685    |
| _std_adv        | 1           |
| _std_discrew    | 0.944       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 237
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.983       |
| ExplainedVarOld | 0.979       |
| KL              | 0.00155816  |
| Phi_loss        | 214.184     |
| PolicyEntropy   | 2.0262      |
| PolicyLoss      | -0.00536442 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0157      |
| _MeanReward     | 3.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.7229      |
| _max_adv        | 7.57        |
| _max_discrew    | 4.16        |
| _max_obs        | 1.31        |
| _mean_act       | -0.00123768 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.18        |
| _mean_obs       | 0.0472      |
| _min_adv        | -4.02       |
| _min_discrew    | 0.0106      |
| _min_obs        | -1.1        |
| _std_act        | 0.662479    |
| _std_adv        | 1           |
| _std_discrew    | 0.998       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 238
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.99        |
| KL              | 0.00257274  |
| Phi_loss        | 306.437     |
| PolicyEntropy   | 1.99759     |
| PolicyLoss      | -0.0289737  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0104      |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.69921     |
| _max_adv        | 4.65        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00205307 |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 3.24        |
| _mean_obs       | 0.0475      |
| _min_adv        | -4.9        |
| _min_discrew    | 0.012       |
| _min_obs        | -1.11       |
| _std_act        | 0.668755    |
| _std_adv        | 1           |
| _std_discrew    | 0.989       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 239
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.992       |
| ExplainedVarOld | 0.992       |
| KL              | 0.00213321  |
| Phi_loss        | 289.796     |
| PolicyEntropy   | 1.97016     |
| PolicyLoss      | -0.0206043  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00873     |
| _MeanReward     | 3.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73247     |
| _max_adv        | 4.26        |
| _max_discrew    | 4.19        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00534782 |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.17        |
| _mean_obs       | 0.0467      |
| _min_adv        | -14.4       |
| _min_discrew    | 0.0106      |
| _min_obs        | -1.13       |
| _std_act        | 0.664119    |
| _std_adv        | 1           |
| _std_discrew    | 0.966       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 240
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.965       |
| ExplainedVarOld | 0.961       |
| KL              | 0.00193482  |
| Phi_loss        | 260.826     |
| PolicyEntropy   | 1.94607     |
| PolicyLoss      | -0.00676304 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0347      |
| _MeanReward     | 3.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.06869     |
| _max_adv        | 2.6         |
| _max_discrew    | 4.19        |
| _max_obs        | 1.43        |
| _mean_act       | -0.0113378  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 3.05        |
| _mean_obs       | 0.0459      |
| _min_adv        | -18.9       |
| _min_discrew    | -0.962      |
| _min_obs        | -1.15       |
| _std_act        | 0.697569    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 241
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.89        |
| ExplainedVarOld | 0.883       |
| KL              | 0.00184988  |
| Phi_loss        | 224.687     |
| PolicyEntropy   | 1.93834     |
| PolicyLoss      | 0.00460247  |
| Steps           | 10000       |
| VarFuncLoss     | 0.165       |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.78582     |
| _max_adv        | 8.91        |
| _max_discrew    | 4.21        |
| _max_obs        | 1.1         |
| _mean_act       | -0.00467274 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.23        |
| _mean_obs       | 0.0467      |
| _min_adv        | -4.04       |
| _min_discrew    | 0.0137      |
| _min_obs        | -1.12       |
| _std_act        | 0.668091    |
| _std_adv        | 1           |
| _std_discrew    | 1.03        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 242
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.989       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00226378  |
| Phi_loss        | 253.135     |
| PolicyEntropy   | 1.90551     |
| PolicyLoss      | -0.0171847  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0132      |
| _MeanReward     | 3.91e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72088     |
| _max_adv        | 25          |
| _max_discrew    | 4.21        |
| _max_obs        | 1.17        |
| _mean_act       | -0.00223373 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.24        |
| _mean_obs       | 0.0473      |
| _min_adv        | -12.5       |
| _min_discrew    | 0.0107      |
| _min_obs        | -1.16       |
| _std_act        | 0.668672    |
| _std_adv        | 1           |
| _std_discrew    | 0.987       |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 243
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.982       |
| ExplainedVarOld | 0.971       |
| KL              | 0.00274698  |
| Phi_loss        | 183.073     |
| PolicyEntropy   | 1.90034     |
| PolicyLoss      | -0.0120821  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0182      |
| _MeanReward     | 4.01e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.76875     |
| _max_adv        | 10.9        |
| _max_discrew    | 4.3         |
| _max_obs        | 1.27        |
| _mean_act       | -0.00312803 |
| _mean_adv       | 2.42e-17    |
| _mean_discrew   | 3.3         |
| _mean_obs       | 0.0478      |
| _min_adv        | -4.67       |
| _min_discrew    | 0.00938     |
| _min_obs        | -1.11       |
| _std_act        | 0.67512     |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 244
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.992        |
| ExplainedVarOld | 0.991        |
| KL              | 0.00195194   |
| Phi_loss        | 334.923      |
| PolicyEntropy   | 1.87085      |
| PolicyLoss      | -0.0214329   |
| Steps           | 10000        |
| VarFuncLoss     | 0.00961      |
| _MeanReward     | 3.96e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.71576      |
| _max_adv        | 19.4         |
| _max_discrew    | 4.25         |
| _max_obs        | 1.17         |
| _mean_act       | -0.000745483 |
| _mean_adv       | -1.14e-17    |
| _mean_discrew   | 3.28         |
| _mean_obs       | 0.0471       |
| _min_adv        | -8.43        |
| _min_discrew    | 0.00801      |
| _min_obs        | -1.2         |
| _std_act        | 0.673393     |
| _std_adv        | 1            |
| _std_discrew    | 1.04         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 245
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00218363 |
| Phi_loss        | 289.671    |
| PolicyEntropy   | 1.8384     |
| PolicyLoss      | -0.028472  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00649    |
| _MeanReward     | 4.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.96065    |
| _max_adv        | 3.43       |
| _max_discrew    | 4.32       |
| _max_obs        | 1.22       |
| _mean_act       | 0.00171456 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.33       |
| _mean_obs       | 0.0483     |
| _min_adv        | -5.67      |
| _min_discrew    | 0.0112     |
| _min_obs        | -1.16      |
| _std_act        | 0.678693   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 246
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.993       |
| KL              | 0.0020663   |
| Phi_loss        | 332.399     |
| PolicyEntropy   | 1.80994     |
| PolicyLoss      | -0.00891536 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00794     |
| _MeanReward     | 3.99e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.83097     |
| _max_adv        | 3.77        |
| _max_discrew    | 4.38        |
| _max_obs        | 1.25        |
| _mean_act       | -0.00181899 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.31        |
| _mean_obs       | 0.0475      |
| _min_adv        | -16.5       |
| _min_discrew    | 0.0135      |
| _min_obs        | -1.24       |
| _std_act        | 0.678368    |
| _std_adv        | 1           |
| _std_discrew    | 1.06        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 247
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.988       |
| ExplainedVarOld | 0.987       |
| KL              | 0.00231874  |
| Phi_loss        | 285.369     |
| PolicyEntropy   | 1.78267     |
| PolicyLoss      | -0.00509011 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0125      |
| _MeanReward     | 4.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.72737     |
| _max_adv        | 7.74        |
| _max_discrew    | 4.47        |
| _max_obs        | 1.13        |
| _mean_act       | 0.000906961 |
| _mean_adv       | 3.98e-17    |
| _mean_discrew   | 3.33        |
| _mean_obs       | 0.0484      |
| _min_adv        | -4.78       |
| _min_discrew    | 0.00541     |
| _min_obs        | -1.12       |
| _std_act        | 0.682268    |
| _std_adv        | 1           |
| _std_discrew    | 1.11        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 248
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00233839 |
| Phi_loss        | 329.075    |
| PolicyEntropy   | 1.77416    |
| PolicyLoss      | -0.0204114 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00947    |
| _MeanReward     | 4.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.842      |
| _max_adv        | 5.62       |
| _max_discrew    | 4.39       |
| _max_obs        | 1.08       |
| _mean_act       | 0.0012794  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.36       |
| _mean_obs       | 0.0486     |
| _min_adv        | -4.07      |
| _min_discrew    | 0.00972    |
| _min_obs        | -1.24      |
| _std_act        | 0.682723   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 249
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.991      |
| KL              | 0.0018468  |
| Phi_loss        | 332.643    |
| PolicyEntropy   | 1.75058    |
| PolicyLoss      | -0.0386011 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00958    |
| _MeanReward     | 4.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82979    |
| _max_adv        | 3.52       |
| _max_discrew    | 4.36       |
| _max_obs        | 1.17       |
| _mean_act       | 0.00201578 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.34       |
| _mean_obs       | 0.0478     |
| _min_adv        | -5.79      |
| _min_discrew    | 0.0125     |
| _min_obs        | -1.07      |
| _std_act        | 0.684179   |
| _std_adv        | 1          |
| _std_discrew    | 1.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 250
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.991       |
| KL              | 0.00230279  |
| Phi_loss        | 310.943     |
| PolicyEntropy   | 1.70982     |
| PolicyLoss      | -0.0026366  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00736     |
| _MeanReward     | 4.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66432     |
| _max_adv        | 3.39        |
| _max_discrew    | 4.38        |
| _max_obs        | 1.19        |
| _mean_act       | 0.000827089 |
| _mean_adv       | -4.55e-17   |
| _mean_discrew   | 3.39        |
| _mean_obs       | 0.0483      |
| _min_adv        | -5.12       |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.16       |
| _std_act        | 0.686039    |
| _std_adv        | 1           |
| _std_discrew    | 1.13        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 251
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00198006  |
| Phi_loss        | 357.326     |
| PolicyEntropy   | 1.68194     |
| PolicyLoss      | -0.0259176  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00649     |
| _MeanReward     | 4.08e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.59762     |
| _max_adv        | 2.97        |
| _max_discrew    | 4.33        |
| _max_obs        | 1.24        |
| _mean_act       | 0.000849642 |
| _mean_adv       | 4.55e-17    |
| _mean_discrew   | 3.36        |
| _mean_obs       | 0.048       |
| _min_adv        | -6.42       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.16       |
| _std_act        | 0.695216    |
| _std_adv        | 1           |
| _std_discrew    | 1.08        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 252
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00237113 |
| Phi_loss        | 339.624    |
| PolicyEntropy   | 1.66133    |
| PolicyLoss      | -0.0451572 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00708    |
| _MeanReward     | 4.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56386    |
| _max_adv        | 3.08       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0037002  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0485     |
| _min_adv        | -6.15      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.14      |
| _std_act        | 0.701357   |
| _std_adv        | 1          |
| _std_discrew    | 1.09       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 253
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.0022138  |
| Phi_loss        | 368.793    |
| PolicyEntropy   | 1.63785    |
| PolicyLoss      | -0.0216766 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00989    |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79422    |
| _max_adv        | 3.97       |
| _max_discrew    | 4.45       |
| _max_obs        | 1.14       |
| _mean_act       | 0.00261627 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0492     |
| _min_adv        | -4.82      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.09      |
| _std_act        | 0.700431   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 254
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.991      |
| KL              | 0.0024557  |
| Phi_loss        | 362.521    |
| PolicyEntropy   | 1.60309    |
| PolicyLoss      | -0.0238747 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00835    |
| _MeanReward     | 4.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77164    |
| _max_adv        | 12.5       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.32       |
| _mean_act       | 0.00163569 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.44       |
| _mean_obs       | 0.0489     |
| _min_adv        | -8.23      |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.2       |
| _std_act        | 0.699282   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 255
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00281146 |
| Phi_loss        | 355.916    |
| PolicyEntropy   | 1.58779    |
| PolicyLoss      | -0.0227726 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00924    |
| _MeanReward     | 3.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.05524    |
| _max_adv        | 1.78       |
| _max_discrew    | 4.52       |
| _max_obs        | 1.47       |
| _mean_act       | -0.01276   |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0468     |
| _min_adv        | -16.8      |
| _min_discrew    | -1.17      |
| _min_obs        | -1.04      |
| _std_act        | 0.76193    |
| _std_adv        | 1          |
| _std_discrew    | 2.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 256
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.897      |
| ExplainedVarOld | 0.884      |
| KL              | 0.00284102 |
| Phi_loss        | 215.247    |
| PolicyEntropy   | 1.5833     |
| PolicyLoss      | -0.0253554 |
| Steps           | 10000      |
| VarFuncLoss     | 0.234      |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.80825    |
| _max_adv        | 19.7       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.15       |
| _mean_act       | 0.00254928 |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 3.42       |
| _mean_obs       | 0.0486     |
| _min_adv        | -15.4      |
| _min_discrew    | 0.0159     |
| _min_obs        | -1.15      |
| _std_act        | 0.706237   |
| _std_adv        | 1          |
| _std_discrew    | 1.15       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 257
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.981     |
| ExplainedVarOld | 0.977     |
| KL              | 0.0214169 |
| Phi_loss        | 343.267   |
| PolicyEntropy   | 1.59153   |
| PolicyLoss      | -0.394278 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0231    |
| _MeanReward     | 4.15e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.77637   |
| _max_adv        | 8.35      |
| _max_discrew    | 4.38      |
| _max_obs        | 1.28      |
| _mean_act       | 0.0124818 |
| _mean_adv       | 3.98e-17  |
| _mean_discrew   | 3.42      |
| _mean_obs       | 0.0487    |
| _min_adv        | -5.8      |
| _min_discrew    | 0.0163    |
| _min_obs        | -1.23     |
| _std_act        | 0.698448  |
| _std_adv        | 1         |
| _std_discrew    | 1.11      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 258
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.0037394  |
| Phi_loss        | 431.018    |
| PolicyEntropy   | 1.58124    |
| PolicyLoss      | -0.0227157 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00642    |
| _MeanReward     | 4.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.10528    |
| _max_adv        | 9.51       |
| _max_discrew    | 4.46       |
| _max_obs        | 1.15       |
| _mean_act       | 0.013216   |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0488     |
| _min_adv        | -4.89      |
| _min_discrew    | 0.012      |
| _min_obs        | -1.13      |
| _std_act        | 0.704853   |
| _std_adv        | 1          |
| _std_discrew    | 1.1        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 259
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00108267 |
| Phi_loss        | 446.829    |
| PolicyEntropy   | 1.56557    |
| PolicyLoss      | -0.0328545 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00893    |
| _MeanReward     | 4.21e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6752     |
| _max_adv        | 3.56       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0137874  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0496     |
| _min_adv        | -6.42      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.14      |
| _std_act        | 0.712848   |
| _std_adv        | 1          |
| _std_discrew    | 1.17       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 260
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00165892 |
| Phi_loss        | 432.865    |
| PolicyEntropy   | 1.54547    |
| PolicyLoss      | -0.0435648 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00704    |
| _MeanReward     | 4.2e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.6412     |
| _max_adv        | 6.86       |
| _max_discrew    | 4.54       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0120867  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0492     |
| _min_adv        | -5.48      |
| _min_discrew    | 0.0116     |
| _min_obs        | -1.18      |
| _std_act        | 0.709845   |
| _std_adv        | 1          |
| _std_discrew    | 1.16       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 261
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00235556 |
| Phi_loss        | 441.79     |
| PolicyEntropy   | 1.48923    |
| PolicyLoss      | -0.030488  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00873    |
| _MeanReward     | 4.19e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.6896     |
| _max_adv        | 7.59       |
| _max_discrew    | 4.48       |
| _max_obs        | 1.14       |
| _mean_act       | 0.012505   |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.46       |
| _mean_obs       | 0.0492     |
| _min_adv        | -16        |
| _min_discrew    | 0.0144     |
| _min_obs        | -1.09      |
| _std_act        | 0.717654   |
| _std_adv        | 1          |
| _std_discrew    | 1.12       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 262
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.983      |
| ExplainedVarOld | 0.982      |
| KL              | 0.00209673 |
| Phi_loss        | 439.439    |
| PolicyEntropy   | 1.46792    |
| PolicyLoss      | -0.0345276 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0193     |
| _MeanReward     | 4.25e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71079    |
| _max_adv        | 10.2       |
| _max_discrew    | 4.49       |
| _max_obs        | 1.17       |
| _mean_act       | 0.0133116  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.5        |
| _mean_obs       | 0.0497     |
| _min_adv        | -6.65      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.16      |
| _std_act        | 0.713638   |
| _std_adv        | 1          |
| _std_discrew    | 1.19       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 263
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00213173 |
| Phi_loss        | 460.575    |
| PolicyEntropy   | 1.43049    |
| PolicyLoss      | 0.00461089 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00905    |
| _MeanReward     | 4.26e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72928    |
| _max_adv        | 26         |
| _max_discrew    | 4.51       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0120241  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.51       |
| _mean_obs       | 0.0491     |
| _min_adv        | -8.25      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.09      |
| _std_act        | 0.71507    |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 264
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00348307 |
| Phi_loss        | 402.816    |
| PolicyEntropy   | 1.4032     |
| PolicyLoss      | -0.0142086 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00657    |
| _MeanReward     | 4.28e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.84331    |
| _max_adv        | 3.76       |
| _max_discrew    | 4.63       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0122736  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.52       |
| _mean_obs       | 0.0495     |
| _min_adv        | -4.66      |
| _min_discrew    | 0.0128     |
| _min_obs        | -1.11      |
| _std_act        | 0.721485   |
| _std_adv        | 1          |
| _std_discrew    | 1.21       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 265
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00241057 |
| Phi_loss        | 481.854    |
| PolicyEntropy   | 1.37222    |
| PolicyLoss      | -0.0237429 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00676    |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.77451    |
| _max_adv        | 5.72       |
| _max_discrew    | 4.6        |
| _max_obs        | 1.13       |
| _mean_act       | 0.0123065  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0498     |
| _min_adv        | -4.86      |
| _min_discrew    | 0.0124     |
| _min_obs        | -1.06      |
| _std_act        | 0.718151   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 266
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00246547 |
| Phi_loss        | 498.077    |
| PolicyEntropy   | 1.34915    |
| PolicyLoss      | -0.0435938 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00818    |
| _MeanReward     | 4.3e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.73014    |
| _max_adv        | 3.61       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0135731  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 3.54       |
| _mean_obs       | 0.0498     |
| _min_adv        | -5.71      |
| _min_discrew    | 0.0168     |
| _min_obs        | -1.14      |
| _std_act        | 0.724484   |
| _std_adv        | 1          |
| _std_discrew    | 1.2        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 267
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00198331  |
| Phi_loss        | 498.78      |
| PolicyEntropy   | 1.32682     |
| PolicyLoss      | -0.00413513 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00831     |
| _MeanReward     | 4.33e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.8061      |
| _max_adv        | 5.09        |
| _max_discrew    | 4.63        |
| _max_obs        | 1.14        |
| _mean_act       | 0.0149494   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.58        |
| _mean_obs       | 0.0498      |
| _min_adv        | -4.4        |
| _min_discrew    | 0.014       |
| _min_obs        | -1.06       |
| _std_act        | 0.732217    |
| _std_adv        | 1           |
| _std_discrew    | 1.22        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 268
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.0022147  |
| Phi_loss        | 504.646    |
| PolicyEntropy   | 1.29296    |
| PolicyLoss      | -0.0154047 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0073     |
| _MeanReward     | 4.34e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66121    |
| _max_adv        | 3.08       |
| _max_discrew    | 4.6        |
| _max_obs        | 1.2        |
| _mean_act       | 0.0136789  |
| _mean_adv       | -3.13e-17  |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0505     |
| _min_adv        | -6.84      |
| _min_discrew    | 0.0156     |
| _min_obs        | -1.18      |
| _std_act        | 0.731254   |
| _std_adv        | 1          |
| _std_discrew    | 1.23       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 269
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00176718 |
| Phi_loss        | 553.159    |
| PolicyEntropy   | 1.2713     |
| PolicyLoss      | -0.0296493 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00895    |
| _MeanReward     | 4.33e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66347    |
| _max_adv        | 3.39       |
| _max_discrew    | 4.63       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0156607  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0496     |
| _min_adv        | -6.24      |
| _min_discrew    | 0.0126     |
| _min_obs        | -1.09      |
| _std_act        | 0.722074   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 270
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00216155 |
| Phi_loss        | 544.878    |
| PolicyEntropy   | 1.2425     |
| PolicyLoss      | -0.0385584 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00887    |
| _MeanReward     | 4.32e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72041    |
| _max_adv        | 3.7        |
| _max_discrew    | 4.63       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0120672  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.56       |
| _mean_obs       | 0.0495     |
| _min_adv        | -4.79      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.06      |
| _std_act        | 0.728302   |
| _std_adv        | 1          |
| _std_discrew    | 1.22       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 271
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00213695 |
| Phi_loss        | 568.189    |
| PolicyEntropy   | 1.21155    |
| PolicyLoss      | -0.0140444 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00819    |
| _MeanReward     | 4.23e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.75657    |
| _max_adv        | 4.11       |
| _max_discrew    | 4.68       |
| _max_obs        | 1.13       |
| _mean_act       | 0.00911747 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.47       |
| _mean_obs       | 0.0491     |
| _min_adv        | -11.4      |
| _min_discrew    | -0.0257    |
| _min_obs        | -1.12      |
| _std_act        | 0.73295    |
| _std_adv        | 1          |
| _std_discrew    | 1.27       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 272
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.925      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00625599 |
| Phi_loss        | 403.749    |
| PolicyEntropy   | 1.20116    |
| PolicyLoss      | -0.0149486 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0962     |
| _MeanReward     | 4.41e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.71928    |
| _max_adv        | 17.9       |
| _max_discrew    | 4.74       |
| _max_obs        | 1.22       |
| _mean_act       | 0.0157647  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.62       |
| _mean_obs       | 0.0502     |
| _min_adv        | -4.32      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.13      |
| _std_act        | 0.739045   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 273
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.99       |
| KL              | 0.00129156 |
| Phi_loss        | 526.823    |
| PolicyEntropy   | 1.18837    |
| PolicyLoss      | -0.0281229 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0156     |
| _MeanReward     | 4.35e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.58672    |
| _max_adv        | 7.33       |
| _max_discrew    | 4.67       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0105676  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.58       |
| _mean_obs       | 0.0495     |
| _min_adv        | -17.1      |
| _min_discrew    | 0.0191     |
| _min_obs        | -1.05      |
| _std_act        | 0.738468   |
| _std_adv        | 1          |
| _std_discrew    | 1.24       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 274
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.973       |
| KL              | 0.00217843  |
| Phi_loss        | 520.299     |
| PolicyEntropy   | 1.16632     |
| PolicyLoss      | -0.00263384 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0291      |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6336      |
| _max_adv        | 12.6        |
| _max_discrew    | 4.76        |
| _max_obs        | 1.19        |
| _mean_act       | 0.0141484   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0501      |
| _min_adv        | -5.1        |
| _min_discrew    | 0.0169      |
| _min_obs        | -1.1        |
| _std_act        | 0.747237    |
| _std_adv        | 1           |
| _std_discrew    | 1.27        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 275
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00167346  |
| Phi_loss        | 527.005     |
| PolicyEntropy   | 1.13974     |
| PolicyLoss      | -0.00243767 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00726     |
| _MeanReward     | 4.45e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66765     |
| _max_adv        | 7.86        |
| _max_discrew    | 4.69        |
| _max_obs        | 1.11        |
| _mean_act       | 0.0145771   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.66        |
| _mean_obs       | 0.0499      |
| _min_adv        | -5.03       |
| _min_discrew    | 0.0156      |
| _min_obs        | -1.06       |
| _std_act        | 0.744461    |
| _std_adv        | 1           |
| _std_discrew    | 1.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 276
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00189708  |
| Phi_loss        | 558.301     |
| PolicyEntropy   | 1.11764     |
| PolicyLoss      | -0.00626794 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00587     |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.88455     |
| _max_adv        | 6.36        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.26        |
| _mean_act       | 0.0106048   |
| _mean_adv       | -1.71e-17   |
| _mean_discrew   | 3.59        |
| _mean_obs       | 0.0492      |
| _min_adv        | -18.2       |
| _min_discrew    | 0.0137      |
| _min_obs        | -1.09       |
| _std_act        | 0.741648    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 277
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.953       |
| KL              | 0.00275285  |
| Phi_loss        | 510.896     |
| PolicyEntropy   | 1.09103     |
| PolicyLoss      | 0.000966964 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0544      |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74784     |
| _max_adv        | 12.6        |
| _max_discrew    | 4.72        |
| _max_obs        | 1.24        |
| _mean_act       | 0.0166331   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0499      |
| _min_adv        | -7.03       |
| _min_discrew    | 0.0178      |
| _min_obs        | -1.04       |
| _std_act        | 0.741964    |
| _std_adv        | 1           |
| _std_discrew    | 1.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 278
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00182782 |
| Phi_loss        | 543.287    |
| PolicyEntropy   | 1.07044    |
| PolicyLoss      | -0.0267664 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0113     |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.06353    |
| _max_adv        | 5.86       |
| _max_discrew    | 4.81       |
| _max_obs        | 1.53       |
| _mean_act       | 0.00504623 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.41       |
| _mean_obs       | 0.0481     |
| _min_adv        | -19.5      |
| _min_discrew    | -1.16      |
| _min_obs        | -1.15      |
| _std_act        | 0.790243   |
| _std_adv        | 1          |
| _std_discrew    | 2.02       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 279
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.892      |
| ExplainedVarOld | 0.886      |
| KL              | 0.00388817 |
| Phi_loss        | 527.918    |
| PolicyEntropy   | 1.06181    |
| PolicyLoss      | -0.0119876 |
| Steps           | 10000      |
| VarFuncLoss     | 0.221      |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70773    |
| _max_adv        | 22.4       |
| _max_discrew    | 4.69       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0115315  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.64       |
| _mean_obs       | 0.0495     |
| _min_adv        | -5.36      |
| _min_discrew    | 0.0139     |
| _min_obs        | -1.11      |
| _std_act        | 0.744366   |
| _std_adv        | 1          |
| _std_discrew    | 1.26       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 280
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00251591 |
| Phi_loss        | 481.341    |
| PolicyEntropy   | 1.04142    |
| PolicyLoss      | -0.0275408 |
| Steps           | 10000      |
| VarFuncLoss     | 0.011      |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57151    |
| _max_adv        | 6.77       |
| _max_discrew    | 4.72       |
| _max_obs        | 1.29       |
| _mean_act       | 0.0155511  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0498     |
| _min_adv        | -7.35      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.03      |
| _std_act        | 0.74704    |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 281
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.992      |
| ExplainedVarOld | 0.99       |
| KL              | 0.00174633 |
| Phi_loss        | 557.339    |
| PolicyEntropy   | 1.02055    |
| PolicyLoss      | -0.0119637 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0102     |
| _MeanReward     | 4.42e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.69805    |
| _max_adv        | 3.26       |
| _max_discrew    | 4.7        |
| _max_obs        | 1.17       |
| _mean_act       | 0.0129773  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.66       |
| _mean_obs       | 0.0491     |
| _min_adv        | -7.67      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.09      |
| _std_act        | 0.742096   |
| _std_adv        | 1          |
| _std_discrew    | 1.28       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 282
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00203569  |
| Phi_loss        | 498.547     |
| PolicyEntropy   | 0.9825      |
| PolicyLoss      | -0.00242505 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00688     |
| _MeanReward     | 4.43e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.77108     |
| _max_adv        | 28.5        |
| _max_discrew    | 4.74        |
| _max_obs        | 1.18        |
| _mean_act       | 0.0132331   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.65        |
| _mean_obs       | 0.0496      |
| _min_adv        | -10.3       |
| _min_discrew    | 0.0159      |
| _min_obs        | -1.11       |
| _std_act        | 0.750279    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 283
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.984     |
| ExplainedVarOld | 0.979     |
| KL              | 0.0123665 |
| Phi_loss        | 501.374   |
| PolicyEntropy   | 0.970234  |
| PolicyLoss      | -0.132967 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0219    |
| _MeanReward     | 4.47e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.72992   |
| _max_adv        | 8.19      |
| _max_discrew    | 4.75      |
| _max_obs        | 1.12      |
| _mean_act       | 0.0142104 |
| _mean_adv       | -2.7e-17  |
| _mean_discrew   | 3.68      |
| _mean_obs       | 0.0495    |
| _min_adv        | -7.94     |
| _min_discrew    | 0.0181    |
| _min_obs        | -1.06     |
| _std_act        | 0.758771  |
| _std_adv        | 1         |
| _std_discrew    | 1.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 284
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00218762 |
| Phi_loss        | 538.843    |
| PolicyEntropy   | 0.951094   |
| PolicyLoss      | 0.00166079 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00643    |
| _MeanReward     | 4.49e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.72213    |
| _max_adv        | 14.7       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0154751  |
| _mean_adv       | 2.7e-17    |
| _mean_discrew   | 3.7        |
| _mean_obs       | 0.0498     |
| _min_adv        | -4.88      |
| _min_discrew    | 0.0137     |
| _min_obs        | -1.07      |
| _std_act        | 0.758737   |
| _std_adv        | 1          |
| _std_discrew    | 1.29       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 285
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.994       |
| KL              | 0.000967174 |
| Phi_loss        | 560.585     |
| PolicyEntropy   | 0.94385     |
| PolicyLoss      | -0.0310327  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00628     |
| _MeanReward     | 4.51e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.60874     |
| _max_adv        | 4.53        |
| _max_discrew    | 4.8         |
| _max_obs        | 1.09        |
| _mean_act       | 0.0151696   |
| _mean_adv       | -2.2e-17    |
| _mean_discrew   | 3.71        |
| _mean_obs       | 0.0496      |
| _min_adv        | -4.28       |
| _min_discrew    | 0.0115      |
| _min_obs        | -1.29       |
| _std_act        | 0.760876    |
| _std_adv        | 1           |
| _std_discrew    | 1.33        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 286
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00172535 |
| Phi_loss        | 654.019    |
| PolicyEntropy   | 0.935557   |
| PolicyLoss      | -0.0165694 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00507    |
| _MeanReward     | 4.38e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67093    |
| _max_adv        | 2.33       |
| _max_discrew    | 4.76       |
| _max_obs        | 1.24       |
| _mean_act       | 0.0137472  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.63       |
| _mean_obs       | 0.0492     |
| _min_adv        | -16.7      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.06      |
| _std_act        | 0.774785   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 287
Draw Samples..
----------------------------------
| Beta            | 0.444        |
| ExplainedVarNew | 0.931        |
| ExplainedVarOld | 0.916        |
| KL              | 0.00387966   |
| Phi_loss        | 488.231      |
| PolicyEntropy   | 0.938509     |
| PolicyLoss      | -0.000929782 |
| Steps           | 10000        |
| VarFuncLoss     | 0.094        |
| _MeanReward     | 4.5e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 3.21327      |
| _max_adv        | 6.48         |
| _max_discrew    | 4.71         |
| _max_obs        | 1.2          |
| _mean_act       | 0.0156007    |
| _mean_adv       | 0            |
| _mean_discrew   | 3.72         |
| _mean_obs       | 0.0493       |
| _min_adv        | -6.25        |
| _min_discrew    | 0.0186       |
| _min_obs        | -1.08        |
| _std_act        | 0.761348     |
| _std_adv        | 1            |
| _std_discrew    | 1.31         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 288
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00225322 |
| Phi_loss        | 644.423    |
| PolicyEntropy   | 0.91186    |
| PolicyLoss      | -0.018529  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0101     |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62083    |
| _max_adv        | 4.54       |
| _max_discrew    | 4.77       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0154796  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.0487     |
| _min_adv        | -4.79      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.06      |
| _std_act        | 0.757609   |
| _std_adv        | 1          |
| _std_discrew    | 1.31       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 289
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.988      |
| KL              | 0.001837   |
| Phi_loss        | 565.469    |
| PolicyEntropy   | 0.901983   |
| PolicyLoss      | -0.0177081 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 4.51e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73782    |
| _max_adv        | 3.52       |
| _max_discrew    | 4.84       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0177797  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.72       |
| _mean_obs       | 0.0493     |
| _min_adv        | -4.66      |
| _min_discrew    | 0.0139     |
| _min_obs        | -1.06      |
| _std_act        | 0.766819   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 290
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00189592 |
| Phi_loss        | 649.777    |
| PolicyEntropy   | 0.859912   |
| PolicyLoss      | -0.0194891 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00702    |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.73064    |
| _max_adv        | 14.3       |
| _max_discrew    | 4.79       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0142472  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.75       |
| _mean_obs       | 0.0496     |
| _min_adv        | -17.2      |
| _min_discrew    | 0.0192     |
| _min_obs        | -1.09      |
| _std_act        | 0.770835   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 291
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.978     |
| KL              | 0.0144464 |
| Phi_loss        | 418.076   |
| PolicyEntropy   | 0.847614  |
| PolicyLoss      | -0.336644 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0167    |
| _MeanReward     | 4.56e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.67282   |
| _max_adv        | 7.3       |
| _max_discrew    | 4.79      |
| _max_obs        | 1.15      |
| _mean_act       | 0.0147153 |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 3.75      |
| _mean_obs       | 0.0496    |
| _min_adv        | -5.7      |
| _min_discrew    | 0.0211    |
| _min_obs        | -1.08     |
| _std_act        | 0.770007  |
| _std_adv        | 1         |
| _std_discrew    | 1.36      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 292
Draw Samples..
---------------------------------
| Beta            | 0.667       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.995       |
| KL              | 0.0023629   |
| Phi_loss        | 720.011     |
| PolicyEntropy   | 0.838101    |
| PolicyLoss      | -0.00382144 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00578     |
| _MeanReward     | 4.55e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55253     |
| _max_adv        | 22.9        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.2         |
| _mean_act       | 0.0142396   |
| _mean_adv       | -2.56e-17   |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0491      |
| _min_adv        | -5.62       |
| _min_discrew    | 0.013       |
| _min_obs        | -1.07       |
| _std_act        | 0.770896    |
| _std_adv        | 1           |
| _std_discrew    | 1.34        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 293
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00129898  |
| Phi_loss        | 715.79      |
| PolicyEntropy   | 0.811884    |
| PolicyLoss      | -0.00563808 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00582     |
| _MeanReward     | 4.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67324     |
| _max_adv        | 40.5        |
| _max_discrew    | 4.86        |
| _max_obs        | 1.2         |
| _mean_act       | 0.0200913   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.78        |
| _mean_obs       | 0.0498      |
| _min_adv        | -6.96       |
| _min_discrew    | 0.015       |
| _min_obs        | -1.04       |
| _std_act        | 0.767185    |
| _std_adv        | 1           |
| _std_discrew    | 1.36        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 294
Draw Samples..
-------------------------------
| Beta            | 0.667     |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.996     |
| KL              | 0.0130857 |
| Phi_loss        | 1556.55   |
| PolicyEntropy   | 0.808293  |
| PolicyLoss      | -0.263864 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00581   |
| _MeanReward     | 4.58e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.63971   |
| _max_adv        | 3.44      |
| _max_discrew    | 4.85      |
| _max_obs        | 1.22      |
| _mean_act       | 0.0188024 |
| _mean_adv       | 3.41e-17  |
| _mean_discrew   | 3.77      |
| _mean_obs       | 0.0499    |
| _min_adv        | -6.66     |
| _min_discrew    | 0.0106    |
| _min_obs        | -1.15     |
| _std_act        | 0.774641  |
| _std_adv        | 1         |
| _std_discrew    | 1.37      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 295
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00297298 |
| Phi_loss        | 969.07     |
| PolicyEntropy   | 0.808329   |
| PolicyLoss      | -0.0439676 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00691    |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.68213    |
| _max_adv        | 3.57       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0208067  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0499     |
| _min_adv        | -4.23      |
| _min_discrew    | 0.0184     |
| _min_obs        | -1.1       |
| _std_act        | 0.773873   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 296
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.0010697  |
| Phi_loss        | 843.312    |
| PolicyEntropy   | 0.797691   |
| PolicyLoss      | -0.0113881 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0082     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65298    |
| _max_adv        | 16.5       |
| _max_discrew    | 4.8        |
| _max_obs        | 1.18       |
| _mean_act       | 0.0169667  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0485     |
| _min_adv        | -4.04      |
| _min_discrew    | 0.0126     |
| _min_obs        | -1.12      |
| _std_act        | 0.769551   |
| _std_adv        | 1          |
| _std_discrew    | 1.32       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 297
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.992       |
| KL              | 0.00145027  |
| Phi_loss        | 820.236     |
| PolicyEntropy   | 0.772295    |
| PolicyLoss      | -0.00822155 |
| Steps           | 10000       |
| VarFuncLoss     | 0.01        |
| _MeanReward     | 4.57e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.67436     |
| _max_adv        | 4.16        |
| _max_discrew    | 5.01        |
| _max_obs        | 1.13        |
| _mean_act       | 0.0194053   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0494      |
| _min_adv        | -13.4       |
| _min_discrew    | 0.016       |
| _min_obs        | -1.12       |
| _std_act        | 0.777697    |
| _std_adv        | 1           |
| _std_discrew    | 1.38        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 298
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.983     |
| ExplainedVarOld | 0.981     |
| KL              | 0.0064523 |
| Phi_loss        | 708.99    |
| PolicyEntropy   | 0.741995  |
| PolicyLoss      | 0.0102713 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0246    |
| _MeanReward     | 4.57e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.77784   |
| _max_adv        | 5.02      |
| _max_discrew    | 4.86      |
| _max_obs        | 1.11      |
| _mean_act       | 0.01944   |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.78      |
| _mean_obs       | 0.0493    |
| _min_adv        | -10.1     |
| _min_discrew    | 0.0116    |
| _min_obs        | -1.1      |
| _std_act        | 0.773799  |
| _std_adv        | 1         |
| _std_discrew    | 1.35      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 299
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00260149 |
| Phi_loss        | 784.899    |
| PolicyEntropy   | 0.713955   |
| PolicyLoss      | -0.0038957 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00818    |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.86095    |
| _max_adv        | 4.53       |
| _max_discrew    | 4.87       |
| _max_obs        | 1.08       |
| _mean_act       | 0.0184455  |
| _mean_adv       | 9.95e-18   |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0489     |
| _min_adv        | -5.65      |
| _min_discrew    | 0.0186     |
| _min_obs        | -1.05      |
| _std_act        | 0.776154   |
| _std_adv        | 1          |
| _std_discrew    | 1.36       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 300
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00211724 |
| Phi_loss        | 789.789    |
| PolicyEntropy   | 0.689673   |
| PolicyLoss      | -0.0127402 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0097     |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.89437    |
| _max_adv        | 7.54       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0180082  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.77       |
| _mean_obs       | 0.0492     |
| _min_adv        | -17.7      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.12      |
| _std_act        | 0.789363   |
| _std_adv        | 1          |
| _std_discrew    | 1.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 301
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.976      |
| KL              | 0.00175415 |
| Phi_loss        | 602.336    |
| PolicyEntropy   | 0.682932   |
| PolicyLoss      | -0.0117204 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0279     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76726    |
| _max_adv        | 11.9       |
| _max_discrew    | 4.88       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0169839  |
| _mean_adv       | -5.97e-17  |
| _mean_discrew   | 3.73       |
| _mean_obs       | 0.0485     |
| _min_adv        | -16.1      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.1       |
| _std_act        | 0.798022   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 302
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.921      |
| KL              | 0.00634016 |
| Phi_loss        | 672.521    |
| PolicyEntropy   | 0.674672   |
| PolicyLoss      | -0.0833744 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0924     |
| _MeanReward     | 4.59e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62762    |
| _max_adv        | 6.89       |
| _max_discrew    | 4.86       |
| _max_obs        | 1.29       |
| _mean_act       | 0.0192394  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.76       |
| _mean_obs       | 0.0489     |
| _min_adv        | -12.9      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.11      |
| _std_act        | 0.788934   |
| _std_adv        | 1          |
| _std_discrew    | 1.47       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 303
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.977      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00139036 |
| Phi_loss        | 705.93     |
| PolicyEntropy   | 0.662281   |
| PolicyLoss      | 0.0106368  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0338     |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65111    |
| _max_adv        | 8.01       |
| _max_discrew    | 4.89       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0188605  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.8        |
| _mean_obs       | 0.0489     |
| _min_adv        | -4.99      |
| _min_discrew    | 0.0149     |
| _min_obs        | -1.14      |
| _std_act        | 0.783729   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 304
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00222148 |
| Phi_loss        | 799.828    |
| PolicyEntropy   | 0.641706   |
| PolicyLoss      | -0.032522  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00894    |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.65168    |
| _max_adv        | 16.8       |
| _max_discrew    | 4.92       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0218004  |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0486     |
| _min_adv        | -8.4       |
| _min_discrew    | 0.0182     |
| _min_obs        | -1.08      |
| _std_act        | 0.78228    |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 305
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.992       |
| KL              | 0.00190657  |
| Phi_loss        | 763.396     |
| PolicyEntropy   | 0.622884    |
| PolicyLoss      | -0.00187039 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0101      |
| _MeanReward     | 4.63e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51194     |
| _max_adv        | 5.66        |
| _max_discrew    | 4.96        |
| _max_obs        | 1.16        |
| _mean_act       | 0.0186885   |
| _mean_adv       | -3.41e-17   |
| _mean_discrew   | 3.82        |
| _mean_obs       | 0.0486      |
| _min_adv        | -5.27       |
| _min_discrew    | 0.0146      |
| _min_obs        | -1.05       |
| _std_act        | 0.789955    |
| _std_adv        | 1           |
| _std_discrew    | 1.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 306
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00233086 |
| Phi_loss        | 838.14     |
| PolicyEntropy   | 0.592403   |
| PolicyLoss      | -0.0268959 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00583    |
| _MeanReward     | 4.48e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 4.24599    |
| _max_adv        | 6.3        |
| _max_discrew    | 4.89       |
| _max_obs        | 1.6        |
| _mean_act       | 0.0147428  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.69       |
| _mean_obs       | 0.048      |
| _min_adv        | -19.4      |
| _min_discrew    | -1.08      |
| _min_obs        | -1.22      |
| _std_act        | 0.826503   |
| _std_adv        | 1          |
| _std_discrew    | 1.8        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 307
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.924      |
| ExplainedVarOld | 0.92       |
| KL              | 0.0019345  |
| Phi_loss        | 819.447    |
| PolicyEntropy   | 0.585466   |
| PolicyLoss      | -0.0162512 |
| Steps           | 10000      |
| VarFuncLoss     | 0.139      |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.00381    |
| _max_adv        | 9.42       |
| _max_discrew    | 4.94       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0224102  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.82       |
| _mean_obs       | 0.0493     |
| _min_adv        | -5.85      |
| _min_discrew    | 0.0166     |
| _min_obs        | -1.07      |
| _std_act        | 0.791544   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 308
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00160557 |
| Phi_loss        | 783.922    |
| PolicyEntropy   | 0.566381   |
| PolicyLoss      | 0.0178694  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0115     |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67385    |
| _max_adv        | 5.67       |
| _max_discrew    | 4.97       |
| _max_obs        | 1.17       |
| _mean_act       | 0.0224469  |
| _mean_adv       | -6.82e-17  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0496     |
| _min_adv        | -4.17      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.11      |
| _std_act        | 0.795518   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 309
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.992      |
| KL              | 0.00134976 |
| Phi_loss        | 758.437    |
| PolicyEntropy   | 0.556623   |
| PolicyLoss      | -0.0200071 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00703    |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62693    |
| _max_adv        | 14.7       |
| _max_discrew    | 4.9        |
| _max_obs        | 1.17       |
| _mean_act       | 0.0207582  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.84       |
| _mean_obs       | 0.0488     |
| _min_adv        | -5.2       |
| _min_discrew    | 0.0185     |
| _min_obs        | -1.13      |
| _std_act        | 0.78999    |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 310
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00350147  |
| Phi_loss        | 830.531     |
| PolicyEntropy   | 0.53126     |
| PolicyLoss      | -0.00547169 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00745     |
| _MeanReward     | 4.7e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.53559     |
| _max_adv        | 4.55        |
| _max_discrew    | 4.96        |
| _max_obs        | 1.16        |
| _mean_act       | 0.0231258   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.85        |
| _mean_obs       | 0.0497      |
| _min_adv        | -4.18       |
| _min_discrew    | 0.0206      |
| _min_obs        | -1.05       |
| _std_act        | 0.79348     |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 311
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00302529 |
| Phi_loss        | 845.169    |
| PolicyEntropy   | 0.494898   |
| PolicyLoss      | 0.0148817  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00681    |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51954    |
| _max_adv        | 4.29       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.24       |
| _mean_act       | 0.0188805  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.0488     |
| _min_adv        | -6.46      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.07      |
| _std_act        | 0.797503   |
| _std_adv        | 1          |
| _std_discrew    | 1.39       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 312
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00322391 |
| Phi_loss        | 762.407    |
| PolicyEntropy   | 0.471154   |
| PolicyLoss      | -0.0134656 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00626    |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.87626    |
| _max_adv        | 24.3       |
| _max_discrew    | 4.94       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0229259  |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 3.87       |
| _mean_obs       | 0.0491     |
| _min_adv        | -12.1      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.06      |
| _std_act        | 0.792843   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 313
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00529198 |
| Phi_loss        | 707.407    |
| PolicyEntropy   | 0.436497   |
| PolicyLoss      | 0.0381563  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00968    |
| _MeanReward     | 4.68e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82238    |
| _max_adv        | 14.6       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0238992  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.049      |
| _min_adv        | -10.8      |
| _min_discrew    | -0.0205    |
| _min_obs        | -1.18      |
| _std_act        | 0.788893   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 314
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00468973  |
| Phi_loss        | 696.528     |
| PolicyEntropy   | 0.409289    |
| PolicyLoss      | -0.00324203 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00685     |
| _MeanReward     | 4.68e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6117      |
| _max_adv        | 4.08        |
| _max_discrew    | 4.98        |
| _max_obs        | 1.2         |
| _mean_act       | 0.0256167   |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.86        |
| _mean_obs       | 0.0486      |
| _min_adv        | -6.67       |
| _min_discrew    | 0.0175      |
| _min_obs        | -1.08       |
| _std_act        | 0.789728    |
| _std_adv        | 1           |
| _std_discrew    | 1.43        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 315
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00327306 |
| Phi_loss        | 866.902    |
| PolicyEntropy   | 0.387851   |
| PolicyLoss      | -0.0221076 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00898    |
| _MeanReward     | 4.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48578    |
| _max_adv        | 4.49       |
| _max_discrew    | 5.06       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0250311  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.9        |
| _mean_obs       | 0.0497     |
| _min_adv        | -4.65      |
| _min_discrew    | 0.0162     |
| _min_obs        | -0.994     |
| _std_act        | 0.795698   |
| _std_adv        | 1          |
| _std_discrew    | 1.47       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 316
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00382219 |
| Phi_loss        | 918.088    |
| PolicyEntropy   | 0.356959   |
| PolicyLoss      | -0.0403389 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00838    |
| _MeanReward     | 4.72e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53269    |
| _max_adv        | 4.33       |
| _max_discrew    | 5          |
| _max_obs        | 1.04       |
| _mean_act       | 0.0248476  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.0491     |
| _min_adv        | -5.87      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.04      |
| _std_act        | 0.799494   |
| _std_adv        | 1          |
| _std_discrew    | 1.43       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 317
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00288137 |
| Phi_loss        | 966.031    |
| PolicyEntropy   | 0.347523   |
| PolicyLoss      | 0.0104786  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00707    |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53424    |
| _max_adv        | 8.29       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0253014  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.88       |
| _mean_obs       | 0.049      |
| _min_adv        | -7.21      |
| _min_discrew    | 0.0176     |
| _min_obs        | -1.05      |
| _std_act        | 0.802197   |
| _std_adv        | 1          |
| _std_discrew    | 1.46       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 318
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00457686 |
| Phi_loss        | 881.043    |
| PolicyEntropy   | 0.332004   |
| PolicyLoss      | -0.0294436 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00712    |
| _MeanReward     | 4.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60519    |
| _max_adv        | 4.09       |
| _max_discrew    | 5.04       |
| _max_obs        | 1.22       |
| _mean_act       | 0.0229606  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 3.91       |
| _mean_obs       | 0.0492     |
| _min_adv        | -4.43      |
| _min_discrew    | 0.0143     |
| _min_obs        | -1.05      |
| _std_act        | 0.808064   |
| _std_adv        | 1          |
| _std_discrew    | 1.44       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 319
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00341731  |
| Phi_loss        | 859.03      |
| PolicyEntropy   | 0.305256    |
| PolicyLoss      | 0.000388875 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00663     |
| _MeanReward     | 4.76e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.73204     |
| _max_adv        | 3.12        |
| _max_discrew    | 5.02        |
| _max_obs        | 1.08        |
| _mean_act       | 0.0272069   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.92        |
| _mean_obs       | 0.0492      |
| _min_adv        | -5.28       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.03       |
| _std_act        | 0.810258    |
| _std_adv        | 1           |
| _std_discrew    | 1.45        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 320
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00395777 |
| Phi_loss        | 899.502    |
| PolicyEntropy   | 0.266753   |
| PolicyLoss      | 0.00420126 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00424    |
| _MeanReward     | 4.75e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55414    |
| _max_adv        | 7.9        |
| _max_discrew    | 5.02       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0247447  |
| _mean_adv       | -3.69e-17  |
| _mean_discrew   | 3.92       |
| _mean_obs       | 0.0496     |
| _min_adv        | -13.4      |
| _min_discrew    | 0.0192     |
| _min_obs        | -1.07      |
| _std_act        | 0.806615   |
| _std_adv        | 1          |
| _std_discrew    | 1.47       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 321
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00508552 |
| Phi_loss        | 789.568    |
| PolicyEntropy   | 0.24159    |
| PolicyLoss      | -0.0374868 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00563    |
| _MeanReward     | 4.77e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49275    |
| _max_adv        | 11.5       |
| _max_discrew    | 5.11       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0262249  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.93       |
| _mean_obs       | 0.0495     |
| _min_adv        | -4.04      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.05      |
| _std_act        | 0.814456   |
| _std_adv        | 1          |
| _std_discrew    | 1.47       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 322
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00368473  |
| Phi_loss        | 949.28      |
| PolicyEntropy   | 0.200423    |
| PolicyLoss      | -0.00809567 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00526     |
| _MeanReward     | 4.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81268     |
| _max_adv        | 4.65        |
| _max_discrew    | 5.11        |
| _max_obs        | 1.1         |
| _mean_act       | 0.0284836   |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 3.94        |
| _mean_obs       | 0.0499      |
| _min_adv        | -4.27       |
| _min_discrew    | 0.0162      |
| _min_obs        | -1.01       |
| _std_act        | 0.817432    |
| _std_adv        | 1           |
| _std_discrew    | 1.45        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 323
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.995       |
| KL              | 0.0028758   |
| Phi_loss        | 983.097     |
| PolicyEntropy   | 0.169531    |
| PolicyLoss      | -0.00763905 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00635     |
| _MeanReward     | 4.74e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.52745     |
| _max_adv        | 4.84        |
| _max_discrew    | 5.06        |
| _max_obs        | 1.13        |
| _mean_act       | 0.0265436   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.88        |
| _mean_obs       | 0.0493      |
| _min_adv        | -16.6       |
| _min_discrew    | 0.0174      |
| _min_obs        | -1.12       |
| _std_act        | 0.814271    |
| _std_adv        | 1           |
| _std_discrew    | 1.47        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 324
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.977       |
| ExplainedVarOld | 0.976       |
| KL              | 0.00479558  |
| Phi_loss        | 743.846     |
| PolicyEntropy   | 0.167529    |
| PolicyLoss      | -0.00386296 |
| Steps           | 10000       |
| VarFuncLoss     | 0.034       |
| _MeanReward     | 4.82e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.41612     |
| _max_adv        | 5.77        |
| _max_discrew    | 5.06        |
| _max_obs        | 1.15        |
| _mean_act       | 0.0255171   |
| _mean_adv       | 0           |
| _mean_discrew   | 3.96        |
| _mean_obs       | 0.0499      |
| _min_adv        | -7.58       |
| _min_discrew    | 0.0118      |
| _min_obs        | -1.03       |
| _std_act        | 0.818865    |
| _std_adv        | 1           |
| _std_discrew    | 1.47        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 325
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00332693 |
| Phi_loss        | 960.665    |
| PolicyEntropy   | 0.140512   |
| PolicyLoss      | -0.0340756 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00907    |
| _MeanReward     | 4.8e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.61035    |
| _max_adv        | 14.3       |
| _max_discrew    | 5.09       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0269862  |
| _mean_adv       | -2.84e-17  |
| _mean_discrew   | 3.96       |
| _mean_obs       | 0.0497     |
| _min_adv        | -5.04      |
| _min_discrew    | 0.0205     |
| _min_obs        | -1.21      |
| _std_act        | 0.822894   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 326
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00311809 |
| Phi_loss        | 989.518    |
| PolicyEntropy   | 0.109396   |
| PolicyLoss      | 0.0276069  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00655    |
| _MeanReward     | 4.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64317    |
| _max_adv        | 3.15       |
| _max_discrew    | 5.04       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0259178  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 3.98       |
| _mean_obs       | 0.0501     |
| _min_adv        | -4.14      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.03      |
| _std_act        | 0.823324   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 327
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00394327  |
| Phi_loss        | 1095.67     |
| PolicyEntropy   | 0.0732765   |
| PolicyLoss      | -0.00855091 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00634     |
| _MeanReward     | 4.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.65275     |
| _max_adv        | 3.12        |
| _max_discrew    | 5.12        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0288828   |
| _mean_adv       | 1.28e-17    |
| _mean_discrew   | 3.97        |
| _mean_obs       | 0.0503      |
| _min_adv        | -6.59       |
| _min_discrew    | 0.0203      |
| _min_obs        | -1.08       |
| _std_act        | 0.831795    |
| _std_adv        | 1           |
| _std_discrew    | 1.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 328
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00291197 |
| Phi_loss        | 1028.47    |
| PolicyEntropy   | 0.0529766  |
| PolicyLoss      | -0.025236  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00603    |
| _MeanReward     | 4.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.63274    |
| _max_adv        | 3.51       |
| _max_discrew    | 5.07       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0262543  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.99       |
| _mean_obs       | 0.05       |
| _min_adv        | -4.95      |
| _min_discrew    | 0.0185     |
| _min_obs        | -1.02      |
| _std_act        | 0.828812   |
| _std_adv        | 1          |
| _std_discrew    | 1.5        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 329
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00375772 |
| Phi_loss        | 1111.75    |
| PolicyEntropy   | 0.0259657  |
| PolicyLoss      | 0.025844   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00457    |
| _MeanReward     | 4.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79952    |
| _max_adv        | 3.26       |
| _max_discrew    | 5.14       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0249336  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4          |
| _mean_obs       | 0.0502     |
| _min_adv        | -6.35      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.03      |
| _std_act        | 0.827594   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 330
Draw Samples..
----------------------------------
| Beta            | 0.296        |
| ExplainedVarNew | 0.994        |
| ExplainedVarOld | 0.994        |
| KL              | 0.00332451   |
| Phi_loss        | 1114.71      |
| PolicyEntropy   | 0.00752068   |
| PolicyLoss      | 0.0034569    |
| Steps           | 10000        |
| VarFuncLoss     | 0.00948      |
| _MeanReward     | 4.45e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 3.29547      |
| _max_adv        | 1.15         |
| _max_discrew    | 5.28         |
| _max_obs        | 1.63         |
| _mean_act       | -0.000696107 |
| _mean_adv       | 7.11e-18     |
| _mean_discrew   | 3.61         |
| _mean_obs       | 0.0474       |
| _min_adv        | -18.7        |
| _min_discrew    | -1.84        |
| _min_obs        | -1.18        |
| _std_act        | 0.929239     |
| _std_adv        | 1            |
| _std_discrew    | 3.08         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 331
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.887      |
| ExplainedVarOld | 0.875      |
| KL              | 0.0236554  |
| Phi_loss        | 1014.58    |
| PolicyEntropy   | 0.00895214 |
| PolicyLoss      | 0.380246   |
| Steps           | 10000      |
| VarFuncLoss     | 0.35       |
| _MeanReward     | 4.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49331    |
| _max_adv        | 25.4       |
| _max_discrew    | 5.21       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0244089  |
| _mean_adv       | 4.26e-18   |
| _mean_discrew   | 3.99       |
| _mean_obs       | 0.0498     |
| _min_adv        | -3.63      |
| _min_discrew    | 0.0189     |
| _min_obs        | -1.16      |
| _std_act        | 0.82403    |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 332
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.993       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00302295  |
| Phi_loss        | 1016.29     |
| PolicyEntropy   | 0.000347137 |
| PolicyLoss      | 0.0361539   |
| Steps           | 10000       |
| VarFuncLoss     | 0.0141      |
| _MeanReward     | 4.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.66427     |
| _max_adv        | 36.8        |
| _max_discrew    | 5.18        |
| _max_obs        | 1.2         |
| _mean_act       | 0.0267437   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.02        |
| _mean_obs       | 0.0498      |
| _min_adv        | -4.31       |
| _min_discrew    | 0.0182      |
| _min_obs        | -1.05       |
| _std_act        | 0.835139    |
| _std_adv        | 1           |
| _std_discrew    | 1.55        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 333
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.989      |
| KL              | 0.0122875  |
| Phi_loss        | 1075.95    |
| PolicyEntropy   | -0.0121126 |
| PolicyLoss      | -0.0800377 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00735    |
| _MeanReward     | 4.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48825    |
| _max_adv        | 3.81       |
| _max_discrew    | 5.13       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0234749  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.99       |
| _mean_obs       | 0.049      |
| _min_adv        | -4.97      |
| _min_discrew    | 0.0122     |
| _min_obs        | -1.13      |
| _std_act        | 0.837521   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 334
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00247599 |
| Phi_loss        | 1304.93    |
| PolicyEntropy   | -0.0353804 |
| PolicyLoss      | -0.0237541 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00806    |
| _MeanReward     | 4.85e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.13487    |
| _max_adv        | 8.79       |
| _max_discrew    | 5.12       |
| _max_obs        | 1.22       |
| _mean_act       | 0.0275272  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4          |
| _mean_obs       | 0.0496     |
| _min_adv        | -5.41      |
| _min_discrew    | 0.0179     |
| _min_obs        | -1.01      |
| _std_act        | 0.831983   |
| _std_adv        | 1          |
| _std_discrew    | 1.5        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 335
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00106048  |
| Phi_loss        | 1285.44     |
| PolicyEntropy   | -0.0541639  |
| PolicyLoss      | -0.00979409 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00631     |
| _MeanReward     | 4.88e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.63112     |
| _max_adv        | 6.45        |
| _max_discrew    | 5.14        |
| _max_obs        | 1.09        |
| _mean_act       | 0.0272936   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 4.02        |
| _mean_obs       | 0.0496      |
| _min_adv        | -4.74       |
| _min_discrew    | 0.0172      |
| _min_obs        | -1.09       |
| _std_act        | 0.838309    |
| _std_adv        | 1           |
| _std_discrew    | 1.53        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 336
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00194335 |
| Phi_loss        | 1273.02    |
| PolicyEntropy   | -0.066184  |
| PolicyLoss      | -0.0340504 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00439    |
| _MeanReward     | 4.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.571      |
| _max_adv        | 6.63       |
| _max_discrew    | 5.19       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0267914  |
| _mean_adv       | 4.12e-17   |
| _mean_discrew   | 4.03       |
| _mean_obs       | 0.0496     |
| _min_adv        | -7.77      |
| _min_discrew    | 0.016      |
| _min_obs        | -1.01      |
| _std_act        | 0.833448   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 337
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.0019448   |
| Phi_loss        | 1173.52     |
| PolicyEntropy   | -0.0801001  |
| PolicyLoss      | -0.00168142 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00546     |
| _MeanReward     | 4.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.71772     |
| _max_adv        | 5.06        |
| _max_discrew    | 5.11        |
| _max_obs        | 1.12        |
| _mean_act       | 0.0247155   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 3.99        |
| _mean_obs       | 0.0489      |
| _min_adv        | -6.19       |
| _min_discrew    | 0.0198      |
| _min_obs        | -1.02       |
| _std_act        | 0.831814    |
| _std_adv        | 1           |
| _std_discrew    | 1.51        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 338
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00157986 |
| Phi_loss        | 1375.78    |
| PolicyEntropy   | -0.101266  |
| PolicyLoss      | -0.0212746 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00673    |
| _MeanReward     | 4.86e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64983    |
| _max_adv        | 5.72       |
| _max_discrew    | 5.17       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0264339  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.01       |
| _mean_obs       | 0.0491     |
| _min_adv        | -7.94      |
| _min_discrew    | 0.0158     |
| _min_obs        | -1.02      |
| _std_act        | 0.844207   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 339
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00154884 |
| Phi_loss        | 1226.81    |
| PolicyEntropy   | -0.103757  |
| PolicyLoss      | -0.0248067 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00652    |
| _MeanReward     | 4.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66131    |
| _max_adv        | 6.6        |
| _max_discrew    | 5.11       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0282537  |
| _mean_adv       | 4.41e-17   |
| _mean_discrew   | 4.02       |
| _mean_obs       | 0.0494     |
| _min_adv        | -5.23      |
| _min_discrew    | 0.014      |
| _min_obs        | -1.16      |
| _std_act        | 0.844263   |
| _std_adv        | 1          |
| _std_discrew    | 1.5        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 340
Draw Samples..
---------------------------------
| Beta            | 0.444       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00203737  |
| Phi_loss        | 1268.23     |
| PolicyEntropy   | -0.130205   |
| PolicyLoss      | -0.00787262 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00566     |
| _MeanReward     | 4.89e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58159     |
| _max_adv        | 3.69        |
| _max_discrew    | 5.22        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0275994   |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 4.03        |
| _mean_obs       | 0.0494      |
| _min_adv        | -6.44       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.01       |
| _std_act        | 0.845831    |
| _std_adv        | 1           |
| _std_discrew    | 1.54        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 341
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00200639 |
| Phi_loss        | 1277.49    |
| PolicyEntropy   | -0.156546  |
| PolicyLoss      | 0.0134032  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00401    |
| _MeanReward     | 4.91e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48661    |
| _max_adv        | 3.44       |
| _max_discrew    | 5.14       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0283222  |
| _mean_adv       | -7.11e-18  |
| _mean_discrew   | 4.04       |
| _mean_obs       | 0.0493     |
| _min_adv        | -4.01      |
| _min_discrew    | 0.0242     |
| _min_obs        | -1.01      |
| _std_act        | 0.843906   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 342
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00176408 |
| Phi_loss        | 1301.59    |
| PolicyEntropy   | -0.176393  |
| PolicyLoss      | 0.0121971  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00504    |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60557    |
| _max_adv        | 3.94       |
| _max_discrew    | 5.19       |
| _max_obs        | 1.26       |
| _mean_act       | 0.0274347  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0495     |
| _min_adv        | -6.98      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.1       |
| _std_act        | 0.838068   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 343
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00137773  |
| Phi_loss        | 1244.55     |
| PolicyEntropy   | -0.193223   |
| PolicyLoss      | -0.00749331 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00509     |
| _MeanReward     | 4.93e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64001     |
| _max_adv        | 6.9         |
| _max_discrew    | 5.27        |
| _max_obs        | 1.07        |
| _mean_act       | 0.02272     |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 4.06        |
| _mean_obs       | 0.0492      |
| _min_adv        | -4.55       |
| _min_discrew    | 0.0166      |
| _min_obs        | -1.01       |
| _std_act        | 0.839634    |
| _std_adv        | 1           |
| _std_discrew    | 1.59        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 344
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.994       |
| KL              | 0.00326662  |
| Phi_loss        | 1255.72     |
| PolicyEntropy   | -0.226533   |
| PolicyLoss      | -0.00790446 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00838     |
| _MeanReward     | 4.94e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.42773     |
| _max_adv        | 3.41        |
| _max_discrew    | 5.21        |
| _max_obs        | 1.31        |
| _mean_act       | 0.0271716   |
| _mean_adv       | -2.13e-18   |
| _mean_discrew   | 4.07        |
| _mean_obs       | 0.0494      |
| _min_adv        | -6.28       |
| _min_discrew    | 0.0167      |
| _min_obs        | -1.07       |
| _std_act        | 0.843957    |
| _std_adv        | 1           |
| _std_discrew    | 1.6         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 345
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00288907 |
| Phi_loss        | 1258.45    |
| PolicyEntropy   | -0.229321  |
| PolicyLoss      | -0.0369697 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00461    |
| _MeanReward     | 4.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.74324    |
| _max_adv        | 3.38       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0272489  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 4.08       |
| _mean_obs       | 0.0494     |
| _min_adv        | -4.51      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.06      |
| _std_act        | 0.844882   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 346
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00275723  |
| Phi_loss        | 1268.57     |
| PolicyEntropy   | -0.242776   |
| PolicyLoss      | -0.0365718  |
| Steps           | 10000       |
| VarFuncLoss     | 0.00665     |
| _MeanReward     | 4.66e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.92031     |
| _max_adv        | 2.89        |
| _max_discrew    | 5.24        |
| _max_obs        | 1.66        |
| _mean_act       | -0.00186323 |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 3.79        |
| _mean_obs       | 0.0469      |
| _min_adv        | -20.6       |
| _min_discrew    | -1.41       |
| _min_obs        | -1.22       |
| _std_act        | 0.908821    |
| _std_adv        | 1           |
| _std_discrew    | 2.73        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 347
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.89       |
| ExplainedVarOld | 0.879      |
| KL              | 0.00794955 |
| Phi_loss        | 1006.27    |
| PolicyEntropy   | -0.222339  |
| PolicyLoss      | 0.043611   |
| Steps           | 10000      |
| VarFuncLoss     | 0.304      |
| _MeanReward     | 4.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47957    |
| _max_adv        | 14.7       |
| _max_discrew    | 5.21       |
| _max_obs        | 1.06       |
| _mean_act       | 0.0265227  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0493     |
| _min_adv        | -3.93      |
| _min_discrew    | 0.0178     |
| _min_obs        | -1.02      |
| _std_act        | 0.853596   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 348
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00181211 |
| Phi_loss        | 1273.61    |
| PolicyEntropy   | -0.236804  |
| PolicyLoss      | -0.0128665 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0101     |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44207    |
| _max_adv        | 8.7        |
| _max_discrew    | 5.15       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0258008  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 4.05       |
| _mean_obs       | 0.0492     |
| _min_adv        | -5.13      |
| _min_discrew    | 0.0196     |
| _min_obs        | -1.01      |
| _std_act        | 0.850566   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 349
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00115193 |
| Phi_loss        | 1079.49    |
| PolicyEntropy   | -0.245265  |
| PolicyLoss      | -0.0158736 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00447    |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59203    |
| _max_adv        | 4.85       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0274584  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.07       |
| _mean_obs       | 0.0491     |
| _min_adv        | -5.06      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.04      |
| _std_act        | 0.853823   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 350
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00270825 |
| Phi_loss        | 1371.8     |
| PolicyEntropy   | -0.276214  |
| PolicyLoss      | 0.00391987 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00787    |
| _MeanReward     | 4.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59214    |
| _max_adv        | 4.28       |
| _max_discrew    | 5.19       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0273572  |
| _mean_adv       | -8.53e-18  |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.049      |
| _min_adv        | -5.14      |
| _min_discrew    | 0.0148     |
| _min_obs        | -1.02      |
| _std_act        | 0.858045   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 351
Draw Samples..
---------------------------------
| Beta            | 0.296       |
| ExplainedVarNew | 0.998       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00290551  |
| Phi_loss        | 1346.66     |
| PolicyEntropy   | -0.29393    |
| PolicyLoss      | -0.00540928 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00377     |
| _MeanReward     | 4.95e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.46948     |
| _max_adv        | 4.52        |
| _max_discrew    | 5.23        |
| _max_obs        | 1.14        |
| _mean_act       | 0.0256754   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.08        |
| _mean_obs       | 0.0489      |
| _min_adv        | -5.17       |
| _min_discrew    | 0.023       |
| _min_obs        | -1          |
| _std_act        | 0.853278    |
| _std_adv        | 1           |
| _std_discrew    | 1.58        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 352
Draw Samples..
--------------------------------
| Beta            | 0.296      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.0030373  |
| Phi_loss        | 1464.97    |
| PolicyEntropy   | -0.29537   |
| PolicyLoss      | -0.0134784 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00471    |
| _MeanReward     | 4.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.47158    |
| _max_adv        | 52.7       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0278759  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.08       |
| _mean_obs       | 0.049      |
| _min_adv        | -4.65      |
| _min_discrew    | 0.0175     |
| _min_obs        | -1.06      |
| _std_act        | 0.851981   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 353
Draw Samples..
-------------------------------
| Beta            | 0.444     |
| ExplainedVarNew | 0.997     |
| ExplainedVarOld | 0.996     |
| KL              | 0.0112377 |
| Phi_loss        | 3616.18   |
| PolicyEntropy   | -0.319705 |
| PolicyLoss      | 0.0475273 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00502   |
| _MeanReward     | 4.91e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.64702   |
| _max_adv        | 6.13      |
| _max_discrew    | 5.2       |
| _max_obs        | 1.15      |
| _mean_act       | 0.0217812 |
| _mean_adv       | 8.53e-18  |
| _mean_discrew   | 4.03      |
| _mean_obs       | 0.0485    |
| _min_adv        | -16.2     |
| _min_discrew    | 0.0154    |
| _min_obs        | -1.13     |
| _std_act        | 0.851342  |
| _std_adv        | 1         |
| _std_discrew    | 1.56      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 354
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.972      |
| ExplainedVarOld | 0.97       |
| KL              | 0.00732503 |
| Phi_loss        | 1271.9     |
| PolicyEntropy   | -0.324683  |
| PolicyLoss      | 0.0359897  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0444     |
| _MeanReward     | 4.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59707    |
| _max_adv        | 6.51       |
| _max_discrew    | 5.21       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0244436  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.08       |
| _mean_obs       | 0.0486     |
| _min_adv        | -6.91      |
| _min_discrew    | 0.0194     |
| _min_obs        | -1.08      |
| _std_act        | 0.847075   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 355
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00146389 |
| Phi_loss        | 1444.58    |
| PolicyEntropy   | -0.33337   |
| PolicyLoss      | -0.0173198 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00611    |
| _MeanReward     | 4.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.64982    |
| _max_adv        | 6.82       |
| _max_discrew    | 5.22       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0269897  |
| _mean_adv       | 3.98e-17   |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0492     |
| _min_adv        | -4.15      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.02      |
| _std_act        | 0.854233   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 356
Draw Samples..
--------------------------------
| Beta            | 0.444      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00168939 |
| Phi_loss        | 1491.26    |
| PolicyEntropy   | -0.362327  |
| PolicyLoss      | -0.0205684 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0057     |
| _MeanReward     | 4.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5888     |
| _max_adv        | 43.2       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0233473  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0479     |
| _min_adv        | -8.91      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.05      |
| _std_act        | 0.851866   |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 357
Draw Samples..
--------------------------------
| Beta            | 0.667      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00618485 |
| Phi_loss        | 2313.04    |
| PolicyEntropy   | -0.382247  |
| PolicyLoss      | -0.0134231 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00909    |
| _MeanReward     | 4.88e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.62184    |
| _max_adv        | 12.9       |
| _max_discrew    | 5.27       |
| _max_obs        | 1.66       |
| _mean_act       | 0.0158407  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.01       |
| _mean_obs       | 0.0479     |
| _min_adv        | -13.9      |
| _min_discrew    | -0.442     |
| _min_obs        | -1.06      |
| _std_act        | 0.867488   |
| _std_adv        | 1          |
| _std_discrew    | 1.78       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 358
Draw Samples..
--------------------------------
| Beta            | 1          |
| ExplainedVarNew | 0.961      |
| ExplainedVarOld | 0.959      |
| KL              | 0.0222413  |
| Phi_loss        | 1536.36    |
| PolicyEntropy   | -0.379676  |
| PolicyLoss      | -0.0711474 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0691     |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.52603    |
| _max_adv        | 8.2        |
| _max_discrew    | 5.19       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0231054  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.05       |
| _mean_obs       | 0.0476     |
| _min_adv        | -4.58      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.04      |
| _std_act        | 0.84227    |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 359
Draw Samples..
-------------------------------
| Beta            | 1.5       |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0146363 |
| Phi_loss        | 1070.91   |
| PolicyEntropy   | -0.377841 |
| PolicyLoss      | 0.0234611 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0075    |
| _MeanReward     | 4.96e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.50463   |
| _max_adv        | 9.09      |
| _max_discrew    | 5.24      |
| _max_obs        | 1.13      |
| _mean_act       | 0.0231742 |
| _mean_adv       | -3.13e-17 |
| _mean_discrew   | 4.08      |
| _mean_obs       | 0.0477    |
| _min_adv        | -5.54     |
| _min_discrew    | 0.0189    |
| _min_obs        | -1.03     |
| _std_act        | 0.835419  |
| _std_adv        | 1         |
| _std_discrew    | 1.58      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 360
Draw Samples..
-------------------------------
| Beta            | 2.25      |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.996     |
| KL              | 0.104564  |
| Phi_loss        | 1543.91   |
| PolicyEntropy   | -0.37522  |
| PolicyLoss      | 0.637841  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00612   |
| _MeanReward     | 4.97e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.42007   |
| _max_adv        | 4.58      |
| _max_discrew    | 5.18      |
| _max_obs        | 1.22      |
| _mean_act       | 0.024196  |
| _mean_adv       | -3.69e-17 |
| _mean_discrew   | 4.09      |
| _mean_obs       | 0.048     |
| _min_adv        | -5.83     |
| _min_discrew    | 0.017     |
| _min_obs        | -1.04     |
| _std_act        | 0.856432  |
| _std_adv        | 1         |
| _std_discrew    | 1.54      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 361
Draw Samples..
-------------------------------
| Beta            | 3.38      |
| ExplainedVarNew | 0.997     |
| ExplainedVarOld | 0.996     |
| KL              | 0.142966  |
| Phi_loss        | 1939.86   |
| PolicyEntropy   | -0.374452 |
| PolicyLoss      | 1.27457   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00509   |
| _MeanReward     | 4.95e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.52053   |
| _max_adv        | 5.22      |
| _max_discrew    | 5.18      |
| _max_obs        | 1.06      |
| _mean_act       | 0.0250051 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 4.09      |
| _mean_obs       | 0.0477    |
| _min_adv        | -9.37     |
| _min_discrew    | 0.0211    |
| _min_obs        | -1.02     |
| _std_act        | 0.865772  |
| _std_adv        | 1         |
| _std_discrew    | 1.58      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 362
Draw Samples..
-------------------------------
| Beta            | 5.06      |
| ExplainedVarNew | 0.997     |
| ExplainedVarOld | 0.997     |
| KL              | 0.113221  |
| Phi_loss        | 1847.34   |
| PolicyEntropy   | -0.37401  |
| PolicyLoss      | 0.929785  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00451   |
| _MeanReward     | 4.94e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.5252    |
| _max_adv        | 21.4      |
| _max_discrew    | 5.29      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0273216 |
| _mean_adv       | -4.26e-18 |
| _mean_discrew   | 4.06      |
| _mean_obs       | 0.0472    |
| _min_adv        | -5.21     |
| _min_discrew    | 0.0173    |
| _min_obs        | -1.03     |
| _std_act        | 0.886931  |
| _std_adv        | 1         |
| _std_discrew    | 1.59      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 363
Draw Samples..
-------------------------------
| Beta            | 7.59      |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0884642 |
| Phi_loss        | 1719.59   |
| PolicyEntropy   | -0.37392  |
| PolicyLoss      | 0.809289  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0103    |
| _MeanReward     | 4.84e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.66584   |
| _max_adv        | 11.4      |
| _max_discrew    | 5.1       |
| _max_obs        | 1.18      |
| _mean_act       | 0.0243733 |
| _mean_adv       | -1.42e-17 |
| _mean_discrew   | 4         |
| _mean_obs       | 0.046     |
| _min_adv        | -16.7     |
| _min_discrew    | 0.0224    |
| _min_obs        | -1.06     |
| _std_act        | 0.899249  |
| _std_adv        | 1         |
| _std_discrew    | 1.5       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 364
Draw Samples..
-------------------------------
| Beta            | 11.4      |
| ExplainedVarNew | 0.987     |
| ExplainedVarOld | 0.985     |
| KL              | 0.0690687 |
| Phi_loss        | 1356.99   |
| PolicyEntropy   | -0.37398  |
| PolicyLoss      | 0.725375  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0205    |
| _MeanReward     | 4.88e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.72477   |
| _max_adv        | 5.1       |
| _max_discrew    | 5.22      |
| _max_obs        | 1.09      |
| _mean_act       | 0.0274184 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 4.02      |
| _mean_obs       | 0.0462    |
| _min_adv        | -5.83     |
| _min_discrew    | 0.0199    |
| _min_obs        | -1.08     |
| _std_act        | 0.905911  |
| _std_adv        | 1         |
| _std_discrew    | 1.55      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 365
Draw Samples..
-------------------------------
| Beta            | 17.1      |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.995     |
| KL              | 0.0552695 |
| Phi_loss        | 1682.5    |
| PolicyEntropy   | -0.374087 |
| PolicyLoss      | 0.742066  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00717   |
| _MeanReward     | 4.8e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.4987    |
| _max_adv        | 5.39      |
| _max_discrew    | 5.16      |
| _max_obs        | 1.18      |
| _mean_act       | 0.0282192 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 4         |
| _mean_obs       | 0.0456    |
| _min_adv        | -7.85     |
| _min_discrew    | 0.0199    |
| _min_obs        | -1.1      |
| _std_act        | 0.914864  |
| _std_adv        | 1         |
| _std_discrew    | 1.5       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 366
Draw Samples..
-------------------------------
| Beta            | 25.6      |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0437985 |
| Phi_loss        | 1479.3    |
| PolicyEntropy   | -0.374532 |
| PolicyLoss      | 0.825534  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0105    |
| _MeanReward     | 4.81e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.72278   |
| _max_adv        | 5.3       |
| _max_discrew    | 5.13      |
| _max_obs        | 1.14      |
| _mean_act       | 0.0322652 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.98      |
| _mean_obs       | 0.0458    |
| _min_adv        | -4.08     |
| _min_discrew    | 0.0171    |
| _min_obs        | -1.12     |
| _std_act        | 0.932829  |
| _std_adv        | 1         |
| _std_discrew    | 1.46      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 367
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0352054 |
| Phi_loss        | 1551.3    |
| PolicyEntropy   | -0.37527  |
| PolicyLoss      | 0.938013  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00801   |
| _MeanReward     | 4.53e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.80068   |
| _max_adv        | 1.94      |
| _max_discrew    | 5.11      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0172827 |
| _mean_adv       | -2.27e-17 |
| _mean_discrew   | 3.71      |
| _mean_obs       | 0.0441    |
| _min_adv        | -8.99     |
| _min_discrew    | -0.835    |
| _min_obs        | -1.04     |
| _std_act        | 0.948428  |
| _std_adv        | 1         |
| _std_discrew    | 2.32      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 368
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.902     |
| ExplainedVarOld | 0.774     |
| KL              | 0.0269383 |
| Phi_loss        | 558.102   |
| PolicyEntropy   | -0.376121 |
| PolicyLoss      | 0.977747  |
| Steps           | 10000     |
| VarFuncLoss     | 0.231     |
| _MeanReward     | 4.62e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.01609   |
| _max_adv        | 9.84      |
| _max_discrew    | 5.18      |
| _max_obs        | 1.13      |
| _mean_act       | 0.0289365 |
| _mean_adv       | -5.68e-18 |
| _mean_discrew   | 3.82      |
| _mean_obs       | 0.0448    |
| _min_adv        | -17.5     |
| _min_discrew    | 0.0151    |
| _min_obs        | -1.09     |
| _std_act        | 0.950216  |
| _std_adv        | 1         |
| _std_discrew    | 1.73      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 369
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.896     |
| ExplainedVarOld | 0.871     |
| KL              | 0.0207055 |
| Phi_loss        | 1472.45   |
| PolicyEntropy   | -0.377024 |
| PolicyLoss      | 0.765071  |
| Steps           | 10000     |
| VarFuncLoss     | 0.182     |
| _MeanReward     | 4.72e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.28106   |
| _max_adv        | 13.7      |
| _max_discrew    | 5.13      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0346069 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 3.91      |
| _mean_obs       | 0.0451    |
| _min_adv        | -4.05     |
| _min_discrew    | 0.0115    |
| _min_obs        | -1.13     |
| _std_act        | 0.948447  |
| _std_adv        | 1         |
| _std_discrew    | 1.44      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 370
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.99       |
| ExplainedVarOld | 0.984      |
| KL              | 0.0170473  |
| Phi_loss        | 1207.96    |
| PolicyEntropy   | -0.377879  |
| PolicyLoss      | 0.578206   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0143     |
| _MeanReward     | 3.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.85259    |
| _max_adv        | 12.2       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.07       |
| _mean_act       | -0.0422354 |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 2.88       |
| _mean_obs       | 0.0381     |
| _min_adv        | -9.4       |
| _min_discrew    | -0.941     |
| _min_obs        | -1.15      |
| _std_act        | 0.966716   |
| _std_adv        | 1          |
| _std_discrew    | 4.05       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 371
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.904     |
| ExplainedVarOld | 0.814     |
| KL              | 0.144743  |
| Phi_loss        | 934.749   |
| PolicyEntropy   | -0.374669 |
| PolicyLoss      | 5.99558   |
| Steps           | 10000     |
| VarFuncLoss     | 0.4       |
| _MeanReward     | 4.81e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.68882   |
| _max_adv        | 9.81      |
| _max_discrew    | 5.12      |
| _max_obs        | 1.11      |
| _mean_act       | 0.0342091 |
| _mean_adv       | -3.69e-17 |
| _mean_discrew   | 3.98      |
| _mean_obs       | 0.0453    |
| _min_adv        | -3.13     |
| _min_discrew    | 0.0201    |
| _min_obs        | -1.23     |
| _std_act        | 0.936909  |
| _std_adv        | 1         |
| _std_discrew    | 1.52      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 372
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.986     |
| ExplainedVarOld | 0.987     |
| KL              | 0.223804  |
| Phi_loss        | 987.904   |
| PolicyEntropy   | -0.371232 |
| PolicyLoss      | 10.223    |
| Steps           | 10000     |
| VarFuncLoss     | 0.034     |
| _MeanReward     | 4.85e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.71708   |
| _max_adv        | 8.42      |
| _max_discrew    | 5.18      |
| _max_obs        | 1.11      |
| _mean_act       | 0.0348318 |
| _mean_adv       | -4.19e-17 |
| _mean_discrew   | 4.01      |
| _mean_obs       | 0.0456    |
| _min_adv        | -5.59     |
| _min_discrew    | 0.0144    |
| _min_obs        | -1.11     |
| _std_act        | 0.913063  |
| _std_adv        | 1         |
| _std_discrew    | 1.55      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 373
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.986     |
| KL              | 0.185115  |
| Phi_loss        | 995.015   |
| PolicyEntropy   | -0.368225 |
| PolicyLoss      | 8.104     |
| Steps           | 10000     |
| VarFuncLoss     | 0.00821   |
| _MeanReward     | 4.87e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.54706   |
| _max_adv        | 14.9      |
| _max_discrew    | 5.13      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0347389 |
| _mean_adv       | 1.99e-17  |
| _mean_discrew   | 4.01      |
| _mean_obs       | 0.0457    |
| _min_adv        | -5.32     |
| _min_discrew    | 0.0172    |
| _min_obs        | -1.05     |
| _std_act        | 0.898179  |
| _std_adv        | 1         |
| _std_discrew    | 1.5       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 374
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.996     |
| KL              | 0.152473  |
| Phi_loss        | 1699.16   |
| PolicyEntropy   | -0.365874 |
| PolicyLoss      | 6.43735   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00585   |
| _MeanReward     | 4.85e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.58561   |
| _max_adv        | 15.7      |
| _max_discrew    | 5.21      |
| _max_obs        | 1.03      |
| _mean_act       | 0.0307029 |
| _mean_adv       | 1.28e-17  |
| _mean_discrew   | 4.02      |
| _mean_obs       | 0.0453    |
| _min_adv        | -4.83     |
| _min_discrew    | 0.0194    |
| _min_obs        | -1.02     |
| _std_act        | 0.870392  |
| _std_adv        | 1         |
| _std_discrew    | 1.49      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 375
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.995     |
| KL              | 0.124001  |
| Phi_loss        | 1623.05   |
| PolicyEntropy   | -0.364131 |
| PolicyLoss      | 5.04516   |
| Steps           | 10000     |
| VarFuncLoss     | 0.007     |
| _MeanReward     | 4.89e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.45015   |
| _max_adv        | 6.51      |
| _max_discrew    | 5.23      |
| _max_obs        | 1.03      |
| _mean_act       | 0.0300881 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 4.01      |
| _mean_obs       | 0.0454    |
| _min_adv        | -4.41     |
| _min_discrew    | 0.0142    |
| _min_obs        | -0.979    |
| _std_act        | 0.857055  |
| _std_adv        | 1         |
| _std_discrew    | 1.55      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 376
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.995       |
| KL              | 0.101573    |
| Phi_loss        | 1795.33     |
| PolicyEntropy   | -0.362602   |
| PolicyLoss      | 4.02975     |
| Steps           | 10000       |
| VarFuncLoss     | 0.0066      |
| _MeanReward     | 4.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86857     |
| _max_adv        | 2.05        |
| _max_discrew    | 5.16        |
| _max_obs        | 1.73        |
| _mean_act       | -0.00514447 |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0432      |
| _min_adv        | -20.6       |
| _min_discrew    | -1.67       |
| _min_obs        | -1.3        |
| _std_act        | 0.931966    |
| _std_adv        | 1           |
| _std_discrew    | 3.09        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 377
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.894     |
| ExplainedVarOld | 0.88      |
| KL              | 0.0782857 |
| Phi_loss        | 1801.72   |
| PolicyEntropy   | -0.361123 |
| PolicyLoss      | 2.9419    |
| Steps           | 10000     |
| VarFuncLoss     | 0.333     |
| _MeanReward     | 4.78e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.56484   |
| _max_adv        | 11.3      |
| _max_discrew    | 4.99      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0274005 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 3.94      |
| _mean_obs       | 0.044     |
| _min_adv        | -6.63     |
| _min_discrew    | 0.0217    |
| _min_obs        | -1.05     |
| _std_act        | 0.823748  |
| _std_adv        | 1         |
| _std_discrew    | 1.47      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 378
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0659231 |
| Phi_loss        | 1462.03   |
| PolicyEntropy   | -0.359954 |
| PolicyLoss      | 2.49995   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0108    |
| _MeanReward     | 4.76e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.51933   |
| _max_adv        | 25.6      |
| _max_discrew    | 5.02      |
| _max_obs        | 1.13      |
| _mean_act       | 0.0257331 |
| _mean_adv       | 8.53e-18  |
| _mean_discrew   | 3.93      |
| _mean_obs       | 0.0434    |
| _min_adv        | -4.88     |
| _min_discrew    | 0.0156    |
| _min_obs        | -0.972    |
| _std_act        | 0.802521  |
| _std_adv        | 1         |
| _std_discrew    | 1.42      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 379
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.991     |
| KL              | 0.0535746 |
| Phi_loss        | 1146.61   |
| PolicyEntropy   | -0.359    |
| PolicyLoss      | 1.97103   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00788   |
| _MeanReward     | 4.7e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.55156   |
| _max_adv        | 5.41      |
| _max_discrew    | 4.91      |
| _max_obs        | 1.18      |
| _mean_act       | 0.0233224 |
| _mean_adv       | -4.55e-17 |
| _mean_discrew   | 3.9       |
| _mean_obs       | 0.0421    |
| _min_adv        | -7.2      |
| _min_discrew    | 0.0165    |
| _min_obs        | -1        |
| _std_act        | 0.786943  |
| _std_adv        | 1         |
| _std_discrew    | 1.39      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 380
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0428638 |
| Phi_loss        | 1507.88   |
| PolicyEntropy   | -0.358414 |
| PolicyLoss      | 1.55795   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00704   |
| _MeanReward     | 4.67e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.55885   |
| _max_adv        | 11.8      |
| _max_discrew    | 4.94      |
| _max_obs        | 1.21      |
| _mean_act       | 0.0222437 |
| _mean_adv       | 0         |
| _mean_discrew   | 3.86      |
| _mean_obs       | 0.0415    |
| _min_adv        | -4.49     |
| _min_discrew    | 0.02      |
| _min_obs        | -0.98     |
| _std_act        | 0.762271  |
| _std_adv        | 1         |
| _std_discrew    | 1.39      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 381
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.994       |
| KL              | 0.0341618   |
| Phi_loss        | 1455.54     |
| PolicyEntropy   | -0.357909   |
| PolicyLoss      | 1.22744     |
| Steps           | 10000       |
| VarFuncLoss     | 0.00832     |
| _MeanReward     | 4.25e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.17052     |
| _max_adv        | 2.86        |
| _max_discrew    | 4.92        |
| _max_obs        | 1.84        |
| _mean_act       | -0.00530422 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.47        |
| _mean_obs       | 0.0389      |
| _min_adv        | -21.6       |
| _min_discrew    | -1.65       |
| _min_obs        | -1.09       |
| _std_act        | 0.82791     |
| _std_adv        | 1           |
| _std_discrew    | 2.51        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 382
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.881     |
| ExplainedVarOld | 0.875     |
| KL              | 0.026255  |
| Phi_loss        | 3242.92   |
| PolicyEntropy   | -0.357358 |
| PolicyLoss      | 0.909961  |
| Steps           | 10000     |
| VarFuncLoss     | 0.307     |
| _MeanReward     | 4.53e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.50981   |
| _max_adv        | 17.5      |
| _max_discrew    | 4.83      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0173554 |
| _mean_adv       | 9.95e-18  |
| _mean_discrew   | 3.75      |
| _mean_obs       | 0.0396    |
| _min_adv        | -5.32     |
| _min_discrew    | 0.0147    |
| _min_obs        | -1.02     |
| _std_act        | 0.724418  |
| _std_adv        | 1         |
| _std_discrew    | 1.34      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 383
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.988     |
| ExplainedVarOld | 0.989     |
| KL              | 0.021795  |
| Phi_loss        | 1283.72   |
| PolicyEntropy   | -0.357253 |
| PolicyLoss      | 0.778097  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0176    |
| _MeanReward     | 4.4e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.49349   |
| _max_adv        | 27.9      |
| _max_discrew    | 4.75      |
| _max_obs        | 0.999     |
| _mean_act       | 0.0132962 |
| _mean_adv       | -3.41e-17 |
| _mean_discrew   | 3.66      |
| _mean_obs       | 0.0378    |
| _min_adv        | -5.61     |
| _min_discrew    | 0.0186    |
| _min_obs        | -1.13     |
| _std_act        | 0.700982  |
| _std_adv        | 1         |
| _std_discrew    | 1.26      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 384
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.988      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0171141  |
| Phi_loss        | 1349.88    |
| PolicyEntropy   | -0.357455  |
| PolicyLoss      | 0.584701   |
| Steps           | 10000      |
| VarFuncLoss     | 0.016      |
| _MeanReward     | 4.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.65047    |
| _max_adv        | 8.42       |
| _max_discrew    | 4.63       |
| _max_obs        | 1.01       |
| _mean_act       | -0.0107077 |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 3.3        |
| _mean_obs       | 0.0367     |
| _min_adv        | -15.1      |
| _min_discrew    | -0.74      |
| _min_obs        | -1.06      |
| _std_act        | 0.738403   |
| _std_adv        | 1          |
| _std_discrew    | 2.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 385
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.847      |
| ExplainedVarOld | 0.829      |
| KL              | 0.0132108  |
| Phi_loss        | 1529.27    |
| PolicyEntropy   | -0.35762   |
| PolicyLoss      | 0.454783   |
| Steps           | 10000      |
| VarFuncLoss     | 0.318      |
| _MeanReward     | 4.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.56957    |
| _max_adv        | 14.2       |
| _max_discrew    | 4.58       |
| _max_obs        | 1.02       |
| _mean_act       | 0.00449799 |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 3.45       |
| _mean_obs       | 0.0351     |
| _min_adv        | -8.45      |
| _min_discrew    | -0.0616    |
| _min_obs        | -1.02      |
| _std_act        | 0.654637   |
| _std_adv        | 1          |
| _std_discrew    | 1.18       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 386
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.982      |
| ExplainedVarOld | 0.98       |
| KL              | 0.0648908  |
| Phi_loss        | 1476.05    |
| PolicyEntropy   | -0.354793  |
| PolicyLoss      | 2.40005    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0208     |
| _MeanReward     | 3.87e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.99779    |
| _max_adv        | 3.67       |
| _max_discrew    | 4.76       |
| _max_obs        | 1.88       |
| _mean_act       | -0.0250111 |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 3.16       |
| _mean_obs       | 0.0359     |
| _min_adv        | -20.6      |
| _min_discrew    | -1.82      |
| _min_obs        | -1.23      |
| _std_act        | 0.837535   |
| _std_adv        | 1          |
| _std_discrew    | 3.14       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 387
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.908      |
| ExplainedVarOld | 0.904      |
| KL              | 0.0942673  |
| Phi_loss        | 1772.05    |
| PolicyEntropy   | -0.351806  |
| PolicyLoss      | 3.67326    |
| Steps           | 10000      |
| VarFuncLoss     | 0.289      |
| _MeanReward     | 4.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.49418    |
| _max_adv        | 1.52       |
| _max_discrew    | 4.85       |
| _max_obs        | 1.75       |
| _mean_act       | -0.0119599 |
| _mean_adv       | 3.69e-17   |
| _mean_discrew   | 3.4        |
| _mean_obs       | 0.0385     |
| _min_adv        | -20.9      |
| _min_discrew    | -1.74      |
| _min_obs        | -1.23      |
| _std_act        | 0.846416   |
| _std_adv        | 1          |
| _std_discrew    | 2.88       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 388
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.887     |
| ExplainedVarOld | 0.883     |
| KL              | 0.0765179 |
| Phi_loss        | 2556.57   |
| PolicyEntropy   | -0.349133 |
| PolicyLoss      | 2.95629   |
| Steps           | 10000     |
| VarFuncLoss     | 0.328     |
| _MeanReward     | 4.62e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.52573   |
| _max_adv        | 29.1      |
| _max_discrew    | 4.99      |
| _max_obs        | 1.08      |
| _mean_act       | 0.0236163 |
| _mean_adv       | 7.96e-17  |
| _mean_discrew   | 3.83      |
| _mean_obs       | 0.0404    |
| _min_adv        | -8.75     |
| _min_discrew    | 0.0144    |
| _min_obs        | -1.06     |
| _std_act        | 0.769873  |
| _std_adv        | 1         |
| _std_discrew    | 1.37      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 389
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.987      |
| ExplainedVarOld | 0.975      |
| KL              | 0.0654222  |
| Phi_loss        | 994.893    |
| PolicyEntropy   | -0.346668  |
| PolicyLoss      | 2.42919    |
| Steps           | 10000      |
| VarFuncLoss     | 0.0227     |
| _MeanReward     | 4.5e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.56909    |
| _max_adv        | 6.04       |
| _max_discrew    | 4.98       |
| _max_obs        | 1.06       |
| _mean_act       | 0.00874841 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0406     |
| _min_adv        | -14.2      |
| _min_discrew    | -1.05      |
| _min_obs        | -1.07      |
| _std_act        | 0.816199   |
| _std_adv        | 1          |
| _std_discrew    | 2.11       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 390
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.894     |
| ExplainedVarOld | 0.837     |
| KL              | 0.0499156 |
| Phi_loss        | 1066.08   |
| PolicyEntropy   | -0.344425 |
| PolicyLoss      | 1.81764   |
| Steps           | 10000     |
| VarFuncLoss     | 0.225     |
| _MeanReward     | 4.77e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.57879   |
| _max_adv        | 39.6      |
| _max_discrew    | 5.04      |
| _max_obs        | 1.04      |
| _mean_act       | 0.0229313 |
| _mean_adv       | -2.84e-17 |
| _mean_discrew   | 3.94      |
| _mean_obs       | 0.0418    |
| _min_adv        | -3.65     |
| _min_discrew    | 0.013     |
| _min_obs        | -1.04     |
| _std_act        | 0.805965  |
| _std_adv        | 1         |
| _std_discrew    | 1.47      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 391
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.988     |
| KL              | 0.0411618 |
| Phi_loss        | 1245.29   |
| PolicyEntropy   | -0.342788 |
| PolicyLoss      | 1.50649   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0175    |
| _MeanReward     | 4.66e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.89076   |
| _max_adv        | 16        |
| _max_discrew    | 5.05      |
| _max_obs        | 1.7       |
| _mean_act       | 0.0171569 |
| _mean_adv       | 1.56e-17  |
| _mean_discrew   | 3.83      |
| _mean_obs       | 0.0415    |
| _min_adv        | -18.4     |
| _min_discrew    | -0.788    |
| _min_obs        | -1.01     |
| _std_act        | 0.833198  |
| _std_adv        | 1         |
| _std_discrew    | 1.79      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 392
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.945     |
| ExplainedVarOld | 0.932     |
| KL              | 0.0320241 |
| Phi_loss        | 3302.01   |
| PolicyEntropy   | -0.341299 |
| PolicyLoss      | 1.18819   |
| Steps           | 10000     |
| VarFuncLoss     | 0.101     |
| _MeanReward     | 4.76e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.58631   |
| _max_adv        | 38.7      |
| _max_discrew    | 5.03      |
| _max_obs        | 0.999     |
| _mean_act       | 0.0259539 |
| _mean_adv       | 8.53e-18  |
| _mean_discrew   | 3.93      |
| _mean_obs       | 0.0421    |
| _min_adv        | -4.06     |
| _min_discrew    | 0.0204    |
| _min_obs        | -1.09     |
| _std_act        | 0.826694  |
| _std_adv        | 1         |
| _std_discrew    | 1.45      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 393
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0261258 |
| Phi_loss        | 1698.1    |
| PolicyEntropy   | -0.339808 |
| PolicyLoss      | 0.925559  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0103    |
| _MeanReward     | 4.69e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.53039   |
| _max_adv        | 8.7       |
| _max_discrew    | 5.04      |
| _max_obs        | 1.06      |
| _mean_act       | 0.022189  |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.85      |
| _mean_obs       | 0.0414    |
| _min_adv        | -17.4     |
| _min_discrew    | 0.0165    |
| _min_obs        | -1.03     |
| _std_act        | 0.831981  |
| _std_adv        | 1         |
| _std_discrew    | 1.64      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 394
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.951     |
| ExplainedVarOld | 0.941     |
| KL              | 0.0204385 |
| Phi_loss        | 1237.47   |
| PolicyEntropy   | -0.338638 |
| PolicyLoss      | 0.759545  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0801    |
| _MeanReward     | 4.79e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.63946   |
| _max_adv        | 13.3      |
| _max_discrew    | 5.08      |
| _max_obs        | 1.04      |
| _mean_act       | 0.024865  |
| _mean_adv       | 0         |
| _mean_discrew   | 3.94      |
| _mean_obs       | 0.0418    |
| _min_adv        | -4.53     |
| _min_discrew    | 0.0159    |
| _min_obs        | -1.08     |
| _std_act        | 0.833937  |
| _std_adv        | 1         |
| _std_discrew    | 1.51      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 395
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0165407 |
| Phi_loss        | 1599.7    |
| PolicyEntropy   | -0.337722 |
| PolicyLoss      | 0.553106  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0104    |
| _MeanReward     | 4.55e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 3.03522   |
| _max_adv        | 7.39      |
| _max_discrew    | 5.03      |
| _max_obs        | 1.75      |
| _mean_act       | 0.0092732 |
| _mean_adv       | -2.27e-17 |
| _mean_discrew   | 3.71      |
| _mean_obs       | 0.041     |
| _min_adv        | -19.7     |
| _min_discrew    | -1.29     |
| _min_obs        | -1.16     |
| _std_act        | 0.886692  |
| _std_adv        | 1         |
| _std_discrew    | 2.14      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 396
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.911     |
| ExplainedVarOld | 0.906     |
| KL              | 0.0128063 |
| Phi_loss        | 1480.59   |
| PolicyEntropy   | -0.336868 |
| PolicyLoss      | 0.464739  |
| Steps           | 10000     |
| VarFuncLoss     | 0.197     |
| _MeanReward     | 4.55e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.69304   |
| _max_adv        | 4.79      |
| _max_discrew    | 5.14      |
| _max_obs        | 1.74      |
| _mean_act       | 0.0108701 |
| _mean_adv       | 2.27e-17  |
| _mean_discrew   | 3.71      |
| _mean_obs       | 0.0412    |
| _min_adv        | -15.1     |
| _min_discrew    | -0.938    |
| _min_obs        | -1.03     |
| _std_act        | 0.880491  |
| _std_adv        | 1         |
| _std_discrew    | 2.31      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 397
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.909     |
| ExplainedVarOld | 0.892     |
| KL              | 0.0209897 |
| Phi_loss        | 1192.83   |
| PolicyEntropy   | -0.333133 |
| PolicyLoss      | 0.739633  |
| Steps           | 10000     |
| VarFuncLoss     | 0.211     |
| _MeanReward     | 4.78e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.8138    |
| _max_adv        | 34.1      |
| _max_discrew    | 5.11      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0299684 |
| _mean_adv       | 4.55e-17  |
| _mean_discrew   | 3.93      |
| _mean_obs       | 0.042     |
| _min_adv        | -4.09     |
| _min_discrew    | 0.0166    |
| _min_obs        | -1        |
| _std_act        | 0.843233  |
| _std_adv        | 1         |
| _std_discrew    | 1.49      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 398
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.99      |
| ExplainedVarOld | 0.984     |
| KL              | 0.0478308 |
| Phi_loss        | 1025.53   |
| PolicyEntropy   | -0.330527 |
| PolicyLoss      | 1.72091   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0168    |
| _MeanReward     | 4.73e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.60607   |
| _max_adv        | 8.08      |
| _max_discrew    | 5.04      |
| _max_obs        | 1.06      |
| _mean_act       | 0.0254409 |
| _mean_adv       | -7.11e-18 |
| _mean_discrew   | 3.9       |
| _mean_obs       | 0.0415    |
| _min_adv        | -17.4     |
| _min_discrew    | 0.016     |
| _min_obs        | -1.03     |
| _std_act        | 0.837014  |
| _std_adv        | 1         |
| _std_discrew    | 1.6       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 399
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.975     |
| ExplainedVarOld | 0.97      |
| KL              | 0.0384607 |
| Phi_loss        | 1159.02   |
| PolicyEntropy   | -0.328155 |
| PolicyLoss      | 1.40744   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0404    |
| _MeanReward     | 4.78e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.71022   |
| _max_adv        | 4.61      |
| _max_discrew    | 5.08      |
| _max_obs        | 1.07      |
| _mean_act       | 0.0303127 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 3.94      |
| _mean_obs       | 0.0423    |
| _min_adv        | -5.16     |
| _min_discrew    | 0.019     |
| _min_obs        | -1.03     |
| _std_act        | 0.822895  |
| _std_adv        | 1         |
| _std_discrew    | 1.5       |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 400
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.996     |
| KL              | 0.0314668 |
| Phi_loss        | 1394.04   |
| PolicyEntropy   | -0.32619  |
| PolicyLoss      | 1.09094   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00671   |
| _MeanReward     | 4.65e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.75235   |
| _max_adv        | 13.4      |
| _max_discrew    | 4.94      |
| _max_obs        | 1.03      |
| _mean_act       | 0.0252279 |
| _mean_adv       | -9.59e-18 |
| _mean_discrew   | 3.84      |
| _mean_obs       | 0.041     |
| _min_adv        | -15.2     |
| _min_discrew    | 0.0213    |
| _min_obs        | -1.1      |
| _std_act        | 0.809782  |
| _std_adv        | 1         |
| _std_discrew    | 1.39      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 401
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.958     |
| ExplainedVarOld | 0.874     |
| KL              | 0.0250181 |
| Phi_loss        | 999.91    |
| PolicyEntropy   | -0.324409 |
| PolicyLoss      | 0.905863  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0609    |
| _MeanReward     | 4.69e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.59463   |
| _max_adv        | 13.9      |
| _max_discrew    | 4.96      |
| _max_obs        | 1.05      |
| _mean_act       | 0.0313098 |
| _mean_adv       | 3.13e-17  |
| _mean_discrew   | 3.88      |
| _mean_obs       | 0.0416    |
| _min_adv        | -5.39     |
| _min_discrew    | 0.0182    |
| _min_obs        | -0.987    |
| _std_act        | 0.805441  |
| _std_adv        | 1         |
| _std_discrew    | 1.44      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 402
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.993     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0205431 |
| Phi_loss        | 1311.31   |
| PolicyEntropy   | -0.323061 |
| PolicyLoss      | 0.699191  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00971   |
| _MeanReward     | 4.68e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.60701   |
| _max_adv        | 10.2      |
| _max_discrew    | 4.93      |
| _max_obs        | 1.09      |
| _mean_act       | 0.0300824 |
| _mean_adv       | 5.68e-18  |
| _mean_discrew   | 3.86      |
| _mean_obs       | 0.0414    |
| _min_adv        | -4.91     |
| _min_discrew    | 0.0195    |
| _min_obs        | -0.99     |
| _std_act        | 0.785914  |
| _std_adv        | 1         |
| _std_discrew    | 1.41      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 403
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.996     |
| ExplainedVarOld | 0.995     |
| KL              | 0.0164097 |
| Phi_loss        | 1468.65   |
| PolicyEntropy   | -0.322017 |
| PolicyLoss      | 0.573868  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00632   |
| _MeanReward     | 4.34e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.73156   |
| _max_adv        | 5.51      |
| _max_discrew    | 4.91      |
| _max_obs        | 1.03      |
| _mean_act       | 0.010476  |
| _mean_adv       | -2.27e-17 |
| _mean_discrew   | 3.59      |
| _mean_obs       | 0.0398    |
| _min_adv        | -13.3     |
| _min_discrew    | -0.854    |
| _min_obs        | -1.02     |
| _std_act        | 0.828937  |
| _std_adv        | 1         |
| _std_discrew    | 2.01      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 404
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.909     |
| ExplainedVarOld | 0.782     |
| KL              | 0.0128361 |
| Phi_loss        | 1118.86   |
| PolicyEntropy   | -0.321273 |
| PolicyLoss      | 0.424313  |
| Steps           | 10000     |
| VarFuncLoss     | 0.184     |
| _MeanReward     | 4.65e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.53124   |
| _max_adv        | 11.7      |
| _max_discrew    | 4.94      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0295224 |
| _mean_adv       | -4.26e-18 |
| _mean_discrew   | 3.85      |
| _mean_obs       | 0.041     |
| _min_adv        | -8.11     |
| _min_discrew    | 0.0173    |
| _min_obs        | -1.08     |
| _std_act        | 0.781927  |
| _std_adv        | 1         |
| _std_discrew    | 1.39      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 405
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.992     |
| ExplainedVarOld | 0.992     |
| KL              | 0.0204884 |
| Phi_loss        | 1286.52   |
| PolicyEntropy   | -0.316393 |
| PolicyLoss      | 0.735642  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0122    |
| _MeanReward     | 4.67e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.74538   |
| _max_adv        | 7.17      |
| _max_discrew    | 4.97      |
| _max_obs        | 1.06      |
| _mean_act       | 0.0271063 |
| _mean_adv       | -4.55e-17 |
| _mean_discrew   | 3.84      |
| _mean_obs       | 0.0409    |
| _min_adv        | -3.91     |
| _min_discrew    | 0.0195    |
| _min_obs        | -0.951    |
| _std_act        | 0.787752  |
| _std_adv        | 1         |
| _std_discrew    | 1.45      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 406
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.992     |
| ExplainedVarOld | 0.987     |
| KL              | 0.0452118 |
| Phi_loss        | 1269.09   |
| PolicyEntropy   | -0.312597 |
| PolicyLoss      | 1.61852   |
| Steps           | 10000     |
| VarFuncLoss     | 0.0111    |
| _MeanReward     | 4.68e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.57611   |
| _max_adv        | 7.77      |
| _max_discrew    | 4.94      |
| _max_obs        | 1.09      |
| _mean_act       | 0.0237748 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.86      |
| _mean_obs       | 0.0404    |
| _min_adv        | -6.44     |
| _min_discrew    | 0.021     |
| _min_obs        | -0.965    |
| _std_act        | 0.800995  |
| _std_adv        | 1         |
| _std_discrew    | 1.38      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 407
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0359953 |
| Phi_loss        | 1534.15   |
| PolicyEntropy   | -0.309266 |
| PolicyLoss      | 1.2823    |
| Steps           | 10000     |
| VarFuncLoss     | 0.00734   |
| _MeanReward     | 4.73e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.62269   |
| _max_adv        | 3.13      |
| _max_discrew    | 5.05      |
| _max_obs        | 1.02      |
| _mean_act       | 0.0227866 |
| _mean_adv       | 2.7e-17   |
| _mean_discrew   | 3.9       |
| _mean_obs       | 0.0403    |
| _min_adv        | -6.66     |
| _min_discrew    | 0.0168    |
| _min_obs        | -1.02     |
| _std_act        | 0.803194  |
| _std_adv        | 1         |
| _std_discrew    | 1.46      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 408
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0286801 |
| Phi_loss        | 1486.62   |
| PolicyEntropy   | -0.30652  |
| PolicyLoss      | 1.01134   |
| Steps           | 10000     |
| VarFuncLoss     | 0.00948   |
| _MeanReward     | 4.74e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.62416   |
| _max_adv        | 4.54      |
| _max_discrew    | 5.09      |
| _max_obs        | 0.999     |
| _mean_act       | 0.02241   |
| _mean_adv       | 1.71e-17  |
| _mean_discrew   | 3.9       |
| _mean_obs       | 0.0402    |
| _min_adv        | -7.22     |
| _min_discrew    | 0.0181    |
| _min_obs        | -0.977    |
| _std_act        | 0.811813  |
| _std_adv        | 1         |
| _std_discrew    | 1.48      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 409
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.994     |
| KL              | 0.0229454 |
| Phi_loss        | 1347.61   |
| PolicyEntropy   | -0.304119 |
| PolicyLoss      | 0.801492  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00806   |
| _MeanReward     | 4.65e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.85755   |
| _max_adv        | 2.4       |
| _max_discrew    | 5.01      |
| _max_obs        | 1.76      |
| _mean_act       | 0.0116942 |
| _mean_adv       | 1.42e-17  |
| _mean_discrew   | 3.81      |
| _mean_obs       | 0.0391    |
| _min_adv        | -16.1     |
| _min_discrew    | -0.609    |
| _min_obs        | -1.04     |
| _std_act        | 0.83109   |
| _std_adv        | 1         |
| _std_discrew    | 1.67      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 410
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.967     |
| ExplainedVarOld | 0.963     |
| KL              | 0.0180865 |
| Phi_loss        | 1241.02   |
| PolicyEntropy   | -0.302081 |
| PolicyLoss      | 0.647516  |
| Steps           | 10000     |
| VarFuncLoss     | 0.0569    |
| _MeanReward     | 4.69e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.63667   |
| _max_adv        | 24.5      |
| _max_discrew    | 4.96      |
| _max_obs        | 1.04      |
| _mean_act       | 0.0164202 |
| _mean_adv       | -1.71e-17 |
| _mean_discrew   | 3.86      |
| _mean_obs       | 0.0388    |
| _min_adv        | -5.53     |
| _min_discrew    | 0.0193    |
| _min_obs        | -1.06     |
| _std_act        | 0.814039  |
| _std_adv        | 1         |
| _std_discrew    | 1.47      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 411
Draw Samples..
-------------------------------
| Beta            | 35        |
| ExplainedVarNew | 0.994     |
| ExplainedVarOld | 0.993     |
| KL              | 0.0145395 |
| Phi_loss        | 1434.9    |
| PolicyEntropy   | -0.300524 |
| PolicyLoss      | 0.489231  |
| Steps           | 10000     |
| VarFuncLoss     | 0.00963   |
| _MeanReward     | 4.59e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.77968   |
| _max_adv        | 8.97      |
| _max_discrew    | 5.06      |
| _max_obs        | 1.04      |
| _mean_act       | 0.010677  |
| _mean_adv       | -2.27e-17 |
| _mean_discrew   | 3.76      |
| _mean_obs       | 0.0378    |
| _min_adv        | -14.8     |
| _min_discrew    | -0.34     |
| _min_obs        | -1.01     |
| _std_act        | 0.820742  |
| _std_adv        | 1         |
| _std_discrew    | 1.56      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 412
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.974      |
| ExplainedVarOld | 0.97       |
| KL              | 0.0136971  |
| Phi_loss        | 974.022    |
| PolicyEntropy   | -0.289969  |
| PolicyLoss      | 0.509312   |
| Steps           | 10000      |
| VarFuncLoss     | 0.0423     |
| _MeanReward     | 4.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.65688    |
| _max_adv        | 10.1       |
| _max_discrew    | 4.93       |
| _max_obs        | 1.77       |
| _mean_act       | -0.0339527 |
| _mean_adv       | 4.26e-17   |
| _mean_discrew   | 3.26       |
| _mean_obs       | 0.0352     |
| _min_adv        | -14.4      |
| _min_discrew    | -1.71      |
| _min_obs        | -1.15      |
| _std_act        | 0.913233   |
| _std_adv        | 1          |
| _std_discrew    | 3.34       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 413
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.865       |
| ExplainedVarOld | 0.844       |
| KL              | 0.0243696   |
| Phi_loss        | 930.681     |
| PolicyEntropy   | -0.286171   |
| PolicyLoss      | 0.823027    |
| Steps           | 10000       |
| VarFuncLoss     | 0.458       |
| _MeanReward     | 4.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79791     |
| _max_adv        | 13.6        |
| _max_discrew    | 4.88        |
| _max_obs        | 1.74        |
| _mean_act       | 0.000746857 |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.0353      |
| _min_adv        | -15.2       |
| _min_discrew    | -0.436      |
| _min_obs        | -1.11       |
| _std_act        | 0.815379    |
| _std_adv        | 1           |
| _std_discrew    | 1.68        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 414
Draw Samples..
---------------------------------
| Beta            | 35          |
| ExplainedVarNew | 0.91        |
| ExplainedVarOld | 0.906       |
| KL              | 0.0208687   |
| Phi_loss        | 1035.6      |
| PolicyEntropy   | -0.282712   |
| PolicyLoss      | 0.820468    |
| Steps           | 10000       |
| VarFuncLoss     | 0.151       |
| _MeanReward     | 4.29e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.74221     |
| _max_adv        | 12.7        |
| _max_discrew    | 4.77        |
| _max_obs        | 1.14        |
| _mean_act       | -0.00474717 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 3.51        |
| _mean_obs       | 0.0331      |
| _min_adv        | -12.4       |
| _min_discrew    | -0.47       |
| _min_obs        | -1.03       |
| _std_act        | 0.787529    |
| _std_adv        | 1           |
| _std_discrew    | 1.5         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 415
Draw Samples..
--------------------------------
| Beta            | 35         |
| ExplainedVarNew | 0.927      |
| ExplainedVarOld | 0.892      |
| KL              | 0.0167477  |
| Phi_loss        | 785.15     |
| PolicyEntropy   | -0.279423  |
| PolicyLoss      | 0.611056   |
| Steps           | 10000      |
| VarFuncLoss     | 0.11       |
| _MeanReward     | 3.29e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 3.15066    |
| _max_adv        | 4.59       |
| _max_discrew    | 4.79       |
| _max_obs        | 2.05       |
| _mean_act       | -0.0732127 |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 2.54       |
| _mean_obs       | 0.0311     |
| _min_adv        | -12.1      |
| _min_discrew    | -1.65      |
| _min_obs        | -1.17      |
| _std_act        | 0.908931   |
| _std_adv        | 1          |
| _std_discrew    | 3.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 416
Draw Samples..
---------------------------------
| Beta            | 23.3        |
| ExplainedVarNew | 0.786       |
| ExplainedVarOld | 0.753       |
| KL              | 0.000892515 |
| Phi_loss        | 1208.75     |
| PolicyEntropy   | -0.281531   |
| PolicyLoss      | -0.0328299  |
| Steps           | 10000       |
| VarFuncLoss     | 0.852       |
| _MeanReward     | 3.78e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.68444     |
| _max_adv        | 4.73        |
| _max_discrew    | 4.68        |
| _max_obs        | 1.8         |
| _mean_act       | -0.0387144  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.01        |
| _mean_obs       | 0.0314      |
| _min_adv        | -11.3       |
| _min_discrew    | -1.47       |
| _min_obs        | -1.18       |
| _std_act        | 0.859335    |
| _std_adv        | 1           |
| _std_discrew    | 2.44        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 417
Draw Samples..
---------------------------------
| Beta            | 15.6        |
| ExplainedVarNew | 0.851       |
| ExplainedVarOld | 0.828       |
| KL              | 5.90429e-05 |
| Phi_loss        | 1516.18     |
| PolicyEntropy   | -0.281962   |
| PolicyLoss      | 0.0374882   |
| Steps           | 10000       |
| VarFuncLoss     | 0.372       |
| _MeanReward     | 3.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.81521     |
| _max_adv        | 7.86        |
| _max_discrew    | 4.84        |
| _max_obs        | 1.76        |
| _mean_act       | -0.0431646  |
| _mean_adv       | 0           |
| _mean_discrew   | 3.06        |
| _mean_obs       | 0.0321      |
| _min_adv        | -13.9       |
| _min_discrew    | -1.62       |
| _min_obs        | -1.14       |
| _std_act        | 0.876856    |
| _std_adv        | 1           |
| _std_discrew    | 3.14        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 418
Draw Samples..
---------------------------------
| Beta            | 10.4        |
| ExplainedVarNew | 0.839       |
| ExplainedVarOld | 0.834       |
| KL              | 5.11167e-06 |
| Phi_loss        | 1531.71     |
| PolicyEntropy   | -0.282288   |
| PolicyLoss      | 0.0239942   |
| Steps           | 10000       |
| VarFuncLoss     | 0.513       |
| _MeanReward     | 3.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.9224      |
| _max_adv        | 8.02        |
| _max_discrew    | 4.69        |
| _max_obs        | 1.77        |
| _mean_act       | -0.0471374  |
| _mean_adv       | -2.27e-17   |
| _mean_discrew   | 2.99        |
| _mean_obs       | 0.0322      |
| _min_adv        | -17         |
| _min_discrew    | -1.72       |
| _min_obs        | -1.28       |
| _std_act        | 0.885775    |
| _std_adv        | 1           |
| _std_discrew    | 3.42        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 419
Draw Samples..
---------------------------------
| Beta            | 6.91        |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.865       |
| KL              | 3.31254e-06 |
| Phi_loss        | 1120.4      |
| PolicyEntropy   | -0.281829   |
| PolicyLoss      | -0.00397704 |
| Steps           | 10000       |
| VarFuncLoss     | 0.396       |
| _MeanReward     | 4.39e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.64553     |
| _max_adv        | 26          |
| _max_discrew    | 4.73        |
| _max_obs        | 1.12        |
| _mean_act       | 0.00193038  |
| _mean_adv       | -8.03e-17   |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.033       |
| _min_adv        | -5.94       |
| _min_discrew    | 0.014       |
| _min_obs        | -1.01       |
| _std_act        | 0.779517    |
| _std_adv        | 1           |
| _std_discrew    | 1.32        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 420
Draw Samples..
---------------------------------
| Beta            | 4.61        |
| ExplainedVarNew | 0.987       |
| ExplainedVarOld | 0.986       |
| KL              | 6.43296e-06 |
| Phi_loss        | 1067.84     |
| PolicyEntropy   | -0.28251    |
| PolicyLoss      | -0.0229464  |
| Steps           | 10000       |
| VarFuncLoss     | 0.0287      |
| _MeanReward     | 3.96e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.75115     |
| _max_adv        | 8.16        |
| _max_discrew    | 4.9         |
| _max_obs        | 1.03        |
| _mean_act       | -0.0243971  |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 3.17        |
| _mean_obs       | 0.0317      |
| _min_adv        | -11.3       |
| _min_discrew    | -0.903      |
| _min_obs        | -1.06       |
| _std_act        | 0.810292    |
| _std_adv        | 1           |
| _std_discrew    | 2.19        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 421
Draw Samples..
---------------------------------
| Beta            | 3.07        |
| ExplainedVarNew | 0.844       |
| ExplainedVarOld | 0.828       |
| KL              | 7.74875e-06 |
| Phi_loss        | 1144.43     |
| PolicyEntropy   | -0.283425   |
| PolicyLoss      | 0.0115574   |
| Steps           | 10000       |
| VarFuncLoss     | 0.361       |
| _MeanReward     | 2.71e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.37033     |
| _max_adv        | 1.38        |
| _max_discrew    | 4.69        |
| _max_obs        | 1.95        |
| _mean_act       | -0.125851   |
| _mean_adv       | 3.41e-17    |
| _mean_discrew   | 2.04        |
| _mean_obs       | 0.0294      |
| _min_adv        | -11.4       |
| _min_discrew    | -1.76       |
| _min_obs        | -1.28       |
| _std_act        | 0.984694    |
| _std_adv        | 1           |
| _std_discrew    | 5.3         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 422
Draw Samples..
---------------------------------
| Beta            | 2.05        |
| ExplainedVarNew | 0.837       |
| ExplainedVarOld | 0.822       |
| KL              | 2.37779e-05 |
| Phi_loss        | 1508.33     |
| PolicyEntropy   | -0.284061   |
| PolicyLoss      | 0.0580081   |
| Steps           | 10000       |
| VarFuncLoss     | 0.882       |
| _MeanReward     | 3.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.94614     |
| _max_adv        | 7.69        |
| _max_discrew    | 4.76        |
| _max_obs        | 1.75        |
| _mean_act       | -0.078958   |
| _mean_adv       | -2.84e-18   |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0304      |
| _min_adv        | -13.8       |
| _min_discrew    | -1.76       |
| _min_obs        | -1.15       |
| _std_act        | 0.946274    |
| _std_adv        | 1           |
| _std_discrew    | 4.58        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 423
Draw Samples..
---------------------------------
| Beta            | 1.37        |
| ExplainedVarNew | 0.89        |
| ExplainedVarOld | 0.876       |
| KL              | 1.58463e-05 |
| Phi_loss        | 1151.59     |
| PolicyEntropy   | -0.282573   |
| PolicyLoss      | 0.0183508   |
| Steps           | 10000       |
| VarFuncLoss     | 0.529       |
| _MeanReward     | 3.75e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.90684     |
| _max_adv        | 9.28        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.72        |
| _mean_act       | -0.0496848  |
| _mean_adv       | 2.84e-17    |
| _mean_discrew   | 2.97        |
| _mean_obs       | 0.0319      |
| _min_adv        | -14.5       |
| _min_discrew    | -1.68       |
| _min_obs        | -1.21       |
| _std_act        | 0.888505    |
| _std_adv        | 1           |
| _std_discrew    | 3.2         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 424
Draw Samples..
---------------------------------
| Beta            | 0.91        |
| ExplainedVarNew | 0.841       |
| ExplainedVarOld | 0.824       |
| KL              | 8.61019e-05 |
| Phi_loss        | 1339.85     |
| PolicyEntropy   | -0.284269   |
| PolicyLoss      | -0.00611639 |
| Steps           | 10000       |
| VarFuncLoss     | 0.511       |
| _MeanReward     | 3.37e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.93303     |
| _max_adv        | 3.96        |
| _max_discrew    | 4.79        |
| _max_obs        | 1.76        |
| _mean_act       | -0.07707    |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 2.6         |
| _mean_obs       | 0.032       |
| _min_adv        | -12.5       |
| _min_discrew    | -1.7        |
| _min_obs        | -1.19       |
| _std_act        | 0.938206    |
| _std_adv        | 1           |
| _std_discrew    | 4.25        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 425
Draw Samples..
---------------------------------
| Beta            | 0.607       |
| ExplainedVarNew | 0.824       |
| ExplainedVarOld | 0.799       |
| KL              | 0.000142743 |
| Phi_loss        | 1397.32     |
| PolicyEntropy   | -0.290171   |
| PolicyLoss      | -0.0175993  |
| Steps           | 10000       |
| VarFuncLoss     | 0.753       |
| _MeanReward     | 3.44e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.04083     |
| _max_adv        | 3.6         |
| _max_discrew    | 4.68        |
| _max_obs        | 1.72        |
| _mean_act       | -0.0698394  |
| _mean_adv       | 0           |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0315      |
| _min_adv        | -12.6       |
| _min_discrew    | -1.67       |
| _min_obs        | -1.35       |
| _std_act        | 0.930636    |
| _std_adv        | 1           |
| _std_discrew    | 3.88        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 426
Draw Samples..
---------------------------------
| Beta            | 0.405       |
| ExplainedVarNew | 0.829       |
| ExplainedVarOld | 0.823       |
| KL              | 0.000202472 |
| Phi_loss        | 1471.32     |
| PolicyEntropy   | -0.299369   |
| PolicyLoss      | 0.013745    |
| Steps           | 10000       |
| VarFuncLoss     | 0.663       |
| _MeanReward     | 4.24e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5961      |
| _max_adv        | 13.9        |
| _max_discrew    | 4.79        |
| _max_obs        | 0.999       |
| _mean_act       | -0.00838979 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.44        |
| _mean_obs       | 0.0332      |
| _min_adv        | -14.7       |
| _min_discrew    | -1.08       |
| _min_obs        | -1.1        |
| _std_act        | 0.795478    |
| _std_adv        | 1           |
| _std_discrew    | 2.05        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 427
Draw Samples..
---------------------------------
| Beta            | 0.27        |
| ExplainedVarNew | 0.884       |
| ExplainedVarOld | 0.867       |
| KL              | 0.000338682 |
| Phi_loss        | 1260.07     |
| PolicyEntropy   | -0.314143   |
| PolicyLoss      | 0.0253468   |
| Steps           | 10000       |
| VarFuncLoss     | 0.28        |
| _MeanReward     | 3.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 3.31719     |
| _max_adv        | 8.54        |
| _max_discrew    | 4.93        |
| _max_obs        | 1.87        |
| _mean_act       | -0.0764604  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 2.68        |
| _mean_obs       | 0.0314      |
| _min_adv        | -11.3       |
| _min_discrew    | -1.72       |
| _min_obs        | -1.3        |
| _std_act        | 0.95087     |
| _std_adv        | 1           |
| _std_discrew    | 4.51        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 428
Draw Samples..
---------------------------------
| Beta            | 0.18        |
| ExplainedVarNew | 0.834       |
| ExplainedVarOld | 0.815       |
| KL              | 0.000489563 |
| Phi_loss        | 1222.98     |
| PolicyEntropy   | -0.306516   |
| PolicyLoss      | 0.0409298   |
| Steps           | 10000       |
| VarFuncLoss     | 0.757       |
| _MeanReward     | 4.35e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.86337     |
| _max_adv        | 4.3         |
| _max_discrew    | 4.89        |
| _max_obs        | 1.68        |
| _mean_act       | -0.00448061 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.55        |
| _mean_obs       | 0.0337      |
| _min_adv        | -16.8       |
| _min_discrew    | -0.978      |
| _min_obs        | -1.05       |
| _std_act        | 0.800265    |
| _std_adv        | 1           |
| _std_discrew    | 1.78        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 429
Draw Samples..
---------------------------------
| Beta            | 0.12        |
| ExplainedVarNew | 0.925       |
| ExplainedVarOld | 0.922       |
| KL              | 0.000945814 |
| Phi_loss        | 1213.78     |
| PolicyEntropy   | -0.289124   |
| PolicyLoss      | -0.0123058  |
| Steps           | 10000       |
| VarFuncLoss     | 0.145       |
| _MeanReward     | 4.32e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.80201     |
| _max_adv        | 9.58        |
| _max_discrew    | 4.83        |
| _max_obs        | 1.68        |
| _mean_act       | -0.00629731 |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.51        |
| _mean_obs       | 0.0336      |
| _min_adv        | -11.3       |
| _min_discrew    | -0.521      |
| _min_obs        | -1.19       |
| _std_act        | 0.802016    |
| _std_adv        | 1           |
| _std_discrew    | 1.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 430
Draw Samples..
----------------------------------
| Beta            | 0.0799       |
| ExplainedVarNew | 0.931        |
| ExplainedVarOld | 0.915        |
| KL              | 0.000818812  |
| Phi_loss        | 1065.61      |
| PolicyEntropy   | -0.288385    |
| PolicyLoss      | -0.0627938   |
| Steps           | 10000        |
| VarFuncLoss     | 0.128        |
| _MeanReward     | 4.4e+03      |
| _lr_multiplier  | 1            |
| _max_act        | 3.02872      |
| _max_adv        | 5.08         |
| _max_discrew    | 4.94         |
| _max_obs        | 1.68         |
| _mean_act       | -0.000372188 |
| _mean_adv       | 1.14e-17     |
| _mean_discrew   | 3.59         |
| _mean_obs       | 0.0342       |
| _min_adv        | -17          |
| _min_discrew    | -0.791       |
| _min_obs        | -1.22        |
| _std_act        | 0.799246     |
| _std_adv        | 1            |
| _std_discrew    | 1.65         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 431
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.945      |
| ExplainedVarOld | 0.943      |
| KL              | 0.00137346 |
| Phi_loss        | 1146.05    |
| PolicyEntropy   | -0.288358  |
| PolicyLoss      | 0.0296867  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0911     |
| _MeanReward     | 4.47e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81419    |
| _max_adv        | 9.99       |
| _max_discrew    | 4.89       |
| _max_obs        | 0.999      |
| _mean_act       | 0.00728808 |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 3.67       |
| _mean_obs       | 0.0343     |
| _min_adv        | -3.95      |
| _min_discrew    | 0.0182     |
| _min_obs        | -0.985     |
| _std_act        | 0.781184   |
| _std_adv        | 1          |
| _std_discrew    | 1.35       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 432
Draw Samples..
--------------------------------
| Beta            | 0.0533     |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.983      |
| KL              | 0.00175382 |
| Phi_loss        | 1077.4     |
| PolicyEntropy   | -0.295402  |
| PolicyLoss      | -0.0248443 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0119     |
| _MeanReward     | 4.53e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.67514    |
| _max_adv        | 8.1        |
| _max_discrew    | 4.89       |
| _max_obs        | 1.13       |
| _mean_act       | 0.00847629 |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 3.71       |
| _mean_obs       | 0.0349     |
| _min_adv        | -4.77      |
| _min_discrew    | 0.00744    |
| _min_obs        | -1.05      |
| _std_act        | 0.777777   |
| _std_adv        | 1          |
| _std_discrew    | 1.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 433
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.994       |
| ExplainedVarOld | 0.993       |
| KL              | 0.00312486  |
| Phi_loss        | 1222.52     |
| PolicyEntropy   | -0.3266     |
| PolicyLoss      | -0.00484132 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00916     |
| _MeanReward     | 4.46e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.53008     |
| _max_adv        | 7.14        |
| _max_discrew    | 4.9         |
| _max_obs        | 1.11        |
| _mean_act       | 0.00235322  |
| _mean_adv       | 2.27e-17    |
| _mean_discrew   | 3.64        |
| _mean_obs       | 0.0351      |
| _min_adv        | -18.4       |
| _min_discrew    | -0.165      |
| _min_obs        | -1.03       |
| _std_act        | 0.799167    |
| _std_adv        | 1           |
| _std_discrew    | 1.6         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 434
Draw Samples..
---------------------------------
| Beta            | 0.0533      |
| ExplainedVarNew | 0.957       |
| ExplainedVarOld | 0.952       |
| KL              | 0.00247634  |
| Phi_loss        | 1306.4      |
| PolicyEntropy   | -0.349786   |
| PolicyLoss      | -0.00326548 |
| Steps           | 10000       |
| VarFuncLoss     | 0.07        |
| _MeanReward     | 4.58e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.5918      |
| _max_adv        | 14.1        |
| _max_discrew    | 4.96        |
| _max_obs        | 1.15        |
| _mean_act       | 0.00588869  |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.76        |
| _mean_obs       | 0.0366      |
| _min_adv        | -15.2       |
| _min_discrew    | -0.408      |
| _min_obs        | -0.984      |
| _std_act        | 0.798715    |
| _std_adv        | 1           |
| _std_discrew    | 1.62        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 435
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.967      |
| ExplainedVarOld | 0.965      |
| KL              | 0.00145845 |
| Phi_loss        | 1217.53    |
| PolicyEntropy   | -0.363553  |
| PolicyLoss      | 0.00501931 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0557     |
| _MeanReward     | 4.6e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.55318    |
| _max_adv        | 8.37       |
| _max_discrew    | 4.95       |
| _max_obs        | 1.11       |
| _mean_act       | 0.00929875 |
| _mean_adv       | -1.71e-17  |
| _mean_discrew   | 3.79       |
| _mean_obs       | 0.0363     |
| _min_adv        | -5.26      |
| _min_discrew    | 0.018      |
| _min_obs        | -0.991     |
| _std_act        | 0.790297   |
| _std_adv        | 1          |
| _std_discrew    | 1.41       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 436
Draw Samples..
--------------------------------
| Beta            | 0.0355     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00153429 |
| Phi_loss        | 1141.75    |
| PolicyEntropy   | -0.368215  |
| PolicyLoss      | 0.0200958  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00889    |
| _MeanReward     | 3.93e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.90728    |
| _max_adv        | 3.6        |
| _max_discrew    | 4.94       |
| _max_obs        | 1.71       |
| _mean_act       | -0.039483  |
| _mean_adv       | 3.13e-17   |
| _mean_discrew   | 3.13       |
| _mean_obs       | 0.0346     |
| _min_adv        | -14.5      |
| _min_discrew    | -1.62      |
| _min_obs        | -1.32      |
| _std_act        | 0.88847    |
| _std_adv        | 1          |
| _std_discrew    | 3.42       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 437
Draw Samples..
---------------------------------
| Beta            | 0.0355      |
| ExplainedVarNew | 0.845       |
| ExplainedVarOld | 0.826       |
| KL              | 0.00279772  |
| Phi_loss        | 1364.08     |
| PolicyEntropy   | -0.402308   |
| PolicyLoss      | 0.0119513   |
| Steps           | 10000       |
| VarFuncLoss     | 0.548       |
| _MeanReward     | 4.42e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79786     |
| _max_adv        | 7.32        |
| _max_discrew    | 5.07        |
| _max_obs        | 1.68        |
| _mean_act       | -0.00782368 |
| _mean_adv       | 0           |
| _mean_discrew   | 3.61        |
| _mean_obs       | 0.0362      |
| _min_adv        | -20.7       |
| _min_discrew    | -1.44       |
| _min_obs        | -1.18       |
| _std_act        | 0.845134    |
| _std_adv        | 1           |
| _std_discrew    | 2.29        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 438
Draw Samples..
-------------------------------
| Beta            | 0.0286    |
| ExplainedVarNew | 0.887     |
| ExplainedVarOld | 0.885     |
| KL              | 0.0010268 |
| Phi_loss        | 1449.41   |
| PolicyEntropy   | -0.423882 |
| PolicyLoss      | 0.0148088 |
| Steps           | 10000     |
| VarFuncLoss     | 0.271     |
| _MeanReward     | 4.1e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.86984   |
| _max_adv        | 6.05      |
| _max_discrew    | 5.02      |
| _max_obs        | 1.69      |
| _mean_act       | -0.032295 |
| _mean_adv       | -1.14e-17 |
| _mean_discrew   | 3.34      |
| _mean_obs       | 0.0353    |
| _min_adv        | -20.4     |
| _min_discrew    | -1.72     |
| _min_obs        | -1.07     |
| _std_act        | 0.893671  |
| _std_adv        | 1         |
| _std_discrew    | 3.48      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 439
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.919      |
| ExplainedVarOld | 0.907      |
| KL              | 0.00107108 |
| Phi_loss        | 1369.7     |
| PolicyEntropy   | -0.416415  |
| PolicyLoss      | -0.0133977 |
| Steps           | 10000      |
| VarFuncLoss     | 0.282      |
| _MeanReward     | 4.57e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.5121     |
| _max_adv        | 5.72       |
| _max_discrew    | 4.99       |
| _max_obs        | 1.08       |
| _mean_act       | 0.00397068 |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.74       |
| _mean_obs       | 0.0371     |
| _min_adv        | -17.1      |
| _min_discrew    | -0.799     |
| _min_obs        | -1.13      |
| _std_act        | 0.809949   |
| _std_adv        | 1          |
| _std_discrew    | 1.87       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 440
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.923      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00221617 |
| Phi_loss        | 1143.27    |
| PolicyEntropy   | -0.401721  |
| PolicyLoss      | 0.00553214 |
| Steps           | 10000      |
| VarFuncLoss     | 0.143      |
| _MeanReward     | 4.69e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.59103    |
| _max_adv        | 35.2       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0117423  |
| _mean_adv       | -4.55e-17  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0374     |
| _min_adv        | -4.84      |
| _min_discrew    | 0.0156     |
| _min_obs        | -1.03      |
| _std_act        | 0.794694   |
| _std_adv        | 1          |
| _std_discrew    | 1.45       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 441
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.991      |
| ExplainedVarOld | 0.986      |
| KL              | 0.0015523  |
| Phi_loss        | 964.249    |
| PolicyEntropy   | -0.391704  |
| PolicyLoss      | -0.0159403 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0139     |
| _MeanReward     | 4.24e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54302    |
| _max_adv        | 2.45       |
| _max_discrew    | 4.96       |
| _max_obs        | 1.09       |
| _mean_act       | -0.0144704 |
| _mean_adv       | 0          |
| _mean_discrew   | 3.43       |
| _mean_obs       | 0.0369     |
| _min_adv        | -16.6      |
| _min_discrew    | -1.28      |
| _min_obs        | -0.996     |
| _std_act        | 0.845358   |
| _std_adv        | 1          |
| _std_discrew    | 2.93       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 442
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.883      |
| ExplainedVarOld | 0.872      |
| KL              | 0.00245138 |
| Phi_loss        | 1553.29    |
| PolicyEntropy   | -0.398635  |
| PolicyLoss      | -0.0882575 |
| Steps           | 10000      |
| VarFuncLoss     | 0.35       |
| _MeanReward     | 4.62e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.81012    |
| _max_adv        | 9.05       |
| _max_discrew    | 5.02       |
| _max_obs        | 1.74       |
| _mean_act       | 0.00622632 |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.78       |
| _mean_obs       | 0.0377     |
| _min_adv        | -18        |
| _min_discrew    | -0.86      |
| _min_obs        | -1.29      |
| _std_act        | 0.825312   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 443
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.94       |
| ExplainedVarOld | 0.937      |
| KL              | 0.00248813 |
| Phi_loss        | 1395.52    |
| PolicyEntropy   | -0.411336  |
| PolicyLoss      | -0.0154855 |
| Steps           | 10000      |
| VarFuncLoss     | 0.106      |
| _MeanReward     | 4.7e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.49016    |
| _max_adv        | 23.4       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0129029  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.038      |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.05      |
| _std_act        | 0.802279   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 444
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.99        |
| ExplainedVarOld | 0.986       |
| KL              | 0.00217361  |
| Phi_loss        | 1194.8      |
| PolicyEntropy   | -0.420859   |
| PolicyLoss      | -0.00104392 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0167      |
| _MeanReward     | 4.73e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.58641     |
| _max_adv        | 15.7        |
| _max_discrew    | 5.08        |
| _max_obs        | 1.28        |
| _mean_act       | 0.0123559   |
| _mean_adv       | 2.84e-18    |
| _mean_discrew   | 3.9         |
| _mean_obs       | 0.0388      |
| _min_adv        | -9.79       |
| _min_discrew    | -0.0337     |
| _min_obs        | -1.09       |
| _std_act        | 0.80618     |
| _std_adv        | 1           |
| _std_discrew    | 1.52        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 445
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.993      |
| ExplainedVarOld | 0.991      |
| KL              | 0.00243248 |
| Phi_loss        | 1301.3     |
| PolicyEntropy   | -0.430209  |
| PolicyLoss      | -0.0128392 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0114     |
| _MeanReward     | 4.71e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7301     |
| _max_adv        | 4.81       |
| _max_discrew    | 5.12       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0150042  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.86       |
| _mean_obs       | 0.0386     |
| _min_adv        | -15.6      |
| _min_discrew    | -0.27      |
| _min_obs        | -1.03      |
| _std_act        | 0.813465   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 446
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.981       |
| ExplainedVarOld | 0.98        |
| KL              | 0.00434142  |
| Phi_loss        | 1712.95     |
| PolicyEntropy   | -0.45       |
| PolicyLoss      | 0.000179664 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0305      |
| _MeanReward     | 4.77e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.54737     |
| _max_adv        | 10.7        |
| _max_discrew    | 5.02        |
| _max_obs        | 1.09        |
| _mean_act       | 0.0198615   |
| _mean_adv       | -1.14e-17   |
| _mean_discrew   | 3.93        |
| _mean_obs       | 0.0397      |
| _min_adv        | -5.17       |
| _min_discrew    | 0.0163      |
| _min_obs        | -0.992      |
| _std_act        | 0.809881    |
| _std_adv        | 1           |
| _std_discrew    | 1.49        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 447
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00390773 |
| Phi_loss        | 1204.59    |
| PolicyEntropy   | -0.48706   |
| PolicyLoss      | -0.0396613 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0082     |
| _MeanReward     | 4.78e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.61409    |
| _max_adv        | 7.63       |
| _max_discrew    | 5.01       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0195201  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 3.93       |
| _mean_obs       | 0.0395     |
| _min_adv        | -4.51      |
| _min_discrew    | 0.022      |
| _min_obs        | -1.01      |
| _std_act        | 0.812519   |
| _std_adv        | 1          |
| _std_discrew    | 1.48       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 448
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.0028505  |
| Phi_loss        | 1453.61    |
| PolicyEntropy   | -0.536454  |
| PolicyLoss      | 0.00174836 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00641    |
| _MeanReward     | 4.81e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54526    |
| _max_adv        | 3.97       |
| _max_discrew    | 5.05       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0192364  |
| _mean_adv       | -3.41e-17  |
| _mean_discrew   | 3.95       |
| _mean_obs       | 0.0399     |
| _min_adv        | -5.18      |
| _min_discrew    | 0.0144     |
| _min_obs        | -0.992     |
| _std_act        | 0.815796   |
| _std_adv        | 1          |
| _std_discrew    | 1.49       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 449
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00369647 |
| Phi_loss        | 1581.78    |
| PolicyEntropy   | -0.567632  |
| PolicyLoss      | -0.0354657 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00779    |
| _MeanReward     | 4.84e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.40967    |
| _max_adv        | 4.64       |
| _max_discrew    | 5.13       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0248874  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 3.97       |
| _mean_obs       | 0.0407     |
| _min_adv        | -5.9       |
| _min_discrew    | 0.0161     |
| _min_obs        | -1.18      |
| _std_act        | 0.820016   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 450
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00348619 |
| Phi_loss        | 1580.29    |
| PolicyEntropy   | -0.599173  |
| PolicyLoss      | -0.0031041 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00602    |
| _MeanReward     | 4.82e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.7715     |
| _max_adv        | 8.65       |
| _max_discrew    | 5.1        |
| _max_obs        | 0.999      |
| _mean_act       | 0.0257163  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 3.97       |
| _mean_obs       | 0.0409     |
| _min_adv        | -5.63      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.18      |
| _std_act        | 0.824063   |
| _std_adv        | 1          |
| _std_discrew    | 1.51       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 451
Draw Samples..
-------------------------------
| Beta            | 0.0286    |
| ExplainedVarNew | 0.995     |
| ExplainedVarOld | 0.995     |
| KL              | 0.0032634 |
| Phi_loss        | 1611.7    |
| PolicyEntropy   | -0.645805 |
| PolicyLoss      | 0.0176377 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00686   |
| _MeanReward     | 4.84e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.77798   |
| _max_adv        | 4.32      |
| _max_discrew    | 5.11      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0231758 |
| _mean_adv       | 1.14e-17  |
| _mean_discrew   | 3.99      |
| _mean_obs       | 0.041     |
| _min_adv        | -8.64     |
| _min_discrew    | 0.0174    |
| _min_obs        | -1.01     |
| _std_act        | 0.827173  |
| _std_adv        | 1         |
| _std_discrew    | 1.51      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 452
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00425943  |
| Phi_loss        | 1587.8      |
| PolicyEntropy   | -0.674578   |
| PolicyLoss      | 0.0116852   |
| Steps           | 10000       |
| VarFuncLoss     | 0.00449     |
| _MeanReward     | 4.31e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.49682     |
| _max_adv        | 10.6        |
| _max_discrew    | 5.05        |
| _max_obs        | 1.06        |
| _mean_act       | -0.00382818 |
| _mean_adv       | 8.53e-18    |
| _mean_discrew   | 3.56        |
| _mean_obs       | 0.0395      |
| _min_adv        | -23.7       |
| _min_discrew    | -1.24       |
| _min_obs        | -1.1        |
| _std_act        | 0.880632    |
| _std_adv        | 1           |
| _std_discrew    | 3.02        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 453
Draw Samples..
-------------------------------
| Beta            | 0.0286    |
| ExplainedVarNew | 0.991     |
| ExplainedVarOld | 0.967     |
| KL              | 0.0021245 |
| Phi_loss        | 532.704   |
| PolicyEntropy   | -0.67347  |
| PolicyLoss      | 0.0147434 |
| Steps           | 10000     |
| VarFuncLoss     | 0.0282    |
| _MeanReward     | 4.88e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.57397   |
| _max_adv        | 14.8      |
| _max_discrew    | 5.15      |
| _max_obs        | 1.09      |
| _mean_act       | 0.0245976 |
| _mean_adv       | -1.42e-17 |
| _mean_discrew   | 4.01      |
| _mean_obs       | 0.0418    |
| _min_adv        | -3        |
| _min_discrew    | 0.0174    |
| _min_obs        | -1.07     |
| _std_act        | 0.829109  |
| _std_adv        | 1         |
| _std_discrew    | 1.54      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 454
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00241011  |
| Phi_loss        | 1054.83     |
| PolicyEntropy   | -0.690222   |
| PolicyLoss      | -0.00674734 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00794     |
| _MeanReward     | 4.9e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.70785     |
| _max_adv        | 15.2        |
| _max_discrew    | 5.15        |
| _max_obs        | 1.04        |
| _mean_act       | 0.0276394   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.03        |
| _mean_obs       | 0.0423      |
| _min_adv        | -4.17       |
| _min_discrew    | 0.0141      |
| _min_obs        | -1.04       |
| _std_act        | 0.830027    |
| _std_adv        | 1           |
| _std_discrew    | 1.57        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 455
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00288484 |
| Phi_loss        | 1166.66    |
| PolicyEntropy   | -0.721604  |
| PolicyLoss      | -0.0252218 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00501    |
| _MeanReward     | 4.89e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57843    |
| _max_adv        | 35.9       |
| _max_discrew    | 5.12       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0263005  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.02       |
| _mean_obs       | 0.042      |
| _min_adv        | -4.21      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.04      |
| _std_act        | 0.82572    |
| _std_adv        | 1          |
| _std_discrew    | 1.55       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 456
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00285267 |
| Phi_loss        | 1493.59    |
| PolicyEntropy   | -0.746024  |
| PolicyLoss      | 0.00396821 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00603    |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53131    |
| _max_adv        | 31         |
| _max_discrew    | 5.23       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0272507  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0425     |
| _min_adv        | -5.89      |
| _min_discrew    | 0.018      |
| _min_obs        | -1.02      |
| _std_act        | 0.837793   |
| _std_adv        | 1          |
| _std_discrew    | 1.54       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 457
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00208346 |
| Phi_loss        | 1353.14    |
| PolicyEntropy   | -0.761075  |
| PolicyLoss      | -0.0237877 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00926    |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.57995    |
| _max_adv        | 4.59       |
| _max_discrew    | 5.19       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0251478  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.04       |
| _mean_obs       | 0.0426     |
| _min_adv        | -5.33      |
| _min_discrew    | 0.0146     |
| _min_obs        | -1.01      |
| _std_act        | 0.838925   |
| _std_adv        | 1          |
| _std_discrew    | 1.56       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 458
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00276676 |
| Phi_loss        | 1691.04    |
| PolicyEntropy   | -0.763034  |
| PolicyLoss      | -0.0105842 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00722    |
| _MeanReward     | 4.95e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.41446    |
| _max_adv        | 7.73       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0289885  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.07       |
| _mean_obs       | 0.0431     |
| _min_adv        | -5.17      |
| _min_discrew    | 0.0142     |
| _min_obs        | -1.06      |
| _std_act        | 0.844913   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 459
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00380193 |
| Phi_loss        | 1692.4     |
| PolicyEntropy   | -0.780996  |
| PolicyLoss      | -0.0345258 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00482    |
| _MeanReward     | 4.92e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45461    |
| _max_adv        | 2.53       |
| _max_discrew    | 5.19       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0263027  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.04       |
| _mean_obs       | 0.0433     |
| _min_adv        | -13.5      |
| _min_discrew    | -0.348     |
| _min_obs        | -1.02      |
| _std_act        | 0.841003   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 460
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.979      |
| ExplainedVarOld | 0.974      |
| KL              | 0.00417534 |
| Phi_loss        | 1087.16    |
| PolicyEntropy   | -0.79856   |
| PolicyLoss      | -0.0596783 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0363     |
| _MeanReward     | 4.76e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48395    |
| _max_adv        | 5.38       |
| _max_discrew    | 5.12       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0229435  |
| _mean_adv       | 0          |
| _mean_discrew   | 3.89       |
| _mean_obs       | 0.0425     |
| _min_adv        | -18.9      |
| _min_discrew    | -0.82      |
| _min_obs        | -0.979     |
| _std_act        | 0.859366   |
| _std_adv        | 1          |
| _std_discrew    | 2.04       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 461
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.921      |
| ExplainedVarOld | 0.914      |
| KL              | 0.00213388 |
| Phi_loss        | 1666.61    |
| PolicyEntropy   | -0.817209  |
| PolicyLoss      | -0.0197643 |
| Steps           | 10000      |
| VarFuncLoss     | 0.164      |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.66637    |
| _max_adv        | 31.8       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0341119  |
| _mean_adv       | 1.56e-17   |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0439     |
| _min_adv        | -7.91      |
| _min_discrew    | 0.02       |
| _min_obs        | -1.02      |
| _std_act        | 0.844897   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 462
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00347585 |
| Phi_loss        | 1419.5     |
| PolicyEntropy   | -0.843748  |
| PolicyLoss      | -0.0380312 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0104     |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.48879    |
| _max_adv        | 21         |
| _max_discrew    | 5.21       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0326343  |
| _mean_adv       | -2.13e-17  |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.044      |
| _min_adv        | -6.07      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.07      |
| _std_act        | 0.850256   |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 463
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00444851 |
| Phi_loss        | 1367.62    |
| PolicyEntropy   | -0.870986  |
| PolicyLoss      | -0.0342872 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00558    |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45871    |
| _max_adv        | 9.38       |
| _max_discrew    | 5.28       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0347035  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 4.1        |
| _mean_obs       | 0.0442     |
| _min_adv        | -6.89      |
| _min_discrew    | 0.021      |
| _min_obs        | -1.05      |
| _std_act        | 0.859334   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 464
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00464295 |
| Phi_loss        | 1700.97    |
| PolicyEntropy   | -0.873449  |
| PolicyLoss      | -0.0420288 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00511    |
| _MeanReward     | 4.96e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44628    |
| _max_adv        | 7.87       |
| _max_discrew    | 5.24       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0394501  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0443     |
| _min_adv        | -9.93      |
| _min_discrew    | 0.0165     |
| _min_obs        | -1.02      |
| _std_act        | 0.865469   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 465
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.0032451   |
| Phi_loss        | 1556.78     |
| PolicyEntropy   | -0.874522   |
| PolicyLoss      | -0.00455611 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00596     |
| _MeanReward     | 5.03e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.6318      |
| _max_adv        | 5.09        |
| _max_discrew    | 5.34        |
| _max_obs        | 1.3         |
| _mean_act       | 0.0406845   |
| _mean_adv       | 0           |
| _mean_discrew   | 4.15        |
| _mean_obs       | 0.0451      |
| _min_adv        | -5.71       |
| _min_discrew    | 0.0183      |
| _min_obs        | -1.08       |
| _std_act        | 0.866739    |
| _std_adv        | 1           |
| _std_discrew    | 1.58        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 466
Draw Samples..
--------------------------------
| Beta            | 0.0286     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00192154 |
| Phi_loss        | 1691.36    |
| PolicyEntropy   | -0.880975  |
| PolicyLoss      | 0.00440578 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00649    |
| _MeanReward     | 5e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.49339    |
| _max_adv        | 5.32       |
| _max_discrew    | 5.2        |
| _max_obs        | 1.07       |
| _mean_act       | 0.0360417  |
| _mean_adv       | 2.84e-17   |
| _mean_discrew   | 4.13       |
| _mean_obs       | 0.0444     |
| _min_adv        | -8.42      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.01      |
| _std_act        | 0.870205   |
| _std_adv        | 1          |
| _std_discrew    | 1.6        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 467
Draw Samples..
---------------------------------
| Beta            | 0.0286      |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00383196  |
| Phi_loss        | 1716.61     |
| PolicyEntropy   | -0.892505   |
| PolicyLoss      | -0.00139777 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00489     |
| _MeanReward     | 4.87e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79444     |
| _max_adv        | 4.58        |
| _max_discrew    | 5.21        |
| _max_obs        | 1.74        |
| _mean_act       | 0.026062    |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 4           |
| _mean_obs       | 0.0437      |
| _min_adv        | -19.7       |
| _min_discrew    | -0.939      |
| _min_obs        | -1.19       |
| _std_act        | 0.889268    |
| _std_adv        | 1           |
| _std_discrew    | 1.97        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 468
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.934      |
| ExplainedVarOld | 0.928      |
| KL              | 0.00692434 |
| Phi_loss        | 1414.65    |
| PolicyEntropy   | -0.905457  |
| PolicyLoss      | -0.0110393 |
| Steps           | 10000      |
| VarFuncLoss     | 0.132      |
| _MeanReward     | 5e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.45383    |
| _max_adv        | 30.2       |
| _max_discrew    | 5.2        |
| _max_obs        | 1.11       |
| _mean_act       | 0.0379892  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.12       |
| _mean_obs       | 0.045      |
| _min_adv        | -3.23      |
| _min_discrew    | 0.0147     |
| _min_obs        | -1.14      |
| _std_act        | 0.866125   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 469
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00538404 |
| Phi_loss        | 1422.7     |
| PolicyEntropy   | -0.887649  |
| PolicyLoss      | 0.00160475 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0072     |
| _MeanReward     | 4.98e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60493    |
| _max_adv        | 6.6        |
| _max_discrew    | 5.19       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0333301  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.12       |
| _mean_obs       | 0.0445     |
| _min_adv        | -5.47      |
| _min_discrew    | 0.0214     |
| _min_obs        | -1.09      |
| _std_act        | 0.871377   |
| _std_adv        | 1          |
| _std_discrew    | 1.58       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 470
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00538386 |
| Phi_loss        | 1674.43    |
| PolicyEntropy   | -0.888391  |
| PolicyLoss      | -0.0249484 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00396    |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.60717    |
| _max_adv        | 15         |
| _max_discrew    | 5.21       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0367322  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.12       |
| _mean_obs       | 0.0446     |
| _min_adv        | -7.75      |
| _min_discrew    | 0.0217     |
| _min_obs        | -1.06      |
| _std_act        | 0.875876   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 471
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.998      |
| ExplainedVarOld | 0.998      |
| KL              | 0.00279546 |
| Phi_loss        | 1824.57    |
| PolicyEntropy   | -0.895711  |
| PolicyLoss      | -0.0140889 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00375    |
| _MeanReward     | 5e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.45967    |
| _max_adv        | 6.03       |
| _max_discrew    | 5.29       |
| _max_obs        | 1.26       |
| _mean_act       | 0.0348429  |
| _mean_adv       | -1.99e-17  |
| _mean_discrew   | 4.12       |
| _mean_obs       | 0.0451     |
| _min_adv        | -6.33      |
| _min_discrew    | 0.0225     |
| _min_obs        | -1.06      |
| _std_act        | 0.879873   |
| _std_adv        | 1          |
| _std_discrew    | 1.61       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 472
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00476902 |
| Phi_loss        | 1841.88    |
| PolicyEntropy   | -0.932971  |
| PolicyLoss      | 0.0275289  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00516    |
| _MeanReward     | 4.99e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51068    |
| _max_adv        | 4.66       |
| _max_discrew    | 5.23       |
| _max_obs        | 1.07       |
| _mean_act       | 0.0396875  |
| _mean_adv       | 7.11e-18   |
| _mean_discrew   | 4.11       |
| _mean_obs       | 0.0446     |
| _min_adv        | -5.17      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.03      |
| _std_act        | 0.873812   |
| _std_adv        | 1          |
| _std_discrew    | 1.57       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 473
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00416289 |
| Phi_loss        | 1870.83    |
| PolicyEntropy   | -0.956606  |
| PolicyLoss      | -0.0330787 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00522    |
| _MeanReward     | 5.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.49747    |
| _max_adv        | 17.5       |
| _max_discrew    | 5.29       |
| _max_obs        | 1.05       |
| _mean_act       | 0.0382854  |
| _mean_adv       | 1.99e-17   |
| _mean_discrew   | 4.15       |
| _mean_obs       | 0.0452     |
| _min_adv        | -8.68      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.09      |
| _std_act        | 0.874534   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 474
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00506767 |
| Phi_loss        | 1699.23    |
| PolicyEntropy   | -0.958231  |
| PolicyLoss      | -0.0166241 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00431    |
| _MeanReward     | 4.94e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.76411    |
| _max_adv        | 13         |
| _max_discrew    | 5.42       |
| _max_obs        | 1.06       |
| _mean_act       | 0.0330688  |
| _mean_adv       | 7.82e-18   |
| _mean_discrew   | 4.06       |
| _mean_obs       | 0.0448     |
| _min_adv        | -15.4      |
| _min_discrew    | 0.0186     |
| _min_obs        | -1         |
| _std_act        | 0.892275   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 475
Draw Samples..
---------------------------------
| Beta            | 0.0429      |
| ExplainedVarNew | 0.932       |
| ExplainedVarOld | 0.83        |
| KL              | 0.00313307  |
| Phi_loss        | 861.813     |
| PolicyEntropy   | -0.941695   |
| PolicyLoss      | 0.000314197 |
| Steps           | 10000       |
| VarFuncLoss     | 0.113       |
| _MeanReward     | 5.04e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.42841     |
| _max_adv        | 7.69        |
| _max_discrew    | 5.35        |
| _max_obs        | 0.999       |
| _mean_act       | 0.0380978   |
| _mean_adv       | -8.53e-18   |
| _mean_discrew   | 4.15        |
| _mean_obs       | 0.0451      |
| _min_adv        | -6.78       |
| _min_discrew    | 0.0178      |
| _min_obs        | -1.06       |
| _std_act        | 0.879587    |
| _std_adv        | 1           |
| _std_discrew    | 1.64        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 476
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00515816 |
| Phi_loss        | 1448.12    |
| PolicyEntropy   | -0.935162  |
| PolicyLoss      | -0.0378688 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00725    |
| _MeanReward     | 5.02e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.53225    |
| _max_adv        | 13.6       |
| _max_discrew    | 5.25       |
| _max_obs        | 1.03       |
| _mean_act       | 0.042004   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.13       |
| _mean_obs       | 0.0457     |
| _min_adv        | -6.73      |
| _min_discrew    | 0.0133     |
| _min_obs        | -1.07      |
| _std_act        | 0.882056   |
| _std_adv        | 1          |
| _std_discrew    | 1.59       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 477
Draw Samples..
--------------------------------
| Beta            | 0.0429     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00440254 |
| Phi_loss        | 1724.94    |
| PolicyEntropy   | -0.938977  |
| PolicyLoss      | -0.0382825 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00669    |
| _MeanReward     | 5.03e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39455    |
| _max_adv        | 34.5       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.1        |
| _mean_act       | 0.038986   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.14       |
| _mean_obs       | 0.0455     |
| _min_adv        | -8.65      |
| _min_discrew    | 0.0162     |
| _min_obs        | -1.07      |
| _std_act        | 0.883173   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 478
Draw Samples..
----------------------------------
| Beta            | 0.0429       |
| ExplainedVarNew | 0.993        |
| ExplainedVarOld | 0.993        |
| KL              | 0.00402979   |
| Phi_loss        | 1513.42      |
| PolicyEntropy   | -0.948318    |
| PolicyLoss      | -0.000928158 |
| Steps           | 10000        |
| VarFuncLoss     | 0.0115       |
| _MeanReward     | 5.04e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.51842      |
| _max_adv        | 5.13         |
| _max_discrew    | 5.32         |
| _max_obs        | 1.18         |
| _mean_act       | 0.0364231    |
| _mean_adv       | 1.42e-17     |
| _mean_discrew   | 4.16         |
| _mean_obs       | 0.0456       |
| _min_adv        | -9.01        |
| _min_discrew    | 0.0204       |
| _min_obs        | -1.1         |
| _std_act        | 0.890276     |
| _std_adv        | 1            |
| _std_discrew    | 1.62         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 479
Draw Samples..
----------------------------------
| Beta            | 0.0429       |
| ExplainedVarNew | 0.995        |
| ExplainedVarOld | 0.995        |
| KL              | 0.00435709   |
| Phi_loss        | 1962.0       |
| PolicyEntropy   | -0.972114    |
| PolicyLoss      | -0.000633082 |
| Steps           | 10000        |
| VarFuncLoss     | 0.00749      |
| _MeanReward     | 4.88e+03     |
| _lr_multiplier  | 1            |
| _max_act        | 2.43986      |
| _max_adv        | 3.01         |
| _max_discrew    | 5.42         |
| _max_obs        | 1.21         |
| _mean_act       | 0.0284239    |
| _mean_adv       | 0            |
| _mean_discrew   | 3.99         |
| _mean_obs       | 0.0451       |
| _min_adv        | -17.8        |
| _min_discrew    | -0.597       |
| _min_obs        | -1.03        |
| _std_act        | 0.899352     |
| _std_adv        | 1            |
| _std_discrew    | 2.12         |
----------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 480
Draw Samples..
-------------------------------
| Beta            | 0.0643    |
| ExplainedVarNew | 0.912     |
| ExplainedVarOld | 0.896     |
| KL              | 0.012488  |
| Phi_loss        | 1655.26   |
| PolicyEntropy   | -0.956342 |
| PolicyLoss      | 0.19149   |
| Steps           | 10000     |
| VarFuncLoss     | 0.191     |
| _MeanReward     | 5.06e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.42578   |
| _max_adv        | 30.6      |
| _max_discrew    | 5.35      |
| _max_obs        | 1.13      |
| _mean_act       | 0.0368523 |
| _mean_adv       | -8.53e-18 |
| _mean_discrew   | 4.16      |
| _mean_obs       | 0.0458    |
| _min_adv        | -3.33     |
| _min_discrew    | 0.0197    |
| _min_obs        | -1.03     |
| _std_act        | 0.881915  |
| _std_adv        | 1         |
| _std_discrew    | 1.63      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 481
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00803126 |
| Phi_loss        | 1609.3     |
| PolicyEntropy   | -0.964241  |
| PolicyLoss      | 0.00849758 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0122     |
| _MeanReward     | 5.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.55625    |
| _max_adv        | 34.5       |
| _max_discrew    | 5.34       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0339006  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0461     |
| _min_adv        | -5.49      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.08      |
| _std_act        | 0.882186   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 482
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00295116 |
| Phi_loss        | 2471.94    |
| PolicyEntropy   | -0.987584  |
| PolicyLoss      | -0.0389941 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00751    |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.34806    |
| _max_adv        | 5.96       |
| _max_discrew    | 5.33       |
| _max_obs        | 0.999      |
| _mean_act       | 0.0394253  |
| _mean_adv       | -4.26e-18  |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.0462     |
| _min_adv        | -5.2       |
| _min_discrew    | 0.0129     |
| _min_obs        | -1.07      |
| _std_act        | 0.875889   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 483
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00334952  |
| Phi_loss        | 2059.16     |
| PolicyEntropy   | -0.995772   |
| PolicyLoss      | 0.000713728 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00424     |
| _MeanReward     | 5.06e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.36709     |
| _max_adv        | 17.1        |
| _max_discrew    | 5.37        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0365202   |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 4.18        |
| _mean_obs       | 0.046       |
| _min_adv        | -6.61       |
| _min_discrew    | 0.0195      |
| _min_obs        | -1.01       |
| _std_act        | 0.877543    |
| _std_adv        | 1           |
| _std_discrew    | 1.65        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 484
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00252251 |
| Phi_loss        | 2088.35    |
| PolicyEntropy   | -1.01185   |
| PolicyLoss      | 0.0226206  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00992    |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.36641    |
| _max_adv        | 7.4        |
| _max_discrew    | 5.34       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0354821  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0456     |
| _min_adv        | -5.09      |
| _min_discrew    | 0.0166     |
| _min_obs        | -1.12      |
| _std_act        | 0.875823   |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 485
Draw Samples..
-------------------------------
| Beta            | 0.0964    |
| ExplainedVarNew | 0.997     |
| ExplainedVarOld | 0.997     |
| KL              | 0.0030125 |
| Phi_loss        | 2016.85   |
| PolicyEntropy   | -1.03944  |
| PolicyLoss      | 0.0111868 |
| Steps           | 10000     |
| VarFuncLoss     | 0.00509   |
| _MeanReward     | 5.05e+03  |
| _lr_multiplier  | 1         |
| _max_act        | 2.30763   |
| _max_adv        | 7.44      |
| _max_discrew    | 5.35      |
| _max_obs        | 1.14      |
| _mean_act       | 0.0318274 |
| _mean_adv       | -1.99e-17 |
| _mean_discrew   | 4.16      |
| _mean_obs       | 0.0453    |
| _min_adv        | -4.57     |
| _min_discrew    | 0.0178    |
| _min_obs        | -1.03     |
| _std_act        | 0.882279  |
| _std_adv        | 1         |
| _std_discrew    | 1.63      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 486
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00324016 |
| Phi_loss        | 1939.16    |
| PolicyEntropy   | -1.06544   |
| PolicyLoss      | -0.0322397 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00517    |
| _MeanReward     | 5.08e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45982    |
| _max_adv        | 16.9       |
| _max_discrew    | 5.46       |
| _max_obs        | 1.1        |
| _mean_act       | 0.0342264  |
| _mean_adv       | 8.53e-18   |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.046      |
| _min_adv        | -5.38      |
| _min_discrew    | 0.02       |
| _min_obs        | -1.07      |
| _std_act        | 0.881922   |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 487
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00251263 |
| Phi_loss        | 1824.2     |
| PolicyEntropy   | -1.09289   |
| PolicyLoss      | 0.00585254 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00582    |
| _MeanReward     | 5.06e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44709    |
| _max_adv        | 3.96       |
| _max_discrew    | 5.39       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0344774  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0456     |
| _min_adv        | -9.75      |
| _min_discrew    | 0.0186     |
| _min_obs        | -1.07      |
| _std_act        | 0.880282   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 488
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00255001 |
| Phi_loss        | 1998.46    |
| PolicyEntropy   | -1.12569   |
| PolicyLoss      | -0.0208966 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00619    |
| _MeanReward     | 5.07e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.44964    |
| _max_adv        | 4.06       |
| _max_discrew    | 5.34       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0340382  |
| _mean_adv       | -6.25e-17  |
| _mean_discrew   | 4.17       |
| _mean_obs       | 0.0459     |
| _min_adv        | -6.23      |
| _min_discrew    | 0.0135     |
| _min_obs        | -1.06      |
| _std_act        | 0.88205    |
| _std_adv        | 1          |
| _std_discrew    | 1.64       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 489
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00354454 |
| Phi_loss        | 2056.62    |
| PolicyEntropy   | -1.15764   |
| PolicyLoss      | -0.0189274 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00686    |
| _MeanReward     | 5.04e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3697     |
| _max_adv        | 17.9       |
| _max_discrew    | 5.32       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0327827  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.18       |
| _mean_obs       | 0.0453     |
| _min_adv        | -5.27      |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.1       |
| _std_act        | 0.88543    |
| _std_adv        | 1          |
| _std_discrew    | 1.62       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 490
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00265094 |
| Phi_loss        | 2180.19    |
| PolicyEntropy   | -1.19253   |
| PolicyLoss      | -0.0202405 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00499    |
| _MeanReward     | 5.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.51725    |
| _max_adv        | 4.33       |
| _max_discrew    | 5.39       |
| _max_obs        | 1.05       |
| _mean_act       | 0.033877   |
| _mean_adv       | 0          |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.0461     |
| _min_adv        | -8.47      |
| _min_discrew    | 0.0174     |
| _min_obs        | -1.05      |
| _std_act        | 0.892351   |
| _std_adv        | 1          |
| _std_discrew    | 1.65       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 491
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00374031 |
| Phi_loss        | 2165.29    |
| PolicyEntropy   | -1.20368   |
| PolicyLoss      | 0.00442201 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00739    |
| _MeanReward     | 5.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.42673    |
| _max_adv        | 4.99       |
| _max_discrew    | 5.4        |
| _max_obs        | 1.11       |
| _mean_act       | 0.0359921  |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.2        |
| _mean_obs       | 0.0462     |
| _min_adv        | -10.1      |
| _min_discrew    | 0.0224     |
| _min_obs        | -1.09      |
| _std_act        | 0.886935   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 492
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00410965 |
| Phi_loss        | 2103.65    |
| PolicyEntropy   | -1.21402   |
| PolicyLoss      | -0.0106042 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00643    |
| _MeanReward     | 5.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.42523    |
| _max_adv        | 42.7       |
| _max_discrew    | 5.4        |
| _max_obs        | 1.12       |
| _mean_act       | 0.0337372  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.046      |
| _min_adv        | -8.28      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.07      |
| _std_act        | 0.889544   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 493
Draw Samples..
--------------------------------
| Beta            | 0.0964     |
| ExplainedVarNew | 0.998      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00267974 |
| Phi_loss        | 1609.69    |
| PolicyEntropy   | -1.23477   |
| PolicyLoss      | 0.009368   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00418    |
| _MeanReward     | 5.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32268    |
| _max_adv        | 5.22       |
| _max_discrew    | 5.4        |
| _max_obs        | 1.16       |
| _mean_act       | 0.0352286  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.2        |
| _mean_obs       | 0.046      |
| _min_adv        | -11.2      |
| _min_discrew    | 0.0199     |
| _min_obs        | -1.07      |
| _std_act        | 0.890099   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 494
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.996       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00425324  |
| Phi_loss        | 2082.88     |
| PolicyEntropy   | -1.26711    |
| PolicyLoss      | -0.00860491 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00603     |
| _MeanReward     | 4.61e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51552     |
| _max_adv        | 6.08        |
| _max_discrew    | 5.33        |
| _max_obs        | 1.05        |
| _mean_act       | 0.00492435  |
| _mean_adv       | 5.68e-18    |
| _mean_discrew   | 3.78        |
| _mean_obs       | 0.0436      |
| _min_adv        | -15.2       |
| _min_discrew    | -1.13       |
| _min_obs        | -1.05       |
| _std_act        | 0.932234    |
| _std_adv        | 1           |
| _std_discrew    | 3.12        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 495
Draw Samples..
-------------------------------
| Beta            | 0.0964    |
| ExplainedVarNew | 0.927     |
| ExplainedVarOld | 0.852     |
| KL              | 0.0044435 |
| Phi_loss        | 1498.67   |
| PolicyEntropy   | -1.2658   |
| PolicyLoss      | 0.0328214 |
| Steps           | 10000     |
| VarFuncLoss     | 0.229     |
| _MeanReward     | 5.1e+03   |
| _lr_multiplier  | 1         |
| _max_act        | 2.29984   |
| _max_adv        | 20.5      |
| _max_discrew    | 5.31      |
| _max_obs        | 1.1       |
| _mean_act       | 0.0323212 |
| _mean_adv       | 1.42e-17  |
| _mean_discrew   | 4.2       |
| _mean_obs       | 0.0457    |
| _min_adv        | -3.22     |
| _min_discrew    | 0.0183    |
| _min_obs        | -1.11     |
| _std_act        | 0.893417  |
| _std_adv        | 1         |
| _std_discrew    | 1.66      |
-------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 496
Draw Samples..
---------------------------------
| Beta            | 0.0964      |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00340704  |
| Phi_loss        | 1599.36     |
| PolicyEntropy   | -1.26967    |
| PolicyLoss      | -0.00804051 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00858     |
| _MeanReward     | 4.83e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.79739     |
| _max_adv        | 3.29        |
| _max_discrew    | 5.36        |
| _max_obs        | 1.79        |
| _mean_act       | 0.00705755  |
| _mean_adv       | -1.28e-17   |
| _mean_discrew   | 3.94        |
| _mean_obs       | 0.0447      |
| _min_adv        | -20.6       |
| _min_discrew    | -1.53       |
| _min_obs        | -1.25       |
| _std_act        | 0.951079    |
| _std_adv        | 1           |
| _std_discrew    | 2.85        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 497
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.885       |
| ExplainedVarOld | 0.876       |
| KL              | 0.0110171   |
| Phi_loss        | 2103.51     |
| PolicyEntropy   | -1.23907    |
| PolicyLoss      | 0.0369193   |
| Steps           | 10000       |
| VarFuncLoss     | 0.328       |
| _MeanReward     | 4.49e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.55545     |
| _max_adv        | 1.92        |
| _max_discrew    | 5.39        |
| _max_obs        | 1.06        |
| _mean_act       | -0.00295354 |
| _mean_adv       | 1.71e-17    |
| _mean_discrew   | 3.7         |
| _mean_obs       | 0.0431      |
| _min_adv        | -25.3       |
| _min_discrew    | -1.18       |
| _min_obs        | -0.998      |
| _std_act        | 0.943636    |
| _std_adv        | 1           |
| _std_discrew    | 3.88        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 498
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.986      |
| ExplainedVarOld | 0.964      |
| KL              | 0.00391753 |
| Phi_loss        | 1752.54    |
| PolicyEntropy   | -1.23188   |
| PolicyLoss      | 0.0498459  |
| Steps           | 10000      |
| VarFuncLoss     | 0.058      |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31979    |
| _max_adv        | 46         |
| _max_discrew    | 5.42       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0314175  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0458     |
| _min_adv        | -7.45      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.06      |
| _std_act        | 0.897139   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 499
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.989      |
| KL              | 0.00173123 |
| Phi_loss        | 1558.45    |
| PolicyEntropy   | -1.24358   |
| PolicyLoss      | 0.0232585  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00972    |
| _MeanReward     | 5.09e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35624    |
| _max_adv        | 25         |
| _max_discrew    | 5.39       |
| _max_obs        | 1.25       |
| _mean_act       | 0.0337384  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 4.2        |
| _mean_obs       | 0.0456     |
| _min_adv        | -4.3       |
| _min_discrew    | 0.0157     |
| _min_obs        | -1.09      |
| _std_act        | 0.886087   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 500
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00247947 |
| Phi_loss        | 1436.97    |
| PolicyEntropy   | -1.27573   |
| PolicyLoss      | 0.0226967  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00676    |
| _MeanReward     | 5e+03      |
| _lr_multiplier  | 1          |
| _max_act        | 2.369      |
| _max_adv        | 5.36       |
| _max_discrew    | 5.4        |
| _max_obs        | 1.1        |
| _mean_act       | 0.0278547  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.1        |
| _mean_obs       | 0.0455     |
| _min_adv        | -20.1      |
| _min_discrew    | -0.614     |
| _min_obs        | -1.02      |
| _std_act        | 0.893443   |
| _std_adv        | 1          |
| _std_discrew    | 2.06       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 501
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.941      |
| ExplainedVarOld | 0.937      |
| KL              | 0.00205736 |
| Phi_loss        | 2307.02    |
| PolicyEntropy   | -1.29145   |
| PolicyLoss      | 0.0118414  |
| Steps           | 10000      |
| VarFuncLoss     | 0.122      |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3408     |
| _max_adv        | 5.75       |
| _max_discrew    | 5.3        |
| _max_obs        | 1.03       |
| _mean_act       | 0.0324068  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0457     |
| _min_adv        | -6.79      |
| _min_discrew    | 0.0153     |
| _min_obs        | -1.02      |
| _std_act        | 0.888737   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 502
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00306795 |
| Phi_loss        | 1981.52    |
| PolicyEntropy   | -1.30665   |
| PolicyLoss      | -0.023626  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00999    |
| _MeanReward     | 5.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.46349    |
| _max_adv        | 29         |
| _max_discrew    | 5.52       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0350217  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0458     |
| _min_adv        | -3.63      |
| _min_discrew    | 0.0173     |
| _min_obs        | -1.08      |
| _std_act        | 0.891044   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 503
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.994      |
| KL              | 0.0039376  |
| Phi_loss        | 1967.22    |
| PolicyEntropy   | -1.30966   |
| PolicyLoss      | -0.0199778 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00603    |
| _MeanReward     | 5.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43712    |
| _max_adv        | 6.04       |
| _max_discrew    | 5.43       |
| _max_obs        | 1.25       |
| _mean_act       | 0.0313731  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0456     |
| _min_adv        | -6.96      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.23      |
| _std_act        | 0.886445   |
| _std_adv        | 1          |
| _std_discrew    | 1.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 504
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00553462 |
| Phi_loss        | 2312.7     |
| PolicyEntropy   | -1.32664   |
| PolicyLoss      | 0.00126746 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00643    |
| _MeanReward     | 5.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.79203    |
| _max_adv        | 8.67       |
| _max_discrew    | 5.47       |
| _max_obs        | 1.13       |
| _mean_act       | 0.0317787  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.25       |
| _mean_obs       | 0.046      |
| _min_adv        | -6.81      |
| _min_discrew    | 0.022      |
| _min_obs        | -1.04      |
| _std_act        | 0.887294   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 505
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00296635 |
| Phi_loss        | 2352.52    |
| PolicyEntropy   | -1.33597   |
| PolicyLoss      | -0.0267948 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00504    |
| _MeanReward     | 5.1e+03    |
| _lr_multiplier  | 1          |
| _max_act        | 2.39281    |
| _max_adv        | 8.36       |
| _max_discrew    | 5.34       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0364813  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.046      |
| _min_adv        | -6.14      |
| _min_discrew    | 0.0197     |
| _min_obs        | -0.958     |
| _std_act        | 0.890859   |
| _std_adv        | 1          |
| _std_discrew    | 1.63       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 506
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.0035706  |
| Phi_loss        | 2254.98    |
| PolicyEntropy   | -1.34223   |
| PolicyLoss      | 0.0209593  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00823    |
| _MeanReward     | 4.64e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70878    |
| _max_adv        | 12.3       |
| _max_discrew    | 5.44       |
| _max_obs        | 1.1        |
| _mean_act       | 0.00656929 |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 3.85       |
| _mean_obs       | 0.0435     |
| _min_adv        | -21.4      |
| _min_discrew    | -1.05      |
| _min_obs        | -1.08      |
| _std_act        | 0.932451   |
| _std_adv        | 1          |
| _std_discrew    | 3.03       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 507
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.985       |
| ExplainedVarOld | 0.946       |
| KL              | 0.00159464  |
| Phi_loss        | 1076.13     |
| PolicyEntropy   | -1.34852    |
| PolicyLoss      | -0.00389471 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0462      |
| _MeanReward     | 5.11e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.46759     |
| _max_adv        | 41.2        |
| _max_discrew    | 5.38        |
| _max_obs        | 1.06        |
| _mean_act       | 0.0328403   |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 4.22        |
| _mean_obs       | 0.0456      |
| _min_adv        | -4.24       |
| _min_discrew    | 0.0166      |
| _min_obs        | -0.994      |
| _std_act        | 0.892927    |
| _std_adv        | 1           |
| _std_discrew    | 1.66        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 508
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.995      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00341517 |
| Phi_loss        | 1794.94    |
| PolicyEntropy   | -1.37441   |
| PolicyLoss      | -0.008267  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00913    |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.70314    |
| _max_adv        | 26.1       |
| _max_discrew    | 5.43       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0293271  |
| _mean_adv       | -2.84e-18  |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0456     |
| _min_adv        | -4.91      |
| _min_discrew    | 0.0197     |
| _min_obs        | -1.01      |
| _std_act        | 0.892594   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 509
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.995      |
| KL              | 0.00268362 |
| Phi_loss        | 1924.22    |
| PolicyEntropy   | -1.38325   |
| PolicyLoss      | -0.0168255 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00671    |
| _MeanReward     | 5.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.51175    |
| _max_adv        | 9.61       |
| _max_discrew    | 5.41       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0327688  |
| _mean_adv       | -9.24e-18  |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0458     |
| _min_adv        | -8.69      |
| _min_discrew    | 0.0202     |
| _min_obs        | -1.01      |
| _std_act        | 0.898332   |
| _std_adv        | 1          |
| _std_discrew    | 1.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 510
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00397465 |
| Phi_loss        | 2388.86    |
| PolicyEntropy   | -1.39455   |
| PolicyLoss      | -0.0169373 |
| Steps           | 10000      |
| VarFuncLoss     | 0.0061     |
| _MeanReward     | 5.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.29755    |
| _max_adv        | 6.34       |
| _max_discrew    | 5.46       |
| _max_obs        | 1.15       |
| _mean_act       | 0.0315876  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 4.24       |
| _mean_obs       | 0.0462     |
| _min_adv        | -6.16      |
| _min_discrew    | 0.0198     |
| _min_obs        | -1.09      |
| _std_act        | 0.901111   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 511
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00208796 |
| Phi_loss        | 2405.62    |
| PolicyEntropy   | -1.40444   |
| PolicyLoss      | 0.012926   |
| Steps           | 10000      |
| VarFuncLoss     | 0.00672    |
| _MeanReward     | 5.14e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45256    |
| _max_adv        | 55.4       |
| _max_discrew    | 5.45       |
| _max_obs        | 1.09       |
| _mean_act       | 0.0344293  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.046      |
| _min_adv        | -3.18      |
| _min_discrew    | 0.0172     |
| _min_obs        | -1         |
| _std_act        | 0.896295   |
| _std_adv        | 1          |
| _std_discrew    | 1.7        |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 512
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00239292 |
| Phi_loss        | 1788.0     |
| PolicyEntropy   | -1.41755   |
| PolicyLoss      | 0.0203605  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00573    |
| _MeanReward     | 5.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.284      |
| _max_adv        | 4.48       |
| _max_discrew    | 5.41       |
| _max_obs        | 1.15       |
| _mean_act       | 0.027984   |
| _mean_adv       | -1.14e-17  |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0456     |
| _min_adv        | -6.57      |
| _min_discrew    | 0.017      |
| _min_obs        | -0.987     |
| _std_act        | 0.897807   |
| _std_adv        | 1          |
| _std_discrew    | 1.71       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 513
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00333428 |
| Phi_loss        | 2492.12    |
| PolicyEntropy   | -1.42489   |
| PolicyLoss      | 0.0245526  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00716    |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.34586    |
| _max_adv        | 15.3       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.2        |
| _mean_act       | 0.0308649  |
| _mean_adv       | -2.56e-17  |
| _mean_discrew   | 4.21       |
| _mean_obs       | 0.0456     |
| _min_adv        | -7.5       |
| _min_discrew    | 0.0177     |
| _min_obs        | -1.09      |
| _std_act        | 0.89327    |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 514
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00213572 |
| Phi_loss        | 2480.27    |
| PolicyEntropy   | -1.4341    |
| PolicyLoss      | -0.0237184 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00557    |
| _MeanReward     | 5.12e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35099    |
| _max_adv        | 5.29       |
| _max_discrew    | 5.44       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0318715  |
| _mean_adv       | 3.41e-17   |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0454     |
| _min_adv        | -6.17      |
| _min_discrew    | 0.0221     |
| _min_obs        | -1.06      |
| _std_act        | 0.896657   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 515
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00346879 |
| Phi_loss        | 2471.57    |
| PolicyEntropy   | -1.44465   |
| PolicyLoss      | 0.0111281  |
| Steps           | 10000      |
| VarFuncLoss     | 0.00702    |
| _MeanReward     | 5.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.38472    |
| _max_adv        | 8.08       |
| _max_discrew    | 5.45       |
| _max_obs        | 1.11       |
| _mean_act       | 0.0295778  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 4.26       |
| _mean_obs       | 0.0458     |
| _min_adv        | -8.93      |
| _min_discrew    | 0.0191     |
| _min_obs        | -0.997     |
| _std_act        | 0.88831    |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 516
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.997       |
| KL              | 0.00365584  |
| Phi_loss        | 2441.92     |
| PolicyEntropy   | -1.45343    |
| PolicyLoss      | -0.00638662 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00589     |
| _MeanReward     | 4.84e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.38668     |
| _max_adv        | 3.45        |
| _max_discrew    | 5.51        |
| _max_obs        | 1.12        |
| _mean_act       | 0.00819548  |
| _mean_adv       | 1.14e-17    |
| _mean_discrew   | 3.93        |
| _mean_obs       | 0.044       |
| _min_adv        | -17.9       |
| _min_discrew    | -1.1        |
| _min_obs        | -0.989      |
| _std_act        | 0.921796    |
| _std_adv        | 1           |
| _std_discrew    | 2.95        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 517
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.896      |
| ExplainedVarOld | 0.837      |
| KL              | 0.00835291 |
| Phi_loss        | 2255.67    |
| PolicyEntropy   | -1.45149   |
| PolicyLoss      | -0.0239461 |
| Steps           | 10000      |
| VarFuncLoss     | 0.309      |
| _MeanReward     | 5.13e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.54191    |
| _max_adv        | 19.1       |
| _max_discrew    | 5.41       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0273839  |
| _mean_adv       | 2.27e-17   |
| _mean_discrew   | 4.23       |
| _mean_obs       | 0.0454     |
| _min_adv        | -4.43      |
| _min_discrew    | 0.0215     |
| _min_obs        | -1.02      |
| _std_act        | 0.898009   |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 518
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00208036  |
| Phi_loss        | 2926.6      |
| PolicyEntropy   | -1.45862    |
| PolicyLoss      | -0.00941086 |
| Steps           | 10000       |
| VarFuncLoss     | 0.0098      |
| _MeanReward     | 5.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.39241     |
| _max_adv        | 17.2        |
| _max_discrew    | 5.51        |
| _max_obs        | 1.07        |
| _mean_act       | 0.0285724   |
| _mean_adv       | -1.42e-17   |
| _mean_discrew   | 4.27        |
| _mean_obs       | 0.046       |
| _min_adv        | -5.37       |
| _min_discrew    | 0.0188      |
| _min_obs        | -1.03       |
| _std_act        | 0.894377    |
| _std_adv        | 1           |
| _std_discrew    | 1.71        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 519
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00254181 |
| Phi_loss        | 2051.12    |
| PolicyEntropy   | -1.46411   |
| PolicyLoss      | 0.00413965 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00664    |
| _MeanReward     | 5.11e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39284    |
| _max_adv        | 45.5       |
| _max_discrew    | 5.43       |
| _max_obs        | 1.14       |
| _mean_act       | 0.0277872  |
| _mean_adv       | -5.68e-18  |
| _mean_discrew   | 4.22       |
| _mean_obs       | 0.0451     |
| _min_adv        | -7.91      |
| _min_discrew    | 0.0224     |
| _min_obs        | -1.07      |
| _std_act        | 0.885921   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 520
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.997       |
| ExplainedVarOld | 0.996       |
| KL              | 0.00224689  |
| Phi_loss        | 2358.95     |
| PolicyEntropy   | -1.47847    |
| PolicyLoss      | -0.00984687 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00609     |
| _MeanReward     | 5.14e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.51961     |
| _max_adv        | 4.4         |
| _max_discrew    | 5.37        |
| _max_obs        | 1.08        |
| _mean_act       | 0.027735    |
| _mean_adv       | 2.56e-17    |
| _mean_discrew   | 4.25        |
| _mean_obs       | 0.0453      |
| _min_adv        | -5.79       |
| _min_discrew    | 0.0157      |
| _min_obs        | -0.988      |
| _std_act        | 0.888179    |
| _std_adv        | 1           |
| _std_discrew    | 1.73        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 521
Draw Samples..
---------------------------------
| Beta            | 0.145       |
| ExplainedVarNew | 0.995       |
| ExplainedVarOld | 0.995       |
| KL              | 0.00148276  |
| Phi_loss        | 2555.31     |
| PolicyEntropy   | -1.4756     |
| PolicyLoss      | -0.00102848 |
| Steps           | 10000       |
| VarFuncLoss     | 0.00912     |
| _MeanReward     | 5.15e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.41914     |
| _max_adv        | 4.94        |
| _max_discrew    | 5.41        |
| _max_obs        | 1.03        |
| _mean_act       | 0.0265746   |
| _mean_adv       | -5.68e-18   |
| _mean_discrew   | 4.25        |
| _mean_obs       | 0.0453      |
| _min_adv        | -3.79       |
| _min_discrew    | 0.0243      |
| _min_obs        | -1.02       |
| _std_act        | 0.89081     |
| _std_adv        | 1           |
| _std_discrew    | 1.7         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 522
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00308321 |
| Phi_loss        | 2727.79    |
| PolicyEntropy   | -1.47674   |
| PolicyLoss      | -0.0287326 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00622    |
| _MeanReward     | 5.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.43164    |
| _max_adv        | 5.81       |
| _max_discrew    | 5.48       |
| _max_obs        | 1.12       |
| _mean_act       | 0.0290819  |
| _mean_adv       | 0          |
| _mean_discrew   | 4.27       |
| _mean_obs       | 0.046      |
| _min_adv        | -4.14      |
| _min_discrew    | 0.0165     |
| _min_obs        | -0.996     |
| _std_act        | 0.904394   |
| _std_adv        | 1          |
| _std_discrew    | 1.68       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 523
Draw Samples..
--------------------------------
| Beta            | 0.145      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00234431 |
| Phi_loss        | 2683.64    |
| PolicyEntropy   | -1.48954   |
| PolicyLoss      | -0.0136629 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00644    |
| _MeanReward     | 4.97e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.82172    |
| _max_adv        | 4.02       |
| _max_discrew    | 5.42       |
| _max_obs        | 1.8        |
| _mean_act       | 0.0126392  |
| _mean_adv       | -2.27e-17  |
| _mean_discrew   | 4.09       |
| _mean_obs       | 0.0444     |
| _min_adv        | -18.6      |
| _min_discrew    | -1.1       |
| _min_obs        | -1.02      |
| _std_act        | 0.935119   |
| _std_adv        | 1          |
| _std_discrew    | 2.33       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 524
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.915       |
| ExplainedVarOld | 0.907       |
| KL              | 0.0125164   |
| Phi_loss        | 2772.2      |
| PolicyEntropy   | -1.47806    |
| PolicyLoss      | -0.193414   |
| Steps           | 10000       |
| VarFuncLoss     | 0.199       |
| _MeanReward     | 4.6e+03     |
| _lr_multiplier  | 1           |
| _max_act        | 2.52566     |
| _max_adv        | 7.28        |
| _max_discrew    | 5.43        |
| _max_obs        | 1.26        |
| _mean_act       | -0.00508238 |
| _mean_adv       | 1.99e-17    |
| _mean_discrew   | 3.75        |
| _mean_obs       | 0.0429      |
| _min_adv        | -20.3       |
| _min_discrew    | -1.2        |
| _min_obs        | -1.04       |
| _std_act        | 0.9551      |
| _std_adv        | 1           |
| _std_discrew    | 3.8         |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 525
Draw Samples..
---------------------------------
| Beta            | 0.217       |
| ExplainedVarNew | 0.932       |
| ExplainedVarOld | 0.927       |
| KL              | 0.00409547  |
| Phi_loss        | 2413.83     |
| PolicyEntropy   | -1.46985    |
| PolicyLoss      | -0.00805903 |
| Steps           | 10000       |
| VarFuncLoss     | 0.259       |
| _MeanReward     | 5.17e+03    |
| _lr_multiplier  | 1           |
| _max_act        | 2.33509     |
| _max_adv        | 10.1        |
| _max_discrew    | 5.45        |
| _max_obs        | 1.21        |
| _mean_act       | 0.0262881   |
| _mean_adv       | 3.13e-17    |
| _mean_discrew   | 4.25        |
| _mean_obs       | 0.0453      |
| _min_adv        | -3.35       |
| _min_discrew    | 0.0183      |
| _min_obs        | -0.985      |
| _std_act        | 0.912064    |
| _std_adv        | 1           |
| _std_discrew    | 1.72        |
---------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 526
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.994      |
| ExplainedVarOld | 0.994      |
| KL              | 0.00250175 |
| Phi_loss        | 1795.93    |
| PolicyEntropy   | -1.49166   |
| PolicyLoss      | 0.0111488  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0108     |
| _MeanReward     | 5.15e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.32372    |
| _max_adv        | 38.6       |
| _max_discrew    | 5.37       |
| _max_obs        | 1.04       |
| _mean_act       | 0.0235336  |
| _mean_adv       | 1.42e-18   |
| _mean_discrew   | 4.24       |
| _mean_obs       | 0.0452     |
| _min_adv        | -5.53      |
| _min_discrew    | 0.0202     |
| _min_obs        | -1.06      |
| _std_act        | 0.904386   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 527
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.993      |
| KL              | 0.00214383 |
| Phi_loss        | 1952.45    |
| PolicyEntropy   | -1.51642   |
| PolicyLoss      | -0.0101211 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00657    |
| _MeanReward     | 5.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37989    |
| _max_adv        | 7.98       |
| _max_discrew    | 5.47       |
| _max_obs        | 1.02       |
| _mean_act       | 0.0236018  |
| _mean_adv       | 1.14e-17   |
| _mean_discrew   | 4.28       |
| _mean_obs       | 0.0453     |
| _min_adv        | -6.91      |
| _min_discrew    | 0.0204     |
| _min_obs        | -1.04      |
| _std_act        | 0.907987   |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 528
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00162693 |
| Phi_loss        | 2468.73    |
| PolicyEntropy   | -1.53559   |
| PolicyLoss      | 0.00353291 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00645    |
| _MeanReward     | 5.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.31136    |
| _max_adv        | 12         |
| _max_discrew    | 5.38       |
| _max_obs        | 1.18       |
| _mean_act       | 0.0248719  |
| _mean_adv       | 5.68e-18   |
| _mean_discrew   | 4.27       |
| _mean_obs       | 0.0453     |
| _min_adv        | -4.74      |
| _min_discrew    | 0.0183     |
| _min_obs        | -1.07      |
| _std_act        | 0.903204   |
| _std_adv        | 1          |
| _std_discrew    | 1.67       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 529
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00176105 |
| Phi_loss        | 2752.78    |
| PolicyEntropy   | -1.55518   |
| PolicyLoss      | 0.00184724 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00549    |
| _MeanReward     | 5.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.45072    |
| _max_adv        | 4.32       |
| _max_discrew    | 5.56       |
| _max_obs        | 1.16       |
| _mean_act       | 0.0256737  |
| _mean_adv       | 2.84e-18   |
| _mean_discrew   | 4.27       |
| _mean_obs       | 0.0458     |
| _min_adv        | -6.67      |
| _min_discrew    | 0.0163     |
| _min_obs        | -1.04      |
| _std_act        | 0.904877   |
| _std_adv        | 1          |
| _std_discrew    | 1.77       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 530
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00165718 |
| Phi_loss        | 2656.68    |
| PolicyEntropy   | -1.56506   |
| PolicyLoss      | -0.0115614 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00677    |
| _MeanReward     | 5.17e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.39206    |
| _max_adv        | 26.9       |
| _max_discrew    | 5.46       |
| _max_obs        | 1.21       |
| _mean_act       | 0.0267363  |
| _mean_adv       | -1.42e-17  |
| _mean_discrew   | 4.26       |
| _mean_obs       | 0.0455     |
| _min_adv        | -3.5       |
| _min_discrew    | 0.023      |
| _min_obs        | -0.985     |
| _std_act        | 0.906185   |
| _std_adv        | 1          |
| _std_discrew    | 1.73       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 531
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00213065 |
| Phi_loss        | 2716.88    |
| PolicyEntropy   | -1.57726   |
| PolicyLoss      | -0.0310417 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00598    |
| _MeanReward     | 5.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.35768    |
| _max_adv        | 4.36       |
| _max_discrew    | 5.36       |
| _max_obs        | 1.01       |
| _mean_act       | 0.0278646  |
| _mean_adv       | 1.71e-17   |
| _mean_discrew   | 4.26       |
| _mean_obs       | 0.0455     |
| _min_adv        | -6.33      |
| _min_discrew    | 0.0164     |
| _min_obs        | -1.03      |
| _std_act        | 0.90525    |
| _std_adv        | 1          |
| _std_discrew    | 1.66       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 532
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.996      |
| ExplainedVarOld | 0.996      |
| KL              | 0.00157007 |
| Phi_loss        | 2660.21    |
| PolicyEntropy   | -1.58448   |
| PolicyLoss      | -0.0108892 |
| Steps           | 10000      |
| VarFuncLoss     | 0.00602    |
| _MeanReward     | 5.16e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.37427    |
| _max_adv        | 13.8       |
| _max_discrew    | 5.43       |
| _max_obs        | 1.3        |
| _mean_act       | 0.0249367  |
| _mean_adv       | 2.56e-17   |
| _mean_discrew   | 4.27       |
| _mean_obs       | 0.0455     |
| _min_adv        | -11.7      |
| _min_discrew    | 0.0167     |
| _min_obs        | -1.04      |
| _std_act        | 0.908047   |
| _std_adv        | 1          |
| _std_discrew    | 1.69       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
--------------------------------


#Training Iter 533
Draw Samples..
--------------------------------
| Beta            | 0.217      |
| ExplainedVarNew | 0.997      |
| ExplainedVarOld | 0.997      |
| KL              | 0.00213764 |
| Phi_loss        | 2505.31    |
| PolicyEntropy   | -1.60775   |
| PolicyLoss      | 0.0276852  |
| Steps           | 10000      |
| VarFuncLoss     | 0.0053     |
| _MeanReward     | 5.18e+03   |
| _lr_multiplier  | 1          |
| _max_act        | 2.3165     |
| _max_adv        | 7.93       |
| _max_discrew    | 5.58       |
| _max_obs        | 1.03       |
| _mean_act       | 0.0268646  |
| _mean_adv       | 1.42e-17   |
| _mean_discrew   | 4.28       |
| _mean_obs       | 0.0459     |
| _min_adv        | -4.55      |
| _min_discrew    | 0.015      |
| _min_obs        | -1.08      |
| _std_act        | 0.913017   |
| _std_adv        | 1          |
| _std_discrew    | 1.72       |
--------------------------------
Starting Training...
Training Policy for 20 epochs
Training Phi for 500 epochs
